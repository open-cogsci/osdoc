{
  "Download": {
    "fr": "Télécharger",
    "de": "Herunterladen"
  },
  "<script>\nfunction startDownload(url) {\n\tdocument.getElementById('click-here').href = url\n\twindow.location.href = url\n\tdocument.getElementById('download-started').style.display = 'block'\n\tdocument.getElementById('download-started').scrollIntoView()\n}\n</script>\n\n<div class=\"info-box\" id=\"download-started\" markdown=\"1\" style=\"display:none;\">\n\n<h3>Your download should start shortly!</h3>\n\n<a role=\"button\" class=\"btn btn-success btn-align-left\" href=\"https://www.buymeacoffee.com/cogsci\">\n<span class=\"glyphicon glyphicon-heart\" aria-hidden=\"true\"></span>\nHelp us stay focused and buy us a coffee!\n</a>\n\nCoffee keeps us awake so that we can develop free software and answer your questions on the support forum!\n\nClick <a id=\"click-here\">here</a> if your download doesn't start.\n</div>\n\n\n## Overview\n\n<notranslate>\ntoc:\n exclude: [Overview]\n mindepth: 2\n maxdepth: 3\n</notranslate>\n\n\n## All download options\n\nThe latest $status$ version is $version$ *$codename$*, released on $release-date$ ([release notes](http://osdoc.cogsci.nl/$branch$/notes/$notes$)).\n\n\n### Windows\n\nThe Windows package is based on Python 3.11 for 64 bit systems. The installer and `.zip` packages are identical, except for the installation. Most people download the installer package (green button).\n\n<a role=\"button\" class=\"btn btn-success btn-align-left\" onclick=\"startDownload('$url-windows-exe-py3$')\">\n\t<b>Standard</b> Windows installer (.exe)\n</a>\n\n<a role=\"button\" class=\"btn btn-default btn-align-left\" onclick=\"startDownload('$url-windows-zip-py3$')\">\n\t<b>Standard</b> Windows no installation required (.zip)\n</a>\n\n\n### Mac OS\n\nThere are currently no prerelease packages of OpenSesame 4.0 for Mac OS. Please use conda or pip.\n{: .page-notification}\n\n[This article](https://support.apple.com/en-in/guide/mac-help/mh40616/mac) on the Mac OS support site explains how to override the security settings of Mac OS that will by default prevent OpenSesame from launching.\n\nThe package below is built for Intel processors but also runs on ARM (M1) processors.\n\n<a role=\"button\" class=\"btn btn-default btn-align-left\" onclick=\"startDownload('$url-osx-dmg-x64-py3$')\">\n\t<b>Python 3 for Intel x64</b> Mac OS package (.dmg)\n</a>\n\nTo install OpenSesame with [Homebrew](https://brew.sh/), run the following command in a terminal:\n\n```bash\nbrew install --cask opensesame\n```\n\n\n### Ubuntu\n\nPackages are developed and tested on Ubuntu 22.04 Jammy Jellyfish. Packages are only available for 22.04 and 22.10.\n\nIf you have OpenSesame 3.X installed, first deinstall all packages . This is required to avoid package conflicts due to slight renaming of some packages in OpenSesame 4.0.\n\n```bash\n# If necessary: uninstall OpenSesame 3.X\nsudo apt remove python3-opensesame python3-pyqode.python python3-pyqode.core python3-rapunzel python3-opensesame-extension* python3-opensesame-plugin*\n```\n\nNext, to add the required repositories to your software sources and install OpenSesame (and Rapunzel), run the following commands in a terminal:\n\n```bash\n# Add repository for stable packages\nsudo add-apt-repository ppa:smathot/cogscinl\n# Add repository for development packages\nsudo add-apt-repository ppa:smathot/milgram\n# Install OpenSesame 4.X packages plus useful extensions\nsudo apt install python3-opensesame python3-rapunzel python3-opensesame-extension-updater python3-pygaze python3-pygame python3-opensesame-extension-language_server\n```\n\nSome commonly used packages are not available through the PPA. You can install them through `pip`:\n\n```bash\n# Install optional packages that are only available through pip\npip install opensesame-extension-osweb opensesame-plugin-psychopy opensesame-plugin-media_player_mpy http://files.cogsci.nl/expyriment-0.10.0+opensesame2-py3-none-any.whl\n```\n\nPsychoPy is best installed through pip, because the Ubuntu package is currently broken. \n\n```bash\n# Install psychopy\npip install psychopy psychopy_sounddevice python-bidi arabic_reshaper\n```\n\n\n### PyPi (crossplatform)": {
    "fr": "<script>\nfunction startDownload(url) {\n\tdocument.getElementById('click-here').href = url\n\twindow.location.href = url\n\tdocument.getElementById('download-started').style.display = 'block'\n\tdocument.getElementById('download-started').scrollIntoView()\n}\n</script>\n\n<div class=\"info-box\" id=\"download-started\" markdown=\"1\" style=\"display:none;\">\n\n<h3>Votre téléchargement devrait commencer sous peu !</h3>\n\n<a role=\"button\" class=\"btn btn-success btn-align-left\" href=\"https://www.buymeacoffee.com/cogsci\">\n<span class=\"glyphicon glyphicon-heart\" aria-hidden=\"true\"></span>\nAidez-nous à rester concentrés et offrez-nous un café !\n</a>\n\nLe café nous permet de rester éveillés pour développer des logiciels gratuits et répondre à vos questions sur le forum d'assistance !\n\nCliquez <a id=\"click-here\">ici</a> si votre téléchargement ne démarre pas.\n</div>\n\n\n## Aperçu\n\n<notranslate>\ntoc:\n exclude: [Aperçu]\n mindepth: 2\n maxdepth: 3\n</notranslate>\n\n\n## Toutes les options de téléchargement\n\nLa dernière version $status$ est $version$ *$codename$*, sortie le $release-date$ ([notes de version](http://osdoc.cogsci.nl/$branch$/notes/$notes$)).\n\n\n### Windows\n\nLe package Windows est basé sur Python 3.11 pour les systèmes 64 bits. Les packages d'installation et `.zip` sont identiques, à l'exception de l'installation. La plupart des gens téléchargent le package d'installation (bouton vert).\n\n<a role=\"button\" class=\"btn btn-success btn-align-left\" onclick=\"startDownload('$url-windows-exe-py3$')\">\n\t<b>Standard</b> Installateur Windows (.exe)\n</a>\n\n<a role=\"button\" class=\"btn btn-default btn-align-left\" onclick=\"startDownload('$url-windows-zip-py3$')\">\n\t<b>Standard</b> Windows sans installation requise (.zip)\n</a>\n\n\n### Mac OS\n\nIl n'y a actuellement pas de packages de pré-version d'OpenSesame 4.0 pour Mac OS. Veuillez utiliser conda ou pip.\n{: .page-notification}\n\n[Cet article](https://support.apple.com/fr-fr/guide/mac-help/mh40616/mac) sur le site d'assistance Mac OS explique comment contourner les paramètres de sécurité de Mac OS qui empêchent par défaut le lancement d'OpenSesame.\n\nLe package ci-dessous est conçu pour les processeurs Intel mais fonctionne également sur les processeurs ARM (M1).\n\n<a role=\"button\" class=\"btn btn-default btn-align-left\" onclick=\"startDownload('$url-osx-dmg-x64-py3$')\">\n\t<b>Python 3 pour Intel x64</b> Package Mac OS (.dmg)\n</a>\n\nPour installer OpenSesame avec [Homebrew](https://brew.sh/), exécutez la commande suivante dans un terminal :\n\n```bash\nbrew install --cask opensesame\n```\n\n\n### Ubuntu\n\nLes packages sont développés et testés sur Ubuntu 22.04 Jammy Jellyfish. Les packages sont uniquement disponibles pour les versions 22.04 et 22.10.\n\nSi vous avez OpenSesame 3.X installé, désinstallez d'abord tous les packages. Ceci est nécessaire pour éviter les conflits de packages dus à un léger renommage de certains packages dans OpenSesame 4.0.\n\n```bash\n# Si nécessaire : désinstaller OpenSesame 3.X\nsudo apt remove python3-opensesame python3-pyqode.python python3-pyqode.core python3-rapunzel python3-opensesame-extension* python3-opensesame-plugin*\n```\n\nEnsuite, pour ajouter les dépôts nécessaires à vos sources de logiciels et installer OpenSesame (et Rapunzel), exécutez les commandes suivantes dans un terminal :\n\n```bash\n# Ajouter le dépôt pour les packages stables\nsudo add-apt-repository ppa:smathot/cogscinl\n# Ajouter le dépôt pour les packages de développement\nsudo add-apt-repository ppa:smathot/milgram\n# Installer les packages OpenSesame 4.X ainsi que les extensions utiles\nsudo apt install python3-opensesame python3-rapunzel python3-opensesame-extension-updater python3-pygaze python3-pygame python3-opensesame-extension-language_server\n```\n\nCertains packages couramment utilisés ne sont pas disponibles via le PPA. Vous pouvez les installer via `pip` :\n\n```bash\n# Installer les packages optionnels qui sont uniquement disponibles via pip\npip install opensesame-extension-osweb opensesame-plugin-psychopy opensesame-plugin-media_player_mpy http://files.cogsci.nl/expyriment-0.10.0+opensesame2-py3-none-any.whl\n```\n\nPsychoPy est préférablement installé via pip, car le package Ubuntu est actuellement défectueux. \n\n```bash\n# Installer psychopy\npip install psychopy psychopy_sounddevice python-bidi arabic_reshaper\n```\n\n\n### PyPi (multiplateforme)"
  },
  "All packages can be pip-installed. Note that OpenSesame is called `opensesame-core` on PyPi.\n\n```bash\npip install --pre opensesame-core rapunzel opensesame-extension-osweb opensesame-extension-updater opensesame-plugin-psychopy opensesame-plugin-media_player_mpy\npip install psychopy psychopy_sounddevice pygame http://files.cogsci.nl/expyriment-0.10.0+opensesame2-py3-none-any.whl https://github.com/smathot/PyGaze/releases/download/prerelease%2F0.8.0a3/python_pygaze-0.8.0a3-py3-none-any.whl\n```\n\nOnce you have installed all packages, you can simply run OpenSesame by (after having activated the correct environment) running:\n\n```bash\nopensesame\n```\n\nOr for the Rapunzel code editor:\n\n```bash\nrapunzel\n```\n\n\n### Anaconda (cross-platform)\n\nFirst, create a new Python environment for OpenSesame (optional):\n\n```bash\nconda create -n opensesame-py3\nconda activate opensesame-py3\n```\n\nNext, add the relevant channels (`cogsci`) and (`conda-forge`) and install all relevant packages. Make sure that `pyqode.core` and `pyqode.python` are >= 3.2 from the `cogsci` channel, and not the older versions from the `conda-forge` channel.\n\n```bash\nconda config --add channels conda-forge --add channels cogsci\nconda install opensesame opensesame-extension-osweb opensesame-extension-updater opensesame-plugin-psychopy rapunzel pygaze\n```\n\nSome packages are not available through conda. You can use `pip install` for these.\n\n```bash\npip install soundfile pygame psychopy psychopy-sounddevice http://files.cogsci.nl/expyriment-0.10.0+opensesame2-py3-none-any.whl\n```\n\nOnce you have installed all packages, you can simply run OpenSesame by (after having activated the correct environment) running:\n\n```bash\nopensesame\n```\n\nOr for the Rapunzel code editor:\n\n```bash\nrapunzel\n```\n\n\n### Older versions\n\nOlder versions can be downloaded from GitHub releases:\n\n- <https://github.com/open-cogsci/OpenSesame/releases>\n\n\n### Source code\n\nThe source code of OpenSesame is available on [GitHub](https://github.com/open-cogsci/OpenSesame).\n\n\n## Tips\n\n\n### Which version of Python to use?\n\nOpenSesame is currently built and tested with Python 3.11.0. Others versions of Python >=3.7 work but are not extensively tested. Python 2 is no longer supported. The last release that included a Python 2 package was 3.3.12, which can still be downloaded from the [release archive](https://github.com/open-cogsci/OpenSesame/releases/tag/release%2F3.3.12).\n\n\n### When (not) to update?\n\n- Update while developing and testing your experiment; it is always best to use the latest version of OpenSesame.\n- Do not update while running an experiment; that is, do not update while you are collecting data.\n- Run an experiment with the same version of OpenSesame that you used for developing and testing.\n\n\n### Manually upgrading packages\n\nOpenSesame is a regular Python environment, and you can upgrade packages with `pip` or `conda` as described here:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>\n\n\n### Tips for system administrators\n\n- When a new major version of OpenSesame is released (with a version ending in 0, e.g. 3.1.0), it is generally followed quickly by one or two maintenance releases (e.g. 3.1.1 and 3.1.2) that address major bugs. Therefore, if you are installing OpenSesame on systems that you do not update often, it is best to wait until the second or third maintenance release (e.g. 3.0.2, 3.1.3, etc.). That way you minimize the risk of rolling out a version of OpenSesame that contains major bugs.\n- The Windows installer allows you to silently install OpenSesame using the `/S` flag.\n": {
    "fr": "Tous les packages peuvent être installés avec pip. Notez qu'OpenSesame s'appelle `opensesame-core` sur PyPi.\n\n```bash\npip install --pre opensesame-core rapunzel opensesame-extension-osweb opensesame-extension-updater opensesame-plugin-psychopy opensesame-plugin-media_player_mpy\npip install psychopy psychopy_sounddevice pygame http://files.cogsci.nl/expyriment-0.10.0+opensesame2-py3-none-any.whl https://github.com/smathot/PyGaze/releases/download/prerelease%2F0.8.0a3/python_pygaze-0.8.0a3-py3-none-any.whl\n```\n\nUne fois que vous avez installé tous les packages, vous pouvez simplement exécuter OpenSesame en (après avoir activé le bon environnement) exécutant :\n\n```bash\nopensesame\n```\n\nOu pour l'éditeur de code Rapunzel :\n\n```bash\nrapunzel\n```\n\n\n### Anaconda (multiplateforme)\n\nD'abord, créez un nouvel environnement Python pour OpenSesame (facultatif) :\n\n```bash\nconda create -n opensesame-py3\nconda activate opensesame-py3\n```\n\nEnsuite, ajoutez les canaux pertinents (`cogsci`) et (`conda-forge`) et installez tous les packages pertinents. Assurez-vous que `pyqode.core` et `pyqode.python` sont >= 3.2 à partir du canal `cogsci`, et non pas les anciennes versions à partir du canal `conda-forge`.\n\n```bash\nconda config --add channels conda-forge --add channels cogsci\nconda install opensesame opensesame-extension-osweb opensesame-extension-updater opensesame-plugin-psychopy rapunzel pygaze\n```\n\nCertains packages ne sont pas disponibles via conda. Vous pouvez utiliser `pip install` pour ceux-ci.\n\n```bash\npip install soundfile pygame psychopy psychopy-sounddevice http://files.cogsci.nl/expyriment-0.10.0+opensesame2-py3-none-any.whl\n```\n\nUne fois que vous avez installé tous les packages, vous pouvez simplement exécuter OpenSesame en (après avoir activé le bon environnement) exécutant :\n\n```bash\nopensesame\n```\n\nOu pour l'éditeur de code Rapunzel :\n\n```bash\nrapunzel\n```\n\n\n### Versions antérieures\n\nLes versions antérieures peuvent être téléchargées à partir des versions GitHub :\n\n- <https://github.com/open-cogsci/OpenSesame/releases>\n\n\n### Code source\n\nLe code source d'OpenSesame est disponible sur [GitHub](https://github.com/open-cogsci/OpenSesame).\n\n\n## Astuces\n\n\n### Quelle version de Python utiliser ?\n\nOpenSesame est actuellement construit et testé avec Python 3.11.0. D'autres versions de Python >= 3.7 fonctionnent, mais ne sont pas testées de manière approfondie. Python 2 n'est plus pris en charge. La dernière version qui incluait un package Python 2 était la 3.3.12, qui peut toujours être téléchargée à partir de l'[archive de versions](https://github.com/open-cogsci/OpenSesame/releases/tag/release%2F3.3.12).\n\n\n### Quand (ne pas) mettre à jour ?\n\n- Mettez à jour pendant le développement et les tests de votre expérience ; il est toujours préférable d'utiliser la dernière version d'OpenSesame.\n- Ne mettez pas à jour pendant le déroulement d'une expérience ; c'est-à-dire, ne mettez pas à jour pendant que vous collectez des données.\n- Exécutez une expérience avec la même version d'OpenSesame que celle que vous avez utilisée pour la développer et la tester.\n\n\n### Mise à niveau manuelle des packages\n\nOpenSesame est un environnement Python régulier, et vous pouvez mettre à jour les packages avec `pip` ou `conda` comme décrit ici :\n\n- <https://rapunzel.cogsci.nl/manual/environment/>\n\n\n### Conseils pour les administrateurs système\n\n- Lorsqu'une nouvelle version majeure d'OpenSesame est publiée (avec une version se terminant par 0, par exemple 3.1.0), elle est généralement suivie rapidement par une ou deux versions de maintenance (par exemple 3.1.1 et 3.1.2) qui résolvent les problèmes majeurs. Par conséquent, si vous installez OpenSesame sur des systèmes que vous ne mettez pas à jour souvent, il est préférable d'attendre la deuxième ou la troisième version de maintenance (par exemple 3.0.2, 3.1.3, etc.). Ainsi, vous minimisez le risque de déployer une version d'OpenSesame qui contient des bogues majeurs.\n- L'installateur Windows vous permet d'installer silencieusement OpenSesame en utilisant le flag `/S`."
  },
  "Binus University 2022 workshop": {
    "fr": "Atelier Binus University 2022"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## Practical information\n\n- Host: Binus University\n- Location: online\n- Dates: \n    - Day 1: Friday, April 1st, 2022, 08:00-12:00 CEST, 13:00 - 17:00 Jakarta\n    - Day 2: Wednesday, April 20th, 2022, 08:00-12:00 CEST, 13:00 - 17:00 Jakarta\n    - Day 3: Thursday, April 21st, 2022, 08:00-12:00 CEST, 13:00 - 17:00 Jakarta\n    - Day 4: Wednesday, April 27th, 2022, 08:00-12:00 CEST, 13:00 - 17:00 Jakarta\n- Presenter: Sebastiaan Mathôt\n- [Spreadsheet with participant overview](https://binusianorg.sharepoint.com/sites/WyLab/_layouts/15/guestaccess.aspx?guestaccesstoken=wvSvcpJoabwkk99w%2BuZhpJX58EgC6O4ug%2FgWYbN4H%2BI%3D&docid=2_15f25248401074bb79187e333dcb63088&rev=1&e=iPtB1U)\n\n\n## Description\n\nIn this four-day, hands-on, online workshop, you will learn how to implement psychological experiments with the open-source software OpenSesame. You will learn:\n\n- How to run experiments online as well as in a traditional laboratory set-up.\n- The limitations and advantages of online and laboratory-based experiments.\n- How to include eye tracking in laboratory-based experiments. (And a sneak-peak at eye-tracking in online experiments!)\n- How to analyze data collected from online and laboratory-based experiments.\n\nFinally, using the skills that you will learn during the workshop, you will design and implement an experiment for your own research, of course with assistance from us! For this purpose, please already think about what kind of experiment you'd like to create, and indicate this in the [participant spreadsheet](https://binusianorg.sharepoint.com/sites/WyLab/_layouts/15/guestaccess.aspx?guestaccesstoken=wvSvcpJoabwkk99w%2BuZhpJX58EgC6O4ug%2FgWYbN4H%2BI%3D&docid=2_15f25248401074bb79187e333dcb63088&rev=1&e=iPtB1U). If you're unsure what kind of experiment you'd like to create, take a look a the list of suggested experiments below.\n\nPlease install OpenSesame on your computer before the workshop. You can download OpenSesame for free from <https://osdoc.cogsci.nl/>. No prior experience with OpenSesame, Python, or JavaScript is required.\n\nI’m looking forward to meeting you all!\n\n— Sebastiaan\n\n\n## Day 1: Introduction (April 1)\n\nSlides: %static:attachments/binus2022/binus-day-1.pdf%\n\n- 13:00 – 14:30: __Introduction to OpenSesame__. A general introduction to the software OpenSesame, followed by a hands-on tutorial in which you will learn the basic concepts of the software.\n- Break\n- 15:00 – 16:00: __Introduction to OpenSesame (continued)__.\n- 16:00 – 17:00: __Free time to develop your own experiment__. What kind of experiment would you like to build for your own research? You will draft a design for your own experiment, which you will continue to work on during the rest of the workshop.\n\n\n## Day 2: Online experiments (April 20)\n\nSlides: %static:attachments/binus2022/binus-day-2.pdf%\n\n- 13:00 – 14:30: __Building an online task (cats, dogs, and capybaras)__. We will start this session with a general introduction to online experiments. This is followed by a hands-on tutorial in which you will implement a task that is suitable for running online. The tutorial includes various assignments of different difficulty levels.\n- Break\n- 15:00 – 16:00: __Using <https://mindprobe.eu> (a JATOS server) to run experiments online__. In this session, you will learn how to use mindprobe.eu, which is a free server that runs the open-source software JATOS, to actually run an experiment online. A mindprobe.eu account will be provided to each participant.\n- 16:00 – 17:00: __Free time to develop your own experiment__. During this session, you will continue to work on your own experiment.\n\n\n## Day 3 : Eye-tracking experiments (April 21)\n\nSlides: %static:attachments/binus2022/binus-day-3.pdf%": {
    "fr": "\n<notranslate>[TOC]</notranslate>\n\n\n## Informations pratiques\n\n- Hôte : Université Binus\n- Lieu : en ligne\n- Dates : \n    - Jour 1 : Vendredi 1er avril 2022, 08:00-12:00 CEST, 13:00 - 17:00 Jakarta\n    - Jour 2 : Mercredi 20 avril 2022, 08:00-12:00 CEST, 13:00 - 17:00 Jakarta\n    - Jour 3 : Jeudi 21 avril 2022, 08:00-12:00 CEST, 13:00 - 17:00 Jakarta\n    - Jour 4 : Mercredi 27 avril 2022, 08:00-12:00 CEST, 13:00 - 17:00 Jakarta\n- Présentateur : Sebastiaan Mathôt\n- [Tableur avec vue d'ensemble des participants](https://binusianorg.sharepoint.com/sites/WyLab/_layouts/15/guestaccess.aspx?guestaccesstoken=wvSvcpJoabwkk99w%2BuZhpJX58EgC6O4ug%2FgWYbN4H%2BI%3D&docid=2_15f25248401074bb79187e333dcb63088&rev=1&e=iPtB1U)\n\n\n## Description\n\nDans cet atelier pratique en ligne de quatre jours, vous apprendrez à mettre en œuvre des expériences psychologiques avec le logiciel open-source OpenSesame. Vous apprendrez :\n\n- Comment réaliser des expériences en ligne et dans un cadre de laboratoire traditionnel.\n- Les limitations et les avantages des expériences en ligne et en laboratoire.\n- Comment intégrer le suivi oculaire dans les expériences en laboratoire. (Et un aperçu du suivi oculaire dans les expériences en ligne !)\n- Comment analyser les données collectées lors d'expériences en ligne et en laboratoire.\n\nEnfin, en utilisant les compétences que vous apprendrez lors de l'atelier, vous concevrez et mettrez en œuvre une expérience pour votre propre recherche, bien sûr avec notre aide ! A cet effet, réfléchissez dès maintenant au type d'expérience que vous aimeriez créer et indiquez-le dans le [tableur des participants](https://binusianorg.sharepoint.com/sites/WyLab/_layouts/15/guestaccess.aspx?guestaccesstoken=wvSvcpJoabwkk99w%2BuZhpJX58EgC6O4ug%2FgWYbN4H%2BI%3D&docid=2_15f25248401074bb79187e333dcb63088&rev=1&e=iPtB1U). Si vous ne savez pas quel type d'expérience vous aimeriez créer, consultez la liste des expériences suggérées ci-dessous.\n\nVeuillez installer OpenSesame sur votre ordinateur avant l'atelier. Vous pouvez télécharger OpenSesame gratuitement à partir de <https://osdoc.cogsci.nl/>. Aucune expérience préalable avec OpenSesame, Python ou JavaScript n'est requise.\n\nJ'ai hâte de vous rencontrer tous !\n\n— Sebastiaan\n\n\n## Jour 1 : Introduction (1er avril)\n\nDiapositives: %static:attachments/binus2022/binus-day-1.pdf%\n\n- 13:00 - 14:30 : __Introduction à OpenSesame__. Une introduction générale au logiciel OpenSesame, suivie d'un tutoriel pratique dans lequel vous apprendrez les concepts de base du logiciel.\n- Pause\n- 15:00 - 16:00 : __Introduction à OpenSesame (suite)__.\n- 16:00 - 17:00 : __Temps libre pour développer votre propre expérience__. Quel type d'expérience aimeriez-vous créer pour votre propre recherche ? Vous rédigerez un plan pour votre propre expérience, sur lequel vous continuerez à travailler pendant le reste de l'atelier.\n\n\n## Jour 2 : Expériences en ligne (20 avril)\n\nDiapositives: %static:attachments/binus2022/binus-day-2.pdf%\n\n- 13:00 - 14:30 : __Création d'une tâche en ligne (chats, chiens et capybaras)__. Nous commencerons cette session par une introduction générale aux expériences en ligne. Cela sera suivi d'un tutoriel pratique dans lequel vous mettrez en œuvre une tâche adaptée pour être réalisée en ligne. Le tutoriel comprend divers devoirs de niveaux de difficulté différents.\n- Pause\n- 15:00 - 16:00 : __Utilisation de <https://mindprobe.eu> (un serveur JATOS) pour réaliser des expériences en ligne__. Au cours de cette session, vous apprendrez à utiliser mindprobe.eu, qui est un serveur gratuit fonctionnant avec le logiciel open-source JATOS, pour réaliser réellement une expérience en ligne. Un compte mindprobe.eu sera fourni à chaque participant.\n- 16:00 - 17:00 : __Temps libre pour développer votre propre expérience__. Durant cette session, vous continuerez à travailler sur votre propre expérience.\n\n\n## Jour 3 : Expériences de suivi oculaire (21 avril)\n\nDiapositives: %static:attachments/binus2022/binus-day-3.pdf%"
  },
  "- 13:00 – 14:30: __Building a self-paced reading task with eye-tracking__. We will start this session with a general introduction to eye tracking. This is followed by a hands-on tutorial in which you will implement a self-paced reading task with basic eye tracking. We will focus on using the EyeLink, which is a specific eye tracker. However, concepts and techniques are largely also applicable to other eye trackers. We will also briefly look at eye tracking in online experiment with WebGazer.js.\n- Break\n- 15:00 – 16:00: __Gaze-contingent eye-tracking.__ You will learn how to implement experiments that react to the eye movements of the participant, that is, gaze-contingent experiments.\n- 16:00 – 17:00: __Free time to develop your own experiment.__ During this session, you will continue to work on your own experiment.\n\n\n## Day 4: Data analysis (April 27)\n\nSlides: %static:attachments/binus2022/binus-day-4.pdf%\n\n- 13:00 – 14:30: __Getting data ready for analysis.__ We will start this session with a general explanation of how data is structured, both for experiments that are conducted online and for experiments that are conducted in a traditional laboratory set-up. Next, we will see how to transform this data into a format that lends itself to statistical analysis in the free statistical software JASP. Specifically, we will learn how data from multiple participants can be merged into a single .csv spreadsheet; we will also learn how data from an online experiment can be downloaded from JATOS and converted to a .csv spreadsheet; finally, we will learn how to create a so-called ‘pivot table’, which lends itself to analysis in JASP.\n- Break\n- 15:00 – 16:30: __Conducting a statistical analysis__. We will use the open-source software JASP to perform statistical tests.\n- 16:30 – 17:00: __Q&A__. We will close the workshop with time for questions and remarks.\n\n\n## Suggested experiments\n\nA list of experiments that are easy to implement, with references to papers that contain a clear results section.\n\n- Attention network task (ANT)\n    - Fan, J., McCandliss, B. D., Sommer, T., Raz, A., & Posner, M. I. (2002). Testing the efficiency and independence of attentional networks. *Journal of cognitive neuroscience*, *14*(3), 340-347.\n- Posner cueing task\n    - For a version that focuses specifically on inhibition of return (IOR), see: Klein, R. M. (2000). Inhibition of return. *Trends in cognitive sciences*, *4*(4), 138-147.\n- Implicit association test (IAT)\n    - For a replication study, see Johnson, D. J., Ampofo, D., Erbas, S. A., Robey, A., Calvert, H., Garriques, V., ... & Dougherty, M. (2021). Cognitive Control and the Implicit Association Test: A Replication of Siegel, Dougherty, and Huber (2012). *Collabra: Psychology*, *7*(1), 27356.\n    - See also <https://osdoc.cogsci.nl/3.3/tutorials/iat>\n- Color categorization, a test for the Sapir-Whorf hypothesis. Note that stimulus creation might be challenging\n    - Brown, A. M., Lindsey, D. T., & Guckes, K. M. (2011). Color names, color categories, and color-cued visual search: Sometimes, color perception is not categorical. *Journal of vision*, *11*(12), 2-2.\n- Cognitive reflection task\n    - Sirota, M., & Juanchich, M. (2018). Effect of response format on cognitive reflection: Validating a two-and four-option multiple choice question version of the Cognitive Reflection Test. *Behavior Research Methods*, *50*(6), 2511-2522.\n- Attentional capture task.\n    - Theeuwes, J. (1992). Perceptual selectivity for color and form. *Perception & Psychophysics*, *51*(6), 599–606. <https://doi.org/10.3758/BF03211656>\n- Visual-search task.\n    - Treisman, A. M., & Gelade, G. (1980). A feature-integration theory of attention. *Cognitive Psychology*, *12*(1), 97–136. <https://doi.org/10.1016/0010-0285(80)90005-5>\n    - See also <https://osdoc.cogsci.nl/3.3/tutorials/intermediate-javascript>\n": {
    "fr": "- 13h00 – 14h30 : __Création d'une tâche de lecture auto-rythmée avec eye-tracking__. Nous commencerons cette session par une introduction générale à l'eye-tracking. Nous poursuivrons ensuite par un tutoriel pratique dans lequel vous mettrez en place une tâche de lecture auto-rythmée avec un suivi oculaire de base. Nous nous concentrerons sur l'utilisation de l'EyeLink, qui est un dispositif de suivi oculaire spécifique. Cependant, les concepts et techniques sont également largement applicables à d'autres dispositifs de suivi oculaire. Nous examinerons également brièvement l'eye-tracking dans les expériences en ligne avec WebGazer.js.\n- Pause\n- 15h00 – 16h00 : __Eye-tracking basé sur le regard.__ Vous apprendrez à mettre en oeuvre des expériences qui réagissent aux mouvements des yeux du participant, c'est-à-dire des expériences basées sur le regard.\n- 16h00 – 17h00 : __Temps libre pour développer votre propre expérience.__ Au cours de cette session, vous continuerez à travailler sur votre propre expérience.\n\n## Jour 4 : Analyse des données (27 avril)\n\nDiapositives : %static:attachments/binus2022/binus-day-4.pdf%\n\n- 13h00 – 14h30 : __Préparation des données pour l'analyse.__ Nous commencerons cette session par une explication générale de la façon dont les données sont structurées, tant pour les expériences menées en ligne que pour celles menées dans un laboratoire traditionnel. Ensuite, nous verrons comment transformer ces données en un format qui se prête à une analyse statistique dans le logiciel statistique gratuit JASP. Plus précisément, nous apprendrons comment les données de plusieurs participants peuvent être fusionnées dans un seul tableur .csv ; nous apprendrons également comment les données d'une expérience en ligne peuvent être téléchargées à partir de JATOS et converties en feuille de calcul .csv ; enfin, nous apprendrons à créer ce que l'on appelle une « table pivot », qui se prête à l'analyse dans JASP.\n- Pause\n- 15h00 – 16h30 : __Conduite d'une analyse statistique.__ Nous utiliserons le logiciel open source JASP pour effectuer des tests statistiques.\n- 16h30 – 17h00 : __Q&R.__ Nous clôturerons l'atelier avec un temps pour les questions et les remarques.\n\n## Expériences suggérées\n\nUne liste d'expériences faciles à mettre en œuvre, avec des références aux articles qui contiennent une section de résultats claire.\n\n- Tâche du réseau d'attention (ANT)\n    - Fan, J., McCandliss, B. D., Sommer, T., Raz, A., & Posner, M. I. (2002). Testing the efficiency and independence of attentional networks. *Journal of cognitive neuroscience*, *14*(3), 340-347.\n- Tâche d'amorçage de Posner\n    - Pour une version qui se concentre spécifiquement sur l'inhibition du retour (IOR), voir : Klein, R. M. (2000). Inhibition of return. *Trends in cognitive sciences*, *4*(4), 138-147.\n- Test d'association implicite (IAT)\n    - Pour une étude de réplication, voir Johnson, D. J., Ampofo, D., Erbas, S. A., Robey, A., Calvert, H., Garriques, V., ... & Dougherty, M. (2021). Cognitive Control and the Implicit Association Test: A Replication of Siegel, Dougherty, and Huber (2012). *Collabra: Psychology*, *7*(1), 27356.\n    - Voir également <https://osdoc.cogsci.nl/3.3/tutorials/iat>\n- Catégorisation des couleurs, un test pour l'hypothèse Sapir-Whorf. Notez que la création de stimuli peut être difficile\n    - Brown, A. M., Lindsey, D. T., & Guckes, K. M. (2011). Color names, color categories, and color-cued visual search: Sometimes, color perception is not categorical. *Journal of vision*, *11*(12), 2-2.\n- Tâche de réflexion cognitive\n    - Sirota, M., & Juanchich, M. (2018). Effect of response format on cognitive reflection: Validating a two-and four-option multiple choice question version of the Cognitive Reflection Test. *Behavior Research Methods*, *50*(6), 2511-2522.\n- Tâche de capture attentionnelle.\n    - Theeuwes, J. (1992). Perceptual selectivity for color and form. *Perception & Psychophysics*, *51*(6), 599–606. <https://doi.org/10.3758/BF03211656>\n- Tâche de recherche visuelle.\n    - Treisman, A. M., & Gelade, G. (1980). A feature-integration theory of attention. *Cognitive Psychology*, *12*(1), 97–136. <https://doi.org/10.1016/0010-0285(80)90005-5>\n    - Voir également <https://osdoc.cogsci.nl/3.3/tutorials/intermediate-javascript>"
  },
  "ESCoP 2017 workshop": {
    "fr": "Atelier ESCoP 2017"
  },
  "<notranslate>[TOC]</notranslate>\n\n\n## About the workshop\n\nThis OpenSesame workshop took place as a pre-conference event before ESCoP 2017.\n\nThe workshop consisted of two main parts. In the first part, corresponding to the Tutorial below, we created a complete experiment together. In the second part, corresponding to the Extra assignments below, the workshop participants improved this experiment by themselves, based on a few suggestions.\n\nYou can download the full experiment, including the solutions of the extra assignments here:\n\n- <http://osf.io/jw7dr>\n\n### When?\n\n- September 3rd, 2017\n- JASP: 09:00 - 12:00\n- OpenSesame: 13:00 - 16:00\n\n### Where?\n\n- University Potsdam\n- Campus III - Griebnitzsee\n- Building 6 (Lecture hall building)\n- August-Bebel-Straße 89\n- 14482 Potsdam\n- Germany\n\n### More info\n\n- Conference site: <http://www.escop2017.org/program>\n- JASP site: <https://jasp-stats.org/>\n\n\n## Screencast\n\n<notranslate>\nvideo:\n source: youtube\n id: EscopTutorial\n videoid: ICa0vPoYrYw\n width: 640\n height: 360\n caption: |\n  The tutorial in video form.\n</notranslate>\n\n\n## The tutorial\n\n<notranslate>\nfigure:\n id: FigMeowingCapybara\n source: meowing-capybara.png\n caption: |\n  Don't be fooled by meowing capybaras! ([Source][capybara_photo])\n</notranslate>\n\n<notranslate>[TOC]</notranslate>\n\nWe will create a simple animal-filled multisensory integration task, in which participants see a picture of a dog, cat, or capybara. A meow or a bark is played while the picture is shown. The participant reports whether a dog or a cat is shown, by pressing the right or the left key. No response should be given when a capybara is shown: those are catch trials.\n\nTo make things more fun, we will design the experiment so that you can run it on [OSWeb](http://osweb.cogsci.nl/), an online runtime for OpenSesame experiments (which is still a work in progress, but it works for basic experiments).\n\nWe make two simple predictions:\n\n- Participants should be faster to identify dogs when a barking sound is played, and faster to identify cats when a meowing sound is played. In other words, we expect a multisensory congruency effect.\n- When participants see a capybara, they are more likely to report seeing a dog when they hear a bark, and more likely to report seeing a cat when they hear a meow. In other words, false alarms are biased by the sound.\n\n\n### Step 1: Download and start OpenSesame\n\nOpenSesame is available for Windows, Linux, Mac OS, and Android (runtime only). This tutorial is written for OpenSesame 3.1.X, and you can use either the version based on Python 2.7 (default) or Python 3.5. You can download OpenSesame from here:\n\n- %link:download%\n\nWhen you start OpenSesame, you will be given a choice of template experiments, and (if any) a list of recently opened experiments (see %FigStartUp).\n\n<notranslate>\nfigure:\n id: FigStartUp\n source: start-up.png\n caption: |\n  The OpenSesame window on start-up.\n</notranslate>\n\nThe *Extended template* provides a good starting point for creating Android-based experiments. However, in this tutorial we will create the entire experiment from scratch. Therefore, we will continue with the 'default template', which is already loaded when OpenSesame is launched (%FigDefaultTemplate). Therefore, simply close the 'Get started!' and (if shown) 'Welcome!' tabs.\n\n<notranslate>\nfigure:\n id: FigDefaultTemplate\n source: default-template.png\n caption: |\n  The structure of the 'Default template' as seen in the overview area.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 1: Basics**": {
    "fr": "## À propos de l'atelier\n\nCet atelier OpenSesame a eu lieu en tant qu'événement pré-conférence avant ESCoP 2017.\n\nL'atelier se composait de deux parties principales. Dans la première partie, correspondant au tutoriel ci-dessous, nous avons créé une expérience complète ensemble. Dans la deuxième partie, correspondant aux missions supplémentaires ci-dessous, les participants à l'atelier ont amélioré cette expérience par eux-mêmes, selon quelques suggestions.\n\nVous pouvez télécharger l'expérience complète, y compris les solutions des missions supplémentaires ici :\n\n- <http://osf.io/jw7dr>\n\n### Quand ?\n\n- 3 septembre 2017\n- JASP : 09:00 - 12:00\n- OpenSesame : 13:00 - 16:00\n\n### Où ?\n\n- Université de Potsdam\n- Campus III - Griebnitzsee\n- Bâtiment 6 (Bâtiment de l'amphithéâtre)\n- August-Bebel-Straße 89\n- 14482 Potsdam\n- Allemagne\n\n### Plus d'infos\n\n- Site de la conférence : <http://www.escop2017.org/program>\n- Site JASP : <https://jasp-stats.org/>\n\n\n## Screencast\n\n<notranslate>\nvidéo:\n source: youtube\n id: EscopTutorial\n videoid: ICa0vPoYrYw\n largeur: 640\n hauteur: 360\n légende: |\n  Le tutoriel sous forme de vidéo.\n</notranslate>\n\n\n## Le tutoriel\n\n<notranslate>\nfigure:\n id: FigMeowingCapybara\n source: meowing-capybara.png\n légende: |\n  Ne te laisse pas berner par les capybaras qui miaulent ! ([Source][capybara_photo])\n</notranslate>\n\n<notranslate>[TOC]</notranslate>\n\nNous allons créer une tâche simple d'intégration multisensorielle remplie d'animaux, dans laquelle les participants voient une photo d'un chien, d'un chat ou d'un capybara. Un miaulement ou un aboiement est joué pendant que la photo est montrée. Le participant indique si un chien ou un chat est montré, en appuyant sur la touche droite ou gauche. Aucune réponse ne doit être donnée lorsqu'un capybara est montré : ce sont des essais surprises.\n\nPour rendre les choses plus amusantes, nous concevrons l'expérience de manière à ce que vous puissiez la réaliser sur [OSWeb](http://osweb.cogsci.nl/), un runtime en ligne pour les expériences OpenSesame (qui est encore en cours de développement, mais fonctionne pour les expériences de base).\n\nNous formulons deux prédictions simples :\n\n- Les participants devraient être plus rapides pour identifier les chiens lorsqu'un aboiement est joué, et plus rapides pour identifier les chats lorsqu'un miaulement est joué. En d'autres termes, nous nous attendons à un effet de congruence multisensorielle.\n- Lorsque les participants voient un capybara, ils sont plus susceptibles de signaler avoir vu un chien lorsqu'ils entendent un aboiement, et plus susceptibles de signaler avoir vu un chat lorsqu'ils entendent un miaulement. En d'autres termes, les fausses alertes sont biaisées par le son.\n\n\n### Étape 1 : Téléchargez et démarrez OpenSesame\n\nOpenSesame est disponible pour Windows, Linux, Mac OS et Android (runtime uniquement). Ce tutoriel est écrit pour OpenSesame 3.1.X, et vous pouvez utiliser la version basée sur Python 2.7 (par défaut) ou Python 3.5. Vous pouvez télécharger OpenSesame ici :\n\n- %link:download%\n\nLorsque vous démarrez OpenSesame, vous aurez le choix entre des expériences modèles et (le cas échéant) une liste d'expériences récemment ouvertes (voir %FigStartUp).\n\n<notranslate>\nfigure:\n id: FigStartUp\n source: start-up.png\n légende: |\n  La fenêtre OpenSesame au démarrage.\n</notranslate>\n\nLe *modèle étendu* offre un bon point de départ pour créer des expériences basées sur Android. Cependant, dans ce tutoriel, nous créerons l'ensemble de l'expérience à partir de zéro. Par conséquent, nous continuerons avec le \"modèle par défaut\", qui est déjà chargé lorsque OpenSesame est lancé (%FigDefaultTemplate). Fermez simplement les onglets \"Get started!\" et (si affichés) \"Welcome!\".\n\n<notranslate>\nfigure:\n id: FigDefaultTemplate\n source: default-template.png\n légende: |\n  La structure du \"modèle par défaut\" telle que vue dans la zone de présentation.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 1 : Bases**"
  },
  "OpenSesame experiments are collections of *items*. An item is a small chunk of functionality that, for example, can be used to present visual stimuli (the SKETCHPAD item) or to record key presses (the KEYBOARD_RESPONSE item). Items have a type and a name. For example, you might have two items of the type KEYBOARD_RESPONSE with the names *t1_response* and *t2_response*. To make the distinction between item types and item names clear, we will use THIS_STYLE for types, and *this style* for names.\n\nTo give structure to your experiment, two types of items are especially important: the LOOP and the SEQUENCE. Understanding how you can combine LOOPs and SEQUENCEs to build experiments is perhaps the trickiest part of working with OpenSesame, so let's get that out of the way first.\n\nA LOOP is where, in most cases, you define your independent variables. In a LOOP you can create a table in which each column corresponds to a variable, and each row corresponds to a single run of the 'item to run'. To make this more concrete, let's consider the following *block_loop* (unrelated to this tutorial):\n\n<notranslate>\nfigure:\n id: FigLoopTable\n source: loop-table.png\n caption: |\n  An example of variables defined in a loop table. (This example is not related to the experiment created in this tutorial.)\n</notranslate>\n\nThis *block_loop* will execute *trial_sequence* four times. Once while `soa` is 100 and `target` is 'F', once while `soa` is 100 and `target` is 'H', etc. The order in which the rows are walked through is random by default, but can also be set to sequential in the top-right of the tab.\n\nA SEQUENCE consists of a series of items that are executed one after another. A prototypical SEQUENCE is the *trial_sequence*, which corresponds to a single trial. For example, a basic *trial_sequence* might consist of a SKETCHPAD, to present a stimulus, a KEYBOARD_RESPONSE, to collect a response, and a LOGGER, to write the trial information to the log file.\n\n<notranslate>\nfigure:\n id: FigExampleSequence\n source: example-sequence.png\n caption: |\n  An example of a SEQUENCE item used as a trial sequence. (This example is not related to the experiment created in this tutorial.)\n</notranslate>\n\nYou can combine LOOPs and SEQUENCEs in a hierarchical way, to create trial blocks, and practice and experimental phases. For example, the *trial_sequence* is called by the *block_loop*. Together, these correspond to a single block of trials. One level up, the *block_sequence* is called by the *practice_loop*. Together, these correspond to the practice phase of the experiment.\n\n</div>\n\n\n### Step 2: Add a block_loop and trial_sequence\n\nThe default template starts with three items: A NOTEPAD called *getting_started*, a SKETCHPAD called *welcome*, and a SEQUENCE called *experiment*. We don't need *getting_started* and *welcome*, so let's remove these right away. To do so, right-click on these items and select 'Delete'. Don't remove *experiment*, because it is the entry for the experiment (i.e. the first item that is called when the experiment is started).\n\nOur experiment will have a very simple structure. At the top of the hierarchy is a LOOP, which we will call *block_loop*. The *block_loop* is the place where we will define our independent variables (see also Background box 1). To add a LOOP to your experiment, drag the LOOP icon from the item toolbar onto the *experiment* item in the overview area.\n\nA LOOP item needs another item to run; usually, and in this case as well, this is a SEQUENCE. Drag the SEQUENCE item from the item toolbar onto the *new_loop* item in the overview area. OpenSesame will ask whether you want to insert the SEQUENCE into or after the LOOP. Select 'Insert into new_loop'.": {
    "fr": "Les expériences OpenSesame sont des collections d'éléments. Un élément est un petit morceau de fonctionnalité qui, par exemple, peut être utilisé pour présenter des stimuli visuels (l'élément SKETCHPAD) ou pour enregistrer des pressions de touches (l'élément KEYBOARD_RESPONSE). Les éléments ont un type et un nom. Par exemple, vous pourriez avoir deux éléments du type KEYBOARD_RESPONSE avec les noms *t1_response* et *t2_response*. Pour bien distinguer les types et les noms d'éléments, nous utiliserons CE_STYLE pour les types et *ce style* pour les noms.\n\nPour donner une structure à votre expérience, deux types d'éléments sont particulièrement importants : la boucle (LOOP) et la séquence (SEQUENCE). Comprendre comment combiner les LOOPs et les SEQUENCEs pour construire des expériences est peut-être la partie la plus délicate du travail avec OpenSesame, alors abordons ce point en premier.\n\nUne LOOP est l'endroit où, dans la plupart des cas, vous définissez vos variables indépendantes. Dans une LOOP, vous pouvez créer un tableau où chaque colonne correspond à une variable et chaque ligne correspond à une seule exécution de l’”élément à exécuter”. Pour rendre cela plus concret, considérons la *block_loop* suivante (sans rapport avec ce tutoriel) :\n\n<notranslate>\nfigure:\n id: FigLoopTable\n source: loop-table.png\n caption: |\n  Un exemple de variables définies dans un tableau de boucle (LOOP). (Cet exemple n'est pas lié à l'expérience créée dans ce tutoriel.)\n</notranslate>\n\nCe *block_loop* exécutera *trial_sequence* quatre fois. Une fois avec `soa` à 100 et `target` à 'F', une fois avec `soa` à 100 et `target` à 'H', etc. L'ordre dans lequel les lignes sont parcourues est aléatoire par défaut, mais peut aussi être défini en séquentiel en haut à droite de l'onglet.\n\nUne SEQUENCE est composée d'une série d'éléments qui sont exécutés les uns après les autres. Une SEQUENCE prototypique est *trial_sequence*, qui correspond à une seule tentative. Par exemple, une *trial_sequence* basique pourrait contenir un SKETCHPAD, pour présenter un stimulus, un KEYBOARD_RESPONSE, pour recueillir une réponse, et un LOGGER, pour écrire les informations de l'essai dans le fichier journal.\n\n<notranslate>\nfigure:\n id: FigExampleSequence\n source: example-sequence.png\n caption: |\n  Un exemple d'un élément SEQUENCE utilisé comme séquence d'essai. (Cet exemple n'est pas lié à l'expérience créée dans ce tutoriel.)\n</notranslate>\n\nVous pouvez combiner les LOOPs et les SEQUENCEs de manière hiérarchique pour créer des blocs d'essais et des phases de pratique et d'expérimentation. Par exemple, *trial_sequence* est appelée par *block_loop*. Ensemble, ils correspondent à un seul bloc d'essais. À un niveau supérieur, *block_sequence* est appelée par *practice_loop*. Ensemble, ils correspondent à la phase de pratique de l'expérience.\n\n</div>\n\n\n### Étape 2 : Ajout d'un block_loop et d'un trial_sequence\n\nLe modèle par défaut commence avec trois éléments : un NOTEPAD appelé *getting_started*, un SKETCHPAD appelé *welcome* et une SEQUENCE appelée *experiment*. Nous n'avons pas besoin de *getting_started* et de *welcome*, alors supprimons-les tout de suite. Pour ce faire, faites un clic droit sur ces éléments et sélectionnez \"Supprimer\". Ne supprimez pas *experiment* car il s'agit de l'entrée de l'expérience (c'est-à-dire le premier élément qui est appelé lorsque l'expérience démarre).\n\nNotre expérience aura une structure très simple. Le sommet de la hiérarchie est une LOOP, que nous appellerons *block_loop*. C'est dans *block_loop* que nous définirons nos variables indépendantes (voir également l'encadré Contexte 1). Pour ajouter une LOOP à votre expérience, faites glisser l'icône LOOP de la barre d'outils des éléments sur l'élément *experiment* dans la zone d'aperçu.\n\nUn élément LOOP a besoin d'un autre élément pour s'exécuter; en général et dans ce cas également, il s'agit d'une SEQUENCE. Faites glisser l'élément SEQUENCE de la barre d'outils des éléments sur l'élément *new_loop* dans la zone d'aperçu. OpenSesame vous demandera si vous souhaitez insérer la SEQUENCE dans ou après la LOOP. Sélectionnez \"Insérer dans new_loop\"."
  },
  "By default, items have names such as *new_sequence*, *new_loop*, *new_sequence_2*, etc. These names are not very informative, and it is good practice to rename them. Item names must consist of alphanumeric characters and/ or underscores. To rename an item, double-click on the item in the overview area. Rename *new_sequence* to *trial_sequence* to indicate that it will correspond to a single trial. Rename *new_loop* to *block_loop* to indicate that will correspond to a block of trials.\n\nThe overview area of our experiment now looks as in %FigStep3.\n\n<notranslate>\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  The overview area at the end of Step 2.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 3: Unused items**\n\n__Tip__ — Deleted items are still available in the Unused Items bin, until you select 'Permanently delete unused items' in the Unused Items tab. You can re-add deleted items to your experiment by dragging them out of the Unused Items bin into a SEQUENCE or LOOP.\n\n</div>\n\n### Step 3: Import images and sound files\n\nFor this experiment, we will use images of cats, dogs, and capybaras. We will also use sound samples of meows and barks. You can download all the required files from here:\n\n- %static:attachments/cats-dogs-capybaras/stimuli.zip%\n\nDownload `stimuli.zip` and extract it somewhere (to your desktop, for example). Next, in OpenSesame, click on the 'Show file pool' button in the main toolbar (or: Menu →View → Show file pool). This will show the file pool, by default on the right side of the window. The easiest way to add the stimuli to the file pool is by dragging them from the desktop (or wherever you have extracted the files to) into the file pool. Alternatively, you can click on the '+' button in the file pool and add files using the file-selection dialog that appears. The file pool will automatically be saved with your experiment.\n\nAfter you have added all stimuli, your file pool looks as in %FigStep4.\n\n<notranslate>\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  The file pool at the end of Step 3.\n</notranslate>\n\n### Step 4: Define the experimental variables in the block_loop\n\nConceptually, our experiment has a fully crossed 3×2 design: We have three types of visual stimuli (cats, dogs, and capybaras) which occur in combination with two types of auditory stimuli (meows and barks). However, we have five exemplars for each stimulus type: five meow sounds, five capybara pictures, etc. From a technical point of view, it therefore makes sense to treat our experiment as a 5×5×3×2 design, in which picture number and sound number are factors with five levels.\n\nOpenSesame is very good at generating full-factorial designs. First, open *block_loop* by clicking on it in the overview area. Next, click on the Full-Factorial Design button. This will open a wizard for generating full-factorial designs, which works in a straightforward way: Every column corresponds to an experimental variable (i.e. a factor). The first row is the name of the variable, the rows below contain all possible values (i.e. levels). In our case, we can specify our 5×5×3×2 design as shown in %FigLoopWizard.\n\n<notranslate>\nfigure:\n id: FigLoopWizard\n source: loop-wizard.png\n caption: |\n  The loop wizard generates full-factorial designs.\n</notranslate>\n\nAfter clicking 'Ok', you will see that there is now a LOOP table with four rows, one for each experimental variable. There are 150 cycles (=5×5×3×2), which means that we have 150 unique trials. Your LOOP table now looks as in %FigStep5.\n\n<notranslate>\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  The LOOP table at the end of Step 4.\n</notranslate>\n\n### Step 5: Add items to the trial sequence\n\nOpen *trial_sequence*, which is still empty. It's time to add some items! Our basic *trial_sequence* is:": {
    "fr": "Par défaut, les éléments ont des noms tels que *new_sequence*, *new_loop*, *new_sequence_2*, etc. Ces noms ne sont pas très informatifs et il est recommandé de les renommer. Les noms d'éléments doivent être constitués de caractères alphanumériques et/ou de traits de soulignement. Pour renommer un élément, double-cliquez dessus dans la zone d'aperçu. Renommez *new_sequence* en *trial_sequence* pour indiquer qu'il correspondra à un essai unique. Renommez *new_loop* en *block_loop* pour indiquer qu'il correspondra à un bloc d'essais.\n\nLa zone d'aperçu de notre expérience ressemble maintenant à celle figurée dans %FigStep3.\n\n<notranslate>\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  La zone d'aperçu à la fin de l'étape 2.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 3 : Éléments inutilisés**\n\n__Astuce__ — Les éléments supprimés sont toujours disponibles dans la corbeille des éléments inutilisés, jusqu'à ce que vous sélectionniez \"Supprimer définitivement les éléments inutilisés\" dans l'onglet des éléments inutilisés. Vous pouvez remettre les éléments supprimés dans votre expérience en les faisant glisser depuis la corbeille des éléments inutilisés vers une SÉQUENCE ou LOOP.\n\n</div>\n\n### Étape 3 : Importer des images et des fichiers sonores\n\nPour cette expérience, nous utiliserons des images de chats, de chiens et de capybaras. Nous utiliserons également des échantillons sonores de miaulements et d'aboiements. Vous pouvez télécharger tous les fichiers requis ici :\n\n- %static:attachments/cats-dogs-capybaras/stimuli.zip%\n\nTéléchargez `stimuli.zip` et extrayez-le quelque part (sur votre bureau, par exemple). Ensuite, dans OpenSesame, cliquez sur le bouton \"Afficher le pool de fichiers\" dans la barre d'outils principale (ou : Menu → Affichage → Afficher le pool de fichiers). Cela affichera le pool de fichiers, par défaut sur le côté droit de la fenêtre. La façon la plus simple d'ajouter les stimuli au pool de fichiers est de les faire glisser depuis le bureau (ou depuis l'endroit où vous avez extrait les fichiers) vers le pool de fichiers. Vous pouvez également cliquer sur le bouton '+' dans le pool de fichiers et ajouter des fichiers en utilisant la boîte de dialogue de sélection de fichiers qui apparaît. Le pool de fichiers sera automatiquement enregistré avec votre expérience.\n\nAprès avoir ajouté tous les stimuli, votre pool de fichiers ressemblera à celui de la %FigStep4.\n\n<notranslate>\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  Le pool de fichiers à la fin de l'étape 3.\n</notranslate>\n\n### Étape 4 : Définir les variables expérimentales dans le block_loop\n\nConceptuellement, notre expérience a un plan croisé complet 3x2 : nous avons trois types de stimuli visuels (chats, chiens et capybaras) qui apparaissent en combinaison avec deux types de stimuli auditifs (miaulements et aboiements). Cependant, nous avons cinq exemplaires pour chaque type de stimulus : cinq sons de miaulement, cinq photos de capybara, etc. D'un point de vue technique, il est donc logique de considérer notre expérience comme un plan 5x5x3x2, dans lequel le numéro d'image et le numéro de son sont des facteurs à cinq niveaux.\n\nOpenSesame est très efficace pour générer des plans factoriels complets. Tout d'abord, ouvrez *block_loop* en cliquant dessus dans la zone d'aperçu. Ensuite, cliquez sur le bouton Full-Factorial Design. Cela ouvrira un assistant pour générer des plans factoriels complets, qui fonctionne de manière simple : chaque colonne correspond à une variable expérimentale (c'est-à-dire un facteur). La première ligne est le nom de la variable, les lignes ci-dessous contiennent toutes les valeurs possibles (c'est-à-dire les niveaux). Dans notre cas, nous pouvons spécifier notre plan 5×5×3×2 comme indiqué dans %FigLoopWizard.\n\n<notranslate>\nfigure:\n id: FigLoopWizard\n source: loop-wizard.png\n caption: |\n  L'assistant de boucle génère des plans factoriels complets.\n</notranslate>\n\nAprès avoir cliqué sur \"Ok\", vous verrez qu'il y a maintenant une table LOOP avec quatre lignes, une pour chaque variable expérimentale. Il y a 150 cycles (=5×5×3×2), ce qui signifie que nous avons 150 essais uniques. Votre table LOOP ressemble maintenant à celle de la %FigStep5.\n\n<notranslate>\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  La table LOOP à la fin de l'étape 4.\n</notranslate>\n\n### Étape 5 : Ajouter des éléments à la séquence d'essais\n\nOuvrez *trial_sequence*, qui est encore vide. Il est temps d'ajouter des éléments ! Notre *trial_sequence* de base est :"
  },
  "1. A SKETCHPAD to display a central fixation dot for 500 ms\n2. A SAMPLER to play an animal sound\n3. A SKETCHPAD to display an animal picture\n4. A KEYBOARD_RESPONSE to collect a response\n5. A LOGGER to write the data to file\n\nTo add these items, simply drag them one by one from the item toolbar into the *trial_sequence*. If you accidentally drop items in the wrong place, you can simply re-order them by dragging and dropping. Once all items are in the correct order, give each of them a sensible name. The overview area now looks as in %FigStep6.\n\n<notranslate>\nfigure:\n id: FigStep6\n source: step6.png\n caption: |\n  The overview area at the end of Step 5.\n</notranslate>\n\n### Step 6: Define the central fixation dot\n\nClick on *fixation_dot* in the overview area. This opens a basic drawing board that you can use to design your visual stimuli. To draw a central fixation dot, first click on the crosshair icon, and then click on the center of the display, i.e. at position (0, 0).\n\nWe also need to specify for how long the fixation dot is visible. To do so, change the duration from 'keypress' to 495 ms, in order to specify a 500 ms duration. (See Background box 4 for an explanation.)\n\nThe *fixation_dot* item now looks as in %FigStep7.\n\n<notranslate>\nfigure:\n id: FigStep7\n source: step7.png\n caption: |\n  The *fixation_dot* item at the end of Step 6.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 4: Selecting the correct duration**\n\nWhy specify a duration of 495 if we want a duration of 500 ms? The reason for this is that the actual display-presentation duration is always rounded up to a value that is compatible with your monitor's refresh rate. This may sound complicated, but for most purposes the following rules of thumb are sufficient:\n\n1. Choose a duration that is possible given your monitor's refresh rate. For example, if your monitor's refresh rate is 60 Hz, this means that every frame lasts 16.7 ms (=1000 ms/60 Hz). Therefore, on a 60 Hz monitor, you should always select a duration that is a multiple of 16.7 ms, such as 16.7, 33.3, 50, 100, etc.\n2. In the duration field of the SKETCHPAD specify a duration that is a few milliseconds shorter than what you're aiming for. So if you want to present a SKETCHPAD for 50 ms, choose a duration of 45. If you want to present a SKETCHPAD for 1000 ms, choose a duration of 995. Etcetera.\n\nFor a detailed discussion of experimental timing, see:\n\n- %link:timing%\n\n</div>\n\n### Step 7: Define the animal sound\n\nOpen *animal_sound*. The SAMPLER item provides a number of options, the most important being the sound file that should be played. Click on the browse button to open the file-pool selection dialog, and select one of the sound files, such as `bark1.ogg`.\n\nOf course, we don't want to play the same sound over-and-over again! Instead, we want to select a sound based on the variables `sound` and `sound_nr` that we have defined in the *block_loop* (Step 5). To do this, simply replace the part of the string that you want to have depend on a variable by the name of that variable between square brackets. More specifically, 'bark1.ogg' becomes '[sound][sound_nr].ogg', because we want to replace 'bark' by the value of the variable `sound` and '1' by the value of `sound_nr`.\n\nWe also need to change the duration of the SAMPLER. By default, the duration is 'sound', which means that the experiment will pause while the sound is playing. Change the duration to 0. This does not mean that the sound will be played for only 0 ms, but that the experiment will advance right away to the next item, while the sound continues to play in the background. The item *animal_sound* now looks as shown in %FigStep8.\n\n<notranslate>\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  The item *animal_sound* at the end of Step 7.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 5: Variables**\n\nFor more information about using variables, see:\n\n- %link:manual/variables%\n\n</div>": {
    "fr": "1. Un SKETCHPAD pour afficher un point de fixation central pendant 500 ms\n2. Un SAMPLER pour jouer un son d'animal\n3. Un SKETCHPAD pour afficher une image d'animal\n4. Une KEYBOARD_RESPONSE pour collecter une réponse\n5. Un LOGGER pour écrire les données dans un fichier\n\nPour ajouter ces éléments, faites-les simplement glisser un par un de la barre d'outils des éléments dans la *trial_sequence*. Si vous déposez accidentellement des éléments au mauvais endroit, vous pouvez simplement les réorganiser en les faisant glisser et déposer. Une fois tous les éléments dans le bon ordre, donnez-leur un nom sensé. La zone d'aperçu ressemble maintenant à celle de %FigStep6.\n\n<notranslate>\nfigure:\n id: FigStep6\n source: step6.png\n caption: |\n  La zone d'aperçu à la fin de l'étape 5.\n<notranslate>\n\n### Étape 6 : Définir le point de fixation central\n\nCliquez sur *fixation_dot* dans la zone d'aperçu. Cela ouvre une planche à dessin de base que vous pouvez utiliser pour concevoir vos stimuli visuels. Pour dessiner un point de fixation central, cliquez d'abord sur l'icône en forme de croix, puis sur le centre de l'affichage, c'est-à-dire à la position (0, 0).\n\nNous devons également préciser combien de temps le point de fixation est visible. Pour ce faire, changez la durée de 'keypress' à 495 ms, afin de spécifier une durée de 500 ms. (Voir l'encadré 4 pour une explication.)\n\nL'élément *fixation_dot* ressemble maintenant à %FigStep7.\n\n<notranslate>\nfigure:\n id: FigStep7\n source: step7.png\n caption: |\n  L'élément *fixation_dot* à la fin de l'étape 6.\n<notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 4 : Choisir la bonne durée**\n\nPourquoi choisir une durée de 495 si nous voulons une durée de 500 ms ? La raison en est que la durée réelle de présentation de l'affichage est toujours arrondie à une valeur compatible avec le taux de rafraîchissement de votre moniteur. Cela peut sembler compliqué, mais pour la plupart des besoins, les règles suivantes sont suffisantes :\n\n1. Choisissez une durée possible étant donné le taux de rafraîchissement de votre moniteur. Par exemple, si le taux de rafraîchissement de votre moniteur est de 60 Hz, cela signifie que chaque image dure 16,7 ms (= 1000 ms/60 Hz). Par conséquent, sur un moniteur de 60 Hz, vous devez toujours choisir une durée multiple de 16,7 ms, comme 16,7, 33,3, 50, 100, etc.\n2. Dans le champ de durée du SKETCHPAD, spécifiez une durée de quelques millisecondes plus courte que celle que vous visez. Ainsi, si vous voulez présenter un SKETCHPAD pendant 50 ms, choisissez une durée de 45. Si vous voulez présenter un SKETCHPAD pendant 1000 ms, choisissez une durée de 995. Etc.\n\nPour une discussion détaillée sur le minutage des expériences, voir :\n\n- %link:timing%\n\n</div>\n\n### Étape 7 : Définir le son de l'animal\n\nOuvrez *animal_sound*. L'élément SAMPLER fournit un certain nombre d'options, la plus importante étant le fichier sonore à jouer. Cliquez sur le bouton de navigation pour ouvrir la boîte de dialogue de sélection du fichier, et sélectionnez l'un des fichiers sonores, tels que `bark1.ogg`.\n\nBien sûr, nous ne voulons pas jouer le même son encore et encore ! Au lieu de cela, nous voulons sélectionner un son en fonction des variables `sound` et `sound_nr` que nous avons définies dans la *block_loop* (étape 5). Pour ce faire, remplacez simplement la partie de la chaîne sur laquelle vous voulez que la variable dépende par le nom de cette variable entre crochets. Plus précisément, 'bark1.ogg' devient '[sound][sound_nr].ogg', car nous voulons remplacer 'bark' par la valeur de la variable `sound` et '1' par la valeur de `sound_nr`.\n\nNous devons également changer la durée du SAMPLER. Par défaut, la durée est 'sound', ce qui signifie que l'expérience sera interrompue pendant la lecture du son. Changez la durée à 0. Cela ne signifie pas que le son sera lu pendant seulement 0 ms, mais que l'expérience passera immédiatement à l'élément suivant, pendant que le son continue de jouer en arrière-plan. L'élément *animal_sound* ressemble maintenant à celui de %FigStep8.\n\n<notranslate>\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  L'élément *animal_sound* à la fin de l'étape 7.\n<notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 5 : Variables**\n\nPour plus d'informations sur l'utilisation des variables, voir :\n\n- %link:manual/variables%\n\n</div>"
  },
  "### Step 8: Define the animal picture\n\nOpen *animal_picture*. Select the image tool by clicking on the button with the landscape-like icon. Click on the center (0, 0) of the display. In the File Pool dialog that appears, select `capybara1.png`. The capybara's sideways glance will now lazily stare at you from the center of the display. But of course, we don't always want to show the same capybara. Instead, we want to have the image depend on the variables `animal` and `pic_nr` that we have defined in the *block_loop* (Step 5).\n\nWe can use essentially the same trick as we did for *animal_sound*, although things work slightly differently for images. First, right-click on the capybara and select 'Edit script'. This allows you to edit the following line of OpenSesame script that corresponds to the capybara picture:\n\n\tdraw image center=1 file=\"capybara1.png\" scale=1 show_if=always x=0 y=0 z_index=0\n\nNow change the name of image file from 'capybara.png' to '[animal][pic_nr].png':\n\n\tdraw image center=1 file=\"[animal][pic_nr].png\" scale=1 show_if=always x=0 y=0 z_index=0\n\nClick on 'Ok' to apply the change. The capybara is now gone, replaced by a placeholder image, and OpenSesame tells you that one object is not shown, because it is defined using variables. Don't worry, it will be shown during the experiment!\n\nTo remind the participant of the task, also add two response circles, one marked 'dog' on the left side of the screen, and one marked 'cat' on the right side. I'm sure you will able to figure out how to do this with the SKETCHPAD drawing tools. My rendition is shown in %FigStep9. Note that these response circles are purely visual, and we still need to explicitly define the response criteria (see Step 10).\n\nFinally, set 'Duration' field to '0'. This does not mean that the picture is presented for only 0 ms, but that the experiment will advance to the next item (*response*) right away. Since *response* waits for a response, but doesn't change what's on the screen, the target will remain visible until a response has been given.\n\n<notranslate>\nfigure:\n id: FigStep9\n source: step9.png\n caption: |\n  The *animal_picture* SKETCHPAD at the end of Step 8.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 6: Image formats**\n\n__Tip__ -- OpenSesame can handle a wide variety of image formats. However, some (non-standard) `.bmp` formats are known to cause trouble. If you find that a `.bmp` image is not shown, you may want to consider using a different format, such as `.png`. You can convert images easily with free tools such as [GIMP].\n\n</div>\n\n\n### Step 9: Define the response\n\nOpen the *response* item. This is a KEYBOARD_RESPONSE item, which collects a single key press. There are a few options:\n\n- __Correct response__ — let's skip this for now; we'll get back to it in Step 10.\n- __Allowed responses__ is a semicolon-separated list of keys that are accepted. Let's set this to *left;right* to indicate that only the left and right arrow keys are accepted. (The *escape* key pauses the experiment, and is always accepted!)\n- __Timeout__ indicates a duration after which the response will be set to 'None', and the experiment will continue. A timeout is important in our experiment, because participants need to have the opportunity to *not* respond when they see a capybara. So let's set the timeout to 2000.\n- __Flush pending keypresses__ indicates that we should only accept new key presses. This is best left enabled (it is by default).\n\n<notranslate>\nfigure:\n id: FigStep10\n source: step10.png\n caption: |\n  The *response* KEYBOARD_RESPONSE at the end of Step 9.\n</notranslate>\n\n\n### Step 10: Define the correct response": {
    "fr": "### Étape 8: Définir l'image d'animal\n\nOuvrez *animal_picture*. Sélectionnez l'outil Image en cliquant sur le bouton avec l'icône en forme de paysage. Cliquez sur le centre (0, 0) de l'affichage. Dans la boîte de dialogue File Pool qui apparaît, sélectionnez `capybara1.png`. Le regard de côté du capybara vous fixe maintenant paresseusement depuis le centre de l'écran. Mais bien sûr, nous ne voulons pas toujours montrer le même capybara. Au lieu de cela, nous voulons que l'image dépende des variables `animal` et `pic_nr` que nous avons définies dans le *block_loop* (Étape 5).\n\nNous pouvons utiliser essentiellement la même astuce que celle utilisée pour *animal_sound*, bien que les choses fonctionnent légèrement différemment pour les images. Faites d'abord un clic droit sur le capybara et sélectionnez \"Modifier le script\". Cela vous permet de modifier la ligne suivante de script OpenSesame qui correspond à l'image du capybara :\n\n\tdraw image center=1 file=\"capybara1.png\" scale=1 show_if=always x=0 y=0 z_index=0\n\nMaintenant, changez le nom du fichier image de 'capybara.png' à '[animal][pic_nr].png':\n\n\tdraw image center=1 file=\"[animal][pic_nr].png\" scale=1 show_if=always x=0 y=0 z_index=0\n\nCliquez sur 'Ok' pour appliquer le changement. Le capybara a maintenant disparu, remplacé par une image de remplacement, et OpenSesame vous indique qu'un objet n'est pas affiché, car il est défini à l'aide de variables. Ne vous inquiétez pas, il sera affiché pendant l'expérience !\n\nPour rappeler la tâche au participant, ajoutez également deux cercles de réponse, un marqué \"chien\" sur le côté gauche de l'écran et un marqué \"chat\" sur le côté droit. Je suis sûr que vous pourrez comprendre comment faire cela avec les outils de dessin de SKETCHPAD. Mon interprétation est montrée dans %FigStep9. Notez que ces cercles de réponse sont purement visuels, et nous devons encore définir explicitement les critères de réponse (voir Étape 10).\n\nEnfin, définissez le champ \"Durée\" à \"0\". Cela ne signifie pas que l'image est présentée pendant seulement 0 ms, mais que l'expérience passera à l'élément suivant (*response*) immédiatement. Comme *response* attend une réponse, mais ne change pas ce qui est affiché à l'écran, la cible restera visible jusqu'à ce qu'une réponse soit donnée.\n\n<notranslate>\nfigure:\n id: FigStep9\n source: step9.png\n caption: |\n  Le SKETCHPAD *animal_picture* à la fin de l'étape 8.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 6: Formats d'image**\n\n__Astuce__ -- OpenSesame peut gérer une grande variété de formats d'image. Cependant, certains formats `.bmp` (non standard) sont connus pour poser des problèmes. Si vous trouvez qu'une image `.bmp` n'est pas affichée, vous pouvez envisager d'utiliser un format différent, tel que `.png`. Vous pouvez convertir facilement les images avec des outils gratuits tels que [GIMP].\n\n</div>\n\n\n### Étape 9 : Définir la réponse\n\nOuvrez l'élément *response*. Il s'agit d'un élément KEYBOARD_RESPONSE, qui collecte une seule pression de touche. Il y a quelques options :\n\n- __Réponse correcte__ — passons cela pour l'instant ; nous y reviendrons à l'étape 10.\n- __Réponses autorisées__ est une liste séparée par des points-virgules des touches acceptées. Définissons cela sur *left;right* pour indiquer que seules les touches fléchées gauche et droite sont acceptées. (La touche *escape* met l'expérience en pause et est toujours acceptée !)\n- __Délai__ indique une durée après laquelle la réponse sera définie sur \"Aucune\" et l'expérience continuera. Un délai est important dans notre expérience, car les participants doivent avoir la possibilité de *ne pas* répondre lorsqu'ils voient un capybara. Réglons donc le délai d'attente à 2000.\n- __Vider les touches en attente__ indique que nous devons accepter uniquement les nouvelles pressions de touches. Il est préférable de laisser cette option activée (elle l'est par défaut).\n\n<notranslate>\nfigure:\n id: FigStep10\n source: step10.png\n caption: |\n  La KEYBOARD_RESPONSE *response* à la fin de l'étape 9.\n</notranslate>\n\n\n### Étape 10: Définir la réponse correcte"
  },
  "So far, we haven't defined the correct response for each trial. This is done by defining a `correct_response` variable. You can do this either by creating a `correct_response` column in a LOOP table (here the *block_loop*) and entering the correct responses manually, or by specifying the correct response in a Python INLINE_SCRIPT item—which is what we will do here.\n\nFirst, drag an INLINE_SCRIPT item from the item toolbar and insert it at the top of the *trial_sequence*. (Don't forget to give it a sensible name!) You now see a text editor with two tabs: a *Run* tab, and a *Prepare* tab. You can enter Python code in both tabs, but this code is executed during different phases of the experiment. The *Prepare* phase is executed first whenever a SEQUENCE is executed; this gives all items in the SEQUENCE a chance to perform time consuming operations that could otherwise slow down the experiment at time-sensitive moments. Next, the *Run* phase is executed; this is where the action happens, such as showing a display, collecting a response, etc.\n\nFor more information, see:\n\n- %link:prepare-run%\n\nDefining a correct response is a clear example of something that should be done in the *Prepare* phase. The following script will do the trick:\n\n~~~ .python\nif var.animal == 'dog':\n\tvar.correct_response = 'left'\nelif var.animal == 'cat':\n\tvar.correct_response = 'right'\nelif var.animal == 'capybara':\n\tvar.correct_response = None # A timeout is coded as None!\nelse:\n\traise ValueError('Invalid animal: %s' % var.animal)\n~~~\n\nThis code is almost plain English, but a few pointers may be useful:\n\n- In Python script, experimental variables are not referred to using square brackets (`[my_variable]`), as they are elsewhere in OpenSesame, but as properties of the `var` object (i.e. `var.my_variable`).\n- We also consider the possibility that the animal is neither a dog, a cat, nor a capybara. Of course this should never happen, but by taking this possibility into account, we protect ourselves against typos and other bugs. This is called 'defensive programming'.\n\n\n### Step 11: Define the logger\n\nWe don't need to configure the LOGGER, because its default settings are fine; but let's take a look at it anyway. Click on *logger* in the overview area to open it. You see that the option 'Log all variables (recommended)' is selected. This means that OpenSesame logs everything, which is fine.\n\n<div class='info-box' markdown='1'>\n\n**Background box 8: Always check your data!**\n\n__The one tip to rule them all__ — Always triple-check whether all necessary variables are logged in your experiment! The best way to check this is to run the experiment and investigate the resulting log files.\n\n</div>\n\n### Step 12: Add per-trial feedback\n\nIt is good practice to inform the participant of whether the response was correct or not. To avoid disrupting the flow of the experiment, this type of immediate feedback should be as unobtrusive as possible. Here, we will do this by briefly showing a green fixation dot after a correct response, and a red fixation dot after an incorrect response.\n\nFirst, add two new SKETCHPADs to the end of the *trial_sequence*. Rename the first one to *feedback_correct* and the second one to *feedback_incorrect*. Of course, we want to run only one of these items on any given trial, depending on whether or not the response was correct. To do this, we can make use of the built-in variable `correct`, which has the value 0 after an incorrect response, and 1 after a correct response. (Provided that we have defined `correct_response`, which we did in Step 11.) To tell the *trial_sequence* that the *feedback_correct* item should be called only when the response is correct, we use the following run-if statement:\n\n\t[correct] = 1\n\nThe square brackets around `correct` indicate that this is the name of a variable, and not simply the string 'correct'. Analogously, we use the following run-if statement for the *feedback_incorrect* item:\n\n\t[correct] = 0": {
    "fr": "Jusqu'à présent, nous n'avons pas défini la réponse correcte pour chaque essai. Cela se fait en définissant une variable `correct_response`. Vous pouvez le faire en créant une colonne `correct_response` dans un tableau LOOP (ici, le *block_loop*) et en entrant manuellement les réponses correctes, ou en spécifiant la réponse correcte dans un élément PYTHON INLINE_SCRIPT, ce que nous ferons ici.\n\nPremièrement, faites glisser un élément INLINE_SCRIPT à partir de la barre d'outils des éléments et insérez-le en haut du *trial_sequence*. (N'oubliez pas de lui donner un nom significatif!) Vous voyez maintenant un éditeur de texte avec deux onglets: un onglet *Run* et un onglet *Prepare*. Vous pouvez entrer du code Python dans les deux onglets, mais ce code est exécuté pendant différentes phases de l'expérience. La phase *Prepare* est exécutée en premier chaque fois qu'une SEQUENCE est exécutée ; cela donne à tous les éléments de la SEQUENCE la possibilité d'effectuer des opérations longues qui pourraient autrement ralentir l'expérience à des moments sensibles au temps. Ensuite, la phase *Run* est exécutée ; c'est là que se déroule l'action, comme montrer un affichage, collecter une réponse, etc.\n\nPour plus d'informations, consultez:\n\n- %link:prepare-run %\n\nDéfinir une réponse correcte est un exemple clair de quelque chose qui doit être fait dans la phase *Prepare*. Le script suivant fera l'affaire:\n\n~~~ .python\nif var.animal == 'chien':\n\tvar.correct_response = 'gauche'\nelif var.animal == 'chat':\n\tvar.correct_response = 'droite'\nelif var.animal == 'capybara':\n\tvar.correct_response = None # Un délai d'attente est codé comme None !\nelse:\n\traise ValueError('Animal invalide : %s' % var.animal)\n~~~\n\nCe code est presque en anglais simple, mais quelques conseils peuvent être utiles:\n\n- Dans le script Python, les variables expérimentales ne sont pas mentionnées en utilisant des crochets (`[my_variable]`), comme elles le sont ailleurs dans OpenSesame, mais en tant que propriétés de l'objet `var` (c'est-à-dire `var.my_variable`).\n- Nous considérons également la possibilité que l'animal ne soit ni un chien, ni un chat, ni un capybara. Bien sûr, cela ne doit jamais arriver, mais en tenant compte de cette possibilité, nous nous protégeons contre les fautes de frappe et autres bugs. Cela s'appelle la 'programmation défensive'.\n\n\n### Étape 11: Définir le journal\n\nNous n'avons pas besoin de configurer le LOGGER, car ses paramètres par défaut sont corrects ; mais jetons-y un coup d'œil de toute façon. Cliquez sur *logger* dans la zone d'aperçu pour l'ouvrir. Vous voyez que l'option 'Log all variables (recommended)' est sélectionnée. Cela signifie qu'OpenSesame enregistre tout, ce qui est très bien.\n\n<div class='info-box' markdown='1'>\n\n**Boîte d'informations 8 : Vérifiez toujours vos données !**\n\n__Le seul conseil pour les gouverner tous__ — Vérifiez toujours si toutes les variables nécessaires sont enregistrées dans votre expérience! La meilleure façon de vérifier cela est d'exécuter l'expérience et d'examiner les fichiers de journal résultants.\n\n</div>\n\n### Étape 12: Ajouter un retour d'information par essai\n\nIl est de bon ton d'informer le participant de la réponse était correcte ou non. Pour éviter de perturber le déroulement de l'expérience, ce type de rétroaction immédiate doit être aussi discret que possible. Ici, nous le ferons en montrant brièvement un point de fixation vert après une réponse correcte et un point de fixation rouge après une réponse incorrecte.\n\nPremièrement, ajoutez deux nouveaux SKETCHPADs à la fin du *trial_sequence*. Renommez le premier en *feedback_correct* et le second en *feedback_incorrect*. Bien sûr, nous ne voulons exécuter qu'un seul de ces éléments lors d'un essai donné, en fonction de la réponse correcte ou non. Pour ce faire, nous pouvons utiliser la variable intégrée `correct`, qui a la valeur 0 après une réponse incorrecte et 1 après une réponse correcte. (À condition que nous ayons défini `correct_response`, ce que nous avons fait à l'étape 11.) Pour dire au *trial_sequence* que l'élément *feedback_correct* doit être appelé uniquement lorsque la réponse est correcte, nous utilisons la déclaration run-if suivante:\n\n\t[correct] = 1\n\nLes crochets autour de `correct` indiquent qu'il s'agit du nom d'une variable, et non simplement de la chaîne 'correct'. De même, nous utilisons la déclaration run-if suivante pour l'élément *feedback_incorrect*:\n\n\t[correct] = 0"
  },
  "We still need to give content to the *feedback_correct* and *feedback_incorrect* items. To do this, simply open the items and draw a green or red fixation dot in the center. Also, don't forget to change the durations from 'keypress' to some brief interval, such as 195.\n\nThe *trial_sequence* now looks as shown in %FigStep13.\n\n<notranslate>\nfigure:\n id: FigStep13\n source: step13.png\n caption: |\n  The *trial_sequence* at the end of Step 12.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 9: Conditional statements**\n\nFor more information about conditional 'if' statements, see:\n\n- %link:manual/variables%\n\n</div>\n\n### Step 13: Add instructions and goodbye screens\n\nA good experiment always start with an instruction screen, and ends by thanking the participant for his or her time. The easiest way to do this in OpenSesame is with `form_text_display` items.\n\nDrag two `form_text_display`s into the main *experiment* SEQUENCE. One should be at the very start, and renamed to *form_instructions*. The other should be at the very end, and renamed to *form_finished*. Now simply add some appropriate text to these forms, for example as shown in %FigStep14.\n\n<notranslate>\nfigure:\n id: FigStep14\n source: step14.png\n caption: |\n  The *form_instructions* item at the end of Step 13.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 10: Text**\n\n__Tip__ -- Forms, and text more generally, support a subset of HTML tags to allow for text formatting (i.e. colors, boldface, etc.). This is described here:\n\n- %link:visual%\n\n</div>\n\n### Step 15: Finished!\n\nYour experiment is now finished! Click on the 'Run fullscreen' (`Control+R`) button in the main toolbar to give it a test run. You can also upload the experiment to OSWeb (<http://osweb.cogsci.nl/>) and run it online!\n\n<div class='info-box' markdown='1'>\n\n**Background box 11: Quick run**\n\n__Tip__ — A test run is executed even faster by clicking the orange 'Run in window' button, which doesn't ask you how to save the logfile (and should therefore only be used for testing purposes).\n\n</div>\n\n\n## Extra assignments\n\nThe solutions to these extra assingments can be found in the [experiment file](http://osf.io/jw7dr).\n\n### Extra 1: Add an instruction and goodbye screen\n\nTips:\n\n- SKETCHPAD and FORM_TEXT_DISPLAY can present text\n- Good instructions are brief and concrete\n\n### Extra 2: Analyze the data\n\nTips:\n\n- Run the experiment once on yourself\n- Open the data file in Excel, LibreOffice, or JASP\n\n### Extra 3: Divide the trials into multiple blocks\n\nTips:\n\n- Use a break-if statement to break the loop after (say) 15 trials: `([count_trial_sequence]+1) % 15 = 0`\n- Add a new LOOP-SEQUENCE structure above the *block_loop* to repeat a block of trials multiple times\n- Disable the 'Evaluate on first cycle' option in the *block_loop* so that the break-if statement isn't evaluated when the `count_trial_sequence` variable doesn't yet exist\n- Enable the 'Resume after break' option in the *block_loop* to randomly sample without replacement from the LOOP table\n\n### Extra 4: Add accuracy and average response time feedback after every block\n\nFirst do Extra 3!\n\nTips:\n\n- Use a FEEDBACK item to provide feedback\n- The variables `acc` and `avg_rt` contain the running accuracy and average reaction time\n\n### Extra 5: Counterbalance the response rule\n\nTips:\n\n- The variable `subject_parity` is 'even' or 'odd'\n- This requires a simple INLINE_SCRIPT\n- Make sure that the instructions match the response rule!\n\n\n## References\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314–324. doi:10.3758/s13428-011-0168-7\n{: .reference}": {
    "fr": "Nous avons encore besoin de donner du contenu aux éléments *feedback_correct* et *feedback_incorrect*. Pour ce faire, ouvrez simplement les éléments et tracez un point de fixation vert ou rouge au centre. N'oubliez pas non plus de changer les durées de 'keypress' à un intervalle bref, comme 195.\n\nLa *trial_sequence* ressemble maintenant à ce qui est montré dans %FigStep13.\n\n<notranslate>\nfigure:\n id: FigStep13\n source: step13.png\n caption: |\n  La *trial_sequence* à la fin de l'étape 12.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 9 : Instructions conditionnelles**\n\nPour plus d'informations sur les instructions conditionnelles 'if', consultez :\n\n- %link:manual/variables%\n\n</div>\n\n### Étape 13 : Ajouter des instructions et des écrans d'au revoir\n\nUne bonne expérience commence toujours par un écran d'instruction et se termine par des remerciements au participant pour le temps qu'il a consacré. La manière la plus simple de faire cela dans OpenSesame consiste à utiliser des éléments `form_text_display`.\n\nFaites glisser deux `form_text_display` dans la séquence principale de l' *experiment*. L'un doit être placé tout au début et renommé en *form_instructions*. L'autre doit être placé à la toute fin et renommé en *form_finished*. Ajoutez maintenant un texte approprié à ces formulaires, par exemple comme indiqué dans %FigStep14.\n\n<notranslate>\nfigure:\n id: FigStep14\n source: step14.png\n caption: |\n  L'élément *form_instructions* à la fin de l'étape 13.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 10 : Texte**\n\n__Astuce__ -- Les formulaires, et plus généralement le texte, prennent en charge un sous-ensemble de balises HTML pour permettre la mise en forme du texte (c'est-à-dire les couleurs, le gras, etc.). Ceci est décrit ici :\n\n- %link:visual%\n\n</div>\n\n### Étape 15 : Terminé !\n\nVotre expérience est maintenant terminée ! Cliquez sur le bouton \"Exécuter en plein écran\" (`Control+R`) dans la barre d'outils principale pour effectuer un test. Vous pouvez également télécharger l'expérience sur OSWeb (<http://osweb.cogsci.nl/>) et l'exécuter en ligne !\n\n<div class='info-box' markdown='1'>\n\n**Encadré 11 : Exécution rapide**\n\n__Astuce__ — Une exécution de test est réalisée encore plus rapidement en cliquant sur le bouton orange \"Exécuter dans une fenêtre\", qui ne vous demande pas comment sauvegarder le fichier journal (et ne doit donc être utilisé qu'à des fins de test).\n\n</div>\n\n\n## Travaux pratiques supplémentaires\n\nLes solutions à ces travaux pratiques supplémentaires se trouvent dans le [fichier de l'expérience](http://osf.io/jw7dr).\n\n### Supplément 1 : Ajouter un écran d'instruction et d'au revoir\n\nConseils :\n\n- Les éléments SKETCHPAD et FORM_TEXT_DISPLAY peuvent présenter du texte\n- De bonnes instructions sont brèves et concrètes\n\n### Supplément 2 : Analyser les données\n\nConseils :\n\n- Exécutez l'expérience une fois sur vous-même\n- Ouvrez le fichier de données dans Excel, LibreOffice, ou JASP\n\n### Supplément 3 : Diviser les essais en plusieurs blocs\n\nConseils :\n\n- Utilisez une instruction break-if pour interrompre la boucle après (disons) 15 essais : `([count_trial_sequence]+1) % 15 = 0`\n- Ajoutez une nouvelle structure LOOP-SEQUENCE au-dessus de la *block_loop* pour répéter un bloc d'essais plusieurs fois\n- Désactivez l'option \"Évaluer au premier cycle\" dans la *block_loop* afin que l'instruction break-if ne soit pas évaluée lorsque la variable `count_trial_sequence` n'existe pas encore\n- Activez l'option \"Reprendre après la pause\" dans la *block_loop* pour échantillonner aléatoirement sans remplacement à partir de la table LOOP\n\n### Supplément 4 : Ajouter un retour d'information sur la précision et le temps de réponse moyen après chaque bloc\n\nFaites d'abord le supplément 3 !\n\nConseils :\n\n- Utilisez un élément FEEDBACK pour donner un retour d'information\n- Les variables `acc` et `avg_rt` contiennent la précision en cours et le temps de réaction moyen\n\n### Supplément 5 : Contrebalancer la règle de réponse\n\nConseils :\n\n- La variable `subject_parity` est 'pair' ou 'impair'\n- Cela nécessite un simple script INLINE_SCRIPT\n- Assurez-vous que les instructions correspondent à la règle de réponse !\n\n## Références\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314–324. doi:10.3758/s13428-011-0168-7\n{: .reference}"
  },
  "[OpenSesame runtime for Android]: /getting-opensesame/android\n[slides]: /attachments/rovereto2014-workshop-slides.pdf\n[modulo]: http://en.wikipedia.org/wiki/Modulo_operation\n[pdf]: /rovereto2014/index.pdf\n[gimp]: http://www.gimp.org/\n[capybara_photo]: https://commons.wikimedia.org/wiki/File:Capybara_Hattiesburg_Zoo_(70909b-58)_2560x1600.jpg\n": {
    "fr": "[OpenSesame runtime pour Android]: /getting-opensesame/android\n[diapositives]: /attachments/rovereto2014-workshop-slides.pdf\n[modulo]: http://fr.wikipedia.org/wiki/Opération_modulo\n[pdf]: /rovereto2014/index.pdf\n[gimp]: http://www.gimp.org/\n[photo_de_capybara]: https://commons.wikimedia.org/wiki/File:Capybara_Hattiesburg_Zoo_(70909b-58)_2560x1600.jpg"
  },
  "Kurt Lewin Institute Workshop 2020 Part 2": {
    "fr": "Atelier de l'Institut Kurt Lewin 2020 Partie 2"
  },
  "## Part 2 Kurt Lewin Institute Workshop 2020\n\n<notranslate>\nfigure:\n id: KLI\n source: KLI.png\n</notranslate>\n\n## Gaze cuing\n\nIn this tutorial, you will create a gaze-cuing experiment, as introduced by [Friesen and Kingstone (1998)][references]. In this experiment, a face is presented in the center of the screen (%FigGazeCuing). This face looks either to the right or to the left. A target letter (an 'F' or an 'H') is presented to the left or right of the face. A distractor stimulus (the letter 'X') is presented on the other side of the face. The task is to indicate as quickly as possible whether the target letter is an 'F' or an 'H'. In the *congruent* condition, the face looks at the target. In the *incongruent* condition, the face looks at the distractor.\n\n\n<notranslate>\nfigure:\n id: FigGazeCuing\n source: gaze-cuing.png\n caption: |\n  The gaze-cuing paradigm [(Friesen and Kingstone, 1998)][references] that you will implement in this tutorial. This example depicts a trial in the incongruent condition, because the smiley looks at the distractor ('X') and not at the target ('F').\n</notranslate>\n\n\n## Prediction\n\nAs you may have guessed, the typical finding is that participants respond faster in the congruent condition, compared to to the incongruent condition, even though the direction of gaze is not predictive of the target location. This shows that our attention is automatically guided by other people's gaze, even in situations where this doesn't serve any purpose. (And even when the face is just a smiley!)\n\nThe experiment consists of a practice and an experimental phase. Visual feedback will be presented after every block of trials, and a sound will be played after every incorrect response.\n\n## Experimental design\n\nThis design:\n\n- is *within-subject*, because all participants do all conditions\n- is *fully-crossed* (or full factorial), because all combinations of conditions occur\n- has three factors (or independent variables):\n    - *gaze side* with two levels (left, right)\n    - *target side* with two levels (left, right)\n    - *target letter* with two levels (F, H)\n\n<notranslate>\nfigure:\n id: conditions\n source: conditions.png\n caption: |\n  The factors in the current experiment are fully crossed. This figure shows the four combinations of the factors *gaze side* and *target side*.\n</notranslate>\n\n## Step 1: Create the main sequence\n\nWhen you start OpenSesame, you'll see a 'Get started!' tab, which shows you a list of templates as well as recently opened experiments (%GetStarted). As before, we will use the 'Extended template'.\n\n<notranslate>\nfigure:\n id: GetStarted\n source: get-started.png\n caption: |\n  OpenSesame's welcome window. Here, we use the 'extended template'.\n</notranslate>\n\nAfter opening the extended template, we start by saving our experiment. To do this, click *File* -> *Save*, brows to the appropriate folder and give your experiment a meaningful name.\n\n<notranslate>\nfigure:\n id: FigGetStarted\n source: get-started.png\n caption: |\n  The 'Get started' dialog on OpenSesame start-up.\n</notranslate>\n\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- %Hierarchy schematically shows the structure of the experiment that you will create. If you get confused during the tutorial, you can refer to %Hierarchy to see where you are.\n\n<notranslate>\nfigure:\n id: Hierarchy\n source: hierarchy.png\n caption: |\n  A schematic representation of the structure of the 'Gaze cuing' experiment.\n</notranslate>\n\n</div>\n\n\n__Removing some items from the overvew area__\n\nAs a start, remove the following items from the experimental hierarchy (right mouse click -> remove or shortcult `Del`):\n\n- *about_this_template*\n- *instructions*\n- *end_of_practice*\n- *end_of_experiment*\n\nNext, remove the items from the 'Unused items' bin, by clicking on this part of the overview area and clicking 'Permanently delete unused items'.\n\n__Append a `form_text_display` item for the instruction display__": {
    "fr": "## Partie 2 Atelier Kurt Lewin Institute 2020\n\n<notranslate>\nfigure:\n id: KLI\n source: KLI.png\n</notranslate>\n\n## Orientation du regard\n\nDans ce tutoriel, vous allez créer une expérience d'orientation du regard, comme présenté par [Friesen et Kingstone (1998)][references]. Dans cette expérience, un visage est présenté au centre de l'écran (%FigGazeCuing). Ce visage regarde soit à droite, soit à gauche. Une lettre cible (un 'F' ou un 'H') est présentée à gauche ou à droite du visage. Un stimulus distracteur (la lettre 'X') est présenté de l'autre côté du visage. La tâche consiste à indiquer le plus rapidement possible si la lettre cible est un 'F' ou un 'H'. Dans la condition *congruente*, le visage regarde la cible. Dans la condition *incongruente*, le visage regarde le distracteur.\n\n<notranslate>\nfigure:\n id: FigGazeCuing\n source: gaze-cuing.png\n caption: |\n  Le paradigme d'orientation du regard [(Friesen et Kingstone, 1998)][references] que vous allez mettre en œuvre dans ce tutoriel. Cet exemple dépeint un essai dans la condition incongruente, car le smiley regarde le distracteur ('X') et non la cible ('F').\n</notranslate>\n\n## Prédiction\n\nComme vous l'aurez deviné, la découverte typique est que les participants répondent plus rapidement dans la condition congruente, par rapport à la condition incongruente, même si la direction du regard n'est pas prédictive de l'emplacement de la cible. Cela montre que notre attention est automatiquement guidée par le regard des autres, même dans des situations où cela ne sert à rien. (Et même quand le visage est juste un smiley !)\n\nL'expérience se compose d'une phase de pratique et d'une phase expérimentale. Un feedback visuel sera présenté après chaque bloc d'essais et un son sera joué après chaque réponse incorrecte.\n\n## Conception expérimentale\n\nCe design :\n- est *intra-sujet*, car tous les participants font toutes les conditions\n- est *entièrement croisé* (ou factoriel complet), car toutes les combinaisons de conditions se produisent\n- a trois facteurs (ou variables indépendantes) :\n    - *côté du regard* avec deux niveaux (gauche, droite)\n    - *côté de la cible* avec deux niveaux (gauche, droite)\n    - *lettre cible* avec deux niveaux (F, H)\n\n<notranslate>\nfigure:\n id: conditions\n source: conditions.png\n caption: |\n  Les facteurs de l'expérience actuelle sont entièrement croisés. Cette figure montre les quatre combinaisons des facteurs *côté du regard* et *côté de la cible*.\n</notranslate>\n\n## Étape 1 : Créer la séquence principale\n\nLorsque vous lancez OpenSesame, vous verrez un onglet 'Commencer !' qui vous montre une liste de modèles ainsi que des expériences récemment ouvertes (%GetStarted). Comme précédemment, nous utiliserons le modèle 'Extended template'.\n\n<notranslate>\nfigure:\n id: GetStarted\n source: get-started.png\n caption: |\n  Fenêtre de bienvenue d'OpenSesame. Ici, nous utilisons le modèle \"extended template\".\n</notranslate>\n\nAprès avoir ouvert le modèle étendu, nous commençons par enregistrer notre expérience. Pour ce faire, cliquez sur *Fichier* -> *Enregistrer*, parcourez le dossier approprié et donnez un nom significatif à votre expérience.\n\n<notranslate>\nfigure:\n id: FigGetStarted\n source: get-started.png\n caption: |\n  La boîte de dialogue \"Commencer\" au démarrage d'OpenSesame.\n</notranslate>\n\n\n<div class='info-box' markdown='1'>\n\n__Astuce__ -- %Hierarchy montre schématiquement la structure de l'expérience que vous allez créer. Si vous êtes confus pendant le tutoriel, vous pouvez vous référer à %Hierarchy pour voir où vous en êtes.\n\n<notranslate>\nfigure:\n id: Hierarchy\n source: hierarchy.png\n caption: |\n  Représentation schématique de la structure de l'expérience \"Orientation du regard\".\n</notranslate>\n\n</div>\n\n\n__Suppression de certains éléments de la zone de survol__\n\nPour commencer, supprimez les éléments suivants de la hiérarchie expérimentale (clic droit de la souris -> supprimer ou raccourci `Del`) :\n\n- *about_this_template*\n- *instructions*\n- *end_of_practice*\n- *end_of_experiment*\n\nEnsuite, supprimez les éléments de la corbeille \"Éléments inutilisés\" en cliquant sur cette partie de la zone de présentation et en cliquant sur \"Supprimer définitivement les éléments inutilisés\".\n\n__Ajouter un élément `form_text_display` pour l'affichage des instructions__"
  },
  "As the name suggests, a `form_text_display` is a form that displays text. We are going to use a `form_text_display` (instead of a `sketchpad` item) to give instructions to the participant at the beginning of the experiment.\n\nDrag a `form_text_display` from the item toolbar (under 'Form') onto the *experiment* sequence in the overview area. When you let go, a new `form_text_display` item will be inserted into the *experiment* sequence. Rename this item to *instructions*. Make sure the item appears at the very beginning of the experiment.\n\n__Append a new `form_text_display` item, for the goodbye message__\n\nWhen the experiment is finished, we should say goodbye to the participant. For this we need another `form_text_display` item. Drag a `form_text_display` from the item toolbar onto *experimental_loop*. In the pop-up menu that appears, select 'Insert after experimental_loop'. Rename this item to *goodbye*.\n\nThe overview area of your experiment now looks like %FigStep1. This would be a good time to save your experiment (shortcut: `Ctrl+S`).\n\n<notranslate>\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of the step 1.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ — If you don't like having many tabs open, you can close all tabs except the currently opened one by clicking on the 'Close other tabs' button in the main toolbar (shortcut: `Ctrl+T`).\n\n</div>\n\n## Step 2: Fill the block loop with independent variables\n\nAs the name suggests, *block_loop* corresponds to a single block of trials. In the previous step we created the *block_loop*, but we still need to define the independent variables that will be varied within the block. Our experiment has three independent variables:\n\n- __gaze_cue__ can be 'left' or 'right'.\n- __target_pos__ (the position of the target) can be '-300' or '300'. These values reflect the X-coordinate of the target in pixels (0 = center). Using the coordinates directly, rather than 'left' and 'right', will be convenient when we create the target displays (see Step 5).\n- __target_letter__ (the target letter) can be 'F' or 'H'.\n\nTherefore, our experiment has 2 x 2 x 2 = 8 levels. Although 8 levels is not that many (most experiments will have more), we don't need to enter all possible combinations by hand. Click on *block_loop* in the overview to open its tab. Now click on the 'Full-factorial design' button. In the variable wizard, you simply define all variables by typing the name in the first row and the levels in the rows below the name (see %FigVariableWizard). If you select 'Ok', you will see that *block_loop* has been filled with all 8 possible combinations.\n\nIn the resulting loop table, each row corresponds to one run of *trial_sequence*. Because, in our case, one run of *trial_sequence* corresponds to one trial, each row in our loop table corresponds to one trial. Each column corresponds to one variable, which can have a different value on each trial.\n\n<notranslate>\nfigure:\n id: FigVariableWizard\n source: variable-wizard.png\n caption: |\n  The loop variable wizard in Step 2.\n</notranslate>\n\nBut we are not done yet. We need to add three more variables: the location of the distractor, the correct response, and the congruency.": {
    "fr": "Comme son nom l'indique, un `form_text_display` est un formulaire qui affiche du texte. Nous allons utiliser un `form_text_display` (à la place d'un élément `sketchpad`) pour donner les instructions au participant au début de l'expérience.\n\nFaites glisser un `form_text_display` de la barre d'outils des éléments (sous 'Form') sur la séquence *experiment* dans la zone d'aperçu. Lorsque vous relâchez, un nouvel élément `form_text_display` est inséré dans la séquence *experiment*. Renommez cet élément en *instructions*. Assurez-vous que l'élément apparaît au tout début de l'expérience.\n\n__Ajouter un nouvel élément `form_text_display`, pour le message d'au revoir__\n\nLorsque l'expérience est terminée, nous devons dire au revoir au participant. Pour cela, nous avons besoin d'un autre élément `form_text_display`. Faites glisser un `form_text_display` de la barre d'outils des éléments sur *experimental_loop*. Dans le menu contextuel qui apparaît, sélectionnez 'Insérer après experimental_loop'. Renommez cet élément en *goodbye*.\n\nLa zone d'aperçu de votre expérience ressemble maintenant à %FigStep1. C'est le moment de sauvegarder votre expérience (raccourci : `Ctrl+S`).\n\n<notranslate>\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  La zone d'aperçu à la fin de l'étape 1.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Encadré__\n\n__Astuce__ — Si vous n'aimez pas avoir de nombreux onglets ouverts, vous pouvez fermer tous les onglets sauf celui en cours en cliquant sur le bouton 'Fermer les autres onglets' dans la barre d'outils principale (raccourci : `Ctrl+T`).\n\n</div>\n\n## Étape 2 : Remplissez la boucle de bloc avec des variables indépendantes\n\nComme son nom l'indique, *block_loop* correspond à un seul bloc d'essais. À l'étape précédente, nous avons créé la *block_loop*, mais nous devons encore définir les variables indépendantes qui seront modifiées au sein du bloc. Notre expérience a trois variables indépendantes :\n\n- __gaze_cue__ peut être 'left' ou 'right'.\n- __target_pos__ (la position de la cible) peut être '-300' ou '300'. Ces valeurs reflètent la coordonnée X de la cible en pixels (0 = centre). Utiliser les coordonnées directement, plutôt que 'left' et 'right', sera pratique lorsque nous créerons les affichages cibles (voir étape 5).\n- __target_letter__ (la lettre cible) peut être 'F' ou 'H'.\n\nNotre expérience a donc 2 x 2 x 2 = 8 niveaux. Bien que 8 niveaux ne soient pas si nombreux (la plupart des expériences en auront plus), il ne faut pas entrer toutes les combinaisons possibles à la main. Cliquez sur *block_loop* dans l'aperçu pour ouvrir son onglet. Cliquez maintenant sur le bouton 'Full-factorial design'. Dans l'assistant de variables, vous définissez simplement toutes les variables en tapant le nom dans la première ligne et les niveaux dans les lignes en-dessous du nom (voir %FigVariableWizard). Si vous sélectionnez 'Ok', vous verrez que *block_loop* a été rempli avec les 8 combinaisons possibles.\n\nDans le tableau de boucle résultant, chaque ligne correspond à une exécution de *trial_sequence*. Dans notre cas, une exécution de *trial_sequence* correspond à un essai, chaque ligne de notre tableau de boucle correspond à un essai. Chaque colonne correspond à une variable, qui peut avoir une valeur différente à chaque essai.\n\n<notranslate>\nfigure:\n id: FigVariableWizard\n source: variable-wizard.png\n caption: |\n  L'assistant de variables de boucle à l'étape 2.\n</notranslate>\n\nMais nous n'avons pas encore terminé. Nous devons ajouter trois autres variables : l'emplacement du distracteur, la réponse correcte et la congruence."
  },
  "- __dist_pos__ -- On the first row of the first empty column, enter 'dist_pos'. This automatically adds a new experimental variable named 'dist_pos'. In the rows below, enter '300' wherever 'target_pos' is -300, and '-300' wherever 'target_pos' is 300. In other words, the target and the distractor should be positioned opposite from each other.\n- __correct_response__ -- Create another variable, in another empty column, with the name 'correct_response'. Set 'correct_response' to 'z' where 'target_letter' is 'F', and to 'm' where 'target_letter' is 'H'. This means that:\n    - The participant should press the 'z' key if he/she sees an 'F'\n    - and the 'm' key if he/she sees an 'H'.\n- __congruency__ -- Create another variable with the name 'congruency'. Set 'congruency' to 'congruent' where 'target_pos' is '-300' and 'gaze_cue' is 'left', and where 'target_pos' is '300' and 'gaze_cue' is 'right'. In other words, a trial is congruent if the face looks at the target. Set 'congruency' to 'incronguent' for the trials on which the face looks at the distractor. The 'congruency' variable is not necessary to run the experiment; however, it is useful for analyzing the data later on.\n\nWe need to do one last thing. 'Repeat' is currently set to '1,00'. This means that each cycle will be executed once. So the block now consists of 8 trials, which is a bit short. A reasonable length for a block of trials is 24, so set 'Repeat' to 3,00 (3 repeats x 8 cycles = 24 trials). You don't need to change 'Order', because 'random' is exactly what we want.\n\nThe *block_loop* now looks like %FigStep3. Remember to save your experiment regularly.\n\n<notranslate>\nfigure:\n id: FigStep3\n source: step3.png\n caption: \"The *block_loop* at the end of Step 3.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- You can set 'Repeat' to a non-integer number. For example, by setting 'Repeat' to '0,5', only half the trials (randomly selected) are executed.\n\n</div>\n\n## Step 3: Add images and sound files to the file pool\n\nFor our stimuli, we will use images from file. In addition, we will play a sound if the participant makes an error. For this we need a sound file.\n\nYou can download the required files here (in most webbrowsers you can right-click the links and choose 'Save Link As' or a similar option):\n\n- [gaze_neutral.png](/img/beginner-tutorial/gaze_neutral.png)\n- [gaze_left.png](/img/beginner-tutorial/gaze_left.png)\n- [gaze_right.png](/img/beginner-tutorial/gaze_right.png)\n- [incorrect.ogg](/img/beginner-tutorial/incorrect.ogg)\n\nAfter you have downloaded these files (to your desktop, for example), you can add them to the file pool. If the file pool is not already visible (by default on the right side of the window), click on the 'Show file pool' button in the main toolbar (shortcut: `Ctrl+P`). The easiest way to add the four files to the file pool is to drag them from the desktop (or wherever you have downloaded the files to) into the file pool. Alternatively, you can click on the '+' button in the file pool and add files using the file select dialog that appears. The file pool will be automatically saved with your experiment.\n\nYour file pool now looks like %FigStep4. Remember to save your experiment regularly.\n\n<notranslate>\nfigure:\n id: FigStep4\n source: step4.png\n caption: \"The file pool at the end of Step 4.\"\n</notranslate>\n\n## Step 4: Fill the trial sequence with items\n\nA trial in our experiment looks as follows (see %TrialSeq):\n\n1. __Fixation dot__ -- 750 ms, `sketchpad` item\n2. __Neutral gaze__ -- 750 ms, `sketchpad` item\n3. __Gaze cue__ -- 500 ms, `sketchpad` item\n4. __Target__  -- 0 ms, `sketchpad` item\n5. __Response collection__ \t-- `keyboard_response` item\n6. __Play a sound if response was incorrect__ --  `sampler` item\n7. __Log response to file__ -- `logger` item\n\n\n<notranslate>\nfigure:\n id: TrialSeq\n source: trial_sequence_gaze_cuing.png\n caption: \"A typical trial sequence in the gaze-cuing experiment.\"\n</notranslate>": {
    "fr": "- __dist_pos__ -- Sur la première ligne de la première colonne vide, entrez 'dist_pos'. Cela ajoute automatiquement une nouvelle variable expérimentale nommée 'dist_pos'. Dans les lignes ci-dessous, saisissez '300' partout où 'target_pos' est -300, et '-300' partout où 'target_pos' est 300. En d'autres termes, la cible et le distractor doivent être positionnés à l'opposé l'un de l'autre.\n- __correct_response__ -- Créez une autre variable, dans une autre colonne vide, avec le nom 'correct_response'. Définissez 'correct_response' sur 'z' lorsque 'target_letter' est 'F', et sur 'm' lorsque 'target_letter' est 'H'. Cela signifie que :\n    - Le participant doit appuyer sur la touche 'z' s'il/elle voit un 'F'\n    - et la touche 'm' s'il/elle voit un 'H'.\n- __congruency__ -- Créez une autre variable avec le nom 'congruency'. Définissez 'congruency' sur 'congruent' lorsque 'target_pos' est '-300' et que 'gaze_cue' est 'left', et lorsque 'target_pos' est '300' et que 'gaze_cue' est 'right'. En d'autres termes, un essai est congruent si le visage regarde la cible. Définissez 'congruency' sur 'incronguent' pour les essais où le visage regarde le distractor. La variable 'congruency' n'est pas nécessaire pour exécuter l'expérience ; cependant, elle est utile pour analyser les données ultérieurement.\n\nNous devons faire une dernière chose. 'Répéter' est actuellement réglé sur '1,00'. Cela signifie que chaque cycle sera exécuté une fois. Le bloc se compose donc de 8 essais, ce qui est un peu court. Une longueur raisonnable pour un bloc d'essais est de 24, alors réglez 'Répéter' sur 3,00 (3 répétitions x 8 cycles = 24 essais). Vous n'avez pas besoin de changer 'Ordre', car 'random' est exactement ce que nous voulons.\n\nLe *block_loop* ressemble maintenant à %FigStep3. N'oubliez pas de sauvegarder régulièrement votre expérience.\n\n<notranslate>\nfigure:\n id: FigStep3\n source: step3.png\n caption: \"Le *block_loop* à la fin de l'étape 3.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Astuce__ -- Vous pouvez définir 'Répéter' sur un nombre non entier. Par exemple, en définissant 'Repeat' sur '0,5', seuls la moitié des essais (sélectionnés au hasard) sont exécutés.\n\n</div>\n\n## Étape 3 : Ajouter des images et des fichiers sonores au pool de fichiers\n\nPour nos stimuli, nous utiliserons des images provenant de fichiers. De plus, nous jouerons un son si le participant commet une erreur. Pour cela, nous avons besoin d'un fichier sonore.\n\nVous pouvez télécharger les fichiers requis ici (dans la plupart des navigateurs web, vous pouvez faire un clic droit sur les liens et choisir 'Enregistrer le lien sous' ou une option similaire) :\n\n- [gaze_neutral.png](/img/beginner-tutorial/gaze_neutral.png)\n- [gaze_left.png](/img/beginner-tutorial/gaze_left.png)\n- [gaze_right.png](/img/beginner-tutorial/gaze_right.png)\n- [incorrect.ogg](/img/beginner-tutorial/incorrect.ogg)\n\nUne fois que vous avez téléchargé ces fichiers (sur votre bureau, par exemple), vous pouvez les ajouter au pool de fichiers. Si le pool de fichiers n'est pas déjà visible (par défaut à droite de la fenêtre), cliquez sur le bouton 'Afficher le pool de fichiers' dans la barre d'outils principale (raccourci : `Ctrl+P`). La façon la plus simple d'ajouter les quatre fichiers au pool de fichiers est de les faire glisser du bureau (ou d'où vous les avez téléchargés) dans le pool de fichiers. Vous pouvez également cliquer sur le bouton '+' dans le pool de fichiers et ajouter des fichiers à l'aide de la boîte de dialogue de sélection de fichiers qui apparaît. Le pool de fichiers sera automatiquement enregistré avec votre expérience.\n\nVotre pool de fichiers ressemble maintenant à %FigStep4. N'oubliez pas de sauvegarder régulièrement votre expérience.\n\n<notranslate>\nfigure:\n id: FigStep4\n source: step4.png\n caption: \"Le pool de fichiers à la fin de l'étape 4.\"\n</notranslate>\n\n## Étape 4 : Remplir la séquence d'essais avec des éléments\n\nUn essai dans notre expérience se déroule comme suit (voir %TrialSeq) :\n\n1. __Point de fixation__ -- 750 ms, élément `sketchpad`\n2. __Regard neutre__ -- 750 ms, élément `sketchpad`\n3. __Repère de regard__ -- 500 ms, élément `sketchpad`\n4. __Cible__  -- 0 ms, élément `sketchpad`\n5. __Collecte des réponses__ -- élément `keyboard_response`\n6. __Jouer un son si la réponse est incorrecte__ -- élément `sampler`\n7. __Enregistrer la réponse dans un fichier__ -- élément `logger`\n\n<notranslate>\nfigure:\n id: TrialSeq\n source: trial_sequence_gaze_cuing.png\n caption: \"Une séquence d'essais typique dans l'expérience de l'orientation du regard.\"\n</notranslate>"
  },
  "As you can see in the overview area, our *trial_sequence* already contains one `sketchpad`, as well as a `keyboard_response` item and and a `logger`.\n\n\nTo add the remaining items:\n\nPick up a `sketchpad` from the item toolbar and drag it into the *trial_sequence*. Repeat this two more times, so that *trial_sequence* contains four `sketchpad`s. Next, select and append a `sampler` item. Make sure the `sampler` item appears right after the *keyboard_response*, but before the *logger*.\n\nAgain, we will rename the new items, to make sure that the *trial_sequence* is easy to understand. Rename:\n\n- the first sketchpad to *fixation_dot*\n- the second sketchpad to *neutral_gaze*\n- the third sketchpad to *gaze_cue*\n- the fourth sketchpad to *target*\n- the `sampler` item to *incorrect_sound*\n\nThe *incorrect_sound* item should only be executed if an error was made. To do this, we need to change the 'Run if …' statement to `[correct] = 0` in the *trial_sequence* tab. This works, because the *keyboard_response* item automatically creates a `correct` variable, which is set to `1` (correct), `0` (incorrect), or `undefined` (this relies on the `correct_response` variable that was defined in Step 3). The square brackets indicate that `correct` should be interpreted as the name of a variable and not as text. To change a run-if statement, double click on it (shortcut: `F3`).\n\nThe *trial_sequence* now looks like %FigStep5.\n\n<notranslate>\nfigure:\n id: FigStep5\n source: step5.png\n caption: \"The *trial_sequence* at the end of Step 5.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- Variables and conditional \"if\" statements are very powerful! To learn more about them, see:\n\n- %link:manual/variables%\n\n</div>\n\n## Step 5: Draw the sketchpad items\n\nThe `sketchpad` items that we have created in Step 5 are still blank. It's time to do some drawing!\n\n__Draw the fixation dot__\n\n- Open the *fixation_dot* tab by clicking on this item in the overview area. Because we chose the 'Extended template', OpenSesame already created a fixation point for us. The only thing we need to change is how long the fixation dot will remain on screen\n- Click on the 'Duration' box and change its value to 750 (see %TrialSeq).\n\n__Draw the neutral gaze__\n\nOpen the *neutral_gaze* item. Now select the `image tool` by clicking on the button with the moon-mountain-landscape-like icon. Click on the center of the screen (0, 0). The 'Select file from pool' dialog will appear. Select the file `gaze_neutral.png` and click on the 'Select' button. The neutral gaze image will now stare at you from the center of the screen! Finally, like before, change the 'Duration' field from 'keypress' to '750'.\n\n__Draw the gaze cue__\n\nOpen the *gaze_cue* item, and again select the `image` tool. Click on the center of the screen (0, 0) and select the file `gaze_left.png`.\n\nObviously, we are not done yet, because the gaze cue should not always be 'left', but should depend on the variable `gaze_cue`, which we have defined in Step 3. However, by drawing the `gaze_left.png` image to the sketchpad, we have generated a script that needs only a tiny modification to make sure that the proper image is shown. Click on the 'Select view' button at the top-right of the *gaze_cue* tab and select 'View script'. You will now see the script that corresponds to the sketchpad that we have just created:\n\n~~~ .python\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=always x=0 y=0 z_index=0\n~~~\n\nThe only thing that we need to do is replace `gaze_left.png` with `gaze_[gaze_cue].png`. This means that OpenSesame uses the variable `gaze_cue` (which has the values `left` and `right`) to determine which image should be shown.\n\nWhile we are at it, we might as well change the duration to '500'. The script now looks like this:": {
    "fr": "Comme vous pouvez le voir dans la zone d'aperçu, notre *trial_sequence* contient déjà un `sketchpad`, ainsi qu'un élément `keyboard_response` et un `logger`.\n\n\nPour ajouter les éléments restants :\n\nPrenez un `sketchpad` dans la barre d'outils d'éléments et faites-le glisser sur le *trial_sequence*. Répétez cette opération deux fois de plus, de sorte que *trial_sequence* contient quatre `sketchpad`s. Ensuite, sélectionnez et ajoutez un élément `sampler`. Assurez-vous que l'élément `sampler` apparaît juste après le *keyboard_response*, mais avant le *logger*.\n\nDe nouveau, nous renommerons les nouveaux éléments, pour nous assurer que le *trial_sequence* est facile à comprendre. Renommez :\n\n- le premier sketchpad en *fixation_dot*\n- le deuxième sketchpad en *neutral_gaze*\n- le troisième sketchpad en *gaze_cue*\n- le quatrième sketchpad en *target*\n- l'élément `sampler` en *incorrect_sound*\n\nL'élément *incorrect_sound* ne doit s'exécuter que si une erreur a été commise. Pour ce faire, nous devons modifier l'instruction \"Run if …\" en `[correct] = 0` dans l'onglet *trial_sequence*. Cela fonctionne, car l'élément *keyboard_response* crée automatiquement une variable `correct`, qui est définie sur `1` (correct), `0` (incorrect) ou `undefined` (cela repose sur la variable `correct_response` qui a été définie à l'étape 3). Les crochets indiquent que `correct` doit être interprété comme le nom d'une variable et non comme du texte. Pour modifier une instruction run-if, double-cliquez dessus (raccourci : `F3`).\n\nLe *trial_sequence* ressemble maintenant à %FigStep5.\n\n<notranslate>\nfigure:\n id: FigStep5\n source: step5.png\n caption: \"Le *trial_sequence* à la fin de l'étape 5.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Astuce__ -- Les variables et les instructions conditionnelles \"si\" sont très puissantes ! Pour en savoir plus à leur sujet, consultez :\n\n- %link:manual/variables%\n\n</div>\n\n## Étape 5 : Dessinez les éléments sketchpad\n\nLes éléments `sketchpad` que nous avons créés à l'étape 5 sont encore vierges. Il est temps de dessiner !\n\n__Dessinez le point de fixation__\n\n- Ouvrez l'onglet *fixation_dot* en cliquant sur cet élément dans la zone d'aperçu. Parce que nous avons choisi le « modèle étendu », OpenSesame a déjà créé un point de fixation pour nous. La seule chose que nous devons changer est la durée pendant laquelle le point de fixation restera à l'écran\n- Cliquez sur la case « Duration » et changez sa valeur à 750 (voir %TrialSeq).\n\n__Dessinez le regard neutre__\n\nOuvrez l'élément *neutral_gaze*. Sélectionnez maintenant l'`image tool` en cliquant sur le bouton avec l'icône en forme de paysage lunaire et montagneux. Cliquez sur le centre de l'écran (0, 0). La boîte de dialogue \"Select file from pool\" apparaîtra. Sélectionnez le fichier `gaze_neutral.png` et cliquez sur le bouton \"Sélectionner\". L'image du regard neutre vous regardera maintenant depuis le centre de l'écran ! Enfin, comme précédemment, changez le champ \"Duration\" de \"keypress\" à \"750\".\n\n__Dessinez le regard directionnel__\n\nOuvrez l'élément *gaze_cue* et sélectionnez à nouveau l'`image tool`. Cliquez sur le centre de l'écran (0, 0) et sélectionnez le fichier `gaze_left.png`.\n\nÉvidemment, nous n'avons pas encore terminé, car le regard directionnel ne doit pas toujours être « à gauche », mais doit dépendre de la variable `gaze_cue`, que nous avons définie à l'étape 3. Cependant, en dessinant l'image `gaze_left.png` sur le sketchpad, nous avons généré un script qui nécessite juste une petite modification pour s'assurer que l'image appropriée est affichée. Cliquez sur le bouton « Select view » en haut à droite de l'onglet *gaze_cue* et sélectionnez « View script ». Vous verrez maintenant le script qui correspond au sketchpad que nous venons de créer :\n\n~~~ .python\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=always x=0 y=0 z_index=0\n~~~\n\nLa seule chose que nous devons faire est de remplacer `gaze_left.png` par `gaze_[gaze_cue].png`. Cela signifie qu'OpenSesame utilise la variable `gaze_cue` (qui a les valeurs `left` et `right`) pour déterminer quelle image doit être affichée.\n\nPendant que nous y sommes, nous pouvons également changer la durée à « 500 ». Le script ressemble maintenant à ceci :"
  },
  "~~~ .python\nset duration 500\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_[gaze_cue].png\" scale=1 show_if=always x=0 y=0 z_index=0\n~~~\n\nClick the 'Apply and close' button at the top right to apply your changes to the script and return to the regular item controls. OpenSesame will warn you that the image cannot be shown, because it is defined using variables, and a placeholder image will be shown instead. Don't worry, the correct image will be shown during the experiment!\n\n__Draw the target__\n\nWe want three objects to be part of the target display: the target letter, the distractor letter, and the gaze cue (see %FigGazeCuing). As before, we will start by creating a static display using the `sketchpad` editor. After this, we will only need to make minor changes to the script so that the exact display depends on the variables.\n\nClick on *target* in the overview to open the target tab and like before, draw the `gaze_left.png` image at the center of the screen. Now select the `draw text tool` by clicking on the button with the 'A' icon. The default font size is 18 px, which is a bit small for our purpose, so change the font size to 32 px. Now click on (-320, 0) in the sketchpad (the X-coordinate does not need to be exactly 320, since we will change this to a variable anyway). Enter \"[target_letter]\" in the dialog that appears, to draw the target letter (when drawing text, you can use variables directly). Similarly, click on (320, 0) and draw an 'X' (the distractor is always an 'X').\n\nNow open the script editor by clicking on the 'Select view' button at the top-right of the tab and selecting 'View script'. The script looks like this:\n\n~~~ .python\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=always x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=always text=\"[target_letter]\" x=-320 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=always text=X x=320 y=0 z_index=0\n~~~\n\nLike before, change `gaze_left.png` to `gaze_[gaze_cue].png`. We also need to make the position of the target and the distractor depend on the variables `target_pos` and `dist_pos` respectively. To do this, simply change `-320` to `[target_pos]` and `320` to `[dist_pos]`. Make sure that you leave the `0`, which is the Y-coordinate. The script now looks like this:\n\n~~~ .python\nset duration \"keypress\"\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_[gaze_cue].png\" scale=1 show_if=always x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=always text=\"[target_letter]\" x=[target_pos] y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=always text=X x=[dist_pos] y=0 z_index=0\n~~~\n\nClick on the 'Apply and close' button to apply the script and go back to the regular item controls.\n\nFinally, set the 'Duration' field to '0'. This does not mean that the target is presented for only 0 ms, but that the experiment will advance to the next item (the *keyboard_response*) right away. Since the *keyboard_response* waits for a response, but doesn't change what's on the screen, the target will remain visible until a response has been given.\n\nRemember to save your experiment regularly.\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- Again, make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n## Step 7: Configure the keyboard response item\n\nClick on *keyboard_response* in the overview to open its tab. You see three options: Correct response, Allowed responses, and Timeout.": {
    "fr": "~~~ .python\nset duration 500\nset description \"Affiche les stimuli\"\ndraw image center=1 file=\"gaze_[gaze_cue].png\" scale=1 show_if=toujours x=0 y=0 z_index=0\n~~~\n\nCliquez sur le bouton 'Appliquer et fermer' en haut à droite pour appliquer vos modifications au script et revenir aux contrôles d'élément habituels. OpenSesame vous avertira que l'image ne peut pas être affichée, car elle est définie à l'aide de variables, et une image fictive sera affichée à la place. Ne vous inquiétez pas, la bonne image sera affichée pendant l'expérience!\n\n__Dessiner la cible__\n\nNous voulons que trois objets fassent partie de l'affichage de la cible: la lettre cible, la lettre distractrice et l'indice du regard (voir %FigGazeCuing). Comme précédemment, nous commencerons par créer un affichage statique avec l'éditeur `sketchpad`. Ensuite, nous devrons seulement apporter de légères modifications au script pour que l'affichage exact dépende des variables.\n\nCliquez sur *cible* dans l'aperçu pour ouvrir l'onglet cible et comme auparavant, dessinez l'image `gaze_left.png` au centre de l'écran. Sélectionnez ensuite l'`outil de dessin de texte` en cliquant sur le bouton avec l'icône \"A\". La taille de police par défaut est de 18 px, ce qui est un peu petit pour notre objectif, changez donc la taille de la police à 32 px. Cliquez maintenant sur (-320, 0) dans le sketchpad (la coordonnée X n'a pas besoin d'être exactement 320, car nous la changerons de toute façon pour une variable). Entrez \"[target_letter]\" dans la boîte de dialogue qui apparaît, pour dessiner la lettre cible (lors du dessin du texte, vous pouvez utiliser directement des variables). De même, cliquez sur (320, 0) et dessinez un 'X' (la distractrice est toujours un 'X').\n\nOuvrez maintenant l'éditeur de script en cliquant sur le bouton 'Sélectionner la vue' en haut à droite de l'onglet et en sélectionnant 'Afficher le script'. Le script ressemble à cela :\n\n~~~ .python\nset duration keypress\nset description \"Affiche les stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=toujours x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=non font_family=mono font_italic=non font_size=32 html=yes show_if=toujours text=\"[target_letter]\" x=-320 y=0 z_index=0\ndraw textline center=1 color=black font_bold=non font_family=mono font_italic=non font_size=32 html=yes show_if=toujours text=X x=320 y=0 z_index=0\n~~~\n\nComme auparavant, changez `gaze_left.png` en `gaze_[gaze_cue].png`. Nous devons également rendre la position de la cible et du distracteur dépendante des variables `target_pos` et `dist_pos` respectivement. Pour ce faire, changez simplement `-320` en `[target_pos]` et `320` en `[dist_pos]`. Assurez-vous de laisser le `0`, qui est la coordonnée Y. Le script ressemble maintenant à cela :\n\n~~~ .python\nset duration \"keypress\"\nset description \"Affiche les stimuli\"\ndraw image center=1 file=\"gaze_[gaze_cue].png\" scale=1 show_if=toujours x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=non font_family=mono font_italic=non font_size=32 html=yes show_if=toujours text=\"[target_letter]\" x=[target_pos] y=0 z_index=0\ndraw textline center=1 color=black font_bold=non font_family=mono font_italic=non font_size=32 html=yes show_if=toujours text=X x=[dist_pos] y=0 z_index=0\n~~~\n\nCliquez sur le bouton 'Appliquer et fermer' pour appliquer le script et revenir aux contrôles d'élément habituels.\n\nEnfin, définissez le champ 'Durée' sur '0'. Cela ne signifie pas que la cible est présentée pendant seulement 0 ms, mais que l'expérience passe à l'élément suivant (la *réponse au clavier*) immédiatement. Étant donné que la *réponse au clavier* attend une réponse, mais ne modifie pas ce qui est à l'écran, la cible restera visible jusqu'à ce qu'une réponse ait été donnée.\n\nN'oubliez pas d'enregistrer régulièrement votre expérience.\n\n<div class='info-box' markdown='1'>\n\n__Astuce__ -- Encore une fois, assurez-vous que la couleur (de premier plan) est réglée sur noir. Sinon, vous dessinerez du blanc sur du blanc et vous ne verrez rien!\n\n</div>\n\n## Étape 7: Configurer l'élément de réponse au clavier\n\nCliquez sur *keyboard_response* dans l'aperçu pour ouvrir son onglet. Vous voyez trois options: Réponse correcte, Réponses autorisées et Délai."
  },
  "We have already set the `correct_response` variable in Step 3. Unless we explicitly specify a correct response, OpenSesame automatically uses the `correct_response` variable if it is available. Therefore, we don't need to change the 'Correct response' field here.\n\nWe do need to set the allowed responses. Enter 'z;m' in the allowed-responses field (or other keys if you have chosen different response keys). The semicolon is used to separate responses. The `keyboard_response` item now only accepts 'z' and 'm' keys. All other key presses are ignored, with the exception of 'escape', which pauses the experiment.\n\nWe also want to set a timeout, which is the maximum interval that the KEYBOARD_RESPONSE waits before deciding that the response is incorrect and setting the 'response' variable to 'None'. '2000' (ms) is a good value.\n\nThe content of the *keyboard_response* item now looks like %FigStep7.\n\n<notranslate>\nfigure:\n id: FigStep7\n source: step7.png\n caption: \"The *keyboard_response* at the end of Step 7.\"\n</notranslate>\n\n## Step 8: Configure the incorrect (sampler) item\n\nThe *incorrect_sound* item doesn't need much work: We only need to select the sound that should be played. Click on *incorrect_sound* in the overview to open its tab. Click on the 'Browse' button and select `incorrect.ogg` from the file pool.\n\nThe sampler now looks like %FigStep8.\n\n<notranslate>\nfigure:\n id: FigStep8\n source: step8.png\n caption: \"The *incorrect_sound* item at the end of Step 8.\"\n</notranslate>\n\n## Step 9: Configure the variable logger\n\nActually, we don't need to configure the `logger` item, but let's take a look at it anyway. Click on *logger* in the overview to open its tab. You see that the option 'Log all variables (recommended)' is selected. This means that OpenSesame logs everything, which is fine.\n\n<div class='info-box' markdown='1'>\n\n__The one tip to rule them all__ -- Always triple-check whether all the necessary variables are logged in your experiment! The best way to check this is to run the experiment and investigate the resulting log files.\n\n</div>\n\n## Step 10: Draw the feedback item\n\nAfter every block of trials, we want to present feedback to the participant to let him/ her know how well he/ she is doing. Therefore, in Step 2, we added a `feedback` item, simply named *feedback* to the end of *block_sequence*.\n\nClick on *feedback* in the overview to open its tab, select the draw text tool, change the foreground color to 'black' (if it isn't already), and click at (0, 0). Now enter the following text:\n\n    End of block\n\n    Your average response time was [avg_rt] ms\n    Your accuracy was [acc] %\n\n    Press any key to continue\n\nBecause we want the feedback item to remain visible as long as the participant wants (i.e. until he/ she presses a key), we leave 'Duration' field set to 'keypress'.\n\nThe feedback item now looks like %FigStep_10.\n\n<notranslate>\nfigure:\n id: FigStep_10\n source: step10.png\n caption: \"The feedback item at the end of Step 10.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Feedback and variables__ -- Response items automatically keep track of the accuracy and average response time of the participant in the variables 'acc' (synonym: 'accuracy') and 'avg_rt' (synonym: 'average_response_time') respectively. See also:\n\n- %link:manual/variables%\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n## Step 11: Set the length of the practice phase and experimental phase\n\nWe have previously created the *practice_loop* and *experiment_loop* items, which both call *block_sequence* (i.e., a block of trials). However, right now they call *block_sequence* only once, which means that both the practice and the experimental phase consist of only a single block of trials.\n\nClick on *practice_loop* to open its tab and set 'Repeat' to '2,00'. This means that the practice phase consists of two blocks.": {
    "fr": "Nous avons déjà défini la variable `correct_response` à l'étape 3. À moins de spécifier explicitement une réponse correcte, OpenSesame utilise automatiquement la variable `correct_response` si elle est disponible. Par conséquent, nous n'avons pas besoin de modifier le champ 'Réponse correcte' ici.\n\nNous devons définir les réponses autorisées. Entrez 'z;m' dans le champ des réponses autorisées (ou d'autres touches si vous avez choisi des touches de réponse différentes). Le point-virgule est utilisé pour séparer les réponses. L'élément `keyboard_response` accepte maintenant uniquement les touches 'z' et 'm'. Toutes les autres pressions de touches sont ignorées, à l'exception de 'échap', qui met en pause l'expérience.\n\nNous souhaitons également définir un délai d'attente, qui est l'intervalle maximum que KEYBOARD_RESPONSE attend avant de décider que la réponse est incorrecte et de définir la variable 'response' sur 'None'. '2000' (ms) est une bonne valeur.\n\nLe contenu de l'élément *keyboard_response* ressemble maintenant à %FigStep7.\n\n<notranslate>\nfigure:\n id: FigStep7\n source: step7.png\n caption: \"Le *keyboard_response* à la fin de l'étape 7.\"\n</notranslate>\n\n## Étape 8 : Configurez l'élément incorrect (sampler)\n\nL'élément *incorrect_sound* ne nécessite pas beaucoup de travail : il suffit de sélectionner le son à jouer. Cliquez sur *incorrect_sound* dans l'aperçu pour ouvrir son onglet. Cliquez sur le bouton 'Parcourir' et sélectionnez `incorrect.ogg` dans la banque de fichiers.\n\nL'échantillonneur ressemble maintenant à %FigStep8.\n\n<notranslate>\nfigure:\n id: FigStep8\n source: step8.png\n caption: \"L'élément *incorrect_sound* à la fin de l'étape 8.\"\n</notranslate>\n\n## Étape 9 : Configurez l'enregistreur de variables\n\nEn réalité, nous n'avons pas besoin de configurer l'élément `logger`, mais jetons-y un coup d'œil. Cliquez sur *logger* dans l'aperçu pour ouvrir son onglet. Vous voyez que l'option 'Log all variables (recommended)' est sélectionnée. Cela signifie qu'OpenSesame enregistre tout, ce qui est très bien.\n\n<div class='info-box' markdown='1'>\n\n__Le conseil ultime__ -- Vérifiez toujours trois fois si toutes les variables nécessaires sont enregistrées dans votre expérience ! La meilleure façon de vérifier cela est de lancer l'expérience et d'examiner les fichiers journaux résultants.\n\n</div>\n\n## Étape 10 : Dessiner l'élément de feedback\n\nAprès chaque bloc d'essais, nous souhaitons présenter un feedback au participant pour lui faire savoir comment il se débrouille. C'est pourquoi, à l'étape 2, nous avons ajouté un élément `feedback`, simplement nommé *feedback* à la fin  de *block_sequence*.\n\nCliquez sur *feedback* dans l'aperçu pour ouvrir son onglet, sélectionnez l'outil de dessin de texte, changez la couleur de premier plan en 'noir' (si ce n'est pas déjà le cas) et cliquez sur (0, 0). Entrez maintenant le texte suivant :\n\n    Fin du bloc\n\n    Votre temps de réponse moyen était de [avg_rt] ms\n    Votre précision était de [acc] %\n\n    Appuyez sur n'importe quelle touche pour continuer\n\nComme nous voulons que l'élément de feedback reste visible aussi longtemps que le participant le souhaite (c'est-à-dire jusqu'à ce qu'il appuie sur une touche), nous laissons le champ 'Durée' défini sur 'keypress'.\n\nL'élément de feedback ressemble maintenant à %FigStep_10.\n\n<notranslate>\nfigure:\n id: FigStep_10\n source: step10.png\n caption: \"L'élément de feedback à la fin de l'étape 10.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Boîte d'arrière-plan__\n\n__Rétroaction et variables__ -- Les éléments de réponse suivent automatiquement la précision et le temps de réponse moyen du participant dans les variables 'acc' (synonyme : 'précision') et 'avg_rt' (synonyme : 'average_response_time') respectivement. Voir aussi :\n\n- %link:manual/variables%\n\n__Conseil__ -- Assurez-vous que la couleur (de premier plan) est réglée sur noir. Sinon, vous dessinerez du blanc sur blanc et vous ne verrez rien !\n\n</div>\n\n## Étape 11 : Définir la durée de la phase de pratique et de la phase expérimentale\n\nNous avons précédemment créé les éléments *practice_loop* et *experiment_loop*, qui appellent tous deux *block_sequence* (c'est-à-dire un bloc d'essais). Cependant, pour le moment, ils appellent *block_sequence* seulement une fois, ce qui signifie que les phases de pratique et expérimentale se composent d'un seul bloc d'essais.\n\nCliquez sur *practice_loop* pour ouvrir son onglet et définissez 'Répéter' sur '2,00'. Cela signifie que la phase de pratique se compose de deux blocs."
  },
  "Click on *experimental_loop* to open its tab and set 'Repeat' to '8,00'. This means that the experimental phase consists of eight blocks.\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- You can create a variable `practice` in both *practice_loop* and *experimental_loop* and set it to 'yes' and 'no' respectively. This is an easy way of keeping track of which trials were part of the practice phase.\n\n</div>\n\n## Step 12: Write the instruction, end_of_practice and end_of_experiment forms\n\nI think you can handle this step your own! Simply open the appropriate items and add some text to present instructions, an end-of-practice message, and an end-of-experiment message.\n\n## Step 13: Run the experiment!\n\nYou're done! Click on the 'Run in window' (shortcut: `Ctrl+W`) or 'Run fullscreen' (shortcut: `Ctrl+R`) buttons in the toolbar to run your experiment.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- A test run is executed even faster by clicking the orange 'Run in window' button (shortcut: `Ctrl+Shift+W`), which doesn't ask you how to save the logfile (and should therefore only be used for testing purposes).\n\n</div>\n\n## References\n\n<div class='reference' markdown='1'>\n\nFriesen, C. K., & Kingstone, A. (1998). The eyes have it! Reflexive orienting is triggered by nonpredictive gaze. *Psychonomic Bulletin & Review*, *5*, 490–495. doi:10.3758/BF03208827\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html\n[gimp]: http://www.gimp.org/\n[audacity]: http://audacity.sourceforge.net/\n[python inline scripting]: /python/about\n": {
    "fr": "Cliquez sur *experimental_loop* pour ouvrir son onglet et définir 'Répéter' sur '8,00'. Cela signifie que la phase expérimentale comprend huit blocs.\n\n<div class='info-box' markdown='1'>\n\n__Astuce__ -- Vous pouvez créer une variable `practice` dans *practice_loop* et *experimental_loop* et la définir respectivement sur 'oui' et 'non'. C'est un moyen simple de suivre les essais faisant partie de la phase de pratique.\n\n</div>\n\n## Étape 12: Rédigez les formulaires d'instruction, de fin_de_pratique et de fin_d'expérience\n\nJe pense que vous pouvez gérer cette étape tout seul ! Ouvrez simplement les éléments appropriés et ajoutez du texte pour présenter des instructions, un message de fin de pratique et un message de fin d'expérience.\n\n## Étape 13: Lancez l'expérience !\n\nC'est terminé ! Cliquez sur les boutons 'Run in window' (raccourci : `Ctrl+W`) ou 'Run fullscreen' (raccourci : `Ctrl+R`) dans la barre d'outils pour lancer votre expérience.\n\n<div class='info-box' markdown='1'>\n\n__Boîte d'arrière-plan__\n\n__Astuce__ -- Un test est exécuté encore plus rapidement en cliquant sur le bouton orange 'Run in window' (raccourci : `Ctrl+Shift+W`), qui ne vous demandera pas comment enregistrer le fichier journal (et ne doit donc être utilisé qu'à des fins de test).\n\n</div>\n\n## Références\n\n<div class='reference' markdown='1'>\n\nFriesen, C. K., & Kingstone, A. (1998). The eyes have it! Reflexive orienting is triggered by nonpredictive gaze. *Psychonomic Bulletin & Review*, *5*, 490–495. doi:10.3758/BF03208827\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\n</div>\n\n[références]: #références\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html\n[gimp]: http://www.gimp.org/\n[audacity]: http://audacity.sourceforge.net/\n[python inline scripting]: /python/about"
  },
  "OpenSesame": {
    "fr": "OpenSesame",
    "de": "OpenSesame"
  },
  "\nOpenSesame is a program to create experiments for psychology, neuroscience, and experimental economics. The latest $status$ version is $version$ *$codename$*, released on $release-date$ ([release notes](http://osdoc.cogsci.nl/$branch$/notes/$notes$)).\n\n<div class=\"btn-group\" role=\"group\" aria-label=\"...\">\n  <a role=\"button\" class=\"btn btn-success\" href=\"%url:download%\">\n\t\t<span class=\"glyphicon glyphicon-download\" aria-hidden=\"true\"></span>\n\t\tDownload\n\t </a>\n  <a role=\"button\" class=\"btn btn-success\" href=\"%url:beginner%\">\n  <span class=\"glyphicon glyphicon-education\" aria-hidden=\"true\"></span>\n  \tTutorial\n  </a>\n  <a role=\"button\" class=\"btn btn-success\" href=\"https://professional.cogsci.nl/\">\n  <span class=\"glyphicon glyphicon-comment\" aria-hidden=\"true\"></span>\n  Get support</a>\n</div>\n\n## Features\n\n- __A user-friendly interface__ — a modern, professional, and easy-to-use graphical [interface](%link:manual/interface%)\n- __Online experiments__ — run your experiment in a browser with [OSWeb](%link:manual/osweb/workflow%)\n- __Python__ — add the power of [Python](%link:manual/python/about%) to your experiment\n- __JavaScript__ — add the power of [JavaScript](%link:manual/python/about%) to your experiment\n- __Use your devices__ — use your [eye tracker](%link:pygaze%), [button box](%link:buttonbox%), [EEG equipment](%link:parallel%), and more.\n- __Free__ — released under the GPL3\n- __Crossplatform__ — Windows, Mac OS, and Linux\n\n## Citations\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nMathôt, S., & March, J. (2022). Conducting linguistic experiments online with OpenSesame and OSWeb. *Language Learning*. doi:10.1111/lang.12509\n<br /><small>[Related preprint (not identical to published manuscript)](https://doi.org/10.31234/osf.io/wnryc)</small>\n": {
    "fr": "OpenSesame est un programme pour créer des expériences en psychologie, neurosciences et économie expérimentale. La dernière version $status$ est la version $version$ *$codename$*, publiée le $release-date$ ([notes de version](http://osdoc.cogsci.nl/$branch$/notes/$notes$)).\n\n<div class=\"btn-group\" role=\"group\" aria-label=\"...\">\n  <a role=\"button\" class=\"btn btn-success\" href=\"%url:download%\">\n\t\t<span class=\"glyphicon glyphicon-download\" aria-hidden=\"true\"></span>\n\t\tTélécharger\n\t </a>\n  <a role=\"button\" class=\"btn btn-success\" href=\"%url:beginner%\">\n  <span class=\"glyphicon glyphicon-education\" aria-hidden=\"true\"></span>\n  \tTutoriel\n  </a>\n  <a role=\"button\" class=\"btn btn-success\" href=\"https://professional.cogsci.nl/\">\n  <span class=\"glyphicon glyphicon-comment\" aria-hidden=\"true\"></span>\n  Obtenir de l'aide</a>\n</div>\n\n## Fonctionnalités\n\n- __Une interface conviviale__ — une [interface](%link:manual/interface%) graphique moderne, professionnelle et facile à utiliser\n- __Expériences en ligne__ — exécutez votre expérience dans un navigateur avec [OSWeb](%link:manual/osweb/workflow%)\n- __Python__ — ajoutez la puissance de [Python](%link:manual/python/about%) à votre expérience\n- __JavaScript__ — ajoutez la puissance de [JavaScript](%link:manual/python/about%) à votre expérience\n- __Utilisez vos appareils__ — utilisez votre [eye-tracker](%link:pygaze%), [boîtier à boutons](%link:buttonbox%), [équipement EEG](%link:parallel%), et plus encore.\n- __Gratuit__ — publié sous licence GPL3\n- __Multiplateforme__ — Windows, Mac OS et Linux\n\n## Références\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame : Un constructeur d'expériences open-source et graphique pour les sciences sociales. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nMathôt, S., & March, J. (2022). Réalisation d'expériences linguistiques en ligne avec OpenSesame et OSWeb. *Language Learning*. doi: 10.1111/lang.12509\n<br /><small>[Pré-impression associée (pas identique au manuscrit publié)](https://doi.org/10.31234/osf.io/wnryc)</small>"
  },
  "Siena 2018 workshop (Day 2)": {
    "fr": "Atelier Siena 2018 (Jour 2)"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n## About the workshop\n\nThis OpenSesame workshop will take place at the University of Siena on February 22 and 23, 2018. This booklet corresponds to day 2.\n\nThe workshop consisted of two main parts. In the first part, corresponding to the Tutorial below, we created a complete experiment together. In the second part, corresponding to the Extra assignments below, the workshop participants improved this experiment by themselves, based on a few suggestions.\n\n- For Day 1, see: <http://osdoc.cogsci.nl/3.2/siena2018day1>\n\n\n## About this tutorial\n\nThis tutorial assumes a basic knowledge of OpenSesame and, for some parts, Python. Therefore, if you're not familiar with OpenSesame or Python, I recommend that you walk through the beginner and intermediate tutorials before continuing with this tutorial:\n\n- %link:beginner%\n- %link:intermediate%\n\nIn this tutorial, you will learn the following:\n\n- Eye tracking with PyGaze\n- Doing things in parallel with `coroutines`\n- Using advanced `loop` operations\n\n\n## About the experiment\n\nIn this tutorial, we will implement a *visual-world paradigm*, which was introduced by Cooper (1974; for a review see also Huettig, Rommers, and Meyer, 2011). In this paradigm, participants hear a spoken sentence, while they are looking at a display with several objects. We will use four separate objects presented in the four quadrants of the display (%FigParadigm).\n\n\n<notranslate>\nfigure:\n id: FigParadigm\n source: visual-world-paradigm.svg\n caption: >\n  A schematic of our trial sequence. This is an example of a Full Match trial, because the target object (the apple) is directly mentioned in the spoken sentence. Stimuli taken from the [BOSS](https://sites.google.com/site/bosstimuli/) stimuli (Brodier et al., 2010).\n</notranslate>\n\n\nThe spoken sentence refers to one or more of the objects. For example, an apple (the target object) may be shown while the spoken sentence \"at breakfast, the girl ate an apple\" is played back. In this case, the target matches the sentence fully. The sentence may also refer indirectly to a shown object. For example, an apple (again the target object) may be shown while the spoken sentence \"at breakfast, the girl ate a banana\" is played back. In this case, the target matches the sentence semantically, because a banana and an apple are both fruits that a girl may eat at breakfast.\n\nDuring the experiment, eye position is recorded, and the proportion of fixations on target and non-target objects is measured over time. The typical finding is then that the eyes are drawn toward target objects; that is, participants look mostly at objects that are directly or indirectly referred to by the spoken sentence. And the more direct the reference, the stronger this effect.\n\nNow let's make this more formal. Our experiment will have the following design:\n\n- One factor (Target Match) with two levels (Full or Semantic), varied within subjects. In the Full Match condition, the target object is directly mentioned in the sentence. In the Semantic Match condition, the target object is semantically related to an object that is mentioned in the sentence.\n- We have 16 spoken sentences and sixteen target objects. Every sentence and every target object is shown twice: once in the Full Match condition, and once in the Semantic Match condition.\n- We have 16 × 3 = 48 distractor objects, each of which (like the targets) is shown twice.\n- Each trial starts with a fixation dot for 1 s, followed by the presentation of the stimuli, followed 1 s later by the onset of the spoken sentence. The trial ends 5 s later.\n\n\n## The tutorial\n\n\n### Step 1: Download and start OpenSesame\n\nOpenSesame is available for Windows, Linux, Mac OS (experimental), and Android (runtime only). This tutorial is written for OpenSesame 3.2.X *Kafkaesque Koffka*. To be able to use PyGaze, you should download the Python 2.7 version (which is the default). You can download OpenSesame from here:\n\n- %link:download%": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de l'atelier\n\nCet atelier OpenSesame se déroulera à l'Université de Sienne les 22 et 23 février 2018. Ce livret correspond au jour 2.\n\nL'atelier se composait de deux parties principales. Dans la première partie, correspondant au tutoriel ci-dessous, nous avons créé une expérience complète ensemble. Dans la deuxième partie, correspondant aux missions supplémentaires ci-dessous, les participants à l'atelier ont amélioré cette expérience par eux-mêmes, sur la base de quelques suggestions.\n\n- Pour le jour 1, voir : <http://osdoc.cogsci.nl/3.2/siena2018day1>\n\n\n## À propos de ce tutoriel\n\nCe tutoriel suppose une connaissance de base d'OpenSesame et, pour certaines parties, de Python. Par conséquent, si vous n'êtes pas familier avec OpenSesame ou Python, je vous recommande de passer par les tutoriels pour débutants et intermédiaires avant de continuer avec ce tutoriel :\n\n- %link:beginner%\n- %link:intermediate%\n\nDans ce tutoriel, vous apprendrez ce qui suit :\n\n- Eye tracking avec PyGaze\n- Faire des choses en parallèle avec `coroutines`\n- Utilisation de `loop` avancé\n\n\n## À propos de l'expérience\n\nDans ce tutoriel, nous mettrons en œuvre un *paradigme du monde visuel*, qui a été introduit par Cooper (1974 ; pour une revue voir aussi Huettig, Rommers et Meyer, 2011). Dans ce paradigme, les participants entendent une phrase parlée, alors qu'ils regardent un écran avec plusieurs objets. Nous utiliserons quatre objets distincts présentés dans les quatre quadrants de l'affichage (%FigParadigm).\n\n\n<notranslate>\nfigure :\n id: FigParadigm\n source: visual-world-paradigm.svg\ncaption: >\n  Un schéma de notre séquence d'essai. Il s'agit d'un exemple d'essai de correspondance complète, car l'objet cible (la pomme) est directement mentionné dans la phrase parlée. Stimuli tirés des stimuli du [BOSS](https://sites.google.com/site/bosstimuli/) (Brodier et al., 2010).\n</notranslate>\n\n\nLa phrase parlée fait référence à un ou plusieurs objets. Par exemple, une pomme (l'objet cible) peut être représentée tandis que la phrase parlée \"au petit déjeuner, la fille a mangé une pomme\" est reproduite. Dans ce cas, la cible correspond à la phrase en totalité. La phrase peut également faire référence indirectement à un objet montré. Par exemple, une pomme (encore l'objet cible) peut être représentée tandis que la phrase parlée \"au petit déjeuner, la fille a mangé une banane\" est reproduite. Dans ce cas, la cible correspond à la phrase sémantiquement, car une banane et une pomme sont tous deux des fruits qu'une fille peut manger au petit déjeuner.\n\nPendant l'expérience, la position des yeux est enregistrée, et la proportion de fixations sur les objets cibles et non cibles est mesurée dans le temps. La constatation typique est alors que les yeux sont attirés par les objets cibles ; c'est-à-dire que les participants regardent principalement les objets qui sont directement ou indirectement mentionnés dans la phrase parlée. Et plus la référence est directe, plus cet effet est fort.\n\nFormalisons cela maintenant. Notre expérience aura la conception suivante :\n\n- Un facteur (correspondance cible) avec deux niveaux (complet ou sémantique), varié entre les sujets. Dans la condition de correspondance complète, l'objet cible est directement mentionné dans la phrase. Dans la condition de correspondance sémantique, l'objet cible est sémantiquement lié à un objet qui est mentionné dans la phrase.\n- Nous avons 16 phrases parlées et seize objets cibles. Chaque phrase et chaque objet cible est montré deux fois : une fois dans la condition de correspondance complète, et une fois dans la condition de correspondance sémantique.\n- Nous avons 16 x 3 = 48 objets distracteurs, dont chacun (comme les cibles) est montré deux fois.\n- Chaque essai commence par un point de fixation pendant 1 s, suivi de la présentation des stimuli, suivi 1 s plus tard par l'apparition de la phrase parlée. L'essai se termine 5 s plus tard.\n\n\n## Le tutoriel\n\n\n### Étape 1 : Télécharger et démarrer OpenSesame\n\nOpenSesame est disponible pour Windows, Linux, Mac OS (expérimental) et Android (runtime uniquement). Ce tutoriel est écrit pour OpenSesame 3.2.X *Kafkaesque Koffka*. Pour pouvoir utiliser PyGaze, vous devez télécharger la version Python 2.7 (qui est celle par défaut). Vous pouvez télécharger OpenSesame ici :\n\n- %link:download%"
  },
  "(If you start OpenSesame for the first time, you will see a Welcome tab. Dismiss this tab.) When you start OpenSesame, you will be given a choice of template experiments, and (if any) a list of recently opened experiments (see %FigStartUp). Click on 'Default Template' to start with an almost empty experiment.\n\n\n<notranslate>\nfigure:\n id: FigStartUp\n source: start-up.png\n caption: |\n  The OpenSesame window on start-up.\n</notranslate>\n\n\n### Step 2: Build the main structure of the experiment\n\nFor now, build the following main structure for your experiment (see also %FigMainStructure):\n\n1. We start with an instructions screen. This will be a `sketchpad`.\n2. Next, we run one block of trials. This will be a single `sequence`, corresponding to a single trial, inside a single `loop`, corresponding to a block of trials. You can leave the trial sequence empty for now!\n3. Finally, we end with a goodbye screen.\n\nWe also need to change the foreground color of the experiment to black, and the background color to white. This is because we will use images that have a white background, and we don't want these images to stand out!\n\nAnd don't forget to give your experiment a sensible name, and to save it!\n\n\n<notranslate>\nfigure:\n id: FigMainStructure\n source: main-structure.png\n caption: |\n  The main structure of the experiment.\n</notranslate>\n\n\n### Step 3: Import files into the file pool\n\nFor this experiment we need stimuli: sound files for the spoken sentences, and image files for the objects. Download these from the link below, extract the `zip` file, and place the stimuli in the file pool of your experiment (see also %FigFilePool).\n\n- %static:attachments/visual-world/stimuli.zip%\n\n<notranslate>\nfigure:\n id: FigFilePool\n source: file-pool.png\n caption: |\n  The file pool of your experiment after all stimuli have been added.\n</notranslate>\n\n\n### Step 4: Define experimental variables in the block_loop\n\nThe *block_loop* is where we define the experimental variables, by entering them into a table, where each row corresponds to a trial, and each column corresponds to an experimental variable.\n\nFor now, we define only the Full Match condition, in which the target object is directly mentioned in the spoken sentence. (We will add the Semantic Match condition as part of the Extra Assignments.)\n\nWe need the following variables. First, simply add columns to the loop table, without giving the rows any content.\n\n- `pic1` — the name of the first picture (e.g. 'apple.jpg')\n- `pic2` — the name of the second picture\n- `pic3` — the name of the third picture\n- `pic4` — the name of the fourth picture\n- `pos1` — the position of the first picture (e.g. 'topleft')\n- `pos2` — the position of the first picture\n- `pos3` — the position of the first picture\n- `pos4` — the position of the first picture\n- `sound` — the name of a sound file that contains a spoken sentence (e.g. 'apple.ogg').\n\nThe target object will always correspond to `pic1`. We have the following target objects; that is, for the following objects, we have sound files that refer to them. Simply copy-paste the following list into the `pic1` column of the table:\n\n~~~\napple.jpg\narmchair.jpg\nbanana.jpg\nbear.jpg\ncard.jpg\ncello.jpg\nchicken.jpg\ncookie.jpg\ncroissant.jpg\ndice.jpg\negg.jpg\nguitar.jpg\nkeyboard.jpg\nmouse.jpg\nsofa.jpg\nwolf.jpg\n~~~\n\nAnd do the same for the sound files:\n\n~~~\napple.ogg\narmchair.ogg\nbanana.ogg\nbear.ogg\ncard.ogg\ncello.ogg\nchicken.ogg\ncookie.ogg\ncroissant.ogg\ndice.ogg\negg.ogg\nguitar.ogg\nkeyboard.ogg\nmouse.ogg\nsofa.ogg\nwolf.ogg\n~~~\n\nThe rest of the pictures are distractors. Copy-paste the following list into the `pic2`, `pic3`, and `pic4` columns, in such a way that each column has exactly 16 rows. (If you accidentally make the table longer than 16 rows, simply select the extraneous rows, right-click and delete them.)": {
    "fr": "(Si vous démarrez OpenSesame pour la première fois, vous verrez un onglet de bienvenue. Fermez cet onglet.) Lorsque vous démarrez OpenSesame, on vous proposera des expériences modèles et (le cas échéant) une liste des expériences récemment ouvertes (voir %FigStartUp). Cliquez sur \"Modèle par défaut\" pour commencer avec une expérience presque vide.\n\n<notranslate>\nfigure :\n id : FigStartUp\n source : start-up.png\n légende : |\n  La fenêtre OpenSesame au démarrage.\n</notranslate>\n\n### Étape 2 : Construire la structure principale de l'expérience\n\nPour l'instant, construisez la structure principale suivante pour votre expérience (voir également %FigMainStructure) :\n\n1. On commence par un écran d'instructions. Ce sera un `sketchpad`.\n2. Ensuite, nous exécutons un bloc d'essais. Ce sera une seule `sequence`, correspondant à un seul essai, à l'intérieur d'une seule `loop`, correspondant à un bloc d'essais. Vous pouvez laisser la séquence d'essais vide pour l'instant !\n3. Enfin, nous terminons avec un écran d'au revoir.\n\nNous devons également changer la couleur de premier plan de l'expérience en noir et la couleur d'arrière-plan en blanc. Cela est dû au fait que nous utiliserons des images ayant un fond blanc, et nous ne voulons pas que ces images ressortent !\n\nEt n'oubliez pas de donner un nom judicieux à votre expérience et de la sauvegarder !\n\n<notranslate>\nfigure :\n id : FigMainStructure\n source : main-structure.png\n légende : |\n  La structure principale de l'expérience.\n</notranslate>\n\n### Étape 3 : Importer des fichiers dans la file d'attente\n\nPour cette expérience, nous avons besoin de stimuli : des fichiers sonores pour les phrases prononcées et des fichiers d'images pour les objets. Téléchargez ceux-ci à partir du lien ci-dessous, extrayez le fichier `zip` et placez les stimuli dans le pool de fichiers de votre expérience (voir également %FigFilePool).\n\n- %static : attachments/visual-world/stimuli.zip %\n\n<notranslate>\nfigure :\n id : FigFilePool\n source : file-pool.png\n légende : |\n  La file d'attente de votre expérience après l'ajout de tous les stimuli.\n</notranslate>\n\n### Étape 4 : Définir les variables expérimentales dans la block_loop\n\nLa *block_loop* est l'endroit où nous définissons les variables expérimentales, en les saisissant dans un tableau, où chaque ligne correspond à un essai, et chaque colonne correspond à une variable expérimentale.\n\nPour l'instant, nous définissons uniquement la condition de Correspondance Complète, dans laquelle l'objet cible est directement mentionné dans la phrase prononcée. (Nous ajouterons la condition de Correspondance Sémantique dans le cadre des Missions Supplémentaires.)\n\nNous aurons besoin des variables suivantes. Tout d'abord, ajoutez simplement des colonnes au tableau de boucle, sans donner de contenu aux lignes.\n\n- `pic1` — le nom de la première image (par exemple, 'apple.jpg')\n- `pic2` — le nom de la deuxième image\n- `pic3` — le nom de la troisième image\n- `pic4` — le nom de la quatrième image\n- `pos1` — la position de la première image (par exemple, 'topleft')\n- `pos2` — la position de la première image\n- `pos3` — la position de la première image\n- `pos4` — la position de la première image\n- `sound` — le nom d'un fichier sonore contenant une phrase prononcée (par exemple, 'apple.ogg').\n\nL'objet cible correspondra toujours à `pic1`. Nous avons les objets cibles suivants ; c'est-à-dire que pour les objets suivants, nous avons des fichiers sonores qui s'y réfèrent. Copiez-collez simplement la liste suivante dans la colonne `pic1` du tableau :\n\n~~~\napple.jpg\narmchair.jpg\nbanana.jpg\nbear.jpg\ncard.jpg\ncello.jpg\nchicken.jpg\ncookie.jpg\ncroissant.jpg\ndice.jpg\negg.jpg\nguitar.jpg\nkeyboard.jpg\nmouse.jpg\nsofa.jpg\nwolf.jpg\n~~~\n\nEt faites de même pour les fichiers sonores :\n\n~~~\napple.ogg\narmchair.ogg\nbanana.ogg\nbear.ogg\ncard.ogg\ncello.ogg\nchicken.ogg\ncookie.ogg\ncroissant.ogg\ndice.ogg\negg.ogg\nguitar.ogg\nkeyboard.ogg\nmouse.ogg\nsofa.ogg\nwolf.ogg\n~~~\n\nLe reste des images sont des distracteurs. Copiez-collez la liste suivante dans les colonnes `pic2`, `pic3` et `pic4`, de manière à ce que chaque colonne ait exactement 16 lignes. (Si vous allongez accidentellement le tableau sur plus de 16 lignes, sélectionnez simplement les lignes superflues, faites un clic droit et supprimez-les.)"
  },
  "~~~\nbasketball01.jpg\nbasketballhoop02.jpg\nbathtub.jpg\nbattery02b.jpg\nbattleaxe.jpg\nbattleship.jpg\nbeachpaddle01a.jpg\nbelt03b.jpg\nbookshelf.jpg\nbottlecap.jpg\nbowl01.jpg\nboxingglove02a.jpg\nboxtruck.jpg\nbracelet01.jpg\nbrainmodel.jpg\nbrick.jpg\nbulldozer.jpg\nbumpercar.jpg\nbust.jpg\nbutton01.jpg\ncactus.jpg\ncalculator01.jpg\ncalendar.jpg\ncamera01b.jpg\ncd.jpg\nceilingfan02.jpg\ncellphone.jpg\nmitten04.jpg\nmonument.jpg\nmoon.jpg\nmotorboat02.jpg\nmotoroilbottle03b.jpg\nmrpotatohead.jpg\nnailclipper03b.jpg\nneedlenosepliers03a.jpg\nnightstand.jpg\nnintendods.jpg\nnoparkingsign.jpg\noven.jpg\npacifier02a.jpg\npaintcan01.jpg\npants.jpg\npaperairplane.jpg\npaperclip02.jpg\nparkfountain.jpg\npatioumbrella.jpg\npencilsharpener03b.jpg\npeppermill01a.jpg\n~~~\n\nNow we need to specify the positions. Simply set:\n\n- `pos1` to 'topleft'\n- `pos2` to 'topright'\n- `pos3` to 'bottomleft'\n- `pos4` to 'bottomright'\n\nYour loop table should now look like %FigLoopTable.\n\n<notranslate>\nfigure:\n id: FigLoopTable\n source: loop-table.png\n caption: |\n  The `loop` table after all experimental variables have been defined.\n</notranslate>\n\n\n### Step 5: Apply advanced loop operations\n\nAlthough you have now defined all experimental variables, the `loop` table is not finished yet! Let's see what's wrong:\n\n\n__Positions__\n\n`pos1` is always the top left, meaning that `pic1` (the target object) is always presented at the top left of the display! (Assuming that we will implement our trial sequence such that these positions are used in that way.) And the same is true for `pos2`, `pos3`, and `pos4`.\n\nWe can fix this by horizontal shuffling of the `pos[x] columns`. That is, for each row, we randomly swap the values of these rows, such that this:\n\n~~~\npos1        pos2         pos3        pos4\ntopleft     topright     bottomleft  bottomright\ntopleft     topright     bottomleft  bottomright\n…\n~~~\n\nBecomes (say) this:\n\n~~~\npos1        pos2         pos3        pos4\nbottomleft  topleft      topright    bottomright\ntopright    bottomright  topright    bottomleft\n…\n~~~\n\nTo do this, view the script of *block_loop*, and add the following line of code to the very end of the script:\n\n~~~\nshuffle_horiz pos1 pos2 pos3 pos4\n~~~\n\nAnd click 'Apply and close'. If you now click on 'Preview', you will get a preview of what your loop table might look like if the experiment were actually run. And you will see that the `pos[x]` columns are horizontally shuffled, meaning that the pictures will be shown at random positions!\n\n\n__Distractors__\n\nThe distactor pictures are always linked to the same target object. For example, 'basketball01.jpg' always occurs together with the target 'apple.jpg'. But this is not what we want! Rather, we want the pairing between distactors and targets to be random, and different for all participants. (Except if by chance an identical pairing occurs for two participants.)\n\nWe can fix this by vertical shuffling of the `pic2`, `pic3`, and `pic4` columns. That is, the order of each of these columns should be shuffled independently. To do this, view the script again, and add the following lines to the very end of the script:\n\n~~~\nshuffle pic2\nshuffle pic3\nshuffle pic4\n~~~\n\nAnd click 'Apply and close'. If you now click on 'Preview', you will see that the `loop` table is properly randomized!\n\nFor more information about advanced loop operations, see:\n\n- %link:manual/structure/loop%\n\n\n<div class='info-box' markdown='1'>\n\n__Question__\n\nAt this point, you may wonder why we do not also need to horizontally shuffle the `pic2`, `pic3`, and `pic4` columns. But we don't! Do you know why not?\n\n</div>\n\n\n### Step 6: Create the trial sequence\n\nAs shown in %FigParadigm, our trial sequence is simple, and consists of:\n\n- central fixation dot (a `sketchpad`)\n- After 1000 ms: stimulus display (another `sketchpad`)\n- After 1000 ms: start sound playback (a `sampler`) while stimulus displays remains on screen\n- After 5000 ms: trial end": {
    "fr": "~~~\nbasketball01.jpg\nbasketballhoop02.jpg\nbaignoire.jpg\nbattery02b.jpg\nhache.jpg\ncuirassé.jpg\nraquetteplage01a.jpg\nbelt03b.jpg\netagere.jpg\ncapsule.jpg\nbol01.jpg\ngantdebox02a.jpg\ncamionnette.jpg\nbracelet01.jpg\nmodèlecervel.jpg\nbrique.jpg\nbulldozer.jpg\n_autotamponneuse.jpg\nbuste.jpg\nbouton01.jpg\ncactus.jpg\ncalculatrice01.jpg\ncalendrier.jpg\nappareilphoto01b.jpg\ncd.jpg\nventilateur_plafond02.jpg\ntéléphone portable.jpg\nmoufle04.jpg\nmonument.jpg\nlune.jpg\nmotortour02.jpg\nflaconhuilemoteur03b.jpg\nmrpatatetête.jpg\ncoupe-ongles03b.jpg\npincenef03a.jpg\ntabledenuit.jpg\nnintendods.jpg\npanneauinterdictionstationner.jpg\nfour.jpg\ntétines02a.jpg\npotdepeinture01.jpg\npantalon.jpg\navion_papier.jpg\ntrombone02.jpg\nfontaine_publique.jpg\n_parasolterrasse.jpg\ntaille-crayon03b.jpg\nmoulinàpoivre01a.jpg\n~~~\n\nMaintenant, nous devons spécifier les positions. Il suffit de définir :\n\n- `pos1` comme 'enhautagauche'\n- `pos2` comme 'enhautadroite'\n- `pos3` comme 'enbasagauche'\n- `pos4` comme 'enbasadroite'\n\nVotre tableau de boucle devrait maintenant ressembler à %FigLoopTable.\n\n<notranslate>\nfigure:\n id: FigLoopTable\n source: loop-table.png\n caption: |\n  Le tableau `loop` après que toutes les variables expérimentales ont été définies.\n</notranslate>\n\n### Étape 5 : Appliquer des opérations de boucle avancées\n\nBien que vous ayez défini toutes les variables expérimentales, le tableau `loop` n'est pas encore terminé ! Voyons ce qui ne va pas :\n\n__Positions__\n\n`pos1` est toujours en haut à gauche, ce qui signifie que `pic1` (l'objet cible) est toujours présenté en haut à gauche de l'écran ! (En supposant que nous allons mettre en œuvre notre séquence de test de telle sorte que ces positions sont utilisées de cette manière.) Et il en va de même pour `pos2`, `pos3` et `pos4`.\n\nNous pouvons résoudre cela en mélangeant horizontalement les colonnes `pos[x]`. C'est-à-dire que pour chaque rangée, nous échangeons aléatoirement les valeurs de ces rangées, de sorte que cela :\n\n~~~\npos1        pos2         pos3        pos4\nenhautagauche     enhautadroite     enbasagauche  enbasadroite\nenhautagauche     enhautadroite     enbasagauche  enbasadroite\n…\n~~~\n\nDevient (par exemple) ceci :\n\n~~~\npos1        pos2         pos3        pos4\nenbasagauche  enhautagauche      enhautadroite    enbasadroite\nenhautadroite    enbasadroite  enhautadroite    enbasagauche\n…\n~~~\n\nPour ce faire, affichez le script de *block_loop*, et ajoutez la ligne de code suivante à la toute fin du script :\n\n~~~\nshuffle_horiz pos1 pos2 pos3 pos4\n~~~\n\nEt cliquez sur « Appliquer et fermer ». Si vous cliquez maintenant sur « Aperçu », vous obtiendrez un aperçu de ce que votre tableau de boucle pourrait ressembler si l'expérience était réellement menée. Et vous verrez que les colonnes `pos[x]` sont mélangées horizontalement, ce qui signifie que les images seront présentées dans des positions aléatoires !\n\n__Distracteurs__\n\nLes images distractives sont toujours liées au même objet cible. Par exemple, « basketball01.jpg » se produit toujours avec la cible « apple.jpg ». Mais ce n'est pas ce que nous voulons ! Nous voulons plutôt que la liaison entre les distracteurs et les cibles soit aléatoire et différente pour tous les participants. (Sauf si par hasard une liaison identique se produit pour deux participants.)\n\nNous pouvons résoudre cela en mélangeant verticalement les colonnes `pic2`, `pic3` et `pic4`. Autrement dit, l'ordre de chacune de ces colonnes doit être mélangé indépendamment. Pour ce faire, affichez à nouveau le script et ajoutez les lignes suivantes à la toute fin du script :\n\n~~~\nshuffle pic2\nshuffle pic3\nshuffle pic4\n~~~\n\nEt cliquez sur « Appliquer et fermer ». Si vous cliquez maintenant sur « Aperçu », vous verrez que le tableau `loop` est correctement randomisé !\n\nPour plus d'informations sur les opérations de boucle avancées, voir :\n\n- %link:manual/structure/loop%\n\n<div class='info-box' markdown='1'>\n\n__Question__\n\nÀ ce stade, vous pouvez vous demander pourquoi nous ne devons pas également mélanger horizontalement les colonnes « pic2 », « pic3 » et « pic4 ». Mais nous ne le faisons pas ! Savez-vous pourquoi ?\n\n</div>\n\n### Étape 6 : Créez la séquence d'essai\n\nComme le montre %FigParadigm, notre séquence d'essai est simple et se compose de :\n\n- Point de fixation central (un « sketchpad »)\n- Après 1000 ms : Affichage du stimulus (un autre « sketchpad »)\n- Après 1000 ms : Lancement de la lecture du son (un « sampler ») pendant que l'affichage du stimulus reste à l'écran\n- Après 5000 ms : Fin de l'essai"
  },
  "For now, the trial sequence is therefore purely sequential, and we could implement it using only a `sequence`, as we've done in other tutorials. However, as one of the Extra Assignments, we want to analyze eye position *during* the trial sequence; in other words, later we'll want to do two things in parallel, and therefore we need a `coroutines` item. (Even if for now we won't do anything that requires this.)\n\nSo we want to have the following structure:\n\n- *trial_sequence* should contain a `coroutines` item (let's call it *trial_coroutines*) followed by a `logger` item.\n- *trial_coroutines* should have a duration of 7000 ms, and contain three items:\n  - A `sketchpad` for the fixation dot (let's call it *fixation_dot*) that is shown after 0 ms\n\t- A `sketchpad` for the stimulus display (let's call it *objects*) that is shown after 1000 ms\n\t- A `sampler` for the sound (let's call it *spoken_sentence*) that is shown after 2000 ms\n\n\nThe structure of your experiment should now look as in %FigCoroutinesStructure.\n\n\n<notranslate>\nfigure:\n id: FigCoroutinesStructure\n source: coroutines-structure.png\n caption: |\n  The experiment structure after defining the trial sequence.\n</notranslate>\n\n\n### Step 7: Define the visual stimuli\n\n__fixation_dot__\n\nThe *fixation_dot* is easily defined: simply draw a central fixation dot on it.\n\nNote that you don't need to specify the duration of the `sketchpad`, as you would normally need to do; this is because the item is part of *trial_coroutines*, and the timing is specified by the start and end time indicated there.\n\n\n__objects__\n\nTo define the *objects*, first create a prototype display, an example of what a display *might* look like on a particular trial. More specifically, draw a central fixation dot, and draw an arbitrary images in each of the four quadrants, as shown in %FigObjectsPrototype.\n\nAlso give each of the four objects a name: `pic1`, `pic2`, `pic3`, and `pic4`. We will use these names in the Extra Assignments to perform a regions-of-interest (ROI) analysis.\n\n\n<notranslate>\nfigure:\n id: FigObjectsPrototype\n source: objects-prototype.png\n caption: |\n  A prototype display with an arbitrary object in each of the four quadrants.\n</notranslate>\n\n\nOf course, we don't want to show the same objects over and over again. Rather, we want the `pic[x]` variables to specify which objects are shown, and the `pos[x]` variables to specify where these objects are shown. Let's start with the first object: the object in top-left, which in my example is an apple.\n\nView the script and find the line that corresponds to the first object. In my example, this is the following line:\n name=pic1\n~~~ .python\ndraw image center=1 file=\"apple.jpg\" scale=1 show_if=always x=-256 y=-192 z_index=0\n~~~\n\nNow change `file=\"apple.jpg\"` to `file=[pic1]`. This will make sure that the target picture as specified in the `pic1` variable is shown, rather than always the same apple.\n\nSo how can we use `pos1`, which has values like 'topleft', 'bottomright', etc., to specify the X and Y coordinates of the image? To do so, we make use of the fact that we can embed Python expressions in OpenSesame script, by using the `[=python_expression]` notation:\n\n- Change `x=-256` to `x=\"[=-256 if 'left' in var.pos1 else 256]\"`\n- Change `y=-192` to `y=\"[=-192 if 'top' in var.pos1 else 192]\"`\n\nAnd do the same for the other images, until the script looks this:": {
    "fr": "Pour l'instant, la séquence d'essai est donc purement séquentielle, et nous pourrions la mettre en œuvre en utilisant uniquement une `sequence`, comme nous l'avons fait dans d'autres tutoriels. Cependant, dans l'un des devoirs supplémentaires, nous voulons analyser la position des yeux *pendant* la séquence d'essai ; en d'autres termes, plus tard, nous voudrons faire deux choses en parallèle, et donc nous avons besoin d'un élément `coroutines`. (Même si pour l'instant nous ne ferons rien qui nécessite cela.)\n\nNous voulons donc avoir la structure suivante :\n\n- *trial_sequence* doit contenir un élément `coroutines` (appelons-le *trial_coroutines*) suivi d'un élément `logger`.\n- *trial_coroutines* doit avoir une durée de 7000 ms et contenir trois éléments :\n  - Un `sketchpad` pour le point de fixation (appelons-le *fixation_dot*) qui est montré après 0 ms\n\t- Un `sketchpad` pour l'affichage des stimuli (appelons-le *objects*) qui est montré après 1000 ms\n\t- Un `sampler` pour le son (appelons-le *spoken_sentence*) qui est montré après 2000 ms\n\nLa structure de votre expérience devrait maintenant ressembler à celle de %FigCoroutinesStructure.\n\n<notranslate>\nfigure:\n id: FigCoroutinesStructure\n source: coroutines-structure.png\n caption: |\n  La structure de l'expérience après avoir défini la séquence d'essai.\n</notranslate>\n\n### Étape 7 : Définir les stimuli visuels\n\n__fixation_dot__\n\nLe *fixation_dot* est facile à définir : il suffit de dessiner un point de fixation central sur celui-ci.\n\nNotez que vous n'avez pas besoin de spécifier la durée du `sketchpad`, comme vous devriez normalement le faire ; cela est dû au fait que l'élément fait partie de *trial_coroutines*, et le timing est spécifié par le temps de début et de fin indiqué là-bas.\n\n__objects__\n\nPour définir les *objects*, créez d'abord un prototype d'affichage, un exemple de ce à quoi un affichage *pourrait* ressembler lors d'un essai particulier. Plus précisément, dessinez un point de fixation central et dessinez une image arbitraire dans chacun des quatre quadrants, comme le montre %FigObjectsPrototype.\n\nDonnez également à chacun des quatre objets un nom : `pic1`, `pic2`, `pic3` et `pic4`. Nous utiliserons ces noms dans les devoirs supplémentaires pour effectuer une analyse des régions d'intérêt (ROI).\n\n<notranslate>\nfigure:\n id: FigObjectsPrototype\n source: objects-prototype.png\n caption: |\n  Un prototype d'affichage avec un objet arbitraire dans chacun des quatre quadrants.\n</notranslate>\n\nBien sûr, nous ne voulons pas montrer les mêmes objets encore et encore. Plutôt, nous voulons que les variables `pic[x]` spécifient quels objets sont montrés, et que les variables `pos[x]` spécifient où ces objets sont montrés. Commençons par le premier objet : l'objet en haut à gauche, qui dans mon exemple est une pomme.\n\nConsultez le script et trouvez la ligne qui correspond au premier objet. Dans mon exemple, il s'agit de la ligne suivante :\n name=pic1\n~~~ .python\ndraw image center=1 file=\"apple.jpg\" scale=1 show_if=always x=-256 y=-192 z_index=0\n~~~\n\nChangez maintenant `file=\"apple.jpg\"` en `file=[pic1]`. Cela permettra de montrer l'image cible telle que spécifiée dans la variable `pic1`, plutôt que toujours la même pomme.\n\nAlors, comment pouvons-nous utiliser `pos1`, qui a des valeurs comme 'topleft', 'bottomright', etc., pour spécifier les coordonnées X et Y de l'image ? Pour ce faire, nous profitons du fait que nous pouvons intégrer des expressions Python dans le script OpenSesame, en utilisant la notation `[=python_expression]` :\n\n- Changez `x=-256` en `x=\"[=-256 if 'left' in var.pos1 else 256]\"` \n- Changez `y=-192` en `y=\"[=-192 if 'top' in var.pos1 else 192]\"` \n\nEt faites la même chose pour les autres images, jusqu'à ce que le script ressemble à ceci :"
  },
  "~~~ .python\ndraw fixdot color=black show_if=always style=default x=0 y=0 z_index=0\ndraw image center=1 file=\"[pic1]\" scale=1 show_if=always x=\"[=-256 if 'left' in var.pos1 else 256]\" y=\"[=-192 if 'top' in var.pos1 else 192]\" z_index=0\ndraw image center=1 file=\"[pic2]\" scale=1 show_if=always x=\"[=-256 if 'left' in var.pos2 else 256]\" y=\"[=-192 if 'top' in var.pos2 else 192]\" z_index=0\ndraw image center=1 file=\"[pic3]\" scale=1 show_if=always x=\"[=-256 if 'left' in var.pos3 else 256]\" y=\"[=-192 if 'top' in var.pos3 else 192]\" z_index=0\ndraw image center=1 file=\"[pic4]\" scale=1 show_if=always x=\"[=-256 if 'left' in var.pos4 else 256]\" y=\"[=-192 if 'top' in var.pos4 else 192]\" z_index=0\n~~~\n\n\n<div class='info-box' markdown='1'>\n\n__Try it yourself: the `if` expression__\n\nIf you're not familiar with the Python `if` *expression*, which is slightly different from the traditional `if` *statement*, open the debug window, and enter the following line:\n\n~~~ .python\nprint('This is shown if True' if True else 'This is shown if False')\n~~~\n\nWhat do you see? Now change `if True else` into `if False else` and run the line again. What do you see now? Do you get the logic?\n\n</div>\n\n\n### Step 8: Define the sound\n\nDefining the sound is easy: simply open the *spoken_sentence* item, and enter '[sound]' in the 'Sound file' box, indicating that the variable `sound` specifies the sound file.\n\n\n### Step 9: Add basic eye tracking\n\nEye tracking is done with the [PyGaze](%url:manual/eyetracking/pygaze%) plug-ins, which are installed by default in OpenSesame. The general procedure is as follows:\n\n- At the start of the experiment, the eye tracker is *initialized and calibrated* with the `pygaze_init` item. This is also where you indicate what eye tracker you wan to use. During, it's convenient to select the Advanced Dummy eye tracker, which allows you to simulate eye movements with the mouse.\n- Before each trial, a *drift-correction* procedure is performed with the `pygaze_drift_correct` item. During drift correction, a single point is shown on the screen and the participant looks at it. This allows the eye tracker to see how much drift error there is in the eye-position measurement. How this error is treated depends on your eye tracker and settings:\n  - The drift error is either used for a single-point recalibration\n  - Or a simple check is performed to see if the drift error does not exceed a certain maximum error, giving the possibility to recalibrate if the maximum error is exceeded.\n- Next, still before each trial, the eye-tracker is told to start collecting data with the `pygaze_start_recording` item. You can specify a status message to indicate the start of each trial. It's convenient to include a trial number in this status message (e.g. 'start_trial [count_trial_sequence]').\n- At the end of each trial, data is sent to the eye-tracker log file with the `pygaze_log` item. It's convenient to enable the 'Automatically detect and log all variables' option.\n- Finally, at the very end of each trial, the eye tracker is told to stop recording with the `pygaze_stop_recording` item.\n\nThe structure of your experiment should now look as in %FigEyeTrackingStructure.\n\n\n<notranslate>\nfigure:\n id: FigEyeTrackingStructure\n source: eye-tracking-structure.png\n caption: |\n  The structure of the experiment after adding PyGaze items for eye tracking.\n</notranslate>\n\n\n### Step 10: Define instructions and goodbye screen\n\nWe now have a working experiment! But we haven't added any content to the *instructions* and *goodbye* items yet. So before you run the experiment, open these items and add some text.\n\n### Step 11: Run the experiment!\n\nCongratulations—you have implemented a visual-world paradigm! It's now time to give your experiment a quick test run by clicking on the orange play button (shortcut: `Ctrl+Shift+W`).\n\n\n## Extra assignments\n\n### Extra 1: Define the Semantic Match condition": {
    "fr": "~~~ .python\ndraw fixdot color=noir show_if=toujours style=default x=0 y=0 z_index=0\ndraw image center=1 file=\"[pic1]\" scale=1 show_if=toujours x=\"[=-256 if 'left' in var.pos1 else 256]\" y=\"[=-192 if 'top' in var.pos1 else 192]\" z_index=0\ndraw image center=1 file=\"[pic2]\" scale=1 show_if=toujours x=\"[=-256 if 'left' in var.pos2 else 256]\" y=\"[=-192 if 'top' in var.pos2 else 192]\" z_index=0\ndraw image center=1 file=\"[pic3]\" scale=1 show_if=toujours x=\"[=-256 if 'left' in var.pos3 else 256]\" y=\"[=-192 if 'top' in var.pos3 else 192]\" z_index=0\ndraw image center=1 file=\"[pic4]\" scale=1 show_if=toujours x=\"[=-256 if 'left' in var.pos4 else 256]\" y=\"[=-192 if 'top' in var.pos4 else 192]\" z_index=0\n~~~\n\n\n<div class='info-box' markdown='1'>\n\n__Essayez-le vous-même : l'expression `if`__\n\nSi vous n'êtes pas familier avec l'expression `if` en Python, qui est légèrement différente de l'instruction `if` traditionnelle, ouvrez la fenêtre de débogage et saisissez la ligne suivante :\n\n~~~ .python\nprint('Ceci est affiché si True' if True else 'Ceci est affiché si False')\n~~~\n\nQue voyez-vous ? Changez maintenant `if True else` en `if False else` et exécutez à nouveau la ligne. Que voyez-vous maintenant ? Vous comprenez la logique ?\n\n</div>\n\n\n### Étape 8 : Définir le son\n\nDéfinir le son est facile : ouvrez simplement l'élément *spoken_sentence* et entrez '[sound]' dans la case 'Sound file', indiquant que la variable `sound` spécifie le fichier son.\n\n\n### Étape 9 : Ajouter un suivi oculaire de base\n\nLe suivi oculaire est effectué avec les plug-ins [PyGaze](%url:manual/eyetracking/pygaze%), qui sont installés par défaut dans OpenSesame. La procédure générale est la suivante :\n\n- Au début de l'expérience, l'eye tracker est *initialisé et calibré* avec l'élément `pygaze_init`. C'est également là que vous indiquez quel eye tracker vous souhaitez utiliser. Pendant, il est pratique de sélectionner le eye tracker Advanced Dummy, qui vous permet de simuler des mouvements oculaires avec la souris.\n- Avant chaque essai, une procédure de *correction de dérive* est effectuée avec l'élément `pygaze_drift_correct`. Pendant la correction de dérive, un seul point est affiché à l'écran et le participant le regarde. Cela permet au eye tracker de voir combien d'erreur de dérive il y a dans la mesure de la position des yeux. La façon dont cette erreur est traitée dépend de votre eye tracker et de vos paramètres :\n  - L'erreur de dérive est soit utilisée pour un recalibrage en un seul point.\n  - Ou un simple contrôle est effectué pour voir si l'erreur de dérive ne dépasse pas une certaine erreur maximale, donnant la possibilité de recalibrer si l'erreur maximale est dépassée.\n- Ensuite, toujours avant chaque essai, on demande au eye-tracker de commencer à collecter des données avec l'élément `pygaze_start_recording`. Vous pouvez spécifier un message d'état pour indiquer le début de chaque essai. Il est pratique d'intégrer un numéro d'essai dans ce message d'état (par exemple 'start_trial [count_trial_sequence]').\n- À la fin de chaque essai, les données sont envoyées au fichier journal de l'eye-tracker avec l'élément `pygaze_log`. Il est pratique d'activer l'option 'Automatically detect and log all variables'.\n- Enfin, à la toute fin de chaque essai, on demande au eye tracker d'arrêter l'enregistrement avec l'élément `pygaze_stop_recording`.\n\nLa structure de votre expérience doit maintenant être similaire à celle de %FigEyeTrackingStructure.\n\n\n<notranslate>\nfigure:\n id: FigEyeTrackingStructure\n source: eye-tracking-structure.png\n caption: |\n  La structure de l'expérience après avoir ajouté des éléments PyGaze pour le suivi oculaire.\n</notranslate>\n\n\n### Étape 10 : Définir les instructions et l'écran d'au revoir\n\nNous avons maintenant une expérience fonctionnelle ! Mais nous n'avons pas encore ajouté de contenu aux éléments *instructions* et *goodbye*. Donc, avant de lancer l'expérience, ouvrez ces éléments et ajoutez du texte.\n\n### Étape 11 : Lancer l'expérience !\n\nFélicitations - vous avez mis en œuvre un paradigme de monde visuel ! Il est maintenant temps de tester rapidement votre expérience en cliquant sur le bouton de lecture orange (raccourci : `Ctrl+Shift+W`).\n\n\n## Travaux supplémentaires\n\n### Supplément 1 : Définir la condition de correspondance sémantique"
  },
  "So far, we have only implemented the Full Match condition, in which the target object (e.g. 'apple') is explicitly mentioned in the spoken sentence (e.g. 'at breakfast, the girl ate an apple').\n\nNow, also implement the Semantic Match condition, in which each target (e.g. 'apple') is paired with a semantically related spoken sentence (e.g. 'at breakfast, the girl at a banana'). The stimuli have been created such that there is one semantically related spoken sentence for each target object.\n\nIn every other way, the Semantic Match condition should be identical to the Full Match condition.\n\nAnd don't forget to create a variable that indicates the condition!\n\n\n### Extra 2: Use Python constants to define coordinates\n\nRight now, the coordinates of the objects have been hard-coded in the *objects* script, in the sense that the coordinates have been typed directly into the script:\n\n~~~ .python\nx=\"[=-256 if 'left' in var.pos1 else 256]\"\n~~~\n\nIt's more elegant to define the coordinates (`XLEFT`, `XRIGHT`, `YTOP`, and `YBOTTOM`) as constants in an `inline_script` at the start of the experiment, and then refer to these constants in the *objects* script.\n\n\n<div class='info-box' markdown='1'>\n\n__Constants in Python__\n\nIn computer science, a *constant* is a variable with a value that you cannot change. In Python, you can always change variables, so constants don't strictly speaking exist in the language. However, if you have a variable that you treat as though it were a constant (i.e. you define it once and never change its value), you typically indicate this by writing the variable name in `ALL_CAPS`.\n\nSuch naming conventions are described in Python's PEP-8 style guidelines:\n\n- <https://www.python.org/dev/peps/pep-0008/>\n\n</div>\n\n\n### Extra 3: Analyze eye position online (challenging!)\n\nIn *trial_coroutines*, you can indicate the name of a generator function (see below for an explanation of generators). Let's enter the name `roi_analysis` here, and also create an `inline_script` at the start of the experiment in which we define this function.\n\nHere's a partly implemented `roi_analysis()` function. Can you finish the TODO list?\n\n~~~ .python\ndef roi_analysis():\n\n\t# sample_nr will be used to create a different variable name for each\n\t# 500 ms sample\n\tsample_nr = 0\n\t# This first yield indicates that the generator has finished preparing\n\tyield\n\t# Retrieve the canvas of the objects sketchpad. We need to do this after\n\t# the yield statement that signals the end of preparation, because that we\n\t# are sure that the canvas object has been constructed (which also happens)\n\t# during preparation.\n\tcanvas = items['objects'].canvas\n\twhile True:\n\t\t# We only want to analyze a gaze sample once very 500 ms. This is so\n\t\t# that we don't end up with too many columns in the log file. If it's\n\t\t# not time to analyze a gaze sample, simply yield and continue.\n\t\tif not clock.once_in_a_while(ms=500):\n\t\t\tyield # so that other items in the coroutines can run\n\t\t\tcontinue\n\t\t#\n\t\t# TODO:\n\t\t#\n\t\t# - Get an eye-position coordinate from the eye tracker\n\t\t#   (Hint: Use eyetracker.sample())\n\t\t# - Check which sketchpad elements are at this coordinate (if any)\n\t\t#   (Hint: use canvas.elements_at())\n\t\t# - If pic1 (the target object) is among these elements set\n\t\t#   var.on_target_[sample_nr] to 1, else to 0\n\t\t#   (Hint: use var.set())\n~~~\n\nSee also:\n\n- %link:manual/structure/coroutines%\n\n<div class='info-box' markdown='1'>\n\n__Generator functions in Python__\n\nIn Python, a *generator* function is a function with a `yield` statement. A `yield` statement is similar to a `return` statement, in that it stops a function. However, whereas `return` stops a function permanently, `yield` merely suspends a function—and the function can later resume from the `yield` point onward.\n\n</div>\n\n## Download the experiment\n\nYou can download the full experiment from here:\n\n- <https://osf.io/z27rt/>\n\n\n## References": {
    "fr": "Jusqu'à présent, nous n'avons mis en œuvre que la condition de correspondance complète, dans laquelle l'objet cible (par exemple, 'pomme') est explicitement mentionné dans la phrase parlée (par exemple, 'au petit déjeuner, la fille a mangé une pomme').\n\nMaintenant, mettez également en œuvre la condition de correspondance sémantique, dans laquelle chaque cible (par exemple, 'pomme') est associée à une phrase parlée sémantiquement liée (par exemple, 'au petit déjeuner, la fille a mangé une banane'). Les stimuli ont été créés de manière à ce qu'il y ait une phrase parlée sémantiquement liée pour chaque objet cible.\n\nDe toutes les autres manières, la condition de correspondance sémantique doit être identique à la condition de correspondance complète.\n\nEt n'oubliez pas de créer une variable qui indique la condition !\n\n### Extra 2 : Utiliser des constantes Python pour définir les coordonnées\n\nActuellement, les coordonnées des objets ont été codées en dur dans le script *objects*, en ce sens que les coordonnées ont été directement saisies dans le script :\n\n~~~ .python\nx=\"[=-256 si 'left' dans var.pos1 else 256]\"\n~~~\n\nIl est plus élégant de définir les coordonnées (`XLEFT`, `XRIGHT`, `YTOP` et `YBOTTOM`) en tant que constantes dans un `inline_script` au début de l'expérience, puis de se référer à ces constantes dans le script *objects*.\n\n<div class='info-box' markdown='1'>\n\n__Constantes en Python__\n\nEn informatique, une *constante* est une variable dont la valeur ne peut pas être modifiée. En Python, vous pouvez toujours modifier des variables, donc les constantes n'existent pas strictement parlant dans le langage. Cependant, si vous avez une variable que vous traitez comme si c'était une constante (c'est-à-dire que vous la définissez une fois et ne changez jamais sa valeur), vous l'indiquez généralement en écrivant le nom de la variable en `MAJUSCULES`.\n\nCes conventions de nommage sont décrites dans les directives de style PEP-8 de Python :\n\n- <https://www.python.org/dev/peps/pep-0008/>\n\n</div>\n\n### Extra 3 : Analyser en ligne la position des yeux (difficile !)\n\nDans *trial_coroutines*, vous pouvez indiquer le nom d'une fonction de générateur (voir ci-dessous pour une explication des générateurs). Entrez ici le nom `roi_analysis` et créez également un `inline_script` au début de l'expérience dans lequel nous définissons cette fonction.\n\nVoici une fonction `roi_analysis()` partiellement implémentée. Pouvez-vous terminer la liste des tâches à faire ?\n\n~~~ .python\ndef roi_analysis():\n\n\t# sample_nr sera utilisé pour créer un nom de variable différent pour chacun\n\t# échantillon de 500 ms\n\tsample_nr = 0\n\t# Ce premier rendement indique que le générateur a fini de se préparer\n\tyield\n\t# Récupérez le canevas du sketchpad des objets. Nous devons le faire après\n\t# la déclaration de rendement qui signale la fin de la préparation, parce que nous\n\t# sommes sûrs que l'objet canevas a été construit (ce qui se produit également)\n\t# lors de la préparation.\n\tcanvas = items['objects'].canvas\n\twhile True:\n\t\t# Nous ne voulons analyser un échantillon de regard que toutes les 500 ms. Cela est fait pour\n\t\t# que nous n'ayons pas trop de colonnes dans le fichier journal. Si ce n'est pas\n\t\t# le temps d'analyser un échantillon de regard, il suffit de céder et de continuer.\n\t\tif not clock.once_in_a_while(ms=500):\n\t\t\tyield # afin que d'autres éléments dans les coroutines puissent fonctionner\n\t\t\tcontinue\n\t\t#\n\t\t# TODO :\n\t\t#\n\t\t# - Obtenir une coordonnée de position des yeux du suivi des yeux\n\t\t#   (Astuce : Utiliser eyetracker.sample())\n\t\t# - Vérifier quels éléments de sketchpad sont à cette coordonnée (le cas échéant)\n\t\t#   (Astuce : utiliser canvas.elements_at())\n\t\t# - Si pic1 (l'objet cible) fait partie de ces éléments, définissez\n\t\t#   var.on_target_[sample_nr] sur 1, sinon sur 0\n\t\t#   (Astuce : utiliser var.set ())\n~~~\n\nVoir aussi :\n\n- %link:manual/structure/coroutines%\n\n<div class='info-box' markdown='1'>\n\n__Fonctions de générateur en Python__\n\nEn Python, une fonction *générateur* est une fonction avec une déclaration `yield`. Une déclaration `yield` est similaire à une déclaration `return`, en ce sens qu'elle arrête une fonction. Cependant, alors que `return` arrête une fonction de manière permanente, `yield` suspend simplement une fonction, et la fonction peut ensuite reprendre à partir du point `yield`.\n\n</div>\n\n## Télécharger l'expérience\n\nVous pouvez télécharger l'expérience complète à partir d'ici :\n\n- <https://osf.io/z27rt/>\n\n\n## Références"
  },
  "Brodeur, M. B., Dionne-Dostie, E., Montreuil, T., Lepage, M., & Op de Beeck, H. P. (2010). The Bank of Standardized Stimuli (BOSS), a new set of 480 normative photos of objects to be used as visual stimuli in cognitive research. *PloS ONE*, *5*(5), e10773. doi:10.1371/journal.pone.0010773\n{: .reference}\n\nCooper, R. M. (1974). The control of eye fixation by the meaning of spoken language: A new methodology for the real-time investigation of speech perception, memory, and language processing. *Cognitive Psychology*, *6*(1), 84–107. doi:10.1016/0010-0285(74)90005-X\n{: .reference}\n\nDalmaijer, E., Mathôt, S., & Van der Stigchel, S. (2014). PyGaze: An open-source, cross-platform toolbox for minimal-effort programming of eyetracking experiments. *Behavior Research Methods*, *46*(4), 913–921. doi:10.3758/s13428-013-0422-2\n{: .reference}\n\nHuettig, F., Rommers, J., & Meyer, A. S. (2011). Using the visual world paradigm to study language processing: A review and critical evaluation. *Acta Psychologica*, *137*(2), 151–171. doi:10.1016/j.actpsy.2010.11.003\n{: .reference}\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314–324. doi:10.3758/s13428-011-0168-7\n{: .reference}\n": {
    "fr": "Brodeur, M. B., Dionne-Dostie, E., Montreuil, T., Lepage, M., & Op de Beeck, H. P. (2010). La Banque de Stimuli Standardisés (BOSS), un nouvel ensemble de 480 photos normatives d'objets à utiliser comme stimuli visuels dans la recherche cognitive. *PloS ONE*, *5*(5), e10773. doi:10.1371/journal.pone.0010773\n{: .reference}\n\nCooper, R. M. (1974). Le contrôle de la fixation des yeux par le sens du langage parlé: Une nouvelle méthodologie pour l'étude en temps réel de la perception du discours, de la mémoire et du traitement du langage. *Cognitive Psychology*, *6*(1), 84–107. doi:10.1016/0010-0285(74)90005-X\n{: .reference}\n\nDalmaijer, E., Mathôt, S., & Van der Stigchel, S. (2014). PyGaze: Une boîte à outils open-source et multiplateforme pour la programmation d'expériences de suivi du regard avec un effort minimal. *Behavior Research Methods*, *46*(4), 913–921. doi:10.3758/s13428-013-0422-2\n{: .reference}\n\nHuettig, F., Rommers, J., & Meyer, A. S. (2011). Utilisation du paradigme du monde visuel pour étudier le traitement du langage: Un examen et une évaluation critique. *Acta Psychologica*, *137*(2), 151–171. doi:10.1016/j.actpsy.2010.11.003\n{: .reference}\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: Un constructeur d'expériences graphiques open-source pour les sciences sociales. *Behavior Research Methods*, *44*(2), 314–324. doi:10.3758/s13428-011-0168-7\n{: .reference}"
  },
  "Support": {
    "fr": "Assistance"
  },
  "\n## Free support\n\nWe offer free support through the community forum at <https://forum.cogsci.nl/>.\n\n\n## Professional (paid) support\n\nFor professional (paid) support, visit <https://professional.cogsci.nl/>.\n": {
    "fr": "## Support gratuit\n\nNous offrons un support gratuit via le forum communautaire à l'adresse <https://forum.cogsci.nl/>.\n\n## Support professionnel (payant)\n\nPour un support professionnel (payant), visitez <https://professional.cogsci.nl/>."
  },
  "Siena 2018 workshop (Day 1)": {
    "fr": "Atelier Siena 2018 (Jour 1)"
  },
  "<notranslate>[TOC]</notranslate>\n\n\n## About the workshop\n\nThis OpenSesame workshop will take place at the University of Siena on February 22 and 23, 2018. This booklet corresponds to day 1.\n\nThe workshop consisted of two main parts. In the first part, corresponding to the Tutorial below, we created a complete experiment together. In the second part, corresponding to the Extra assignments below, the workshop participants improved this experiment by themselves, based on a few suggestions.\n\nYou can download the full experiment, including the solutions of the extra assignments here:\n\n- <http://osf.io/jw7dr>\n\n- For Day 2, see: <http://osdoc.cogsci.nl/3.2/siena2018day2>\n\n\n## The tutorial\n\n<notranslate>\nfigure:\n id: FigMeowingCapybara\n source: meowing-capybara.png\n caption: |\n  Don't be fooled by meowing capybaras! ([Source][capybara_photo])\n</notranslate>\n\n<notranslate>[TOC]</notranslate>\n\nWe will create a simple animal-filled multisensory integration task, in which participants see a picture of a dog, cat, or capybara. A meow or a bark is played while the picture is shown. The participant reports whether a dog or a cat is shown, by pressing the right or the left key. No response should be given when a capybara is shown: those are catch trials.\n\nTo make things more fun, we will design the experiment so that you can run it on [OSWeb](http://osweb.cogsci.nl/), an online runtime for OpenSesame experiments (which is still a work in progress, but it works for basic experiments).\n\nWe make two simple predictions:\n\n- Participants should be faster to identify dogs when a barking sound is played, and faster to identify cats when a meowing sound is played. In other words, we expect a multisensory congruency effect.\n- When participants see a capybara, they are more likely to report seeing a dog when they hear a bark, and more likely to report seeing a cat when they hear a meow. In other words, false alarms are biased by the sound.\n\n\n### Step 1: Download and start OpenSesame\n\nOpenSesame is available for Windows, Linux, Mac OS, and Android (runtime only). This tutorial is written for OpenSesame 3.1.X, and you can use either the version based on Python 2.7 (default) or Python 3.5. You can download OpenSesame from here:\n\n- %link:download%\n\nWhen you start OpenSesame, you will be given a choice of template experiments, and (if any) a list of recently opened experiments (see %FigStartUp).\n\n<notranslate>\nfigure:\n id: FigStartUp\n source: start-up.png\n caption: |\n  The OpenSesame window on start-up.\n</notranslate>\n\nThe *Extended template* provides a good starting point for creating Android-based experiments. However, in this tutorial we will create the entire experiment from scratch. Therefore, we will continue with the 'default template', which is already loaded when OpenSesame is launched (%FigDefaultTemplate). Therefore, simply close the 'Get started!' and (if shown) 'Welcome!' tabs.\n\n<notranslate>\nfigure:\n id: FigDefaultTemplate\n source: default-template.png\n caption: |\n  The structure of the 'Default template' as seen in the overview area.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 1: Basics**\n\nOpenSesame experiments are collections of *items*. An item is a small chunk of functionality that, for example, can be used to present visual stimuli (the SKETCHPAD item) or to record key presses (the KEYBOARD_RESPONSE item). Items have a type and a name. For example, you might have two items of the type KEYBOARD_RESPONSE with the names *t1_response* and *t2_response*. To make the distinction between item types and item names clear, we will use THIS_STYLE for types, and *this style* for names.\n\nTo give structure to your experiment, two types of items are especially important: the LOOP and the SEQUENCE. Understanding how you can combine LOOPs and SEQUENCEs to build experiments is perhaps the trickiest part of working with OpenSesame, so let's get that out of the way first.": {
    "fr": "## À propos de l'atelier\n\nCet atelier OpenSesame aura lieu à l'Université de Sienne les 22 et 23 février 2018. Ce livret correspond au jour 1.\n\nL'atelier se composait de deux parties principales. Dans la première partie, correspondant au didacticiel ci-dessous, nous avons créé une expérience complète ensemble. Dans la deuxième partie, correspondant aux missions supplémentaires ci-dessous, les participants à l'atelier ont amélioré cette expérience par eux-mêmes, en fonction de quelques suggestions.\n\nVous pouvez télécharger l'expérience complète, y compris les solutions des missions supplémentaires ici :\n\n- <http://osf.io/jw7dr>\n\n- Pour le jour 2, voir : <http://osdoc.cogsci.nl/3.2/siena2018day2>\n\n\n## Le tutoriel\n\n<notranslate>\nfigure:\n id: FigMeowingCapybara\n source: meowing-capybara.png\n caption: |\n  Ne vous laissez pas berner par les capybaras qui miaulent ! ([Source][capybara_photo])\n</notranslate>\n\n<notranslate>[TOC]</notranslate>\n\nNous allons créer une tâche simple d'intégration multisensorielle remplie d'animaux, dans laquelle les participants voient une image d'un chien, d'un chat ou d'un capybara. Un miaulement ou un aboiement est joué pendant que l'image est montrée. Le participant signale si un chien ou un chat est montré, en appuyant sur la touche droite ou gauche. Aucune réponse ne doit être donnée lorsqu'un capybara est montré : il s'agit de tests de capture.\n\nPour rendre les choses plus amusantes, nous concevrons l'expérience de manière à ce que vous puissiez l'exécuter sur [OSWeb](http://osweb.cogsci.nl/), un runtime en ligne pour les expériences OpenSesame (qui est encore en cours de développement, mais fonctionne pour des expériences de base).\n\nNous faisons deux prédictions simples :\n\n- Les participants devraient être plus rapides pour identifier les chiens lorsqu'un son d'aboiement est joué, et plus rapides pour identifier les chats lorsqu'un son de miaulement est joué. En d'autres termes, nous nous attendons à un effet de congruence multisensorielle.\n- Lorsque les participants voient un capybara, ils sont plus susceptibles de signaler avoir vu un chien lorsqu'ils entendent un aboiement, et plus susceptibles de signaler avoir vu un chat lorsqu'ils entendent un miaulement. En d'autres termes, les fausses alertes sont biaisées par le son.\n\n### Étape 1 : Téléchargez et démarrez OpenSesame\n\nOpenSesame est disponible pour Windows, Linux, Mac OS et Android (runtime uniquement). Ce tutoriel est écrit pour OpenSesame 3.1.X, et vous pouvez utiliser la version basée sur Python 2.7 (par défaut) ou Python 3.5. Vous pouvez télécharger OpenSesame ici :\n\n- %link:download%\n\nLorsque vous démarrez OpenSesame, on vous propose des expériences modèles, et (le cas échéant) une liste d'expériences récemment ouvertes (voir %FigStartUp).\n\n<notranslate>\nfigure:\n id: FigStartUp\n source: start-up.png\n caption: |\n  La fenêtre OpenSesame au démarrage.\n</notranslate>\n\nLe modèle *Extended* fournit un bon point de départ pour créer des expériences basées sur Android. Cependant, dans ce tutoriel, nous créerons l'ensemble de l'expérience à partir de zéro. Par conséquent, nous continuerons avec le modèle 'par défaut', qui est déjà chargé lorsque OpenSesame est lancé (%FigDefaultTemplate). Fermez simplement les onglets 'Get started!' et (si affiché) 'Welcome!'.\n\n<notranslate>\nfigure:\n id: FigDefaultTemplate\n source: default-template.png\n caption: |\n  La structure du modèle \"par défaut\" telle qu'elle apparaît dans la zone de présentation.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Boîte d'information 1 : Bases**\n\nLes expériences OpenSesame sont des collections d'éléments. Un élément est un petit morceau de fonctionnalité qui, par exemple, peut être utilisé pour présenter des stimuli visuels (l'élément SKETCHPAD) ou pour enregistrer les touches de clavier (l'élément KEYBOARD_RESPONSE). Les éléments ont un type et un nom. Par exemple, vous pouvez avoir deux éléments de type KEYBOARD_RESPONSE avec les noms *t1_response* et *t2_response*. Pour bien distinguer les types d'éléments et les noms d'éléments, nous utiliserons CE_STYLE pour les types et *ce style* pour les noms.\n\nPour donner de la structure à votre expérience, deux types d'éléments sont particulièrement importants : la LOOP et la SEQUENCE. Comprendre comment vous pouvez combiner LOOPs et SEQUENCEs pour construire des expériences est peut-être la partie la plus délicate du travail avec OpenSesame, alors commençons par là."
  },
  "A LOOP is where, in most cases, you define your independent variables. In a LOOP you can create a table in which each column corresponds to a variable, and each row corresponds to a single run of the 'item to run'. To make this more concrete, let's consider the following *block_loop* (unrelated to this tutorial):\n\n<notranslate>\nfigure:\n id: FigLoopTable\n source: loop-table.png\n caption: |\n  An example of variables defined in a loop table. (This example is not related to the experiment created in this tutorial.)\n</notranslate>\n\nThis *block_loop* will execute *trial_sequence* four times. Once while `soa` is 100 and `target` is 'F', once while `soa` is 100 and `target` is 'H', etc. The order in which the rows are walked through is random by default, but can also be set to sequential in the top-right of the tab.\n\nA SEQUENCE consists of a series of items that are executed one after another. A prototypical SEQUENCE is the *trial_sequence*, which corresponds to a single trial. For example, a basic *trial_sequence* might consist of a SKETCHPAD, to present a stimulus, a KEYBOARD_RESPONSE, to collect a response, and a LOGGER, to write the trial information to the log file.\n\n<notranslate>\nfigure:\n id: FigExampleSequence\n source: example-sequence.png\n caption: |\n  An example of a SEQUENCE item used as a trial sequence. (This example is not related to the experiment created in this tutorial.)\n</notranslate>\n\nYou can combine LOOPs and SEQUENCEs in a hierarchical way, to create trial blocks, and practice and experimental phases. For example, the *trial_sequence* is called by the *block_loop*. Together, these correspond to a single block of trials. One level up, the *block_sequence* is called by the *practice_loop*. Together, these correspond to the practice phase of the experiment.\n\n</div>\n\n\n### Step 2: Add a block_loop and trial_sequence\n\nThe default template starts with three items: A NOTEPAD called *getting_started*, a SKETCHPAD called *welcome*, and a SEQUENCE called *experiment*. We don't need *getting_started* and *welcome*, so let's remove these right away. To do so, right-click on these items and select 'Delete'. Don't remove *experiment*, because it is the entry for the experiment (i.e. the first item that is called when the experiment is started).\n\nOur experiment will have a very simple structure. At the top of the hierarchy is a LOOP, which we will call *block_loop*. The *block_loop* is the place where we will define our independent variables (see also Background box 1). To add a LOOP to your experiment, drag the LOOP icon from the item toolbar onto the *experiment* item in the overview area.\n\nA LOOP item needs another item to run; usually, and in this case as well, this is a SEQUENCE. Drag the SEQUENCE item from the item toolbar onto the *new_loop* item in the overview area. OpenSesame will ask whether you want to insert the SEQUENCE into or after the LOOP. Select 'Insert into new_loop'.\n\nBy default, items have names such as *new_sequence*, *new_loop*, *new_sequence_2*, etc. These names are not very informative, and it is good practice to rename them. Item names must consist of alphanumeric characters and/ or underscores. To rename an item, double-click on the item in the overview area. Rename *new_sequence* to *trial_sequence* to indicate that it will correspond to a single trial. Rename *new_loop* to *block_loop* to indicate that will correspond to a block of trials.\n\nThe overview area of our experiment now looks as in %FigStep3.\n\n<notranslate>\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  The overview area at the end of Step 2.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 3: Unused items**\n\n__Tip__ — Deleted items are still available in the Unused Items bin, until you select 'Permanently delete unused items' in the Unused Items tab. You can re-add deleted items to your experiment by dragging them out of the Unused Items bin into a SEQUENCE or LOOP.\n\n</div>": {
    "fr": "Une LOOP est l'endroit où, dans la plupart des cas, vous définissez vos variables indépendantes. Dans une LOOP, vous pouvez créer un tableau dans lequel chaque colonne correspond à une variable et chaque ligne correspond à une seule exécution de l'élément à exécuter. Pour rendre cela plus concret, considérons le *block_loop* suivant (sans rapport avec ce tutoriel) :\n\n<notranslate>\nfigure :\n id : FigLoopTable\n source : loop-table.png\n légende : |\n  Exemple de variables définies dans un tableau de boucle. (Cet exemple n'est pas lié à l'expérience créée dans ce tutoriel. )\n</notranslate>\n\nCe *block_loop* exécutera *trial_sequence* quatre fois. Une fois quand `soa` est 100 et `target` est 'F', une fois quand `soa` est 100 et `target` est 'H', etc. L'ordre dans lequel les lignes sont parcourues est aléatoire par défaut, mais peut aussi être réglé en séquence dans le coin supérieur droit de l'onglet.\n\nUne SEQUENCE se compose d'une série d'éléments qui sont exécutés les uns après les autres. Une SEQUENCE prototypique est le *trial_sequence*, qui correspond à un seul essai. Par exemple, une *trial_sequence* basique pourrait consister en un SKETCHPAD, pour présenter un stimulus, un KEYBOARD_RESPONSE, pour recueillir une réponse, et un LOGGER, pour écrire les informations de l'essai dans le fichier journal.\n\n<notranslate>\nfigure:\n id: FigExampleSequence\n source: example-sequence.png\n caption: |\n  Un exemple d'un élément SEQUENCE utilisé comme séquence d'essai. (Cet exemple n'est pas lié à l'expérience créée dans ce tutoriel. )\n</notranslate>\n\nVous pouvez combiner les LOOPs et les SEQUENCEs de manière hiérarchique, pour créer des blocs d'essais et des phases de pratique et expérimentales. Par exemple, le *trial_sequence* est appelé par le *block_loop*. Ensemble, ceux-ci correspondent à un seul bloc d'essais. Un niveau plus haut, le *block_sequence* est appelé par le *practice_loop*. Ensemble, il s'agit de la phase de pratique de l'expérience.\n\n</div>\n\n\n### Étape 2 : Ajouter un block_loop et trial_sequence\n\nLe modèle par défaut commence avec trois éléments : un NOTEPAD appelé *getting_started*, un SKETCHPAD appelé *welcome* et une SEQUENCE appelée *experiment*. Nous n'avons pas besoin de *getting_started* et de *welcome*, alors supprimons-les tout de suite. Pour ce faire, faites un clic droit sur ces éléments et sélectionnez \"Supprimer\". Ne supprimez pas *experiment*, car il s'agit de l'entrée pour l'expérience (c'est-à-dire du premier élément appelé lorsque l'expérience est lancée).\n\nNotre expérience aura une structure très simple. Au sommet de la hiérarchie se trouve une LOOP, que nous appellerons *block_loop*. La *block_loop* est l'endroit où nous définirons nos variables indépendantes (voir également l'encadré 1 sur les antécédents). Pour ajouter une LOOP à votre expérience, faites glisser l'icône LOOP de la barre d'outils des éléments sur l'élément *experiment* de la zone d'aperçu.\n\nUn élément LOOP a besoin d'un autre élément pour fonctionner ; généralement, et dans ce cas également, il s'agit d'une SEQUENCE. Faites glisser l'élément SEQUENCE de la barre d'outils des éléments sur l'élément *new_loop* de la zone d'aperçu. OpenSesame vous demandera si vous souhaitez insérer la SEQUENCE dans ou après la LOOP. Sélectionnez \"Insérer dans new_loop\".\n\nPar défaut, les éléments ont des noms tels que *new_sequence*, *new_loop*, *new_sequence_2*, etc. Ces noms ne sont pas très informatifs et il est recommandé de les renommer. Les noms des éléments doivent être composés de caractères alphanumériques et/ou de traits de soulignement. Pour renommer un élément, double-cliquez dessus dans la zone d'aperçu. Renommez *new_sequence* en *trial_sequence* pour indiquer qu'il correspondra à un seul essai. Renommez *new_loop* en *block_loop* pour indiquer qu'il correspondra à un bloc d'essais.\n\nLa zone d'aperçu de notre expérience ressemble maintenant à celle de %FigStep3.\n\n<notranslate>\nfigure :\n id : FigStep3\n source : step3.png\n légende : |\n  La zone d'aperçu à la fin de l'étape 2.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 3 : Éléments inutilisés**\n\n__Tip__ — Les éléments supprimés sont toujours disponibles dans la corbeille des éléments inutilisés, jusqu'à ce que vous sélectionnez \"Supprimer définitivement les éléments inutilisés\" dans l'onglet des éléments inutilisés. Vous pouvez réajouter les éléments supprimés à votre expérience en les faisant glisser hors de la corbeille des éléments inutilisés dans une SEQUENCE ou une LOOP.\n\n</div>"
  },
  "### Step 3: Import images and sound files\n\nFor this experiment, we will use images of cats, dogs, and capybaras. We will also use sound samples of meows and barks. You can download all the required files from here:\n\n- %static:attachments/cats-dogs-capybaras/stimuli.zip%\n\nDownload `stimuli.zip` and extract it somewhere (to your desktop, for example). Next, in OpenSesame, click on the 'Show file pool' button in the main toolbar (or: Menu →View → Show file pool). This will show the file pool, by default on the right side of the window. The easiest way to add the stimuli to the file pool is by dragging them from the desktop (or wherever you have extracted the files to) into the file pool. Alternatively, you can click on the '+' button in the file pool and add files using the file-selection dialog that appears. The file pool will automatically be saved with your experiment.\n\nAfter you have added all stimuli, your file pool looks as in %FigStep4.\n\n<notranslate>\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  The file pool at the end of Step 3.\n</notranslate>\n\n### Step 4: Define the experimental variables in the block_loop\n\nConceptually, our experiment has a fully crossed 3×2 design: We have three types of visual stimuli (cats, dogs, and capybaras) which occur in combination with two types of auditory stimuli (meows and barks). However, we have five exemplars for each stimulus type: five meow sounds, five capybara pictures, etc. From a technical point of view, it therefore makes sense to treat our experiment as a 5×5×3×2 design, in which picture number and sound number are factors with five levels.\n\nOpenSesame is very good at generating full-factorial designs. First, open *block_loop* by clicking on it in the overview area. Next, click on the Full-Factorial Design button. This will open a wizard for generating full-factorial designs, which works in a straightforward way: Every column corresponds to an experimental variable (i.e. a factor). The first row is the name of the variable, the rows below contain all possible values (i.e. levels). In our case, we can specify our 5×5×3×2 design as shown in %FigLoopWizard.\n\n<notranslate>\nfigure:\n id: FigLoopWizard\n source: loop-wizard.png\n caption: |\n  The loop wizard generates full-factorial designs.\n</notranslate>\n\nAfter clicking 'Ok', you will see that there is now a LOOP table with four rows, one for each experimental variable. There are 150 cycles (=5×5×3×2), which means that we have 150 unique trials. Your LOOP table now looks as in %FigStep5.\n\n<notranslate>\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  The LOOP table at the end of Step 4.\n</notranslate>\n\n### Step 5: Add items to the trial sequence\n\nOpen *trial_sequence*, which is still empty. It's time to add some items! Our basic *trial_sequence* is:\n\n1. A SKETCHPAD to display a central fixation dot for 500 ms\n2. A SAMPLER to play an animal sound\n3. A SKETCHPAD to display an animal picture\n4. A KEYBOARD_RESPONSE to collect a response\n5. A LOGGER to write the data to file\n\nTo add these items, simply drag them one by one from the item toolbar into the *trial_sequence*. If you accidentally drop items in the wrong place, you can simply re-order them by dragging and dropping. Once all items are in the correct order, give each of them a sensible name. The overview area now looks as in %FigStep6.\n\n<notranslate>\nfigure:\n id: FigStep6\n source: step6.png\n caption: |\n  The overview area at the end of Step 5.\n</notranslate>\n\n### Step 6: Define the central fixation dot\n\nClick on *fixation_dot* in the overview area. This opens a basic drawing board that you can use to design your visual stimuli. To draw a central fixation dot, first click on the crosshair icon, and then click on the center of the display, i.e. at position (0, 0).\n\nWe also need to specify for how long the fixation dot is visible. To do so, change the duration from 'keypress' to 495 ms, in order to specify a 500 ms duration. (See Background box 4 for an explanation.)": {
    "fr": "### Étape 3 : Importer des images et des fichiers audio\n\nPour cette expérience, nous utiliserons des images de chats, de chiens et de capybaras. Nous utiliserons également des échantillons sonores de miaulements et d'aboiements. Vous pouvez télécharger tous les fichiers nécessaires ici :\n\n- %static:attachments/cats-dogs-capybaras/stimuli.zip%\n\nTéléchargez `stimuli.zip` et extrayez-le quelque part (sur votre bureau, par exemple). Ensuite, dans OpenSesame, cliquez sur le bouton \"Afficher le répertoire de fichiers\" dans la barre d'outils principale (ou : Menu → Vue → Afficher le répertoire de fichiers). Cela affichera la banque de fichiers, par défaut sur le côté droit de la fenêtre. La manière la plus simple d'ajouter les stimuli à la banque de fichiers est de les faire glisser depuis le bureau (ou l'endroit où vous avez extrait les fichiers) dans la banque de fichiers. Sinon, vous pouvez cliquer sur le bouton '+' dans la banque de fichiers et ajouter des fichiers à l'aide de la boîte de dialogue de sélection de fichiers qui apparaît. La banque de fichiers sera automatiquement enregistrée avec votre expérience.\n\nUne fois que vous avez ajouté tous les stimuli, votre banque de fichiers ressemble à celle de %FigStep4.\n\n<notranslate>\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  La banque de fichiers à la fin de l'étape 3.\n</notranslate>\n\n### Étape 4 : Définir les variables expérimentales dans le block_loop\n\nConceptuellement, notre expérience a un plan croisé complet 3x2 : nous avons trois types de stimuli visuels (chats, chiens et capybaras) qui se produisent en combinaison avec deux types de stimuli auditifs (miaulements et aboiements). Cependant, nous avons cinq exemplaires pour chaque type de stimulus : cinq sons de miaulement, cinq images de capybara, etc. D'un point de vue technique, il est donc logique de traiter notre expérience comme un plan 5×5×3×2, dans lequel le numéro de l'image et le numéro du son sont des facteurs avec cinq niveaux.\n\nOpenSesame est très bon pour générer des plans factoriels complets. Tout d'abord, ouvrez le *block_loop* en cliquant dessus dans la zone d'aperçu. Ensuite, cliquez sur le bouton Design factoriel complet. Cela ouvrira un assistant pour générer des plans factoriels complets, qui fonctionne de manière simple : chaque colonne correspond à une variable expérimentale (c'est-à-dire un facteur). La première ligne est le nom de la variable, les lignes ci-dessous contiennent toutes les valeurs possibles (c'est-à-dire les niveaux). Dans notre cas, nous pouvons spécifier notre plan 5×5×3×2 comme indiqué dans %FigLoopWizard.\n\n<notranslate>\nfigure:\n id: FigLoopWizard\n source: loop-wizard.png\n caption: |\n  L'assistant de boucle génère des plans factoriels complets.\n</notranslate>\n\nAprès avoir cliqué sur \"Ok\", vous verrez qu'il y a maintenant une table LOOP avec quatre lignes, une pour chaque variable expérimentale. Il y a 150 cycles (=5×5×3×2), ce qui signifie que nous avons 150 essais uniques. Votre table LOOP ressemble maintenant à celle de %FigStep5.\n\n<notranslate>\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  La table LOOP à la fin de l'étape 4.\n</notranslate>\n\n### Étape 5 : Ajouter des éléments à la séquence d'essais\n\nOuvrez *trial_sequence*, qui est encore vide. Il est temps d'ajouter des éléments ! Notre *trial_sequence* de base est :\n\n1. Un SKETCHPAD pour afficher un point de fixation central pendant 500 ms\n2. Un SAMPLER pour jouer un son d'animal\n3. Un SKETCHPAD pour afficher une image d'animal\n4. Une KEYBOARD_RESPONSE pour recueillir une réponse\n5. Un LOGGER pour enregistrer les données dans un fichier\n\nPour ajouter ces éléments, faites-les simplement glisser un par un depuis la barre d'outils des éléments vers la *trial_sequence*. Si vous déposez accidentellement des éléments au mauvais endroit, vous pouvez simplement les réorganiser en les faisant glisser et en les déposant. Une fois que tous les éléments sont dans le bon ordre, donnez à chacun d'entre eux un nom pertinent. La zone d'aperçu ressemble maintenant à celle de %FigStep6.\n\n<notranslate>\nfigure:\n id: FigStep6\n source: step6.png\n caption: |\n  La zone d'aperçu à la fin de l'étape 5.\n</notranslate>\n\n### Étape 6 : Définir le point de fixation central\n\nCliquez sur *fixation_dot* dans la zone d'aperçu. Cela ouvre un tableau de dessin de base que vous pouvez utiliser pour concevoir vos stimuli visuels. Pour dessiner un point de fixation central, cliquez d'abord sur l'icône en forme de croix, puis cliquez au centre de l'affichage, c'est-à-dire à la position (0, 0).\n\nNous devons également préciser combien de temps le point de fixation est visible. Pour ce faire, changez la durée de \"keypress\" à 495 ms, afin de spécifier une durée de 500 ms. (Voir Background box 4 pour une explication.)"
  },
  "The *fixation_dot* item now looks as in %FigStep7.\n\n<notranslate>\nfigure:\n id: FigStep7\n source: step7.png\n caption: |\n  The *fixation_dot* item at the end of Step 6.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 4: Selecting the correct duration**\n\nWhy specify a duration of 495 if we want a duration of 500 ms? The reason for this is that the actual display-presentation duration is always rounded up to a value that is compatible with your monitor's refresh rate. This may sound complicated, but for most purposes the following rules of thumb are sufficient:\n\n1. Choose a duration that is possible given your monitor's refresh rate. For example, if your monitor's refresh rate is 60 Hz, this means that every frame lasts 16.7 ms (=1000 ms/60 Hz). Therefore, on a 60 Hz monitor, you should always select a duration that is a multiple of 16.7 ms, such as 16.7, 33.3, 50, 100, etc.\n2. In the duration field of the SKETCHPAD specify a duration that is a few milliseconds shorter than what you're aiming for. So if you want to present a SKETCHPAD for 50 ms, choose a duration of 45. If you want to present a SKETCHPAD for 1000 ms, choose a duration of 995. Etcetera.\n\nFor a detailed discussion of experimental timing, see:\n\n- %link:timing%\n\n</div>\n\n### Step 7: Define the animal sound\n\nOpen *animal_sound*. The SAMPLER item provides a number of options, the most important being the sound file that should be played. Click on the browse button to open the file-pool selection dialog, and select one of the sound files, such as `bark1.ogg`.\n\nOf course, we don't want to play the same sound over-and-over again! Instead, we want to select a sound based on the variables `sound` and `sound_nr` that we have defined in the *block_loop* (Step 5). To do this, simply replace the part of the string that you want to have depend on a variable by the name of that variable between square brackets. More specifically, 'bark1.ogg' becomes '[sound][sound_nr].ogg', because we want to replace 'bark' by the value of the variable `sound` and '1' by the value of `sound_nr`.\n\nWe also need to change the duration of the SAMPLER. By default, the duration is 'sound', which means that the experiment will pause while the sound is playing. Change the duration to 0. This does not mean that the sound will be played for only 0 ms, but that the experiment will advance right away to the next item, while the sound continues to play in the background. The item *animal_sound* now looks as shown in %FigStep8.\n\n<notranslate>\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  The item *animal_sound* at the end of Step 7.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 5: Variables**\n\nFor more information about using variables, see:\n\n- %link:manual/variables%\n\n</div>\n\n### Step 8: Define the animal picture\n\nOpen *animal_picture*. Select the image tool by clicking on the button with the landscape-like icon. Click on the center (0, 0) of the display. In the File Pool dialog that appears, select `capybara1.png`. The capybara's sideways glance will now lazily stare at you from the center of the display. But of course, we don't always want to show the same capybara. Instead, we want to have the image depend on the variables `animal` and `pic_nr` that we have defined in the *block_loop* (Step 5).\n\nWe can use essentially the same trick as we did for *animal_sound*, although things work slightly differently for images. First, right-click on the capybara and select 'Edit script'. This allows you to edit the following line of OpenSesame script that corresponds to the capybara picture:\n\n\tdraw image center=1 file=\"capybara1.png\" scale=1 show_if=always x=0 y=0 z_index=0\n\nNow change the name of image file from 'capybara.png' to '[animal][pic_nr].png':\n\n\tdraw image center=1 file=\"[animal][pic_nr].png\" scale=1 show_if=always x=0 y=0 z_index=0": {
    "fr": "L'élément *fixation_dot* apparaît maintenant comme dans %FigStep7.\n\n<notranslate>\nfigure:\n id: FigStep7\n source: step7.png\n caption: |\n  L'élément *fixation_dot* à la fin de l'étape 6.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 4 : Choisir la bonne durée**\n\nPourquoi spécifier une durée de 495 si nous voulons une durée de 500 ms ? La raison est que la durée réelle de présentation de l'affichage est toujours arrondie à une valeur compatible avec le taux de rafraîchissement de votre écran. Cela peut sembler compliqué, mais pour la plupart des applications, les règles de base suivantes sont suffisantes :\n\n1. Choisissez une durée possible compte tenu du taux de rafraîchissement de votre écran. Par exemple, si le taux de rafraîchissement de votre écran est de 60 Hz, cela signifie que chaque image dure 16,7 ms (=1000 ms/60 Hz). Par conséquent, sur un écran de 60 Hz, vous devez toujours choisir une durée qui est un multiple de 16,7 ms, comme 16,7, 33,3, 50, 100, etc.\n2. Dans le champ de durée du SKETCHPAD, spécifiez une durée de quelques millisecondes plus courte que celle que vous visez. Ainsi, si vous voulez présenter un SKETCHPAD pendant 50 ms, choisissez une durée de 45. Si vous voulez présenter un SKETCHPAD pendant 1000 ms, choisissez une durée de 995. Etc.\n\nPour une discussion détaillée sur le chronométrage expérimental, voir :\n\n- %link:timing%\n\n</div>\n\n### Étape 7 : Définir le son de l'animal\n\nOuvrez *animal_sound*. L'élément SAMPLER offre un certain nombre d'options, la plus importante étant le fichier son à jouer. Cliquez sur le bouton de navigation pour ouvrir le sélecteur de fichiers et sélectionnez l'un des fichiers audio, comme `bark1.ogg`.\n\nBien évidemment, nous ne voulons pas jouer le même son encore et encore! Au lieu de cela, nous souhaitons sélectionner un son en fonction des variables `sound` et `sound_nr` que nous avons définies dans le *block_loop* (étape 5). Pour ce faire, remplacez simplement la partie de la chaîne de caractères que vous souhaitez dépendre d'une variable par le nom de cette variable entre crochets. Plus précisément, 'bark1.ogg' devient '[sound][sound_nr].ogg', car nous voulons remplacer 'bark' par la valeur de la variable `sound` et '1' par la valeur de `sound_nr`.\n\nNous devons également changer la durée de l'échantillonneur. Par défaut, la durée est 'sound', ce qui signifie que l'expérience est en pause pendant la lecture du son. Modifiez la durée pour 0. Cela ne signifie pas que le son sera joué pendant seulement 0 ms, mais que l'expérience passera immédiatement à l'élément suivant, pendant que le son continue de jouer en arrière-plan. L'élément *animal_sound* ressemble maintenant à celui présenté dans %FigStep8.\n\n<notranslate>\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  L'élément *animal_sound* à la fin de l'étape 7.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 5 : Variables**\n\nPour plus d'informations sur l'utilisation des variables, consultez :\n\n- %link:manual/variables%\n\n</div>\n\n### Étape 8 : Définir l'image de l'animal\n\nOuvrez *animal_picture*. Sélectionnez l'outil image en cliquant sur le bouton avec l'icône de paysage. Cliquez au centre (0, 0) de l'affichage. Dans la boîte de dialogue File Pool qui apparaît, sélectionnez `capybara1.png`. Le regard de côté du capybara vous observera paresseusement au centre de l'affichage. Mais bien sûr, nous ne voulons pas toujours montrer le même capybara. Au lieu de cela, nous voulons que l'image dépende des variables `animal` et `pic_nr` que nous avons définies dans le *block_loop* (étape 5).\n\nNous pouvons utiliser essentiellement la même astuce que pour *animal_sound*, bien que les choses fonctionnement légèrement différemment pour les images. Tout d'abord, faites un clic droit sur le capybara et sélectionnez \"Modifier le script\". Cela vous permet de modifier la ligne de script OpenSesame correspondant à l'image du capybara :\n\n\tdraw image center=1 file=\"capybara1.png\" scale=1 show_if=always x=0 y=0 z_index=0\n\nMaintenant, changez le nom du fichier image de 'capybara.png' en '[animal][pic_nr].png' :\n\n\tdraw image center=1 file=\"[animal][pic_nr].png\" scale=1 show_if=always x=0 y=0 z_index=0"
  },
  "Click on 'Ok' to apply the change. The capybara is now gone, replaced by a placeholder image, and OpenSesame tells you that one object is not shown, because it is defined using variables. Don't worry, it will be shown during the experiment!\n\nTo remind the participant of the task, also add two response circles, one marked 'dog' on the left side of the screen, and one marked 'cat' on the right side. I'm sure you will able to figure out how to do this with the SKETCHPAD drawing tools. My rendition is shown in %FigStep9. Note that these response circles are purely visual, and we still need to explicitly define the response criteria (see Step 10).\n\nFinally, set 'Duration' field to '0'. This does not mean that the picture is presented for only 0 ms, but that the experiment will advance to the next item (*response*) right away. Since *response* waits for a response, but doesn't change what's on the screen, the target will remain visible until a response has been given.\n\n<notranslate>\nfigure:\n id: FigStep9\n source: step9.png\n caption: |\n  The *animal_picture* SKETCHPAD at the end of Step 8.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 6: Image formats**\n\n__Tip__ -- OpenSesame can handle a wide variety of image formats. However, some (non-standard) `.bmp` formats are known to cause trouble. If you find that a `.bmp` image is not shown, you may want to consider using a different format, such as `.png`. You can convert images easily with free tools such as [GIMP].\n\n</div>\n\n\n### Step 9: Define the response\n\nOpen the *response* item. This is a KEYBOARD_RESPONSE item, which collects a single key press. There are a few options:\n\n- __Correct response__ — let's skip this for now; we'll get back to it in Step 10.\n- __Allowed responses__ is a semicolon-separated list of keys that are accepted. Let's set this to *left;right* to indicate that only the left and right arrow keys are accepted. (The *escape* key pauses the experiment, and is always accepted!)\n- __Timeout__ indicates a duration after which the response will be set to 'None', and the experiment will continue. A timeout is important in our experiment, because participants need to have the opportunity to *not* respond when they see a capybara. So let's set the timeout to 2000.\n- __Flush pending keypresses__ indicates that we should only accept new key presses. This is best left enabled (it is by default).\n\n<notranslate>\nfigure:\n id: FigStep10\n source: step10.png\n caption: |\n  The *response* KEYBOARD_RESPONSE at the end of Step 9.\n</notranslate>\n\n\n### Step 10: Define the correct response\n\nSo far, we haven't defined the correct response for each trial. This is done by defining a `correct_response` variable. You can do this either by creating a `correct_response` column in a LOOP table (here the *block_loop*) and entering the correct responses manually, or by specifying the correct response in a Python INLINE_SCRIPT item—which is what we will do here.\n\nFirst, drag an INLINE_SCRIPT item from the item toolbar and insert it at the top of the *trial_sequence*. (Don't forget to give it a sensible name!) You now see a text editor with two tabs: a *Run* tab, and a *Prepare* tab. You can enter Python code in both tabs, but this code is executed during different phases of the experiment. The *Prepare* phase is executed first whenever a SEQUENCE is executed; this gives all items in the SEQUENCE a chance to perform time consuming operations that could otherwise slow down the experiment at time-sensitive moments. Next, the *Run* phase is executed; this is where the action happens, such as showing a display, collecting a response, etc.\n\nFor more information, see:\n\n- %link:prepare-run%\n\nDefining a correct response is a clear example of something that should be done in the *Prepare* phase. The following script will do the trick:": {
    "fr": "Cliquez sur \"Ok\" pour appliquer le changement. Le capybara a disparu, remplacé par une image fantôme, et OpenSesame vous indique qu'un objet n'est pas affiché car il est défini à l'aide de variables. Ne vous inquiétez pas, il sera affiché pendant l'expérience !\n\nPour rappeler la tâche au participant, ajoutez également deux cercles de réponse, un marqué \"chien\" sur le côté gauche de l'écran et un marqué \"chat\" sur le côté droit. Je suis sûr que vous saurez comment faire cela avec les outils de dessin SKETCHPAD. Ma version est présentée dans %FigStep9. Notez que ces cercles de réponse sont purement visuels, et que nous devons encore définir explicitement les critères de réponse (voir l'étape 10).\n\nEnfin, définissez le champ 'Durée' sur '0'. Cela ne signifie pas que l'image est présentée pendant seulement 0 ms, mais que l'expérience passera à l'objet suivant (*réponse*) immédiatement. Comme *réponse* attend une réponse, mais ne change pas ce qui est affiché à l'écran, la cible restera visible jusqu'à ce qu'une réponse soit donnée.\n\n<notranslate>\nfigure:\n id: FigStep9\n source : step9.png\n caption : |\n  Le SKETCHPAD *animal_picture* à la fin de l'étape 8.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 6: Formats d'image**\n\n__Astuce__ -- OpenSesame peut gérer une grande variété de formats d'image. Cependant, certains formats `.bmp` (non standard) sont connus pour poser problème. Si vous constatez qu'une image `.bmp` n'est pas affichée, vous pouvez envisager d'utiliser un format différent, tel que `.png`. Vous pouvez convertir les images facilement avec des outils gratuits tels que [GIMP].\n\n</div>\n\n\n### Étape 9: Définir la réponse\n\nOuvrez l'objet *réponse*. Il s'agit d'un élément KEYBOARD_RESPONSE, qui collecte une seule pression de touche. Il y a quelques options :\n\n- __Réponse correcte__ — passons cela pour le moment ; nous y reviendrons à l'étape 10.\n- __Réponses autorisées__ est une liste de touches séparées par des points-virgules qui sont acceptées. Définissons-le sur *left;right* pour indiquer que seules les touches fléchées gauche et droite sont acceptées. (La touche *escape* met en pause l'expérience et est toujours acceptée !)\n- __Durée__ indique une durée après laquelle la réponse sera définie sur 'Aucune', et l'expérience se poursuivra. Une durée est importante dans notre expérience, car les participants doivent avoir la possibilité de *ne pas* répondre lorsqu'ils voient un capybara. Fixons donc la durée à 2000.\n- __Vider les pressions de touches en attente__ indique que nous devrions seulement accepter les nouvelles pressions de touches. Il est préférable de le laisser activé (il l'est par défaut).\n\n<notranslate>\nfigure:\n id: FigStep10\n source: step10.png\n caption: |\n  Le KEYBOARD_RESPONSE *réponse* à la fin de l'étape 9.\n</notranslate>\n\n\n### Étape 10: Définir la réponse correcte\n\nJusqu'à présent, nous n'avons pas défini de réponse correcte pour chaque essai. Cela se fait en définissant une variable `correct_response`. Vous pouvez le faire soit en créant une colonne `correct_response` dans un tableau LOOP (ici le *block_loop*) et en entrant les réponses correctes manuellement, soit en spécifiant la réponse correcte dans un élément INLINE_SCRIPT Python, ce que nous ferons ici.\n\nTout d'abord, faites glisser un élément INLINE_SCRIPT depuis la barre d'outils des éléments et insérez-le au début de la *trial_sequence*. (N'oubliez pas de lui donner un nom significatif!) Vous voyez maintenant un éditeur de texte avec deux onglets : un onglet *Run* et un onglet *Prepare*. Vous pouvez saisir du code Python dans les deux onglets, mais ce code est exécuté à différentes phases de l'expérience. La phase *Prepare* est exécutée en premier chaque fois qu'une SEQUENCE est exécutée ; cela donne à tous les éléments de la SEQUENCE la possibilité d'effectuer des opérations longues qui pourraient sinon ralentir l'expérience lors de moments sensibles au temps. Ensuite, la phase *Run* est exécutée ; c'est là que se passe l'action, comme montrer un affichage, collecter une réponse, etc.\n\nPour plus d'informations, voir :\n\n- %link:prepare-run %\n\nDéfinir une réponse correcte est un exemple clair de quelque chose qui doit être fait lors de la phase *Prepare*. Le script suivant fera l'affaire:"
  },
  "~~~ .python\nif var.animal == 'dog':\n\tvar.correct_response = 'left'\nelif var.animal == 'cat':\n\tvar.correct_response = 'right'\nelif var.animal == 'capybara':\n\tvar.correct_response = None # A timeout is coded as None!\nelse:\n\traise ValueError('Invalid animal: %s' % var.animal)\n~~~\n\nThis code is almost plain English, but a few pointers may be useful:\n\n- In Python script, experimental variables are not referred to using square brackets (`[my_variable]`), as they are elsewhere in OpenSesame, but as properties of the `var` object (i.e. `var.my_variable`).\n- We also consider the possibility that the animal is neither a dog, a cat, nor a capybara. Of course this should never happen, but by taking this possibility into account, we protect ourselves against typos and other bugs. This is called 'defensive programming'.\n\n\n### Step 11: Define the logger\n\nWe don't need to configure the LOGGER, because its default settings are fine; but let's take a look at it anyway. Click on *logger* in the overview area to open it. You see that the option 'Log all variables (recommended)' is selected. This means that OpenSesame logs everything, which is fine.\n\n<div class='info-box' markdown='1'>\n\n**Background box 8: Always check your data!**\n\n__The one tip to rule them all__ — Always triple-check whether all necessary variables are logged in your experiment! The best way to check this is to run the experiment and investigate the resulting log files.\n\n</div>\n\n### Step 12: Add per-trial feedback\n\nIt is good practice to inform the participant of whether the response was correct or not. To avoid disrupting the flow of the experiment, this type of immediate feedback should be as unobtrusive as possible. Here, we will do this by briefly showing a green fixation dot after a correct response, and a red fixation dot after an incorrect response.\n\nFirst, add two new SKETCHPADs to the end of the *trial_sequence*. Rename the first one to *feedback_correct* and the second one to *feedback_incorrect*. Of course, we want to run only one of these items on any given trial, depending on whether or not the response was correct. To do this, we can make use of the built-in variable `correct`, which has the value 0 after an incorrect response, and 1 after a correct response. (Provided that we have defined `correct_response`, which we did in Step 11.) To tell the *trial_sequence* that the *feedback_correct* item should be called only when the response is correct, we use the following run-if statement:\n\n\t[correct] = 1\n\nThe square brackets around `correct` indicate that this is the name of a variable, and not simply the string 'correct'. Analogously, we use the following run-if statement for the *feedback_incorrect* item:\n\n\t[correct] = 0\n\nWe still need to give content to the *feedback_correct* and *feedback_incorrect* items. To do this, simply open the items and draw a green or red fixation dot in the center. Also, don't forget to change the durations from 'keypress' to some brief interval, such as 195.\n\nThe *trial_sequence* now looks as shown in %FigStep13.\n\n<notranslate>\nfigure:\n id: FigStep13\n source: step13.png\n caption: |\n  The *trial_sequence* at the end of Step 12.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 9: Conditional statements**\n\nFor more information about conditional 'if' statements, see:\n\n- %link:manual/variables%\n\n</div>\n\n### Step 13: Add instructions and goodbye screens\n\nA good experiment always start with an instruction screen, and ends by thanking the participant for his or her time. The easiest way to do this in OpenSesame is with `form_text_display` items.\n\nDrag two `form_text_display`s into the main *experiment* SEQUENCE. One should be at the very start, and renamed to *form_instructions*. The other should be at the very end, and renamed to *form_finished*. Now simply add some appropriate text to these forms, for example as shown in %FigStep14.": {
    "fr": "~~~ .python\nif var.animal == 'chien':\n\tvar.correct_response = 'gauche'\nelif var.animal == 'chat':\n\tvar.correct_response = 'droite'\nelif var.animal == 'capybara':\n\tvar.correct_response = None # Un délai d'attente est codé comme None!\nelse:\n\traise ValueError('Animal invalide : %s' % var.animal)\n~~~\n\nCe code est presque en anglais courant, mais quelques conseils peuvent être utiles :\n\n- Dans le script Python, les variables expérimentales ne sont pas référencées en utilisant des crochets (`[my_variable]`), comme elles le sont ailleurs dans OpenSesame, mais en tant que propriétés de l'objet `var` (c'est-à-dire `var.my_variable`).\n- Nous prenons également en compte la possibilité que l'animal ne soit ni un chien, ni un chat, ni un capybara. Bien sûr, cela ne devrait jamais arriver, mais en prenant cette possibilité en compte, nous nous protégeons contre les fautes de frappe et autres bugs. Ceci s'appelle la 'programmation défensive'.\n\n\n### Étape 11 : Définir le logger\n\nNous n'avons pas besoin de configurer le LOGGER, car ses paramètres par défaut conviennent; mais regardons-le quand même. Cliquez sur *logger* dans la zone d'aperçu pour l'ouvrir. Vous voyez que l'option 'Log all variables (recommended)' est sélectionnée. Cela signifie qu'OpenSesame enregistre tout, ce qui est bien.\n\n<div class='info-box' markdown='1'>\n\n**Encadré 8 : Vérifiez toujours vos données !**\n\n__Le conseil ultime__ — Vérifiez toujours et encore si toutes les variables nécessaires sont enregistrées dans votre expérience! Le meilleur moyen de vérifier cela est de lancer l'expérience et d'examiner les fichiers journaux résultants.\n\n</div>\n\n### Étape 12: Ajouter un retour d'information par essai\n\nIl est bon de prévenir le participant si la réponse était correcte ou non. Pour éviter de perturber le déroulement de l'expérience, ce type de retour d'information immédiat doit être aussi discret que possible. Ici, nous le ferons en affichant brièvement un point de fixation vert après une réponse correcte, et un point de fixation rouge après une réponse incorrecte.\n\nTout d'abord, ajoutez deux nouveaux SKETCHPADs à la fin de la *trial_sequence*. Renommez le premier en *feedback_correct* et le second en *feedback_incorrect*. Bien sûr, nous voulons exécuter seulement l'un de ces éléments lors d'un essai donné, en fonction de la réponse correcte ou non. Pour ce faire, nous pouvons utiliser la variable intégrée `correct`, qui a la valeur 0 après une réponse incorrecte et 1 après une réponse correcte. (À condition d'avoir défini `correct_response`, ce que nous avons fait à l'étape 11.) Pour indiquer à la *trial_sequence* que l'élément *feedback_correct* doit être appelé uniquement lorsque la réponse est correcte, nous utilisons la déclaration run-if suivante :\n\n\t[correct] = 1\n\nLes crochets autour de `correct` indiquent qu'il s'agit du nom d'une variable, et non simplement de la chaîne 'correct'. De manière analogue, nous utilisons la déclaration run-if suivante pour l'élément *feedback_incorrect*:\n\n\t[correct] = 0\n\nIl nous reste à donner du contenu aux éléments *feedback_correct* et *feedback_incorrect*. Pour ce faire, ouvrez simplement les éléments et dessinez un point de fixation vert ou rouge au centre. N'oubliez pas non plus de changer les durées de 'keypress' à un intervalle court, comme 195.\n\nLe *trial_sequence* apparaît maintenant comme indiqué dans %FigStep13.\n\n<notranslate>\nfigure:\n id: FigStep13\n source: step13.png\n caption: |\n  Le *trial_sequence* à la fin de l'étape 12.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 9 : Déclarations conditionnelles**\n\nPour plus d'informations sur les déclarations conditionnelles 'if', voir :\n\n- %link:manual/variables%\n\n</div>\n\n### Étape 13: Ajouter des instructions et des écrans d'au revoir\n\nUne bonne expérience commence toujours par un écran d'instructions et se termine en remerciant le participant pour le temps qu'il a consacré. La manière la plus simple de le faire dans OpenSesame est avec des éléments `form_text_display`.\n\nFaites glisser deux `form_text_display`s dans la SEQUENCE principale *experiment*. L'un doit être au tout début, et renommé en *form_instructions*. L'autre doit être à la toute fin, et renommé en *form_finished*. Maintenant, ajoutez simplement du texte approprié à ces formulaires, par exemple comme indiqué dans %FigStep14."
  },
  "<notranslate>\nfigure:\n id: FigStep14\n source: step14.png\n caption: |\n  The *form_instructions* item at the end of Step 13.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 10: Text**\n\n__Tip__ -- Forms, and text more generally, support a subset of HTML tags to allow for text formatting (i.e. colors, boldface, etc.). This is described here:\n\n- %link:visual%\n\n</div>\n\n### Step 15: Finished!\n\nYour experiment is now finished! Click on the 'Run fullscreen' (`Control+R`) button in the main toolbar to give it a test run. You can also upload the experiment to OSWeb (<http://osweb.cogsci.nl/>) and run it online!\n\n<div class='info-box' markdown='1'>\n\n**Background box 11: Quick run**\n\n__Tip__ — A test run is executed even faster by clicking the orange 'Run in window' button, which doesn't ask you how to save the logfile (and should therefore only be used for testing purposes).\n\n</div>\n\n\n## Extra assignments\n\nThe solutions to these extra assingments can be found in the [experiment file](http://osf.io/jw7dr).\n\n### Extra 1: Add an instruction and goodbye screen\n\nTips:\n\n- SKETCHPAD and FORM_TEXT_DISPLAY can present text\n- Good instructions are brief and concrete\n\n### Extra 2: Analyze the data\n\nTips:\n\n- Run the experiment once on yourself\n- Open the data file in Excel, LibreOffice, or JASP\n\n### Extra 3: Divide the trials into multiple blocks\n\nTips:\n\n- Use a break-if statement to break the loop after (say) 15 trials: `([count_trial_sequence]+1) % 15 = 0`\n- Add a new LOOP-SEQUENCE structure above the *block_loop* to repeat a block of trials multiple times\n- Disable the 'Evaluate on first cycle' option in the *block_loop* so that the break-if statement isn't evaluated when the `count_trial_sequence` variable doesn't yet exist\n- Enable the 'Resume after break' option in the *block_loop* to randomly sample without replacement from the LOOP table\n\n### Extra 4: Add accuracy and average response time feedback after every block\n\nFirst do Extra 3!\n\nTips:\n\n- Use a FEEDBACK item to provide feedback\n- The variables `acc` and `avg_rt` contain the running accuracy and average reaction time\n\n### Extra 5: Counterbalance the response rule\n\nTips:\n\n- The variable `subject_parity` is 'even' or 'odd'\n- This requires a simple INLINE_SCRIPT\n- Make sure that the instructions match the response rule!\n\n\n## References\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314–324. doi:10.3758/s13428-011-0168-7\n{: .reference}\n\n[OpenSesame runtime for Android]: /getting-opensesame/android\n[slides]: /attachments/rovereto2014-workshop-slides.pdf\n[modulo]: http://en.wikipedia.org/wiki/Modulo_operation\n[pdf]: /rovereto2014/index.pdf\n[gimp]: http://www.gimp.org/\n[capybara_photo]: https://commons.wikimedia.org/wiki/File:Capybara_Hattiesburg_Zoo_(70909b-58)_2560x1600.jpg\n": {
    "fr": "<notranslate>\nfigure:\n id: FigStep14\n source: step14.png\n caption: |\n  L'élément *form_instructions* à la fin de l'étape 13.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 10 : Texte**\n\n__Astuce__ -- Les formulaires, et plus généralement le texte, prennent en charge un sous-ensemble de balises HTML pour permettre la mise en forme du texte (c'est-à-dire les couleurs, le gras, etc.). Ceci est décrit ici :\n\n- %link:visual%\n\n</div>\n\n### Étape 15 : Terminé !\n\nVotre expérience est maintenant terminée ! Cliquez sur le bouton \"Run fullscreen\" (`Control+R`) dans la barre d'outils principale pour faire un essai. Vous pouvez également télécharger l'expérience sur OSWeb (<http://osweb.cogsci.nl/>) et la lancer en ligne !\n\n<div class='info-box' markdown='1'>\n\n**Encadré 11 : Exécution rapide**\n\n__Astuce__ — Une exécution de test est encore plus rapide en cliquant sur le bouton orange \"Exécuter dans une fenêtre\", qui ne vous demande pas comment enregistrer le fichier de journalisation (et ne doit donc être utilisé qu'à des fins de test).\n\n</div>\n\n## Travaux pratiques supplémentaires\n\nLes solutions à ces travaux pratiques supplémentaires se trouvent dans le [fichier d'expérience](http://osf.io/jw7dr).\n\n### Supplément 1 : Ajouter un écran d'instructions et d'au revoir\n\nConseils :\n\n- SKETCHPAD et FORM_TEXT_DISPLAY peuvent présenter du texte\n- De bonnes instructions sont brèves et concrètes\n\n### Supplément 2 : Analyser les données\n\nConseils :\n\n- Lancez l'expérience une fois sur vous-même\n- Ouvrez le fichier de données dans Excel, LibreOffice ou JASP\n\n### Supplément 3 : Diviser les essais en plusieurs blocs\n\nConseils :\n\n- Utilisez une instruction break-if pour interrompre la boucle après (disons) 15 essais : `([count_trial_sequence]+1) % 15 = 0`\n- Ajoutez une nouvelle structure LOOP-SEQUENCE au-dessus de la *boucle de bloc* pour répéter un bloc d'essais plusieurs fois\n- Désactivez l'option \"Évaluer lors du premier cycle\" dans la *boucle de bloc* pour que l'instruction break-if ne soit pas évaluée lorsque la variable `count_trial_sequence` n'existe pas encore\n- Activez l'option \"Reprendre après la pause\" dans la *boucle de bloc* pour échantillonner aléatoirement sans remplacement à partir de la table LOOP\n\n### Supplément 4 : Ajouter des commentaires sur la précision et le temps de réponse moyen après chaque bloc\n\nFaites d'abord Supplément 3 !\n\nConseils :\n\n- Utilisez un élément FEEDBACK pour fournir des commentaires\n- Les variables `acc` et `avg_rt` contiennent la précision et le temps de réaction moyen en cours\n\n### Supplément 5 : Contrebalancer la règle de réponse\n\nConseils :\n\n- La variable `subject_parity` est \"pair\" ou \"impair\"\n- Cela nécessite un simple INLINE_SCRIPT\n- Assurez-vous que les instructions correspondent à la règle de réponse !\n\n## Références\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n{: .reference}\n\n[OpenSesame runtime for Android]: /getting-opensesame/android\n[diapositives]: /attachments/rovereto2014-workshop-slides.pdf\n[modulo]: http://fr.wikipedia.org/wiki/Op%C3%A9ration_modulo\n[pdf]: /rovereto2014/index.pdf\n[gimp]: http://www.gimp.org/\n[capybara_photo]: https://commons.wikimedia.org/wiki/File:Capybara_Hattiesburg_Zoo_(70909b-58)_2560x1600.jpg"
  },
  "Meet the team!": {
    "fr": "Rencontrez l'équipe !"
  },
  "OpenSesame is mainly developed by a loose collection of individuals. But anyone is welcome to contribute!\n\n<notranslate>[TOC]</notranslate>\n\n## [Sebastiaan Mathôt](http://www.cogsci.nl/smathot)\n\nProject manager and lead developer\n\n*Laboratoire de Psychologie Cognitive, CNRS, Aix-Marseille Université*\n\n<notranslate>\nfigure:\n source: sebastiaan.png\n id: FigSebastiaan\n caption: Sebastiaan Mathôt\n</notranslate>\n\nI'm currently a Marie Curie fellow at the Laboratoire de Pyschologie Cognitive in Marseille, France. My research focuses on the relationship between the pupillary light response, visual attention, and eye movements.\n\nOpenSesame is the more pragmatic side of my job. With this project, we aim to provide experimental psychologists and neuroscientists with a free (in every sense of the word) high quality experiment builder.\n\n---\n\n## Daniel Schreij\n\nDeveloper\n\n*Freelance software developer*\n\n<notranslate>\nfigure:\n source: daniel.png\n id: FigDaniel\n caption: Daniel Schreij\n</notranslate>\n\nI have always had a fond interest in both technology and human cognition and therefore chose to study Artificial Intelligence (AI), which is a combination of these two disciplines. During this time, I was mainly drawn towards the\n'what makes people tick' side of AI and this led me to follow a master's degree in Cognitive Science. In this area, I also graduated for my PhD Degree at the VU University of Amsterdam, where I have worked as a post-doc. During all this time, I never lost my interest in computer science and kept up to speed with the latest developments in this area. Currently, I am working as a freelance software developer for scientific projects.\n\nI am happy I can assist Sebastiaan in the development of OpenSesame, as it allows to keep doing more pragmatic tasks like software development\nwhich I really like, and at the same time lets me stay involved in psychological research.\n\n---\n\n## [Lotje van der Linden](http://www.cogsci.nl/lvanderlinden)\n\nDocumentation and support\n\n*Laboratoire de Psychologie Cognitive, Aix-Marseille Université*\n\n<notranslate>\nfigure:\n source: lotje.png\n id: FigLotje\n caption: Lotje van der Linden\n</notranslate>\n\nI'm working as a PhD student under supervision of Françoise Vitu at the Laboratoire Psychologie Cognitive at the Aix-Marseille Université. My PhD project is on whether affordances (possibilities for action in our environment) influence how and where we move our eyes.\n\nI really enjoy being involved in the OpenSesame project, from helping with the documentation to offering support on the forum. So don't hesitate to post any questions!\n\n---\n\n## [Edwin Dalmaijer](http://www.pygaze.org/esdalmaijer/)\n\nDeveloper\n\n*Department of Experimental Psychology, Utrecht University*\n\n<notranslate>\nfigure:\n source: edwin.png\n id: FigEdwin\n caption: Edwin Dalmaijer\n</notranslate>\n\nI'm currently a PhD student at Oxford University. For the OpenSesame project, I maintain the affiliated PyGaze package for eye tracking.\n\nBeing young and idealistic, I am a strong believer in the principles of open source software. I think OpenSesame is a great example of how open source software can really be a good alternative to - often very expensive - commercial software.\n\n---\n\n## Eduard Ort\n\nDocumentation and support\n\n*Department of Cognitive Psychology, Vrije Universiteit Amsterdam*\n\n<notranslate>\nfigure:\n source: eduard.png\n id: FigEduard\n caption: Eduard Ort\n</notranslate>\n\nI am a PhD candidate with Chris Olivers and Johannes Fahrenfort. Together we investigate what kinds of representations can serve as attentional templates in visual search.\n\nHaving used Opensesame during my studies, I am very happy to have gotten the chance to contribute to its development. I think many researchers could benefit from using this powerful and easy-to-use tool.\n\n---\n\n## Joshua Snell\n\nDocumentation and support\n\n*Laboratoire de Psychologie Cognitive, CNRS, Aix-Marseille Université*": {
    "fr": "OpenSesame est principalement développé par un groupe informel d'individus. Mais tout le monde est le bienvenu pour contribuer !\n\n<notranslate>[TOC]</notranslate>\n\n## [Sebastiaan Mathôt](http://www.cogsci.nl/smathot)\n\nChef de projet et développeur principal\n\n*Laboratoire de Psychologie Cognitive, CNRS, Aix-Marseille Université*\n\n<notranslate>\nfigure:\n source: sebastiaan.png\n id: FigSebastiaan\n caption: Sebastiaan Mathôt\n</notranslate>\n\nJe suis actuellement boursier Marie Curie au Laboratoire de Psychologie Cognitive de Marseille, en France. Mes recherches portent sur la relation entre la réponse pupillaire à la lumière, l'attention visuelle et les mouvements oculaires.\n\nOpenSesame est l'aspect plus pragmatique de mon travail. Avec ce projet, nous souhaitons fournir aux psychologues expérimentaux et aux neuroscientifiques un générateur d'expériences de haute qualité et gratuit (dans tous les sens du terme).\n\n---\n\n## Daniel Schreij\n\nDéveloppeur\n\n*Développeur de logiciels indépendant*\n\n<notranslate>\nfigure:\n source: daniel.png\n id: FigDaniel\n caption: Daniel Schreij\n</notranslate>\n\nJ'ai toujours été intéressé par la technologie et la cognition humaine, c'est pourquoi j'ai choisi d'étudier l'intelligence artificielle (IA), qui est une combinaison de ces deux disciplines. Pendant cette période, j'ai été principalement attiré par le côté \"ce qui fait agir les gens\" de l'IA, ce qui m'a conduit à suivre une maîtrise en sciences cognitives. Dans ce domaine, j'ai également obtenu mon doctorat à la VU University d'Amsterdam, où j'ai travaillé en tant que post-doctorant. Pendant tout ce temps, je n'ai jamais perdu mon intérêt pour l'informatique et j'ai suivi de près les derniers développements dans ce domaine. Actuellement, je travaille en tant que développeur de logiciels indépendant pour des projets scientifiques.\n\nJe suis ravi de pouvoir aider Sebastiaan dans le développement d'OpenSesame, car cela me permet de continuer à effectuer des tâches plus pragmatiques comme le développement de logiciels, que j'aime beaucoup, et en même temps, de rester impliqué dans la recherche en psychologie.\n\n---\n\n## [Lotje van der Linden](http://www.cogsci.nl/lvanderlinden)\n\nDocumentation et support\n\n*Laboratoire de Psychologie Cognitive, Aix-Marseille Université*\n\n<notranslate>\nfigure:\n source: lotje.png\n id: FigLotje\n caption: Lotje van der Linden\n</notranslate>\n\nJe travaille en tant que doctorante sous la supervision de Françoise Vitu au Laboratoire de Psychologie Cognitive de l'Aix-Marseille Université. Mon projet de doctorat porte sur la façon dont les affordances (possibilités d'action dans notre environnement) influencent les mouvements et les endroits où nous dirigeons nos yeux.\n\nJe suis vraiment ravie de participer au projet OpenSesame, de contribuer à la documentation et d'offrir un soutien sur le forum. N'hésitez donc pas à poser vos questions !\n\n---\n\n## [Edwin Dalmaijer](http://www.pygaze.org/esdalmaijer/)\n\nDéveloppeur\n\n*Département de Psychologie Expérimentale, Université d'Utrecht*\n\n<notranslate>\nfigure:\n source: edwin.png\n id: FigEdwin\n caption: Edwin Dalmaijer\n</notranslate>\n\nJe suis actuellement doctorant à l'Université d'Oxford. Pour le projet OpenSesame, je m'occupe du package PyGaze lié à l'oculométrie.\n\nJeune et idéaliste, je crois fermement aux principes des logiciels libres. Je pense qu'OpenSesame est un excellent exemple de la manière dont les logiciels libres peuvent constituer une véritable alternative aux logiciels commerciaux, souvent très coûteux.\n\n---\n\n## Eduard Ort\n\nDocumentation et support\n\n*Département de Psychologie Cognitive, Vrije Universiteit Amsterdam*\n\n<notranslate>\nfigure:\n source: eduard.png\n id: FigEduard\n caption: Eduard Ort\n</notranslate>\n\nJe suis doctorant avec Chris Olivers et Johannes Fahrenfort. Ensemble, nous étudions les types de représentations pouvant servir de modèles attentionnels dans la recherche visuelle.\n\nAyant utilisé OpenSesame pendant mes études, je suis très heureux d'avoir eu l'occasion de contribuer à son développement. Je pense que de nombreux chercheurs pourraient bénéficier de l'utilisation de cet outil puissant et facile à utiliser.\n\n---\n\n## Joshua Snell\n\nDocumentation et support\n\n*Laboratoire de Psychologie Cognitive, CNRS, Aix-Marseille Université*"
  },
  "<notranslate>\nfigure:\n source: joshua.png\n id: FigJoshua\n caption: Joshua Snell\n</notranslate>\n\nHi! I am a PhD student at the Laboratoire de Psychologie Cognitive in Marseille. I'll happily contribute in finding a solution to any problem you might encounter while realizing your experiment (or whatever it is you want to use OpenSesame for - heck, you could even make games with it!)\n": {
    "fr": "<notranslate>\nfigure:\n source: joshua.png\n id: FigJoshua\n caption: Joshua Snell\n</notranslate>\n\nSalut ! Je suis doctorant au Laboratoire de Psychologie Cognitive à Marseille. Je serai ravi de contribuer à trouver une solution à tout problème que vous pourriez rencontrer lors de la réalisation de votre expérience (ou pour toute autre utilisation d'OpenSesame - vous pourriez même créer des jeux avec !)"
  },
  "Publications": {
    "fr": "Publications"
  },
  "<notranslate>[TOC]</notranslate>\n\n\n## How to cite OpenSesame\n\nIf you have used OpenSesame, we would appreciate it if you cite us:\n\n- Mathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nIf you make extensive use of modules such as SciPy/ NumPy, [PsychoPy][psycho], or [Expyriment][xpyriment], please also cite the respective authors.\n\n\n## OpenSesame in publications, theses, conference proceedings, etc.\n\n<div class=\"reference\" markdown=\"1\">\n\n### 2017 / in press / online first\n\nAdamou, E., & Shen, X. R. (2017). There are no language switching costs when codeswitching is frequent. *International Journal of Bilingualism*. doi:10.1177/1367006917709094\n\nAlbonico, A., & Barton, J. J. S. (2017). Face perception in pure alexia: Complementary contributions of the left fusiform gyrus to facial identity and facial speech processing. *Cortex*. doi:10.1016/j.cortex.2017.08.029\n\nBahn, D., Vesker, M., García Alanis, J. C., Schwarzer, G., & Kauschke, C. (2017). Age-dependent positivity-bias in children’s processing of emotion terms. *Frontiers in Psychology*, 8. doi:10.3389/fpsyg.2017.01268\n\nBonny, J. W., Lindberg, J. C., & Pacampara, M. C. (2017). Hip hop dance experience linked to sociocognitive ability. *PLoS ONE*, *12*(2), e0169947. doi:journal.pone.0169947\n\nBernstein, E. E., Heeren, A., & McNally, R. J. (2017). Unpacking Rumination and Executive Control: A Network Perspective. *Clinical Psychological Science*. doi:10.1177/2167702617702717\n\nÇakır, M. P., Çakır, N. A., Ayaz, H., & Lee, F. J. (2016). Behavioral and neural effects of game-based learning on improving computational fluency with numbers. *Zeitschrift Für Psychologie*, *224*(4), 297–302. doi:10.1027/2151-2604/a000267\n\nĆirić, M., & Đurđević, D. F. (2017). Procene konkretnosti reči zavise od stimulusnog konteksta. *Primenjena Psihologija*, *10*(3), 375–400. doi:10.19090/pp.2017.3.375-400\n\nDeclerck, M., Snell, J., & Grainger, J. (2017). On the role of language membership information during word recognition in bilinguals: Evidence from flanker-language congruency effects. *Psychonomic Bulletin & Review*. doi:10.3758/s13423-017-1374-9\n\nFairhurst, M. T., & Deroy, O. (2017). Testing the shared spatial representation of magnitude of auditory and visual intensity. *Journal of Experimental Psychology: Human Perception and Performance*, *43*(3), 629–637. doi:10.1037/xhp0000332\n\nFairchild, S., & Papafragou, A. (2017). Flexible expectations of speaker informativeness shape pragmatic inference. *University of Pennsylvania Working Papers in Linguistics*, 23(1), 7.\n\nFerrand, L., Méot, A., Spinelli, E., New, B., Pallier, C., Bonin, P., Dufau, S., Mathôt, S., & Grainger, J. (2017). MEGALEX: A megastudy of visual and auditory word recogntion. *Behavior Research Methods*. doi:10.3758/s13428-017-0943-1\n\nFido, D., Santo, M. G. E., Bloxsom, C. A. J., Gregson, M., & Sumich, A. L. (2017). Electrophysiological study of the violence inhibition mechanism in relation to callous-unemotional and aggressive traits. *Personality and Individual Differences*, *118*, 44–49. doi:10.1016/j.paid.2017.01.049\n\nFormoso, J., Barreyro, J.P, Jacubovich, S., & Injoque-Ricle, I. (2017). Possible associations between subitizing, estimation\nand visuospatial working memory (VSWM) in\nchildren. *The Spanish Journal of Psychology*. doi:10.1017/sjp.2017.23\n\nGaraizar, P., & Vadillo, M. A. (2017). Metronome LKM: An open source virtual keyboard driver to measure experiment software latencies. *Behavior Research Methods*. doi:10.3758/s13428-017-0958-7\n\nGarza, R., Heredia, R. R., & Cieślicka, A. B. (2017). An eye tracking examination of men’s attractiveness by conceptive risk women. *Evolutionary Psychology*, *15*(1). doi:10.1177/1474704917690741": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n\n## Comment citer OpenSesame\n\nSi vous avez utilisé OpenSesame, nous vous serions reconnaissants de nous citer :\n\n- Mathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame : Un logiciel libre, concepteur d'expériences graphiques pour les sciences sociales. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nSi vous utilisez largement des modules tels que SciPy/ NumPy, [PsychoPy][psycho], ou [Expyriment][xpyriment], veuillez également citer les auteurs respectifs.\n\n\n## OpenSesame dans les publications, thèses, actes de conférence, etc.\n\n<div class=\"reference\" markdown=\"1\">\n\n### 2017 / sous presse / en ligne en premier\n\nAdamou, E., & Shen, X. R. (2017). Il n'y a pas de coûts de commutation de langue lorsque la commutation de code est fréquente. *International Journal of Bilingualism*. doi:10.1177/1367006917709094\n\nAlbonico, A., & Barton, J. J. S. (2017). Perception du visage dans l'alexie pure : Contributions complémentaires du gyrus fusiforme gauche à l'identité faciale et au traitement de la parole faciale. *Cortex*. doi:10.1016/j.cortex.2017.08.029\n\nBahn, D., Vesker, M., García Alanis, J. C., Schwarzer, G., & Kauschke, C. (2017). Tendance à l'optimisme liée à l'âge dans le traitement des termes émotionnels chez les enfants. *Frontiers in Psychology*, 8. doi:10.3389/fpsyg.2017.01268\n\nBonny, J. W., Lindberg, J. C., & Pacampara, M. C. (2017). L'expérience de la danse hip hop liée à la capacité sociocognitive. *PLoS ONE*, *12*(2), e0169947. doi:journal.pone.0169947\n\nBernstein, E. E., Heeren, A., & McNally, R. J. (2017). Déballer les rumination et contrôle exécutif: Une perspective de réseau. *Clinical Psychological Science*. doi:10.1177/2167702617702717\n\nÇakır, M. P., Çakır, N. A., Ayaz, H., & Lee, F. J. (2016). Effets comportementaux et neuronaux de l'apprentissage basé sur les jeux pour améliorer la fluidité computationnelle avec les chiffres. *Zeitschrift Für Psychologie*, *224*(4), 297–302. doi:10.1027/2151-2604/a000267\n\nĆirić, M., & Đurđević, D. F. (2017). Les estimations de la concrétude des mots dépendent du contexte des stimuli. *Primenjena Psihologija*, *10*(3), 375–400. doi:10.19090/pp.2017.3.375-400\n\nDeclerck, M., Snell, J., & Grainger, J. (2017). The role of language membership information during word recognition in bilinguals: Evidence from flanker-language congruency effects. *Psychonomic Bulletin & Review*. doi:10.3758/s13423-017-1374-9\n\nFairhurst, M. T., & Deroy, O. (2017). Testing the shared spatial representation of magnitude of auditory and visual intensity. *Journal of Experimental Psychology: Human Perception and Performance*, *43*(3), 629–637. doi:10.1037/xhp0000332\n\nFairchild, S., & Papafragou, A. (2017). Les attentes flexibles de l'information du locuteur façonnent l'inférence pragmatique. *University of Pennsylvania Working Papers in Linguistics*, 23(1), 7.\n\nFerrand, L., Méot, A., Spinelli, E., New, B., Pallier, C., Bonin, P., Dufau, S., Mathôt, S., & Grainger, J. (2017). MEGALEX : Une mégétude de la reconnaissance visuelle et auditive des mots . *Behavior Research Methods*. doi:10.3758/s13428-017-0943-1\n\nFido, D., Santo, M. G. E., Bloxsom, C. A. J., Gregson, M., & Sumich, A. L. (2017). Étude électrophysiologique du mécanisme d'inhibition de la violence en relation avec les caractères apathiques-agressifs. *Personality and Individual Differences*, *118*, 44–49. doi:10.1016/j.paid.2017.01.049\n\nFormoso, J., Barreyro, J.P, Jacubovich, S., & Injoque-Ricle, I. (2017). Associations possibles entre la subitisation, l'estimation et la mémoire de travail spatiale visuelle (VSWM) chez les enfants. *The Spanish Journal of Psychology*. doi:10.1017/sjp.2017.23\n\nGaraizar, P., & Vadillo, M. A. (2017). Metronome LKM : Un pilote de clavier virtuel open source pour mesurer les temps de latence des logiciels expérimentaux. *Behavior Research Methods*. doi:10.3758/s13428-017-0958-7\n\nGarza, R., Heredia, R. R., & Cieślicka, A. B. (2017). Un examen oculomoteur de l'attrait des hommes pour les femmes à risque de conception. *Evolutionary Psychology*, *15*(1). doi:10.1177/1474704917690741"
  },
  "Leiden University 2022 workshop": {
    "fr": "Atelier de l'Université de Leiden 2022"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## Practical information\n\n- Host: Leiden University\n- Location and dates: \n    - Day 1: Oct 10, FSW, Living Lab 1B01, 13:00 - 17:00\n    - Day 2: Oct 17, FSW, Living Lab 1B01, 13:00 - 17:00\n- Presenters: Lotje van der Linden and Sebastiaan Mathôt\n\n\n## Description\n\nIn this two-day, hands-on workshop, you will learn how to implement psychological experiments with the open-source software OpenSesame. You will learn:\n\n- How to build and run experiments with OpenSesame\n- The limitations and advantages of online and laboratory-based experiments.\n- How to parse data collected with OpenSesame\n\nAn important aspect of the workshop will also be to help you with things that are directly relevant for your own research. Therefore, each day ends with a Q&A session. To make the most out the workshop, think in advance about what you would like to use OpenSesame for, and what you need help with during this workshop!\n\nIf you want to work on your own computer, please install OpenSesame before the workshop. You can download OpenSesame for free from <https://osdoc.cogsci.nl/>. No prior experience with OpenSesame, Python, or JavaScript is required.\n\nWe're looking forward to meeting you all!\n\n— Lotje and Sebastiaan\n\n\n### Day 1 (Oct 10): Introduction\n\nFirst presentation:\n\n- %static:attachments/leiden2022/1_Intro_OpenSesame_slides.pdf%\n\nSecond presentation:\n\n- %static:attachments/leiden2022/2_Cats_dogs_slides.pdf%\n\nSchedule:\n\n- 13:00 – 14:30: __Introduction to OpenSesame__. A general introduction to the software OpenSesame, followed by a hands-on tutorial in which you will learn the basic concepts of the software.\n- Break\n- 15:00 – 16:00: __Introduction to OpenSesame (continued)__. Continue with extra assignments to improve the experiment.\n- 16:00 – 17:00: __Q&A__ What kind of experiment would you like to build for your own research? And what kind of help do you need from us?\n\n\n### Day 2 (Oct 17): Online experiments + data analysis\n\nSlides:\n\n- *Will be made available here*\n\nExperiment file (in case you didn't create your own during day 1):\n\n- %static:attachments/leiden2022/capybaras.osexp%\n\nParticipant data files (experiment 2 from [this paper](https://doi.org/10.16910/jemr.5.2.4)):\n\n- %static:attachments/leiden2022/jemr2012exp2.zip%\n\nSchedule:\n\n- 13:00 – 14:00: __Building an online experiment.__ We will start this session with a general introduction to online experiments. This is followed by a hands-on tutorial in which we will modify the experiment that we created during Day 1 so that it is suitable for running online.\n- 14:00 – 15:00: __Using <https://mindprobe.eu> (a JATOS server) to run experiments online.__ In this session, you will learn how to use mindprobe.eu, which is a free server that runs the open-source software JATOS, to actually run an experiment online. A mindprobe.eu account will be provided to each participant.\n- Break\n- 15:30 – 16:00: __Getting data ready for analysis.__ We will start this session with a general explanation of how data is structured, both for experiments that are conducted online and for experiments that are conducted in a traditional laboratory set-up. Next, we will see how to transform this data into a format that lends itself to statistical analysis. Specifically, we will learn how data from multiple participants can be merged into a single `.csv` spreadsheet; we will also learn how data from an online experiment can be downloaded from JATOS and converted to a `.csv` spreadsheet.\n- 16:00 – 17:00: __Q&A__ What kind of experiment would you like to build for your own research? And what kind of help do you need from us?\n": {
    "fr": "\n<notranslate>[TOC]</notranslate>\n\n\n## Informations pratiques\n\n- Hôte : Université de Leiden\n- Lieu et dates :\n    - Jour 1 : 10 octobre, FSW, Living Lab 1B01, 13h00 - 17h00\n    - Jour 2 : 17 octobre, FSW, Living Lab 1B01, 13h00 - 17h00\n- Conférenciers : Lotje van der Linden et Sebastiaan Mathôt\n\n\n## Description\n\nDans cet atelier pratique de deux jours, vous apprendrez à mettre en œuvre des expériences de psychologie avec le logiciel open-source OpenSesame. Vous apprendrez:\n\n- Comment construire et exécuter des expériences avec OpenSesame\n- Les limites et avantages des expériences en ligne et en laboratoire.\n- Comment analyser les données collectées avec OpenSesame\n\nUn aspect important de l'atelier sera également de vous aider avec des choses qui sont directement pertinentes pour votre propre recherche. Par conséquent, chaque jour se termine par une séance de questions-réponses. Pour tirer le meilleur parti de l'atelier, réfléchissez à l'avance à ce que vous aimeriez utiliser OpenSesame pour, et à ce dont vous avez besoin d'aide lors de cet atelier !\n\nSi vous souhaitez travailler sur votre propre ordinateur, veuillez installer OpenSesame avant l'atelier. Vous pouvez télécharger OpenSesame gratuitement sur <https://osdoc.cogsci.nl/>. Aucune expérience préalable avec OpenSesame, Python ou JavaScript n'est requise.\n\nNous avons hâte de vous rencontrer tous !\n\n— Lotje et Sebastiaan\n\n### Jour 1 (10 octobre) : Introduction\n\nPremière présentation :\n\n- %static:attachments/leiden2022/1_Intro_OpenSesame_slides.pdf%\n\nDeuxième présentation :\n\n- %static:attachments/leiden2022/2_Cats_dogs_slides.pdf%\n\nProgramme :\n\n- 13h00 – 14h30 : __Introduction à OpenSesame__. Une introduction générale au logiciel OpenSesame, suivie d'un tutoriel pratique dans lequel vous apprendrez les concepts de base du logiciel.\n- Pause\n- 15h00 – 16h00 : __Introduction à OpenSesame (suite)__. Poursuivre avec des exercices supplémentaires pour améliorer l'expérience.\n- 16h00 – 17h00 : __Questions-réponses__ Quel type d'expérience aimeriez-vous créer pour vos propres recherches ? Et de quelle aide avez-vous besoin de notre part ?\n\n### Jour 2 (17 octobre) : Expériences en ligne et analyse de données\n\nDiapositives :\n\n- *Seront mises à disposition ici*\n\nFichier d'expérience (au cas où vous n'en auriez pas créé un lors du Jour1) :\n\n- %static:attachments/leiden2022/capybaras.osexp%\n\nFichiers de données des participants (expérience 2 de [cet article](https://doi.org/10.16910/jemr.5.2.4)) :\n\n- %static:attachments/leiden2022/jemr2012exp2.zip%\n\nProgramme :\n\n- 13h00 – 14h00 : __Création d'une expérience en ligne.__ Nous commencerons cette séance par une introduction générale aux expériences en ligne. Cela sera suivi d'un tutoriel pratique dans lequel nous modifierons l'expérience que nous avons créée lors du Jour 1 afin qu'elle soit adaptée à une utilisation en ligne.\n- 14h00 – 15h00 :__Utilisation de <https://mindprobe.eu> (serveur JATOS) pour exécuter des expériences en ligne.__ Dans cette session, vous apprendrez comment utiliser mindprobe.eu, qui est un serveur gratuit qui exécute le logiciel open-source JATOS, pour effectivement réaliser une expérience en ligne. Un compte mindprobe.eu sera fourni à chaque participant.\n- Pause\n- 15h30 – 16h00 : __Préparation des données pour l'analyse.__ Nous commencerons cette session par une explication générale de la manière dont les données sont structurées, à la fois pour les expériences menées en ligne et pour les expériences menées dans un laboratoire traditionnel. Ensuite, nous verrons comment transformer ces données en un format qui se prête à l'analyse statistique. Plus précisément, nous apprendrons comment les données de plusieurs participants peuvent être fusionnées en une seule feuille de calcul `.csv` ; nous apprendrons également comment les données d'une expérience en ligne peuvent être téléchargées depuis JATOS et converties en une feuille de calcul `.csv`.\n- 16h00 – 17h00 : __Questions-réponses__ Quel type d'expérience aimeriez-vous créer pour vos propres recherches ? Et de quelle aide avez-vous besoin de notre part ?"
  },
  "OpenSesame and PyGaze at ECEM 2017": {
    "fr": "OpenSesame et PyGaze à ECEM 2017"
  },
  "OpenSesame and PyGaze will have a demonstration booth at the European Conference on Eye Movements (ECEM), which will be held in Wuppertal, Germany between August 20 and 24, 2017.\n\n- <http://ecem2017.uni-wuppertal.de/>\n\nDrop by and say hi!\n": {
    "fr": "OpenSesame et PyGaze auront un stand de démonstration lors de la Conférence européenne sur les mouvements oculaires (ECEM), qui se tiendra à Wuppertal, en Allemagne, entre le 20 et le 24 août 2017.\n\n- <http://ecem2017.uni-wuppertal.de/>\n\nPassez nous voir et dites bonjour !"
  },
  "Page not found": {
    "fr": "Page non trouvée"
  },
  "The page that you requested does not exist. Perhaps it has moved.\n\nTo find the information you're looking for:\n\n- Browse the menu at the top of this page; or\n- Search using the search bar at the left of this page.\n": {
    "fr": "La page que vous avez demandée n'existe pas. Peut-être qu'elle a été déplacée.\n\nPour trouver l'information que vous recherchez :\n\n- Parcourez le menu en haut de cette page ; ou\n- Recherchez en utilisant la barre de recherche à gauche de cette page."
  },
  "Donate": {
    "fr": "Faire un don"
  },
  "With a donation you help to keep OpenSesame an active and innovative project! We use donations, among other things, to:\n\n- Reimburse volunteers for their expenses\n- Buy equipment for testing and development\n- Pay for webhosting\n\nGood software needs aware developers! Helps us stay sharp and buy us a coffee!\n\n<div class='cogsci-coffee'>\n<a href=\"https://www.buymeacoffee.com/cogsci\">\n<img style=\"max-width:192px; margin-top: -8px;\" src=\"https://img.buymeacoffee.com/button-api/?text=Buy us a coffee!&emoji=&slug=cogsci&button_colour=FFDD00&font_colour=000000&font_family=Cookie&outline_colour=000000&coffee_colour=ffffff\">\n</a>\n</div>\n\n\nFor large donations or sponsorship contracts, please contact: <s.mathot@cogsci.nl>\n": {
    "fr": "Avec un don, vous contribuez à maintenir OpenSesame comme un projet actif et innovant ! Nous utilisons les dons, entre autres, pour :\n\n- Rembourser les frais des bénévoles\n- Acheter du matériel pour les tests et le développement\n- Payer l'hébergement web\n\nUn bon logiciel nécessite des développeurs conscients ! Aidez-nous à rester à la pointe en nous offrant un café !\n\n<div class='cogsci-coffee'>\n<a href=\"https://www.buymeacoffee.com/cogsci\">\n<img style=\"max-width:192px; margin-top: -8px;\" src=\"https://img.buymeacoffee.com/button-api/?text=Offrez-nous un café !&emoji=&slug=cogsci&button_colour=FFDD00&font_colour=000000&font_family=Cookie&outline_colour=000000&coffee_colour=ffffff\">\n</a>\n</div>\n\n\nPour les gros dons ou les contrats de partenariat, veuillez contacter : <s.mathot@cogsci.nl>"
  },
  "ESCoP 2019 workshop": {
    "fr": "Atelier ESCoP 2019"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About the workshop\n\nThis OpenSesame workshop will take place as a pre-conference event before *ESCoP 2019*. Participation is free and no registration is required.\n\nThe workshop consists of two main parts. In the first part, corresponding to the Basic Steps below, we created a complete experiment together. In the second part, corresponding to the Extra Assignments below, you will finish and improve the experiment by yourself.\n\n\n### When?\n\n- September 25th, 2019\n- 14:30 - 16:10\n\n### Where?\n\n- Conference Center \"La Pirámide de Arona\" (Mare Nostrum Resort)\n- Av. las Américas\n- 38650 Arona\n- Santa Cruz de Tenerife\n- Spain\n\n### More info\n\n- Conference site: <https://escop2019.webs.ull.es/>\n\n\n## The basic steps\n\n\n<notranslate>\nfigure:\n id: FigWCST\n source: wcst.png\n caption: |\n  The Wisconsin Card Sorting Test (WCST) is a neuropsychological test of executive functions.\n</notranslate>\n\n\nYou will implement the Wisconsin Card Sorting Test (WCST) and learn how you can run this test online with OSWeb.\n\nIn the WCST, participants see four stimulus cards, which differ on three dimensions: color (red, green, blue, yellow), shape (circle, star, triangle, cross), and number of shapes (one, two, three, or four). Participants also see a single response card, which also has a color, shape, and number.\n\nThe participant's task is to match the response card to the correct stimulus card, based on a specific dimension (e.g. color), or *matching rule*. The participant initially doesn't know on which dimension to match, and his or her task is to figure out the matching rule through trial and error.\n\nTo make things more difficult, the matching rule changes after every five correct responses. Therefore, the participant needs to flexibly update their matching rule.\n\n\n### Step 1: Download and start OpenSesame\n\nOpenSesame is available for Windows, Linux, and Mac OS. This tutorial is written for OpenSesame 3.2, and you can use either the version based on Python 2.7 (default) or Python 3.6. You can download OpenSesame from here:\n\n- %link:download%\n\n\nWhen you start OpenSesame, you will be given a choice of template experiments, and (if any) a list of recently opened experiments (see %FigStartUp).\n\n<notranslate>\nfigure:\n id: FigStartUp\n source: start-up.png\n caption: |\n  The OpenSesame window on start-up.\n</notranslate>\n\nThe *Extended template* provides a good starting point for creating many experiments that use a block-trial structure. However, in this tutorial we will create the entire experiment from scratch, and we will use the 'default template', which is already loaded when OpenSesame is launched (%FigDefaultTemplate). Therefore, simply close the 'Get started!' and (if shown) 'Welcome!' tabs.\n\n<notranslate>\nfigure:\n id: FigDefaultTemplate\n source: default-template.png\n caption: |\n  The structure of the 'Default template' as seen in the overview area.\n</notranslate>\n\n\n### Step 2: Add a block_loop and trial_sequence\n\nThe default template starts with three items: A NOTEPAD called *getting_started*, a SKETCHPAD called *welcome*, and a SEQUENCE called *experiment*. We don't need *getting_started* and *welcome*, so let's remove these right away. To do so, right-click on these items and select 'Delete'. Don't remove *experiment*, because it is the entry for the experiment (i.e. the first item that is called when the experiment is started).\n\nOur experiment will have a very simple structure. At the top of the hierarchy is a LOOP, which we will call *block_loop*. The *block_loop* is the place where we will define our independent variables. To add a LOOP to your experiment, drag the LOOP icon from the item toolbar onto the *experiment* item in the overview area.": {
    "fr": "## À propos de l'atelier\n\nCet atelier OpenSesame se déroulera lors d'un événement pré-conférence avant *ESCoP 2019*. La participation est gratuite et aucune inscription n'est requise.\n\nL'atelier se compose de deux parties principales. Dans la première partie, correspondant aux étapes de base ci-dessous, nous créons ensemble une expérience complète. Dans la deuxième partie, correspondant aux missions supplémentaires ci-dessous, vous terminez et améliorez l'expérience par vous-même.\n\n\n\n\n### Quand ?\n\n- 25 septembre 2019\n- 14h30 - 16h10\n\n### Où ?\n\n- Centre de conférence \"La Pirámide de Arona\" (Mare Nostrum Resort)\n- Av. las Américas\n- 38650 Arona\n- Santa Cruz de Tenerife\n- Espagne\n\n### Plus d'informations\n\n- Site de la conférence : <https://escop2019.webs.ull.es/>\n\n\n\n## Les étapes de base\n\n\n\nVous allez mettre en œuvre le Wisconsin Card Sorting Test (WCST) et apprendre comment vous pouvez exécuter ce test en ligne avec OSWeb.\n\nDans le WCST, les participants voient quatre cartes stimulus, qui diffèrent sur trois dimensions : couleur (rouge, vert, bleu, jaune), forme (cercle, étoile, triangle, croix) et nombre de formes (un, deux, trois ou quatre). Les participants voient aussi une seule carte de réponse, qui a également une couleur, une forme et un nombre.\n\nLa tâche du participant est de faire correspondre la carte de réponse à la bonne carte stimulus, en fonction d'une dimension spécifique (par exemple, la couleur) ou d'une *règle de correspondance*. Le participant ne sait pas initialement sur quelle dimension faire correspondre, et sa tâche est de découvrir la règle de correspondance par essais et erreurs.\n\nPour compliquer les choses, la règle de correspondance change après chaque cinq réponses correctes. Par conséquent, le participant doit mettre à jour de manière flexible sa règle de correspondance.\n\n\n### Étape 1: Téléchargez et démarrez OpenSesame\n\nOpenSesame est disponible pour Windows, Linux et Mac OS. Ce tutoriel est écrit pour OpenSesame 3.2 et vous pouvez utiliser la version basée sur Python 2.7 (par défaut) ou Python 3.6. Vous pouvez télécharger OpenSesame à partir d'ici:\n\n- %link:download%\n\nLorsque vous démarrez OpenSesame, il vous est proposé de choisir des expériences modèles et (le cas échéant) une liste des expériences ouvertes récemment (voir %FigStartUp).\n\nLe modèle *Extended template* offre un bon point de départ pour créer de nombreuses expériences qui utilisent une structure de blocs-essais. Cependant, dans ce tutoriel, nous créerons toute l'expérience à partir de zéro et nous utiliserons le 'modèle par défaut', qui est déjà chargé au lancement d'OpenSesame (%FigDefaultTemplate). Fermez simplement les onglets 'Get started!' et (si affiché) 'Welcome!'.\n\nNous allons maintenant ajouter un LOOP et une SEQUENCE à notre expérience. Le modèle par défaut démarre avec trois éléments : un NOTEPAD appelé *getting_started*, un SKETCHPAD appelé *welcome*, et une SEQUENCE appelée *experiment*. Nous n'avons pas besoin de *getting_started* et de *welcome*, alors supprimons-les tout de suite. Pour ce faire, faites un clic droit sur ces éléments et sélectionnez 'Supprimer'. Ne supprimez pas *experiment*, car c'est l'entrée de l'expérience (c'est-à-dire le premier élément qui est appelé lorsque l'expérience est lancée).\n\nNotre expérience aura une structure très simple. En haut de la hiérarchie se trouve un LOOP, que nous appellerons *block_loop*. Le *block_loop* est l'endroit où nous définirons nos variables indépendantes. Pour ajouter un LOOP à votre expérience, faites glisser l'icône LOOP de la barre d'outils des éléments sur l'élément *experiment* dans la zone de vue d'ensemble."
  },
  "A LOOP item needs another item to run; usually, and in this case as well, this is a SEQUENCE. Drag the SEQUENCE item from the item toolbar onto the *new_loop* item in the overview area. OpenSesame will ask whether you want to insert the SEQUENCE into or after the LOOP. Select 'Insert into new_loop'.\n\nBy default, items have names such as *new_sequence*, *new_loop*, *new_sequence_2*, etc. These names are not very informative, and it is good practice to rename them. Item names must consist of alphanumeric characters and/ or underscores. To rename an item, double-click on the item in the overview area. Rename *new_sequence* to *trial_sequence* to indicate that it will correspond to a single trial. Rename *new_loop* to *block_loop* to indicate that will correspond to a block of trials.\n\nFinally, click on 'New experiment'to open the General Properties tab. Click on the title of the experiment, and rename it to 'Wisconsin Card Sorting Test'.\n\nThe overview area of our experiment now looks as in %FigBasicStructure.\n\n<notranslate>\nfigure:\n id: FigBasicStructure\n source: basic-structure.png\n caption: |\n  The overview area at the end of Step 2.\n</notranslate>\n\n\n### Step 3: Import images and sound files\n\nFor this experiment, we will use images for the playing cards. You can download these from here:\n\n- %static:attachments/wisconsin-card-sorting-test/stimuli.zip%\n\nDownload `stimuli.zip` and extract it somewhere (to your desktop, for example). Next, in OpenSesame, click on the 'Show file pool' button in the main toolbar (or: Menu →View → Show file pool). This will show the file pool, by default on the right side of the window. The easiest way to add the stimuli to the file pool is by dragging them from the desktop (or wherever you have extracted the files to) into the file pool. Alternatively, you can click on the '+' button in the file pool and add files using the file-selection dialog that appears. The file pool will automatically be saved with your experiment.\n\nAfter you have added all stimuli, your file pool looks as in %FigFilePool.\n\n<notranslate>\nfigure:\n id: FigFilePool\n source: file-pool.png\n caption: |\n  The file pool containing the stimuli.\n</notranslate>\n\n\n### Step 4: Create a static card display\n\nTo start with, we'll create a display with four stimulus cards and one response card. However, which cards are shown will not, for now, depend on variables; that is, we will create a *static* display.\n\nDrag a a SKETCHPAD into *trial_sequence*, and rename it to *card_display*. Use the image tool to draw four cards in a horizontal row somewhere near the top of the display; these will be the stimulus cards. Draw a single card near the bottom of the display; this will be the response card. Also add some text to indicate to the participant what he or she has to do, namely press `a`, `b`, `c`, or `d` to indicate which of the stimulus cards matches the response card. The exact text, layout, and cards are up to you! Tips: you can use the *scale* option to adjust the size of the cards; you can change the background color in the General Properties tab, which you can open by clicking on the top-level item of the experiment.\n\nFor me, the result looks like this:\n\n\n<notranslate>\nfigure:\n id: FigStaticCards\n source: static-cards.png\n caption: |\n  A SKETCHPAD with statically defined cards.\n</notranslate>\n\n\n### Step 5: Make the response card variable\n\nRight now we're always showing the same response card (in the example above a single blue triangle). But of course we want to show a different response card on every trial. To do so, we first need to define the variables that determine which response card we will show. We will do this in the *block_loop*.": {
    "fr": "Un élément LOOP a besoin d'un autre élément pour fonctionner; généralement, et dans ce cas aussi, il s'agit d'une SEQUENCE. Faites glisser l'élément SEQUENCE depuis la barre d'outils des éléments sur l'élément *new_loop* dans la zone d'aperçu. OpenSesame vous demandera si vous souhaitez insérer la SEQUENCE dans ou après la LOOP. Sélectionnez \"Insérer dans new_loop\".\n\nPar défaut, les éléments ont des noms tels que *new_sequence*, *new_loop*, *new_sequence_2*, etc. Ces noms ne sont pas très informatifs et il est recommandé de les renommer. Les noms des éléments doivent être composés de caractères alphanumériques et/ou de traits de soulignement. Pour renommer un élément, double-cliquez sur l'élément dans la zone d'aperçu. Renommez *new_sequence* en *trial_sequence* pour indiquer qu'il correspondra à un essai unique. Renommez *new_loop* en *block_loop* pour indiquer qu'il correspondra à un bloc d'essais.\n\nEnfin, cliquez sur \"New experiment\" pour ouvrir l'onglet Propriétés générales. Cliquez sur le titre de l'expérience et renommez-le \"Wisconsin Card Sorting Test\".\n\nLa zone d'aperçu de notre expérience ressemble maintenant à %FigBasicStructure.\n\n<notranslate>\nfigure :\n id: FigBasicStructure\n source: basic-structure.png\n caption: |\n  La zone d'aperçu à la fin de l'étape 2.\n</notranslate>\n\n\n### Étape 3 : Importer des images et des fichiers audio\n\nPour cette expérience, nous utiliserons des images pour les cartes à jouer. Vous pouvez les télécharger ici :\n\n- %static:attachments/wisconsin-card-sorting-test/stimuli.zip%\n\nTéléchargez `stimuli.zip` et extrayez-le quelque part (sur votre bureau, par exemple). Ensuite, dans OpenSesame, cliquez sur le bouton \"Afficher le pool de fichiers\" dans la barre d'outils principale (ou : Menu → Affichage → Afficher le pool de fichiers). Cela affichera le pool de fichiers, par défaut sur le côté droit de la fenêtre. La manière la plus simple d'ajouter les stimuli au pool de fichiers est de les faire glisser depuis le bureau (ou depuis l'endroit où vous avez extrait les fichiers) dans le pool de fichiers. Sinon, vous pouvez cliquer sur le bouton \"+\" dans le pool de fichiers et ajouter des fichiers en utilisant la boîte de dialogue de sélection de fichiers qui apparaît. Le pool de fichiers est automatiquement sauvegardé avec votre expérience.\n\nAprès avoir ajouté tous les stimuli, votre pool de fichiers ressemble à %FigFilePool.\n\n<notranslate>\nfigure :\n id: FigFilePool\n source: file-pool.png\n caption: |\n  Le pool de fichiers contenant les stimuli.\n</notranslate>\n\n\n### Étape 4 : Créer un affichage de carte statique\n\nPour commencer, nous créerons un affichage avec quatre cartes stimuli et une carte réponse. Cependant, les cartes affichées ne dépendront pas, pour l'instant, des variables ; autrement dit, nous créerons un affichage *statique*.\n\nFaites glisser un SKETCHPAD dans *trial_sequence* et renommez-le en *card_display*. Utilisez l'outil d'image pour dessiner quatre cartes dans une rangée horizontale près du haut de l'affichage; ce seront les cartes stimuli. Dessinez une seule carte près du bas de l'affichage; ce sera la carte réponse. Ajoutez également du texte pour indiquer au participant ce qu'il doit faire, à savoir appuyer sur `a`, `b`, `c` ou `d` pour indiquer laquelle des cartes stimuli correspond à la carte réponse. Le texte exact, la disposition et les cartes dépendent de vous ! Astuces : vous pouvez utiliser l'option *scale* pour ajuster la taille des cartes ; vous pouvez changer la couleur d'arrière-plan dans l'onglet Propriétés générales, que vous pouvez ouvrir en cliquant sur l'élément de niveau supérieur de l'expérience.\n\nPour moi, le résultat ressemble à ça:\n\n<notranslate>\nfigure:\n id: FigStaticCards\n source: static-cards.png\n caption: |\n  Un SKETCHPAD avec des cartes définies statiquement.\n</notranslate>\n\n\n### Étape 5 : Rendre la carte de réponse variable\n\nPour l'instant, nous montrons toujours la même carte réponse (dans l'exemple ci-dessus, un seul triangle bleu). Mais bien sûr, nous voulons montrer une carte réponse différente à chaque essai. Pour ce faire, nous devons d'abord définir les variables qui déterminent quelle carte réponse nous allons montrer. Nous le ferons dans le *block_loop*."
  },
  "Open the *block_loop*. The LOOP table is now empty. To determine the color, shape, and number of the response card, we could manually create three columns (`response_color`, `response_shape`, and `response_number`) and 64 rows for all possible combinations of colors, shapes, and numbers. But that would be a lot of work. Instead, we will use the full-factorial-design wizard, which you can open by clicking on the 'Full-factorial design' button. (A full-factorial design is a design in which all possible combinations of variable levels occur.) In this wizard, you create one column for each of the three variables, and in the cells below enter the possible values for that variable (see %FigDesignWizard).\n\n\n<notranslate>\nfigure:\n id: FigDesignWizard\n source: design-wizard.png\n caption: |\n  The full-factorial-design wizard allows you to easily generate large LOOP tables that correspond to full-factorial designs.\n</notranslate>\n\n\nNext, click the OK button. The *block_loop* now contains all 64 combinations of colors, numbers, and shapes (see %FigLoopTable1).\n\n\n<notranslate>\nfigure:\n id: FigLoopTable1\n source: loop-table-1.png\n caption: |\n  The *block_loop* at the end of step 5.\n</notranslate>\n\n\nNow return to the *card_display*. Every item in OpenSesame is defined through a script. This script is generated automatically by the user interface. Sometimes it can be convenient (or even necessary) to edit this script directly. The most common reason for editing an item's script is to add variables to the script, which is also what we will do now!\n\nTo view the script, click on the 'View' button and select 'View script'. (The view button is the middle button at the top right of the item controls.) This will open a script editor.\n\nThe script for *card_display* mostly consists of `draw` commands, which define each of the five cards, and also the various text elements. Locate the line that corresponds to the response card. You can find it by looking at the Y coordinate, which should be positive (i.e. at the lower part of the display), or by looking at the name of the image file.\n\n```\ndraw image center=1 file=\"1-blue-triangle.png\" scale=0.5 show_if=always x=0 y=192 z_index=0\n```\n\nRight now, in my example, the image file for the response card is always `\"1-blue-triangle.png\"`. But of course we don't always want to show a single blue triangle. Instead, we want to have the image file depend on the variables that we have defined in the *block_loop*. To do so, replace the number by `[response_number]`, the color by `[response_color]`, and the shape by `[response_shape]`: (The square brackets indicate that these refer to names of variables.)\n\n\n```\ndraw image center=1 file=\"[response_number]-[response_color]-[response_shape].png\" scale=0.5 show_if=always x=0 y=192 z_index=0\n```\n\nClick on Apply to accept the changes to the script. The response card has now been replaced by a question-mark icon. This is because OpenSesame doesn't know how to show a preview of an image that has been defined using variables. But don't worry: the image will be shown when you run the experiment!\n\n\n### Step 6: Make the stimulus cards variable\n\nThe stimulus cards should be more-or-less randomly selected, but each color, shape, and number should occur only once; that is, there should never be two red cards or two cards with triangles. (If there were, the matching procedure would become ambiguous.) To accomplish this, we can use *horizontal shuffling*, which is a powerful but unusual feature of the LOOP item.\n\n- %link:loop%\n\nFirst, open the *block_loop* and create 12 (!) new columns to define the stimulus cards: `color1`, for the color of the first card, `color2`, `color3`, `color4`, and `shape1` … `shape4`, and `number1` … `number4`. Each column has the same value on every row (see %FigLoopTable2).\n\n\n<notranslate>\nfigure:\n id: FigLoopTable2\n source: loop-table-2.png\n caption: |\n  The *block_loop* during step 6.\n</notranslate>": {
    "fr": "Ouvrez la *block_loop*. La table LOOP est maintenant vide. Pour déterminer la couleur, la forme et le nombre de la carte réponse, nous pourrions créer manuellement trois colonnes (`response_color`, `response_shape` et `response_number`) et 64 lignes pour toutes les combinaisons possibles de couleurs, formes et nombres. Mais cela représenterait beaucoup de travail. Au lieu de cela, nous allons utiliser l'assistant de planification factorielle complète, que vous pouvez ouvrir en cliquant sur le bouton \"Plan factoriel complet\". (Un plan factoriel complet est un plan dans lequel toutes les combinaisons possibles de niveaux de variables se produisent.) Dans cet assistant, vous créez une colonne pour chacune des trois variables, et dans les cellules du dessous, entrez les valeurs possibles pour cette variable (voir %FigDesignWizard).\n\n<notranslate>\nfigure:\n id: FigDesignWizard\n source: design-wizard.png\n caption: |\n  L'assistant de planification factorielle complète vous permet de générer facilement de grandes tables LOOP correspondant à des plans factoriels complets.\n</notranslate>\n\nEnsuite, cliquez sur le bouton OK. La *block_loop* contient maintenant les 64 combinaisons de couleurs, nombres et formes (voir %FigLoopTable1).\n\n<notranslate>\nfigure:\n id: FigLoopTable1\n source: loop-table-1.png\n caption: |\n  La *block_loop* à la fin de l'étape 5.\n</notranslate>\n\nRevenez maintenant à la *card_display*. Chaque élément dans OpenSesame est défini par un script. Ce script est généré automatiquement par l'interface utilisateur. Parfois, il peut être pratique (ou même nécessaire) d'éditer directement ce script. La raison la plus courante pour éditer le script d'un élément est d'ajouter des variables au script, ce que nous allons faire maintenant !\n\nPour afficher le script, cliquez sur le bouton \"Afficher\" et sélectionnez \"Afficher le script\". (Le bouton Afficher se trouve au milieu des commandes d'élément en haut à droite.) Cela ouvrira un éditeur de script.\n\nLe script pour *card_display* se compose principalement de commandes `draw`, qui définissent chacune des cinq cartes, ainsi que des différents éléments de texte. Repérez la ligne correspondant à la carte réponse. Vous pouvez la trouver en regardant l'axe des Y, qui doit être positif (c'est-à-dire dans la partie inférieure de l'affichage) ou en regardant le nom du fichier image.\n\n```\ndraw image center=1 file=\"1-blue-triangle.png\" scale=0.5 show_if=always x=0 y=192 z_index=0\n```\n\nEn ce moment, dans mon exemple, le fichier image pour la carte réponse est toujours `\"1-blue-triangle.png\"`. Mais bien sûr, nous ne voulons pas toujours montrer un seul triangle bleu. Au lieu de cela, nous voulons avoir le fichier image en fonction des variables que nous avons définies dans la *block_loop*. Pour ce faire, remplacez le nombre par `[response_number]`, la couleur par `[response_color]` et la forme par `[response_shape]`: (Les crochets indiquent qu'il s'agit des noms de variables.)\n\n```\ndraw image center=1 file=\"[response_number]-[response_color]-[response_shape].png\" scale=0.5 show_if=always x=0 y=192 z_index=0\n```\n\nCliquez sur Appliquer pour accepter les modifications apportées au script. La carte réponse a maintenant été remplacée par une icône en forme de point d'interrogation. Cela est dû au fait qu'OpenSesame ne sait pas comment afficher un aperçu d'une image qui a été définie à l'aide de variables. Mais ne vous inquiétez pas : l'image sera affichée lorsque vous exécuterez l'expérience !\n\n### Étape 6: Rendre les cartes stimulus variables\n\nLes cartes stimulus doivent être sélectionnées de manière plus ou moins aléatoire, mais chaque couleur, forme et nombre ne doit apparaître qu'une seule fois ; c'est-à-dire qu'il ne devrait jamais y avoir deux cartes rouges ou deux cartes avec des triangles. (S'il y en avait, la procédure de correspondance deviendrait ambiguë.) Pour y parvenir, nous pouvons utiliser le *mélange horizontal*, qui est une fonctionnalité puissante mais inhabituelle de l'élément LOOP.\n\n- %link:loop%\n\nD'abord, ouvrez le *block_loop* et créez 12 (!) nouvelles colonnes pour définir les cartes stimulus : `color1`, pour la couleur de la première carte, `color2`, `color3`, `color4`, et `shape1` ... `shape4`, et `number1` ... `number4`. Chaque colonne a la même valeur sur chaque ligne (voir %FigLoopTable2).\n\n<notranslate>\nfigure:\n id: FigLoopTable2\n source: loop-table-2.png\n caption: |\n  La *block_loop* pendant l'étape 6.\n</notranslate>"
  },
  "\nBut we're not done yet! Right now, the first stimulus card is always a single red circle, the second two blue triangles, etc. To randomize this we tell OpenSesame to randomly swap (horizontally shuffle) the values of the four color variables, the four shape variables, and the four number variables. To do so, open the script for the *block_loop*. At the semi-last line (right before `run trial_sequence`) add the following commands:\n\n```\nshuffle_horiz color1 color2 color3 color4\nshuffle_horiz shape1 shape2 shape3 shape4\nshuffle_horiz number1 number2 number3 number4\n```\n\nClick on Apply to accept the script. To see if this has worked, click on the Preview button. This will show a preview of how the LOOP table will be randomized during the experiment. Does it look good?\n\nNow return to the *card_display* and have the image of the first stimulus card depend on the variable `color1`, `shape1`, and `number1`, and analogously for the other stimulus cards. (If you're unsure how to do this, revisit step 5.)\n\n\n### Step 7: Determine the correct response (for one matching rule)\n\n\nFor now, we're going to assume that participants always match by shape. (One of the Extra Assignments is to improve this.)\n\nRight now, the duration of *card_display* is set to 'keypress'. This means that the *card_display* is shown until a key is pressed, but it provides no control over how this key press is handled. Therefore, change the duration to 0, and insert a KEYBOARD_RESPONSE directly after the *card_display*. Rename the KEYBOARD_RESPONSE to *press_a*, and specify that the correct response is 'a' and that the allowed responses are 'a;b;c;d'.\n\n\n<notranslate>\nfigure:\n id: FigPressA\n source: press-a.png\n caption: |\n  One of the KEYBOARD_RESPONSE items defined in step 7.\n</notranslate>\n\n\nBut this is not enough! Right now there's a single response item that assumes that the correct response is always 'a'. We have not yet specified *when* the correct response is 'a', nor have we considered trials on which the correct response is 'b', 'c', or 'd'.\n\nTo accomplish this, first create three more KEYBOARD_RESPONSE items: *press_b*, *press_c*, and *press_d*. These are all the same, except for the correct response, which is defined for each of them separately and should be respectively 'b', 'c', and 'd'.\n\nFinally, in the *trial_sequence*, use Run If statements to decide under which condition each of the four KEYBOARD_RESPONSE items should be executed (thus deciding what the correct response is). For *press_a*, the condition is that `shape1` should be equal to `response_shape`. Why? Well, because that means that the shape of the first stimulus card is equal to the shape of the response card, and in that case the correct response is 'a'. This condition corresponds to the following run-if statement: `[shape1] = [response_shape]`. The run-if statements for the other KEYBOARD_RESPONSE items are analogous (see %FigTrialSequence1).\n\n\n<notranslate>\nfigure:\n id: FigTrialSequence1\n source: trial-sequence-1.png\n caption: |\n  The *trial_sequence* at the end of step 7.\n</notranslate>\n\n\n### Step 8: Give feedback to the participant\n\nOpenSesame automatically keeps track of whether a response was correct or not, by setting the variable `correct` to respectively 1 or 0. (Provided, of course, that you have specified the correct response, as we've done in step 7.) We can use this to give feedback to the participant about whether they responded correctly or not.\n\nTo do this, add two new SKETCHPADs to the *trial_sequence* and call them *correct_feedback* and *incorrect_feedback*. Then, specify which of the two should be executed using a run-if statement (see %FigTrialSequence2).\n\n\n<notranslate>\nfigure:\n id: FigTrialSequence2\n source: trial-sequence-2.png\n caption: |\n  The *trial_sequence* at the end of step 8.\n</notranslate>": {
    "fr": "Mais nous n'avons pas encore terminé! En ce moment, la première carte stimulus est toujours un seul cercle rouge, la seconde deux triangles bleus, etc. Pour randomiser cela, nous disons à OpenSesame de permuter aléatoirement (mélanger horizontalement) les valeurs des quatre variables de couleur, des quatre variables de forme et des quatre variables de nombre. Pour ce faire, ouvrez le script pour la *block_loop*. À l'avant-dernière ligne (juste avant `run trial_sequence`), ajoutez les commandes suivantes:\n\n```\nshuffle_horiz color1 color2 color3 color4\nshuffle_horiz shape1 shape2 shape3 shape4\nshuffle_horiz number1 number2 number3 number4\n```\n\nCliquez sur Appliquer pour accepter le script. Pour voir si cela a fonctionné, cliquez sur le bouton Aperçu. Cela montrera un aperçu de la manière dont le tableau LOOP sera randomisé pendant l'expérience. Est-ce que ça a l'air bien?\n\nRevenez maintenant au *card_display* et faites dépendre l'image de la première carte stimulus des variables `color1`, `shape1` et `number1`, et analogiquement pour les autres cartes stimulus. (Si vous n'êtes pas sûr de la manière de procéder, reportez-vous à l'étape 5.)\n\n\n### Étape 7: déterminer la réponse correcte (pour une règle de correspondance)\n\n\nPour l'instant, nous allons supposer que les participants correspondent toujours par forme. (L'une des missions supplémentaires consiste à améliorer cela.)\n\nEn ce moment, la durée du *card_display* est définie sur 'keypress'. Cela signifie que le *card_display* est affiché jusqu'à ce qu'une touche soit enfoncée, mais cela ne fournit aucun contrôle sur la manière dont cette pression de touche est gérée. Par conséquent, changez la durée à 0 et insérez un KEYBOARD_RESPONSE directement après le *card_display*. Renommez la KEYBOARD_RESPONSE en *press_a* et spécifiez que la réponse correcte est 'a' et que les réponses autorisées sont 'a;b;c;d'.\n\n\n<notranslate>\nfigure:\n id: FigPressA\n source: press-a.png\n légende: |\n  L'un des éléments de KEYBOARD_RESPONSE définis à l'étape 7.\n</notranslate>\n\n\nMais cela ne suffit pas! Pour l'instant, il y a un seul élément de réponse qui suppose que la réponse correcte est toujours 'a'. Nous n'avons pas encore spécifié *quand* la réponse correcte est 'a', et nous n'avons pas non plus examiné les essais pour lesquels la réponse correcte est 'b', 'c' ou 'd'.\n\nPour y parvenir, créez d'abord trois autres éléments KEYBOARD_RESPONSE: *press_b*, *press_c* et *press_d*. Ils sont tous les mêmes, sauf pour la réponse correcte, qui est définie pour chacun d'eux séparément et doit être respectivement 'b', 'c' et 'd'.\n\nEnfin, dans le *trial_sequence*, utilisez des instructions Run If pour déterminer dans quelle condition chacun des quatre éléments KEYBOARD_RESPONSE doit être exécuté (décidant ainsi quelle est la réponse correcte). Pour *press_a*, la condition est que `shape1` doit être égal à `response_shape`. Pourquoi? Eh bien, parce que cela signifie que la forme de la première carte stimulus est égale à la forme de la carte réponse, et dans ce cas, la réponse correcte est 'a'. Cette condition correspond à l'instruction run-if suivante: `[shape1] = [response_shape]`. Les instructions run-if pour les autres éléments KEYBOARD_RESPONSE sont analogues (voir %FigTrialSequence1).\n\n\n<notranslate>\nfigure:\n id: FigTrialSequence1\n source: trial-sequence-1.png\n légende: |\n  Le *trial_sequence* à la fin de l'étape 7.\n</notranslate>\n\n\n### Étape 8: donner un retour d'information au participant\n\nOpenSesame suit automatiquement si une réponse était correcte ou non, en définissant la variable `correct` à respectivement 1 ou 0. (À condition, bien sûr, que vous ayez spécifié la réponse correcte, comme nous l'avons fait à l'étape 7.) Nous pouvons utiliser cela pour donner un retour d'information au participant sur le fait qu'il a répondu correctement ou non.\n\nPour ce faire, ajoutez deux nouveaux SKETCHPADs à la *trial_sequence* et appelez-les *correct_feedback* et *incorrect_feedback*. Ensuite, spécifiez lequel des deux doit être exécuté en utilisant une instruction run-if (voir %FigTrialSequence2).\n\n\n<notranslate>\nfigure:\n id: FigTrialSequence2\n source: trial-sequence-2.png\n légende: |\n  Le *trial_sequence* à la fin de l'étape 8.\n</notranslate>"
  },
  "\nFinally, add some useful content to both SKETCHPADs. For example, for *correct_feedback* you could use a green fixation dot, and for *incorrect_feedback* you could use a red fixation dot, in both cases shown for 500 ms (i.e. setting the SKETCHPAD duration to 500). Colored dots are a nice, unobtrusive way to provide feedback.\n\n\n### Step 9: Test the experiment\n\nYou have now created a basic (but incomplete!) implementation of the Wisconsin Card Sorting Test. (You will complete the implementation as part of the Extra Assignments below.)\n\n\n<notranslate>\nfigure:\n id: FigRunButtons\n source: run-buttons.png\n caption: |\n  The main toolbar contains buttons to (from left to right): run fullscreen, run in a window, quick-run (run in a window without asking for log file or participant numebr ), abort the experiment, and run in a browser.\n</notranslate>\n\n\nTo test the experiment, click on the quick-run button (the blue double arrows) to test the experiment on the desktop (see %FigRunButtons). If the experiment runs as expected on the desktop, click on the run-in-browser button (the arrow inside a green circle) to test the experiment in a browser.\n\n\n## Extra assignments\n\n\n### Extra 1 (easy): Add a logger\n\nOpenSesame doesn't automatically log data. Instead, you need to explicitly add a `logger` item to your experiment. In a trial-based experiment, a `logger` is generally the last item of the *trial_sequence*, so that it logs all the data that was collected during the trial.\n\nRight now, our WCST doesn't log any data. Time to fix that!\n\n\n### Extra 2 (easy): Inspect the data file\n\n*Requires that you have completed Extra 1*.\n\nGive the experiment a short test run. Now inspect the log file in a program like Excel, LibreOffice Calc, or JASP. Identify the relevant variables, and think of how you could analyze the results.\n\n__Pro-tip:__ Set the repeat value of the *block_loop* to 0.1 to reduce the number of trials during testing.\n\n\n### Extra 3 (easy): Add instructions and goodbye screen\n\nA good experiment comes with clear instructions. And a polite experiment says goodbye to the participants when they are done. You can use a SKETCHPAD to do this.\n\n__Pro-tip:__ A FORM_TEXT_DISPLAY is not compatible with OSWeb, so you should not use it for instructions if you want to run your experiment online.\n\n\n### Extra 4 (medium): Set the correct response and matching rule through JavaScript\n\nTo include scripting in OSWeb, you can use the INLINE_JAVASCRIPT item, which supports JavaScript. (But it does not currently provide all the functionality that is offered by the regular Python INLINE_SCRIPT!)\n\nSo far, the matching rule is always to match by shape. To change this, add an INLINE_JAVASCRIPT item to the start of the experiment, and use the following script (in the *prepare* phase) to randomly set the variable `matching_rule` to 'shape', 'number', or 'color'.\n\n```javascript\nfunction choice(choices) {\n    // JavaScript does not have a built-in choice function, so we define it\n    // here.\n    let index = Math.floor(Math.random() * choices.length)\n    return choices[index]\n}\n\n\n// The vars object contains all experimental variables, like the var object\n// in Python inline script\nvars.matching_rule = choice(['shape', 'number', 'color'])\n```\n\nNow add another INLINE_JAVASCRIPT item to the start of the *trial_sequence*. In the *prepare* phase, add a script to set the `correct_response` variable to 'a', 'b', 'c', or 'd'. To do so, you need a series of `if` statements, that first look at the matching rule, and then look at which shape corresponds to the response shape (for the shape-matching rule) or which color corresponds to the response color (for the color-matching rule) etc.\n\nTo get started, here's part of the solution (but it needs to be completed!):\n\n```javascript\nif (vars.matching_rule === 'shape') {\n    if (vars.shape1 === vars.response_shape) vars.correct_response = 'a'\n    // Not done yet\n} // Not done yet": {
    "fr": "Enfin, ajoutez du contenu utile aux deux SKETCHPADs. Par exemple, pour *correct_feedback*, vous pouvez utiliser un point de fixation vert, et pour *incorrect_feedback*, vous pourriez utiliser un point de fixation rouge, dans les deux cas montré pendant 500 ms (c'est-à-dire régler la durée du SKETCHPAD sur 500). Les points colorés sont un moyen discret et agréable pour fournir des commentaires.\n\n### Étape 9 : Tester l'expérience\n\nVous avez maintenant créé une mise en œuvre de base (mais incomplète !) du Wisconsin Card Sorting Test. (Vous complèterez la mise en œuvre dans le cadre des missions supplémentaires ci-dessous.)\n\nPour tester l'expérience, cliquez sur le bouton quick-run (les deux flèches bleues) pour tester l'expérience sur le bureau (voir %FigRunButtons). Si l'expérience se déroule comme prévu sur le bureau, cliquez sur le bouton run-in-browser (la flèche à l'intérieur d'un cercle vert) pour tester l'expérience dans un navigateur.\n\n## Missions supplémentaires\n\n### Supplémentaire 1 (facile) : Ajouter un enregistreur\n\nOpenSesame ne journalise pas automatiquement les données. À la place, vous devez ajouter explicitement un élément `logger` à votre expérience. Dans une expérience basée sur des essais, un `logger` est généralement le dernier élément du *trial_sequence*, de sorte qu'il consigne toutes les données collectées pendant l'essai.\n\nActuellement, notre WCST ne consigne aucune donnée. Il est temps de corriger cela !\n\n### Supplémentaire 2 (facile) : Inspecter le fichier de données\n\n*Nécessite d'avoir complété le supplément 1*.\n\nDonnez à l'expérience un court test. Inspectez maintenant le fichier de journal dans un programme comme Excel, LibreOffice Calc ou JASP. Identifiez les variables pertinentes et réfléchissez à la manière d'analyser les résultats.\n\n__Astuce__: Réglez la valeur de répétition du *block_loop* sur 0,1 pour réduire le nombre d'essais lors des tests.\n\n### Supplémentaire 3 (facile) : Ajouter des instructions et un écran d'au revoir\n\nUne bonne expérience est accompagnée d'instructions claires. Et une expérience polie dit au revoir aux participants lorsqu'ils ont terminé. Vous pouvez utiliser un SKETCHPAD pour cela.\n\n__Astuce__: FORM_TEXT_DISPLAY n'est pas compatible avec OSWeb, vous ne devez donc pas l'utiliser pour les instructions si vous voulez exécuter votre expérience en ligne.\n\n### Supplémentaire 4 (moyen): Définir la réponse correcte et la règle de correspondance avec JavaScript\n\nPour inclure des scripts dans OSWeb, vous pouvez utiliser l'élément INLINE_JAVASCRIPT, qui prend en charge JavaScript. (Mais il n'offre pas actuellement toutes les fonctionnalités offertes par le INLINE_SCRIPT Python habituel !)\n\nJusqu'à présent, la règle de correspondance est toujours de faire correspondre par forme. Pour changer cela, ajoutez un élément INLINE_JAVASCRIPT au début de l'expérience et utilisez le script suivant (dans la phase *préparer*) pour définir aléatoirement la variable `matching_rule` sur 'forme', 'nombre' ou 'couleur'.\n\n```javascript\nfunction choix(choix) {\n    // JavaScript n'a pas de fonction de choix intégrée, nous la définissons\n    // ici.\n    let index = Math.floor(Math.random() * choix.length)\n    return choix[index]\n}\n\n// L'objet vars contient toutes les variables expérimentales, comme l'objet var\n// dans le script Python en ligne\nvars.matching_rule = choix(['shape', 'number', 'color'])\n```\n\nAjoutez maintenant un autre élément INLINE_JAVASCRIPT au début du *trial_sequence*. Dans la phase *préparer*, ajoutez un script pour définir la variable `correct_response` sur 'a', 'b', 'c' ou 'd'. Pour ce faire, vous avez besoin d'une série d'instructions `if` qui regardent d'abord la règle de correspondance, puis examinent quelle forme correspond à la forme de réponse (pour la règle de correspondance de forme) ou quelle couleur correspond à la couleur de réponse (pour la règle de correspondance de couleur) etc.\n\nPour commencer, voici une partie de la solution (mais elle doit être complétée !):\n\n```javascript\nif (vars.matching_rule === 'shape') {\n    if (vars.shape1 === vars.response_shape) vars.correct_response = 'a'\n    // Pas encore terminé\n} // Pas encore terminé"
  },
  "// Let's print some info to the debug window\nconsole.log('matching_rule = ' + vars.matching_rule)\nconsole.log('correct_response = ' + vars.correct_response)\n```\n\n\n### Extra 5 (difficult): Periodically change the matching rule\n\nSo far, the matching rule is randomly determined at the start of the experiment, but then remains constant throughout the experiment. In a real WCST, the matching rule changes periodically, typically after the participant has made a fixed number of correct responses.\n\nTo implement this, you need another INLINE_JAVASCRIPT. Here are some pointers to get started:\n\n- Use a counter variable that increments by 1 after a correct response, and is reset to 0 after an incorrect response.\n- When changing the matching rule, make sure that it is not (by coincidence) set to the same matching rule again.\n\n\n### Extra 6 (really difficult): Constrain the response card\n\nRight now, the response card can overlap with a stimulus card on multiple dimensions. For example, if one of the stimulus cards is a single blue circle, the response card might be two blue circles, thus overlapping on both color and shape. In a real WCST, the response card should overlap with each stimulus card on no more than a dimension.\n\nThis one is up to you. No pointers this time!\n\n\n### Extra 7 (easy): Running the experiment online with JATOS\n\nOur WCST is compatible with OSWeb, which means that you can run it in a browser. To test if this still works, you can click on the run-in-browser button in OpenSesame.\n\nHowever, to collect actual data with the experiment in a browser, you need to import the experiment into JATOS, and use JATOS to generate a link that you can distribute to your participants. This is much easier than it sounds! For more information, see:\n\n- %link:manual/osweb/workflow%\n\n\n## Solutions\n\nYou can download the full experiment, including the solutions to the extra assignments, here:\n\n- <https://osf.io/f5er2/>\n": {
    "fr": "// Affichons quelques informations dans la fenêtre de débogage\nconsole.log('règle_de_correspondance = ' + vars.matching_rule)\nconsole.log('réponse_correcte = ' + vars.correct_response)\n```\n\n\n### Supplément 5 (difficile) : Modifier périodiquement la règle de correspondance\n\nJusqu'à présent, la règle de correspondance est déterminée au hasard au début de l'expérience, mais reste constante tout au long de l'expérience. Dans un vrai WCST, la règle de correspondance change périodiquement, généralement après que le participant a fait un nombre fixe de réponses correctes.\n\nPour cela, vous avez besson d'un autre INLINE_JAVASCRIPT. Voici quelques conseils pour commencer :\n\n- Utilisez une variable de compteur qui s'incrémente de 1 après une réponse correcte et qui est réinitialisée à 0 après une réponse incorrecte.\n- Lorsque vous changez la règle de correspondance, assurez-vous qu'elle n'est pas (par hasard) réglée à nouveau sur la même règle de correspondance.\n\n\n### Supplément 6 (vraiment difficile) : Restreindre la carte de réponse\n\nActuellement, la carte de réponse peut se chevaucher avec une carte de stimulus sur plusieurs dimensions. Par exemple, si l'une des cartes de stimulus est un cercle bleu unique, la carte de réponse peut être composée de deux cercles bleus, se chevauchant ainsi sur la couleur et la forme. Dans un vrai WCST, la carte de réponse ne doit se chevaucher avec chaque carte de stimulus que sur une dimension au maximum.\n\nCelui-ci est à votre charge. Pas de conseils cette fois!\n\n\n### Supplément 7 (facile) : Exécuter l'expérience en ligne avec JATOS\n\nNotre WCST est compatible avec OSWeb, ce qui signifie que vous pouvez l'exécuter dans un navigateur. Pour tester si cela fonctionne toujours, vous pouvez cliquer sur le bouton run-in-browser dans OpenSesame.\n\nCependant, pour recueillir des données réelles avec l'expérience dans un navigateur, vous devez importer l'expérience dans JATOS et utiliser JATOS pour générer un lien que vous pouvez distribuer à vos participants. C'est beaucoup plus facile que cela en a l'air ! Pour plus d'informations, consultez :\n\n- %link:manual/osweb/workflow%\n\n## Solutions\n\nVous pouvez télécharger l'expérience complète, y compris les solutions aux tâches supplémentaires, ici :\n\n- <https://osf.io/f5er2/>"
  },
  "Geneva 2018 workshop": {
    "fr": "Atelier Genève 2018"
  },
  "<notranslate>[TOC]</notranslate>\n\n\n## About the workshop\n\nThis OpenSesame workshop will take place at the University of Geneva on March 27, 2018.\n\nThe workshop consisted of two main parts. In the first part, corresponding to the Tutorial below, we created a complete experiment together. In the second part, corresponding to the Extra assignments below, the workshop participants improved this experiment by themselves, based on a few suggestions.\n\nYou can download the full experiment, including the solutions of the extra assignments here:\n\n- <http://osf.io/jw7dr>\n\n\n## The tutorial\n\n<notranslate>\nfigure:\n id: FigMeowingCapybara\n source: meowing-capybara.png\n caption: |\n  Don't be fooled by meowing capybaras! ([Source][capybara_photo])\n</notranslate>\n\n<notranslate>[TOC]</notranslate>\n\nWe will create a simple animal-filled multisensory integration task, in which participants see a picture of a dog, cat, or capybara. A meow or a bark is played while the picture is shown. The participant reports whether a dog or a cat is shown, by pressing the right or the left key. No response should be given when a capybara is shown: those are catch trials.\n\nTo make things more fun, we will design the experiment so that you can run it on [OSWeb](http://osweb.cogsci.nl/), an online runtime for OpenSesame experiments (which is still a work in progress, but it works for basic experiments).\n\nWe make two simple predictions:\n\n- Participants should be faster to identify dogs when a barking sound is played, and faster to identify cats when a meowing sound is played. In other words, we expect a multisensory congruency effect.\n- When participants see a capybara, they are more likely to report seeing a dog when they hear a bark, and more likely to report seeing a cat when they hear a meow. In other words, false alarms are biased by the sound.\n\n\n### Step 1: Download and start OpenSesame\n\nOpenSesame is available for Windows, Linux, Mac OS, and Android (runtime only). This tutorial is written for OpenSesame 3.1.X, and you can use either the version based on Python 2.7 (default) or Python 3.5. You can download OpenSesame from here:\n\n- %link:download%\n\nWhen you start OpenSesame, you will be given a choice of template experiments, and (if any) a list of recently opened experiments (see %FigStartUp).\n\n<notranslate>\nfigure:\n id: FigStartUp\n source: start-up.png\n caption: |\n  The OpenSesame window on start-up.\n</notranslate>\n\nThe *Extended template* provides a good starting point for creating Android-based experiments. However, in this tutorial we will create the entire experiment from scratch. Therefore, we will continue with the 'default template', which is already loaded when OpenSesame is launched (%FigDefaultTemplate). Therefore, simply close the 'Get started!' and (if shown) 'Welcome!' tabs.\n\n<notranslate>\nfigure:\n id: FigDefaultTemplate\n source: default-template.png\n caption: |\n  The structure of the 'Default template' as seen in the overview area.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 1: Basics**\n\nOpenSesame experiments are collections of *items*. An item is a small chunk of functionality that, for example, can be used to present visual stimuli (the SKETCHPAD item) or to record key presses (the KEYBOARD_RESPONSE item). Items have a type and a name. For example, you might have two items of the type KEYBOARD_RESPONSE with the names *t1_response* and *t2_response*. To make the distinction between item types and item names clear, we will use THIS_STYLE for types, and *this style* for names.\n\nTo give structure to your experiment, two types of items are especially important: the LOOP and the SEQUENCE. Understanding how you can combine LOOPs and SEQUENCEs to build experiments is perhaps the trickiest part of working with OpenSesame, so let's get that out of the way first.": {
    "fr": "## À propos de l'atelier\n\nCet atelier OpenSesame aura lieu à l'Université de Genève le 27 mars 2018.\n\nL'atelier se composait de deux parties principales. Dans la première partie, correspondant au tutoriel ci-dessous, nous avons créé une expérience complète ensemble. Dans la deuxième partie, correspondant aux missions supplémentaires ci-dessous, les participants de l'atelier ont amélioré cette expérience par eux-mêmes, sur la base de quelques suggestions.\n\nVous pouvez télécharger l'expérience complète, y compris les solutions des missions supplémentaires ici :\n\n- <http://osf.io/jw7dr>\n\n## Le tutoriel\n\nfigure :\n id : FigMeowingCapybara\n source : meowing-capybara.png\n légende : |\n   Ne vous laissez pas duper par les capybaras qui miaulent ! ([Source][capybara_photo])\n\nNous allons créer une simple tâche d'intégration multisensorielle remplie d'animaux, dans laquelle les participants voient une image d'un chien, d'un chat ou d'un capybara. Un miaulement ou un aboiement est joué pendant que l'image est affichée. Le participant signale si un chien ou un chat est montré, en appuyant sur la touche droite ou gauche. Aucune réponse ne doit être donnée lorsqu'un capybara est montré : il s'agit d'essais surprises.\n\nPour rendre les choses plus amusantes, nous allons concevoir l'expérience de manière à ce que vous puissiez la réaliser sur [OSWeb](http://osweb.cogsci.nl/), un environnement d'exécution en ligne pour les expériences OpenSesame (qui est encore en cours de développement, mais fonctionne pour les expériences basiques).\n\nNous faisons deux prédictions simples :\n\n- Les participants devraient être plus rapides pour identifier les chiens lorsqu'un bruit d'aboiement est joué et plus rapides pour identifier les chats lorsqu'un bruit de miaulement est joué. En d'autres termes, nous nous attendons à un effet de congruence multisensorielle.\n- Lorsque les participants voient un capybara, ils sont plus susceptibles de signaler qu'ils voient un chien lorsqu'ils entendent un aboiement et plus susceptibles de signaler qu'ils voient un chat lorsqu'ils entendent un miaulement. En d'autres termes, les fausses alertes sont biaisées par le son.\n\n### Étape 1 : Téléchargez et démarrez OpenSesame\n\nOpenSesame est disponible pour Windows, Linux, Mac OS et Android (exécution uniquement). Ce tutoriel est écrit pour OpenSesame 3.1.X, et vous pouvez utiliser la version basée sur Python 2.7 (par défaut) ou Python 3.5. Vous pouvez télécharger OpenSesame ici :\n\n- %link:download%\n\nLorsque vous démarrez OpenSesame, vous aurez le choix entre des modèles d'expériences et, le cas échéant, une liste d'expériences récemment ouvertes (voir %FigStartUp).\n\nfigure :\n id : FigStartUp\n source : start-up.png\n légende : |\n   La fenêtre OpenSesame au démarrage.\n\nLe *modèle étendu* offre un bon point de départ pour créer des expériences basées sur Android. Cependant, dans ce tutoriel, nous créerons l'ensemble de l'expérience à partir de zéro. Par conséquent, nous continuerons avec le \"modèle par défaut\", qui est déjà chargé lorsque OpenSesame est lancé (%FigDefaultTemplate). Fermez simplement les onglets \"Get started !\" et (si affiché) \"Welcome!\".\n\nfigure :\n id : FigDefaultTemplate\n source : default-template.png\n légende : |\n   La structure du modèle \"Default template\" telle qu'elle apparaît dans la zone d'aperçu.\n\n<div class='info-box' markdown='1'>\n\n**Encadré 1 : Les bases**\n\nLes expériences OpenSesame sont des collections d'éléments. Un élément est un petit morceau de fonctionnalité qui, par exemple, peut être utilisé pour présenter des stimuli visuels (l'élément SKETCHPAD) ou pour enregistrer des pressions de touches (l'élément KEYBOARD_RESPONSE). Les éléments ont un type et un nom. Par exemple, vous pouvez avoir deux éléments du type KEYBOARD_RESPONSE avec les noms *t1_response* et *t2_response*. Pour distinguer clairement les types et les noms d'éléments, nous utiliserons CE_STYLE pour les types et *ce style* pour les noms.\n\nPour donner une structure à votre expérience, deux types d'éléments sont particulièrement importants : la LOOP et la SEQUENCE. Comprendre comment combiner les LOOPs et les SEQUENCEs pour construire des expériences est peut-être la partie la plus délicate du travail avec OpenSesame, alors abordons ce sujet en premier."
  },
  "<notranslate>\nfigure:\n id: FigStep14\n source: step14.png\n caption: |\n  The *form_instructions* item at the end of Step 13.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 10: Text**\n\n__Tip__ -- Forms, and text more generally, support a subset of HTML tags to allow for text formatting (i.e. colors, boldface, etc.). This is described here:\n\n- %link:visual%\n\n</div>\n\n### Step 15: Finished!\n\nYour experiment is now finished! Click on the 'Run fullscreen' (`Control+R`) button in the main toolbar to give it a test run.\n\n<div class='info-box' markdown='1'>\n\n**Background box 11: Quick run**\n\n__Tip__ — A test run is executed even faster by clicking the orange 'Run in window' button, which doesn't ask you how to save the logfile (and should therefore only be used for testing purposes).\n\n</div>\n\n\n## Extra assignments\n\nThe solutions to these extra assingments can be found in the [experiment file](http://osf.io/jw7dr).\n\n### Extra 1: Add an instruction and goodbye screen\n\nTips:\n\n- SKETCHPAD and FORM_TEXT_DISPLAY can present text\n- Good instructions are brief and concrete\n\n### Extra 2: Analyze the data and check the timing\n\nTips:\n\n- Run the experiment once on yourself\n- Open the data file in Excel, LibreOffice, or JASP\n- You can check the presentation time of `sketchpad`s through the `time_[item name]` variables.\n\n### Extra 3: Divide the trials into multiple blocks\n\nTips:\n\n- Use a break-if statement to break the loop after (say) 15 trials: `([count_trial_sequence]+1) % 15 = 0`\n- Add a new LOOP-SEQUENCE structure above the *block_loop* to repeat a block of trials multiple times\n- Disable the 'Evaluate on first cycle' option in the *block_loop* so that the break-if statement isn't evaluated when the `count_trial_sequence` variable doesn't yet exist\n- Enable the 'Resume after break' option in the *block_loop* to randomly sample without replacement from the LOOP table\n\n### Extra 4: Add accuracy and average response time feedback after every block\n\nFirst do Extra 3!\n\nTips:\n\n- Use a FEEDBACK item to provide feedback\n- The variables `acc` and `avg_rt` contain the running accuracy and average reaction time\n\n### Extra 5: Counterbalance the response rule\n\nTips:\n\n- The variable `subject_parity` is 'even' or 'odd'\n- This requires a simple INLINE_SCRIPT\n- Make sure that the instructions match the response rule!\n\n\n## References\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314–324. doi:10.3758/s13428-011-0168-7\n{: .reference}\n\n[OpenSesame runtime for Android]: /getting-opensesame/android\n[slides]: /attachments/rovereto2014-workshop-slides.pdf\n[modulo]: http://en.wikipedia.org/wiki/Modulo_operation\n[pdf]: /rovereto2014/index.pdf\n[gimp]: http://www.gimp.org/\n[capybara_photo]: https://commons.wikimedia.org/wiki/File:Capybara_Hattiesburg_Zoo_(70909b-58)_2560x1600.jpg\n": {
    "fr": "<notranslate>\nfigure:\n id: FigStep14\n source: step14.png\n caption: |\n  L'élément *form_instructions* à la fin de l'étape 13.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 10 : Texte**\n\n__Astuce__ -- Les formulaires et le texte en général, supportent un sous-ensemble de balises HTML pour permettre la mise en forme du texte (c'est-à-dire les couleurs, le gras, etc.). Ceci est décrit ici :\n\n- %link:visual%\n\n</div>\n\n### Étape 15 : Terminé !\n\nVotre expérience est maintenant terminée ! Cliquez sur le bouton \"Lancer en plein écran\" (`Control+R`) dans la barre d'outils principale pour faire un essai.\n\n<div class='info-box' markdown='1'>\n\n**Encadré 11 : Lancement rapide**\n\n__Astuce__ — Un essai est exécuté encore plus rapidement en cliquant sur le bouton orange \"Lancer dans une fenêtre\", qui ne vous demande pas comment enregistrer le fichier journal (et ne doit donc être utilisé qu'à des fins de test).\n\n</div>\n\n\n## Travaux pratiques supplémentaires\n\nLes solutions de ces travaux pratiques supplémentaires se trouvent dans le [fichier d'expérience](http://osf.io/jw7dr).\n\n### Supplément 1 : Ajouter un écran d'instruction et d'au revoir\n\nConseils :\n\n- SKETCHPAD et FORM_TEXT_DISPLAY peuvent présenter du texte\n- Les bonnes instructions sont brèves et concrètes\n\n### Supplément 2 : Analyser les données et vérifier le timing\n\nConseils :\n\n- Lancez l'expérience une fois sur vous-même\n- Ouvrez le fichier de données dans Excel, LibreOffice, ou JASP\n- Vous pouvez vérifier le temps de présentation des `sketchpad`s grâce aux variables `time_[nom de l'élément]`.\n\n### Supplément 3 : Diviser les essais en plusieurs blocs\n\nConseils :\n\n- Utilisez une instruction break-if pour interrompre la boucle après (disons) 15 essais : `([count_trial_sequence]+1) % 15 = 0`\n- Ajoutez une nouvelle structure LOOP-SEQUENCE au-dessus de la *block_loop* pour répéter un bloc d'essais plusieurs fois\n- Désactivez l'option \"Évaluer lors du premier cycle\" dans la *block_loop* afin que l'instruction break-if ne soit pas évaluée lorsque la variable `count_trial_sequence` n'existe pas encore\n- Activez l'option \"Reprendre après la pause\" dans la *block_loop* pour échantillonner aléatoirement sans remplacement dans la table LOOP\n\n### Supplément 4 : Ajouter un retour d'information sur la précision et le temps de réponse moyen après chaque bloc\n\nFaites d'abord le supplément 3 !\n\nConseils :\n\n- Utilisez un élément FEEDBACK pour fournir des informations\n- Les variables `acc` et `avg_rt` contiennent la précision et le temps de réaction moyen en cours\n\n### Supplément 5 : Contrebalancer la règle de réponse\n\nConseils :\n\n- La variable `subject_parity` est 'even' ou 'odd'\n- Ceci nécessite un simple INLINE_SCRIPT\n- Assurez-vous que les instructions correspondent à la règle de réponse !\n\n## Références\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314–324. doi:10.3758/s13428-011-0168-7\n{: .reference}\n\n[OpenSesame runtime pour Android]: /getting-opensesame/android\n[diapositives]: /attachments/rovereto2014-workshop-slides.pdf\n[modulo]: http://fr.wikipedia.org/wiki/Opération_modulo\n[pdf]: /rovereto2014/index.pdf\n[gimp]: http://www.gimp.org/\n[capybara_photo]: https://commons.wikimedia.org/wiki/File:Capybara_Hattiesburg_Zoo_(70909b-58)_2560x1600.jpg"
  },
  "Professional support": {
    "fr": "Support professionnel",
    "de": "Professionelle Unterstützung"
  },
  "\nWe offer professional (paid) support for the following:\n\n- Implementation of experiments with OpenSesame\n- Analysis of experimental data\n- Organization of workshops on OpenSesame and/ or Python\n\nFor a quote or more information, please send an email to <professional@cogsci.nl>. To be helped quickly, please provide a clear and detailed description of what you are looking for.\n\nFree support is available through the community forum at <https://forum.cogsci.nl/>.\n": {
    "fr": "Nous offrons un soutien professionnel (payant) pour les éléments suivants :\n\n- Mise en œuvre d'expériences avec OpenSesame\n- Analyse des données expérimentales\n- Organisation d'ateliers sur OpenSesame et/ou Python\n\nPour un devis ou plus d'informations, veuillez envoyer un e-mail à <professional@cogsci.nl>. Pour être aidé rapidement, veuillez fournir une description claire et détaillée de ce que vous recherchez.\n\nUn soutien gratuit est disponible via le forum communautaire sur <https://forum.cogsci.nl/>."
  },
  "Important changes in OpenSesame 3": {
    "fr": "Changements importants dans OpenSesame 3"
  },
  "<notranslate>[TOC]</notranslate>\n\n\n## Changes in 3.3\n\nOpenSesame 3.3 several major improvements that make it even easier to develop experiments. OpenSesame 3.3 is fully backwards compatible with 3.2.\n\n\n### Rapunzel: a new code editor\n\nRapunzel is a code editor, focused on numerical computing with Python and R. Technically, Rapunzel is a set of extensions for OpenSesame. But it looks and behaves as a standalone program. Happy coding!\n\n- <https://rapunzel.cogsci.nl/>\n\n\n### A new inline_script editor\n\nRelated to the development of Rapuznel: The INLINE_SCRIPT item now uses a different library (`PyQode`) for the code editor. As a result, the code editor now supports many of the features that you would expect from a modern code editor, including code introspection and static code checking.\n\n\n### More color spaces\n\nOpenSesame now natively supports the HSV, HSL, and CIElab color spaces.\n\n- %link:manual/python/canvas%\n\n\n### New sound backend based on PsychoPy\n\nThe default backend is now *psycho*. One of the advantages of this backend is that the timing of sound presentation should be better. If you experience stuttering (clicky sound playback), you can still fall back to the the *psycho_legacy* backend, which uses the old PyGame-based sound system.\n\n\n### Support for inline_script items in coroutines\n\nYou can now use `inline_script` items in `coroutines`. This makes it easier to combine Python scripting with coroutines, as compared to the old method of writing a custom generator function.\n\n- %link:coroutines%\n\n\n\n### OpenSesame: \n\n\n## Changes in 3.2\n\nOpenSesame 3.2 brings several major improvements that make it even easier to develop experiments. OpenSesame 3.2 is fully backwards compatible with 3.1.\n\n\n### A better, PEP-8-compliant Python API\n\nPEP-8 is a style guide for Python. Much modern Python software follows the PEP-8 guidelines—but, for historical reasons, OpenSesame didn't. As of 3.2, the public API now follows the guideline that the names of classes (and factory functions that generate classes) should be `CamelCase`, while names of objects and functions should be `underscore_case`. Practically speaking, this means that you now create `Canvas` object as follows:\n\n~~~ .python\nmy_canvas = Canvas() # Note the capital C!\nmy_canvas.fixdot()\nmy_canvas.show())\n~~~\n\nOf course, the old `underscore_case` names are still available as aliases, so backwards compatibility is preserved.\n\nThe API for forms has also been simplified. You no longer need to import `libopensesame.widgets`, and you no longer need to pass `exp` as the first argument:\n\n~~~ .python\nform = Form()\nbutton = Button(text=u'Ok!')\nform.set_widget(button, (0, 0))\nform._exec()\n~~~\n\n\n### Improvements to the sketchpad and Canvas\n\n#### Access and modify Canvas elements\n\nElements of a `Canvas` are now objects that can be named, accessed, and modified. This means that you no longer need to redraw an entire canvas to change a single element. For example, you can draw a rotating arm as follows:\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas['arm'] = Line(0, 0, 0, 0)\nfor x, y in xy_circle(n=100, rho=100):\n\tmy_canvas['arm'].ex = x\n\tmy_canvas['arm'].ey = y\n\tmy_canvas.show()\n\tclock.sleep(10)\n~~~\n\nThe SKETCHPAD also allows you to name elements.\n\nFor more information, see:\n\n- %link:manual/python/canvas%\n\n\n#### Improved support for HTML and non-Latin script\n\nText is now rendered by Qt, which is a modern library (the same library that is also used for the graphical interface). This means that you can now use real HTML in your text. This also means that left-to-right script and other non-Latin scripts are rendered much better.\n\n\n#### Images can be rotated\n\nImages can now be rotated. This work both in SKETCHPAD items and `Canvas` objects.\n\n\n#### Work with polar coordinates": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n\n## Changements dans la version 3.3\n\nOpenSesame 3.3 apporte plusieurs améliorations majeures qui facilitent encore plus le développement d'expériences. OpenSesame 3.3 est entièrement compatible avec la version 3.2.\n\n\n### Rapunzel : un nouvel éditeur de code\n\nRapunzel est un éditeur de code, axé sur le calcul numérique avec Python et R. Techniquement, Rapunzel est un ensemble d'extensions pour OpenSesame. Mais il ressemble et se comporte comme un programme autonome. Bon codage !\n\n- <https://rapunzel.cogsci.nl/>\n\n\n### Un nouvel éditeur de inline_script\n\nEn rapport avec le développement de Rapuznel : L'élément INLINE_SCRIPT utilise maintenant une autre bibliothèque (`PyQode`) pour l'éditeur de code. En conséquence, l'éditeur de code prend désormais en charge bon nombre des fonctionnalités que l'on attend d'un éditeur de code moderne, y compris l'introspection du code et la vérification statique du code.\n\n\n### Plus d'espaces de couleurs\n\nOpenSesame prend désormais en charge de manière native les espaces de couleurs HSV, HSL et CIElab.\n\n- %link:manuel/python/canvas%\n\n\n### Un nouveau backend sonore basé sur PsychoPy\n\nLe backend par défaut est désormais *psycho*. L'un des avantages de ce backend est que la synchronisation de la présentation du son devrait être meilleure. Si vous rencontrez des saccades (lecture de son désynchronisée), vous pouvez toujours revenir au backend *psycho_legacy*, qui utilise l'ancien système de sons basé sur PyGame.\n\n\n### Support des éléments inline_script dans les coroutines\n\nVous pouvez désormais utiliser des éléments `inline_script` dans les `coroutines`. Cela facilite la combinaison de scripts Python avec des coroutines, par rapport à l'ancienne méthode d'écriture d'une fonction de générateur personnalisée.\n\n- %link:coroutine%\n\n\n### OpenSesame : \n\n\n## Changements dans la version 3.2\n\nOpenSesame 3.2 apporte plusieurs améliorations majeures qui facilitent encore plus le développement d'expériences. OpenSesame 3.2 est entièrement compatible avec la version 3.1.\n\n### Une meilleure API Python, conforme à la PEP-8\n\nLa PEP-8 est un guide de style pour Python. Beaucoup de logiciels Python modernes suivent les directives PEP-8 - mais, pour des raisons historiques, OpenSesame ne le faisait pas. À partir de la version 3.2, l'API publique suit désormais la directive selon laquelle les noms de classes (et les fonctions d'usine qui génèrent des classes) doivent être en `CamelCase`, tandis que les noms d'objets et de fonctions doivent être en `underscore_case`. En pratique, cela signifie que vous créez maintenant un objet `Canvas` comme suit :\n\n~~~ .python\nmy_canvas = Canvas() # Notez le C majuscule !\nmy_canvas.fixdot()\nmy_canvas.show())\n~~~\n\nBien sûr, les anciens noms en `underscore_case` sont toujours disponibles en tant qu'alias, de sorte que la compatibilité ascendante est préservée.\n\nL'API pour les formulaires a également été simplifiée. Vous n'avez plus besoin d'importer `libopensesame.widgets`, et vous n'avez plus besoin de passer `exp` comme premier argument :\n\n~~~ .python\nform = Form()\nbutton = Button(text=u'Ok!')\nform.set_widget(button, (0, 0))\nform._exec()\n~~~\n\n\n### Améliorations du sketchpad et du Canvas\n\n#### Accéder et modifier les éléments du Canvas\n\nLes éléments d'un `Canvas` sont maintenant des objets qui peuvent être nommés, accessibles et modifiés. Cela signifie que vous n'avez plus besoin de redessiner un canvas entier pour changer un seul élément. Par exemple, vous pouvez dessiner un bras tournant comme suit :\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas['arm'] = Line(0, 0, 0, 0)\nfor x, y in xy_circle(n=100, rho=100):\n\tmy_canvas['arm'].ex = x\n\tmy_canvas['arm'].ey = y\n\tmy_canvas.show()\n\tsleep(clock, 10)\n~~~\n\nLe SKETCHPAD permet également de nommer des éléments.\n\nPour plus d'informations, voir :\n\n- %link:manuel/python/canvas%\n\n\n#### Amélioration de la prise en charge du HTML et des scripts non latins\n\nLe texte est maintenant rendu par Qt, qui est une bibliothèque moderne (la même bibliothèque qui est également utilisée pour l'interface graphique). Cela signifie que vous pouvez maintenant utiliser du vrai HTML dans votre texte. Cela signifie également que les scripts de gauche à droite et d'autres scripts non latins sont rendus beaucoup mieux.\n\n\n#### Les images peuvent être tournées\n\nLes images peuvent maintenant être tournées. Cette fonction est valable à la fois pour les éléments SKETCHPAD et les objets `Canvas`.\n\n#### Travailler avec des coordonnées polaires"
  },
  "If you right-click on a SKETCHPAD elements, you can select 'Specify polar coordinates'. This allows you to calculate cartesian (x, y) coordinates based on polar coordinates, which is especially useful if you want to create circular configurations.\n\n\n### Form improvements\n\n#### Improved form performance\n\nForms are now much faster when using the *psycho* and *xpyriment* backends. This is due to the fact that `Canvas` elements can now be updated individually, as described above.\n\n\n#### Validation of form input\n\nYou can now validate the input of a form; that is, you can prevent a form from closing until certain criteria are met. In addition, you can exclude characters as input from `TextInput` widgets.\n\nFor more information, see:\n\n- %link:manual/forms/validation%\n\n\n### Keyboard Improvements\n\n#### Support for key-release events\n\nThe `Keyboard()` object now has a `get_key_release()` function, which allows you to collect key releases. Due to limitations of the underlying libraries, the function has two important limitations:\n\n- The returned `key` may be incorrect on non-QWERTY keyboard layouts\n- The function has not been implemented for the *psycho* backend\n\nFor more information, see:\n\n- %link:manual/response/keyboard%\n\n\n### Mouse Improvements\n\n#### Support for mouse-release events\n\nThe `Mouse()` object now has a `get_click_release()` function, which allows you to collect mouse-click releases. This function is currently not implemented for the *psycho* backend.\n\nFor more information, see:\n\n- %link:manual/response/mouse%\n\n#### Use sketchpads to define regions of interest\n\nYou can now define a linked SKETCHPAD in a `mouse_response` item. If you do this, the names of the elements on the SKETCHPAD will be automatically used as regions of interest (ROIs) for the mouse clicks.\n\n\n### Forcibly end your experiment\n\nYou can now forcibly end your experiment by clicking on the Kill button in the main toolbar. This means that you no longer need to open a process/ task manager to end run-away experiments!\n\n\n### Improved Mac OS support\n\nThe Mac OS packages have been rebuilt from the ground up by %-- github: {user: dschreij} --%. The Mac OS experience should now be much smoother, faster, and less crash-prone.\n\n\n### A Turkish translation\n\nA complete Turkish translation has been contributed by %-- github: {user: aytackarabay} --%. This means that OpenSesame is now fully translated into French, German, and Turkish. A partial translation is available in several other languages.\n\n\n## Changes in 3.1\n\nOpenSesame 3.1 brings many improvements that make it even easier to develop experiments. OpenSesame 3.1 is fully backwards compatible with 3.0.\n\n### A new look!\n\nOpenSesame has a new icon theme, based on [Moka](https://snwh.org/moka) by Sam Hewitt. In addition, the user interface has been redesigned based on consistent human-interface guidelines. We hope you like the new look as much as we do!\n\n### A redesigned loop\n\nThe LOOP is now easier to use, and allows you to constrain randomization; this makes it possible, for example, to prevent the same stimulus from occurring twice in a row.\n\nFor more information, see:\n\n- %link:loop%\n\n### Coroutines: doing things in parallel\n\nThe COROUTINES plugin is now included by default. COROUTINES allows you to run multiple other items in parallel; this makes it possible, for example, to continuously collect key presses while presenting a series of SKETCHPADs.\n\nFor more information, see:\n\n- %link:coroutines%\n\n### Open Science Framework integration\n\nYou can now log into the [Open Science Framework](http://osf.io) (OSF) from within OpenSesame, and effortlessly synchronize experiments and data between your computer and the OSF. Thanks to the [Center for Open Science](http://cos.io/) for supporting this functionality!\n\nFor more information, see:\n\n- %link:osf%\n\n### A responses object\n\nThere is a new standard Python object: `responses`. This keeps track of all responses that have been collected during the experiment.": {
    "fr": "Si vous faites un clic droit sur un élément SKETCHPAD, vous pouvez sélectionner 'Spécifier les coordonnées polaires'. Cela vous permet de calculer les coordonnées cartésiennes (x, y) à partir des coordonnées polaires, ce qui est particulièrement utile si vous souhaitez créer des configurations circulaires.\n\n### Améliorations des formulaires\n\n#### Performance améliorée des formulaires\n\nLes formulaires sont désormais beaucoup plus rapides lors de l'utilisation des backends *psycho* et *xpyriment*. Ceci est dû au fait que les éléments `Canvas` peuvent maintenant être mis à jour individuellement, comme décrit ci-dessus.\n\n#### Validation de l'entrée du formulaire\n\nVous pouvez désormais valider l'entrée d'un formulaire, c'est-à-dire empêcher la fermeture d'un formulaire tant que certains critères ne sont pas respectés. De plus, vous pouvez exclure des caractères en tant qu'entrée des widgets `TextInput`.\n\nPour plus d'informations, voir:\n\n- %link:manual/forms/validation%\n\n### Améliorations clavier\n\n#### Support des événements de relâchement de touches\n\nL'objet `Keyboard()` dispose désormais d'une fonction `get_key_release()`, qui vous permet de récupérer les relâchements de touches. En raison des limitations des bibliothèques sous-jacentes, cette fonction présente deux limitations importantes :\n\n- La `key` retournée peut être incorrecte sur les dispositions de clavier autres que QWERTY\n- La fonction n'a pas été mise en œuvre pour le backend *psycho*\n\nPour plus d'informations, voir:\n\n- %link:manual/response/keyboard%\n\n### Améliorations de la souris\n\n#### Support des événements de relâchement des clics de la souris\n\nL'objet `Mouse()` dispose désormais d'une fonction `get_click_release()`, qui vous permet de récupérer les relâchements des clics de souris. Cette fonction n'est actuellement pas mise en œuvre pour le backend *psycho*.\n\nPour plus d'informations, voir:\n\n- %link:manual/response/mouse%\n\n#### Utiliser des sketchpads pour définir des zones d'intérêt\n\nVous pouvez maintenant définir un SKETCHPAD lié dans un élément `mouse_response`. Si vous faites cela, les noms des éléments sur le SKETCHPAD seront automatiquement utilisés comme zones d'intérêt (ROIs) pour les clics de souris.\n\n### Mettre fin à votre expérience de force\n\nVous pouvez désormais mettre fin de force à votre expérience en cliquant sur le bouton Kill dans la barre d'outils principale. Cela signifie que vous n'avez plus besoin d'ouvrir un gestionnaire de processus/tâches pour mettre fin aux expériences incontrôlables !\n\n### Support amélioré pour Mac OS\n\nLes packages Mac OS ont été entièrement reconstruits par %-- github: {user: dschreij} --%. L'expérience Mac OS devrait désormais être bien plus fluide, rapide et moins sujette aux plantages.\n\n### Une traduction turque\n\nUne traduction turque complète a été apportée par %-- github: {user: aytackarabay} --%. Cela signifie qu'OpenSesame est maintenant entièrement traduit en français, allemand et turc. Une traduction partielle est disponible dans plusieurs autres langues.\n\n## Changements dans la version 3.1\n\nOpenSesame 3.1 apporte de nombreuses améliorations qui rendent encore plus facile le développement d'expériences. OpenSesame 3.1 est entièrement compatible avec la version 3.0.\n\n### Un nouveau look !\n\nOpenSesame a un nouveau thème d'icônes, basé sur [Moka](https://snwh.org/moka) de Sam Hewitt. De plus, l'interface utilisateur a été repensée sur la base de directives d'interface humaine cohérentes. Nous espérons que vous aimerez ce nouveau look autant que nous !\n\n### Une boucle redessinée\n\nLa LOOP est désormais plus facile à utiliser et vous permet de contraindre l'aléa; cela permet, par exemple, d'empêcher qu'un même stimulus se répète deux fois d'affilée.\n\nPour plus d'informations, voir:\n\n- %link:loop%\n\n### Coroutines: faire les choses en parallèle\n\nLe plugin COROUTINES est désormais inclus par défaut. Les COROUTINES vous permettent d'exécuter plusieurs autres éléments en parallèle ; cela permet, par exemple, de collecter en continu des pressions de touches tout en présentant une série de SKETCHPADs.\n\nPour plus d'informations, voir:\n\n- %link:coroutines%\n\n### Intégration du cadre scientifique ouvert\n\nVous pouvez désormais vous connecter à [Open Science Framework](http://osf.io) (OSF) depuis OpenSesame, et synchroniser sans effort les expériences et les données entre votre ordinateur et l'OSF. Merci au [Center for Open Science](http://cos.io/) pour le soutien de cette fonctionnalité!\n\nPour plus d'informations, voir:\n\n- %link:osf%\n\n### Un objet de réponses \n\nIl y a un nouvel objet Python standard : `responses`. Celui-ci garde une trace de toutes les réponses collectées au cours de l'expérience."
  },
  "For more information, see:\n\n- %link:responses%\n\n## Changes in 3.0\n\nOpenSesame 3.0 has brought many improvements that make it even easier to develop experiments. Most changes are backwards compatible. That is, you can still do things the old way. However, a handful of changes are backwards incompatible, and it's important to be aware of those.\n\n### Backwards incompatible changes\n\n#### Sampler properties\n\nThe SAMPLER object has a number of properties that were previously functions. This concerns:\n\n- `sampler.fade_in`\n- `sampler.pan`\n- `sampler.pitch`\n- `sampler.volume`\n\nFor more information, see:\n\n- %link:sampler%\n\n#### CSS3-compatible colors\n\nYou can now use CSS3-compatible color specifications, as described here:\n\n- %link:manual/python/canvas%\n\nIf you use color names (e.g. 'red', 'green', etc.), this may result in slightly different colors. For example, according to CSS3, 'green' is `#008000` instead (as was the case previously) of `#00FF00`.\n\n### New file format (.osexp)\n\nOpenSesame now saves experiments in `.osexp` format. Of course, you can still open the old formats (`.opensesame` and `.opensesame.tar.gz`). For more information, see:\n\n- %link:fileformat%\n\n### Simplified Python API\n\n#### No more self and exp\n\nIt is no longer necessary to prefix `self.` or `exp.` when calling commonly used functions. For example, this will programmatically set the subject number to 2:\n\n~~~ .python\nset_subject_nr(2)\n~~~\n\nFor a list of common functions, see:\n\n- %link:manual/python/common%\n\n#### The `var` object: Easy getting and setting of experimental variables\n\nThe old way of using `self.get()` to get, and `exp.set()` to set experimental variables has been replaced by a simpler syntax. For example, to set the variable `condition`, so that you can refer to it as `[condition]` in SKETCHPADs, etc.:\n\n~~~ .python\nvar.condition = 'easy`'\n~~~\n\nAnd to get an experimental variable `condition` that was, for example, defined in a LOOP:\n\n~~~ .python\nprint('Condition is %s' % var.condition)\n~~~\n\nFor more information, see:\n\n- %link:var%\n\n#### The `clock` object: Time functions\n\nTime functions are now available through the `clock` object:\n\n~~~ .python\nprint('Current timestamp: %s' % clock.time())\nclock.sleep(1000) # Sleep for 1 s\n~~~\n\nFor more information, see:\n\n- %link:clock%\n\n#### The `pool` object: Accessing the file pool\n\nThe file pool is now accessible through the `pool` object, which supports a `dict`-like interface (but is not really a Python `dict`):\n\n~~~ .python\npath = pool['image.png']\nprint('The full path to image.png is: %s' % path)\n~~~\n\nFor more information, see:\n\n- %link:pool%\n\n#### No more from openexp.* import *\n\nIt is no longer necessary to import `openexp` classes, and to pass `exp` as the first argument. Instead, to create a `canvas` object, you can simply do:\n\n~~~ .python\nmy_canvas = canvas()\n~~~\n\nThere are similar factory functions (as these are called) for `keyboard`, `mouse`, and SAMPLER.\n\nFor more information, see:\n\n- %link:manual/python/common%\n\n#### The synth is now a sampler\n\nThe SYNTH is no longer a class of its own. Instead, it's a function that returns a SAMPLER object that has been filled with a synthesized sample.\n\n### User-interface improvements\n\n#### An IPython debug window\n\nIPython, an interactive Python terminal for scientific computing, is now used for the debug window.\n\n#### A live variable inspector\n\nThe variable inspector now shows the actual values of your variables while your experiment is running, and after your experiment has finished.\n\n#### Undo\n\nYou can finally undo actions!\n\n#### A new color scheme\n\nThe default color scheme is now *Monokai*. Again a dark color scheme, but with a higher contrast than the previous default, *Solarized*. This increased should increase legibility. And it looks good!\n\n### Consistent coordinates": {
    "fr": "Pour plus d'informations, voir :\n\n- %link:responses%\n\n## Changements dans la version 3.0\n\nOpenSesame 3.0 a apporté de nombreuses améliorations qui rendent encore plus facile le développement d'expériences. La plupart des changements sont rétrocompatibles. En d'autres termes, vous pouvez toujours faire les choses de l'ancienne manière. Cependant, quelques changements ne sont pas rétrocompatibles, et il est important d'en être conscient.\n\n### Changements non rétrocompatibles\n\n#### Propriétés de Sampler\n\nL'objet SAMPLER a un certain nombre de propriétés qui étaient auparavant des fonctions. Cela concerne :\n\n- `sampler.fade_in`\n- `sampler.pan`\n- `sampler.pitch`\n- `sampler.volume`\n\nPour plus d'informations, voir :\n\n- %link:sampler%\n\n#### Couleurs compatibles CSS3\n\nVous pouvez désormais utiliser des spécifications de couleurs compatibles CSS3, comme décrit ici :\n\n- %link:manual/python/canvas%\n\nSi vous utilisez des noms de couleurs (par exemple 'red', 'green', etc.), cela peut entraîner des couleurs légèrement différentes. Par exemple, selon CSS3, 'green' est `#008000` au lieu de (comme c'était le cas auparavant) `#00FF00`.\n\n### Nouveau format de fichier (.osexp)\n\nOpenSesame enregistre désormais les expériences au format `.osexp`. Bien sûr, vous pouvez toujours ouvrir les anciens formats (`.opensesame` et `.opensesame.tar.gz`). Pour plus d'informations, voir :\n\n- %link:fileformat%\n\n### API Python simplifiée\n\n#### Plus de self et exp\n\nIl n'est plus nécessaire de préfixer `self.` ou `exp.` lors de l'appel de fonctions couramment utilisées. Par exemple, cela définira de manière programmatique le numéro de sujet à 2 :\n\n~~~ .python\nset_subject_nr(2)\n~~~\n\nPour une liste des fonctions courantes, voir :\n\n- %link:manual/python/common%\n\n#### L'objet `var` : accès et modification faciles des variables expérimentales\n\nL'ancienne façon d'utiliser `self.get()` pour obtenir et `exp.set()` pour définir des variables expérimentales a été remplacée par une syntaxe plus simple. Par exemple, pour définir la variable `condition`, afin de pouvoir la référencer en tant que `[condition]` dans les SKETCHPADs, etc. :\n\n~~~ .python\nvar.condition = 'easy`'\n~~~\n\nEt pour obtenir une variable expérimentale `condition` qui a été, par exemple, définie dans une LOOP :\n\n~~~ .python\nprint('Condition is %s' % var.condition)\n~~~\n\nPour plus d'informations, voir :\n\n- %link:var%\n\n#### L'objet `clock` : fonctions de temps\n\nLes fonctions de temps sont maintenant disponibles via l'objet `clock` :\n\n~~~ .python\nprint('Current timestamp: %s' % clock.time())\nclock.sleep(1000) # Sleep for 1 s\n~~~\n\nPour plus d'informations, voir :\n\n- %link:clock%\n\n#### L'objet `pool` : accès à la pool de fichiers\n\nLa pool de fichiers est maintenant accessible via l'objet `pool`, qui prend en charge une interface de type `dict` (mais qui n'est pas vraiment un `dict` Python) :\n\n~~~ .python\npath = pool['image.png']\nprint('The full path to image.png is: %s' % path)\n~~~\n\nPour plus d'informations, voir :\n\n- %link:pool%\n\n#### Plus de from openexp.* import *\n\nIl n'est plus nécessaire d'importer les classes `openexp`, et de passer `exp` en tant que premier argument. Au lieu de cela, pour créer un objet `canvas`, vous pouvez simplement faire :\n\n~~~ .python\nmy_canvas = canvas()\n~~~\n\nIl existe des fonctions similaires (comme on les appelle) pour `keyboard`, `mouse`, et SAMPLER.\n\nPour plus d'informations, voir :\n\n- %link:manual/python/common%\n\n#### Le synth est maintenant un échantillonneur\n\nLe SYNTH n'est plus une classe à part entière. Au lieu de cela, c'est une fonction qui retourne un objet SAMPLER qui a été rempli avec un échantillon synthétisé.\n\n### Améliorations de l'interface utilisateur\n\n#### Une fenêtre de débogage IPython\n\nIPython, un terminal Python interactif pour le calcul scientifique, est désormais utilisé pour la fenêtre de débogage.\n\n#### Un inspecteur de variables en direct\n\nL'inspecteur de variables affiche désormais les valeurs réelles de vos variables pendant l'exécution de votre expérience et après la fin de celle-ci.\n\n#### Annuler\n\nVous pouvez enfin annuler vos actions !\n\n#### Un nouveau schéma de couleurs\n\nLe schéma de couleurs par défaut est maintenant *Monokai*. Encore un schéma de couleurs sombres, mais avec un contraste plus élevé que le précédent par défaut, *Solarized*. Cette augmentation devrait augmenter la lisibilité. Et ça a l'air bien !\n\n### Coordonnées cohérentes"
  },
  "Previously, OpenSesame used mixed, inconsistent screen coordinates: `0,0` was the display top-left when using Python code, and the display center when working in SKETCHPAD items etc. As of 3.0, the display center is always `0,0`, also in Python code.\n\nIf you want to switch back to the old behavior, you can disable the 'Uniform coordinates' option in the general tab. For backwards compatibility, 'Uniform coordinates' are automatically disabled when you open an old experiment.\n\n### Using Python in text strings\n\nYou can now embed Python in text strings using the `[=...]` syntax. For example, the following text string in a SKETCHPAD:\n\n~~~\nTwo times two equals [=2*2]\n~~~\n\n... will show:\n\n~~~\nTwo times two equals 4\n~~~\n\nFor more information, see:\n\n- %link:text%\n\n### Support for Python 3\n\nOpenSesame now supports Python >= 3.4. However, many of OpenSesame's dependencies, notably PsychoPy and Expyriment, are Python 2-only. Therefore, Python 2.7 remains the default version of Python.\n": {
    "fr": "Précédemment, OpenSesame utilisait des coordonnées d'écran mixtes et incohérentes : `0,0` était en haut à gauche de l'affichage lors de l'utilisation du code Python, et au centre de l'affichage lors de l'utilisation des éléments SKETCHPAD, etc. À partir de la version 3.0, le centre de l'affichage est toujours `0,0`, également dans le code Python.\n\nSi vous souhaitez revenir à l'ancien comportement, vous pouvez désactiver l'option \"Coordonnées uniformes\" dans l'onglet général. Pour des raisons de compatibilité ascendante, les \"Coordonnées uniformes\" sont automatiquement désactivées lorsque vous ouvrez une ancienne expérience.\n\n### Utiliser Python dans les chaînes de texte\n\nVous pouvez désormais intégrer Python dans les chaînes de texte en utilisant la syntaxe `[=...]`. Par exemple, la chaîne de texte suivante dans un SKETCHPAD :\n\n~~~\nDeux fois deux égale [=2*2]\n~~~\n\n... affichera :\n\n~~~\nDeux fois deux égale 4\n~~~\n\nPour plus d'informations, consultez :\n\n- %link:text%\n\n### Support de Python 3\n\nOpenSesame prend désormais en charge Python >= 3.4. Cependant, plusieurs dépendances d'OpenSesame, notamment PsychoPy et Expyriment, sont uniquement en Python 2. Par conséquent, Python 2.7 reste la version par défaut de Python."
  },
  "Leuphana 2021 workshop": {
    "fr": "Atelier Leuphana 2021"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## Practical information\n\n- Host: Leuphana Universität Lüneburg\n- Location: online\n- Dates: Nov 10, 17, and 24, 13:00 – 17:00\n- Presenter: Sebastiaan Mathôt\n- [Spreadsheet with participant overview](https://docs.google.com/spreadsheets/d/1QCUwNuHX5OkadF4kWj0xp9Aj9NDM7WxWJ0q6NBlUWhI/edit?usp=sharing)\n\n\n## Description\n\nIn this three-day, hands-on, online workshop, you will learn how to implement psychological experiments with the open-source software OpenSesame. You will learn how to run experiments online as well as in a traditional laboratory set-up, and about the limitations and advantages of both approaches. You will also learn how to include eye tracking in laboratory-based experiments. Finally, using the skills that you will learn during the workshop, you will design and implement an experiment for your own research.\n\nPlease install OpenSesame on your computer before the workshop. You can download OpenSesame for free from this link:\n\n- %link:download%\n\nNo prior experience with OpenSesame, Python, or JavaScript is required.\n\nI’m looking forward to meeting you all!\n\n— Sebastiaan\n\n\n## Program \n\n\n### Day 1 (Nov 10): Introduction\n\nSlides: %static:attachments/leuphana2021/leuphana-day-1.pdf%\n\n- 13:00 – 14:30: __Introduction to OpenSesame__. A general introduction to the software OpenSesame, followed by a hands-on tutorial in which you will learn the basic concepts of the software. [Click here](%url:/tutorials/capybara%) to go to the tutorial.\n- Break\n- 15:00 – 16:00: __Introduction to OpenSesame (continued)__.\n- 16:00 – 17:00: __Free time to develop your own experiment.__ What kind of experiment would you like to build for your own research? You will draft a design for your own experiment, which you will implement during the next two days. Use [this spreadsheet](https://docs.google.com/spreadsheets/d/1QCUwNuHX5OkadF4kWj0xp9Aj9NDM7WxWJ0q6NBlUWhI/edit?usp=sharing) to indicate which experiment you'd like to create.\n\n\n### Day 2 (Nov 17): Online experiments\n\nSlides: %static:attachments/leuphana2021/leuphana-day-2.pdf%\n\n- 13:00 – 14:30: __Building an online time-reproduction task.__ We will start this session with a general introduction to online experiments. This is followed by a hands-on tutorial in which you will implement a time-reproduction task that is suitable for running online.\n- Break\n- 15:00 – 16:00: __Using <https://mindprobe.eu> (a JATOS server) to run experiments online.__ In this session, you will learn how to use mindprobe.eu, which is a free server that runs the open-source software JATOS, to actually run an experiment online. A mindprobe.eu account will be provided to each participant.\n- 16:00 – 17:00: __Free time to develop your own experiment.__ During this session, you will continue to work on your own experiment.\n\n\n### Day 3 (Nov 24): Eye-tracking experiments\n\nSlides: %static:attachments/leuphana2021/leuphana-day-3.pdf%\n\n- 13:00 – 14:30: __Building a self-paced reading task with eye-tracking.__ We will start this session with a general introduction to eye tracking. This is followed by a hands-on tutorial in which you will implement a self-paced reading task with basic eye tracking. We will focus on using the EyeLink, which is a specific eye tracker. However, concepts and techniques are largely also applicable to other eye trackers.\nBreak\n- Break\n- 15:00 – 16:00: __Gaze-contingent eye-tracking.__ You will learn how to implement experiments that react to the eye movements of the participant, that is, gaze-contingent experiments.\n- 16:00 – 17:00: __Free time to develop your own experiment.__ During this session, you will continue to work on your own experiment.\n- 17:00 – 17:30: __Q&A.__ We will close the workshop with time for questions and remarks.\n": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## Informations pratiques\n\n- Hôte : Leuphana Universität Lüneburg\n- Lieu : en ligne\n- Dates : 10, 17 et 24 novembre, de 13h00 à 17h00\n- Animateur : Sebastiaan Mathôt\n- [Tableur avec un aperçu des participants](https://docs.google.com/spreadsheets/d/1QCUwNuHX5OkadF4kWj0xp9Aj9NDM7WxWJ0q6NBlUWhI/edit?usp=sharing)\n\n## Description\n\nDans cet atelier en ligne de trois jours, vous apprendrez à mettre en œuvre des expériences de psychologie avec le logiciel open-source OpenSesame. Vous apprendrez comment réaliser des expériences en ligne ainsi que dans un laboratoire traditionnel, et vous découvrirez les limites et les avantages de ces deux approches. Vous apprendrez également à inclure le suivi oculaire dans les expériences en laboratoire. Enfin, en utilisant les compétences que vous aurez acquises lors de l'atelier, vous concevrez et mettrez en œuvre une expérience pour votre propre recherche.\n\nVeuillez installer OpenSesame sur votre ordinateur avant l'atelier. Vous pouvez télécharger OpenSesame gratuitement à partir de ce lien :\n\n- %link:download%\n\nAucune expérience préalable en OpenSesame, Python ou JavaScript n'est requise.\n\nJ'ai hâte de vous rencontrer tous !\n\n— Sebastiaan\n\n## Programme\n\n### Jour 1 (10 novembre) : Introduction\n\nDiapositives : %static:attachments/leuphana2021/leuphana-day-1.pdf%\n\n- 13h00 – 14h30 : __Introduction à OpenSesame__. Une introduction générale au logiciel OpenSesame, suivie d'un tutoriel pratique dans lequel vous apprendrez les concepts de base du logiciel. [Cliquez ici](%url:/tutorials/capybara%) pour accéder au tutoriel.\n- Pause\n- 15h00 – 16h00 : __Introduction à OpenSesame (suite)__.\n- 16h00 – 17h00 : __Temps libre pour développer votre propre expérience__. Quel type d'expérience aimeriez-vous réaliser pour votre propre recherche ? Vous élaborerez un plan de votre propre expérience, que vous mettrez en œuvre au cours des deux prochains jours. Utilisez [ce tableur](https://docs.google.com/spreadsheets/d/1QCUwNuHX5OkadF4kWj0xp9Aj9NDM7WxWJ0q6NBlUWhI/edit?usp=sharing) pour indiquer l'expérience que vous souhaitez créer.\n\n### Jour 2 (17 novembre) : Expériences en ligne\n\nDiapositives : %static:attachments/leuphana2021/leuphana-day-2.pdf%\n\n- 13h00 – 14h30 : __Création d'une tâche de reproduction du temps en ligne__. Nous commencerons cette session par une introduction générale aux expériences en ligne. Elle sera suivie d'un tutoriel pratique dans lequel vous mettrez en œuvre une tâche de reproduction du temps adaptée pour fonctionner en ligne.\n- Pause\n- 15h00 – 16h00 : __Utilisation de <https://mindprobe.eu> (un serveur JATOS) pour réaliser des expériences en ligne__. Au cours de cette session, vous apprendrez à utiliser mindprobe.eu, qui est un serveur gratuit qui utilise le logiciel open source JATOS, pour mener réellement une expérience en ligne. Un compte mindprobe.eu sera fourni à chaque participant.\n- 16h00 – 17h00 : __Temps libre pour développer votre propre expérience__. Au cours de cette session, vous continuerez à travailler sur votre propre expérience.\n\n### Jour 3 (24 novembre) : Expériences de suivi oculaire\n\nDiapositives : %static:attachments/leuphana2021/leuphana-day-3.pdf%\n\n- 13h00 – 14h30 : __Création d'une tâche de lecture auto-déclenchée avec suivi oculaire__. Nous commencerons cette session par une introduction générale au suivi oculaire. Elle sera suivie d'un tutoriel pratique dans lequel vous mettrez en œuvre une tâche de lecture auto-déclenchée avec un suivi oculaire basique. Nous nous concentrerons sur l'utilisation de l'EyeLink, qui est un dispositif de suivi oculaire spécifique. Toutefois, les concepts et les techniques sont également en grande partie applicables à d'autres dispositifs de suivi oculaire.\n- Pause\n- 15h00 – 16h00 : __Suivi oculaire dépendant du regard__. Vous apprendrez à mettre en œuvre des expériences qui réagissent aux mouvements oculaires des participants, c'est-à-dire des expériences dépendantes du regard.\n- 16h00 – 17h00 : __Temps libre pour développer votre propre expérience__. Au cours de cette session, vous continuerez à travailler sur votre propre expérience.\n- 17h00 – 17h30 : __Questions-réponses__. Nous clôturerons l'atelier par un temps consacré aux questions et remarques."
  },
  "Degrees of visual angle": {
    "fr": "Degrés d'angle visuel"
  },
  "You will often see that the size of visual stimuli is expressed in degrees of visual angle (°). Visual degrees express the angle between the straight lines from the extremities of the stimulus to the eye's lens. Therefore, visual angle is related to the size that a stimulus subtends on the retina, but only indirectly: It is an angle measured from the eye's lens, as illustrated in %FigEye\n\n<notranslate>[TOC]</notranslate>\n\n<notranslate>\nfigure:\n id: FigEye\n source: fig-eye.png\n caption: A schematic illustration of degrees of visual angle. (Image adapted from [WikiMedia Commons](http://commons.wikimedia.org/wiki/File:Schematic_diagram_of_the_human_eye.svg).)\n</notranslate>\n\nThe reason for using this somewhat odd measure of size is that it reflects the perceived size of a stimulus, which in psychological experiments is often more important than its real size. For example, if you present a picture with a real width of 100 pixels on the monitor, the visual angle may correspond to 3°. If you move the monitor further away, the visual angle of the picture will decrease to, say, 2°. Visual angle thus reflects that the distance between a stimulus and an observer is important.\n\nSee also:\n\n- <http://en.wikipedia.org/wiki/Visual_angle>\n\n## Convert pixels to visual degrees\n\nYou will need to know three things in order to convert pixels to visual degrees:\n\n- `h` is the height of the monitor in centimeters, which you can measure with a ruler. (e.g., 25cm)\n- `d` is the distance from the participant to the monitor in centimeters, which you can measure with a ruler. (e.g., 60cm)\n- `r` is the vertical resolution of the monitor in pixels, which you can find in your operating system's display settings (e.g., 768 px)\n\nYou can calculate angular size of your stimulus as shown below. You can execute this script in the OpenSesame debug window. Of course, you need to substitute all values so that they correspond to your setup. Note that a single visual degree typically corresponds to 30 - 60 pixels, depending on the distance and size of the monitor. Conversely, a single pixel typically corresponds to 0.01 to 0.03 visual degrees. If you obtain values that are far outside of this range, you have probably made a mistake.\n\n```python\nfrom math import atan2, degrees\n\nh = 25           # Monitor height in cm\nd = 60           # Distance between monitor and participant in cm\nr = 768          # Vertical resolution of the monitor\nsize_in_px = 100 # The stimulus size in pixels\n# Calculate the number of degrees that correspond to a single pixel. This will\n# generally be a very small value, something like 0.03.\ndeg_per_px = degrees(atan2(.5 * h, d)) / (.5 * r)\nprint(f'{deg_per_px} degrees correspond to a single pixel')\n# Calculate the size of the stimulus in degrees\nsize_in_deg = size_in_px * deg_per_px\nprint(f'The size of the stimulus is {size_in_px} pixels and {size_in_deg} visual degrees')\n```\n\n## Convert visual degrees to pixels\n\nConverting visual degrees to pixels is simply the inverse of the procedure described above, and can be done as follows:\n\n```python\nfrom math import atan2, degrees\nh = 25           # Monitor height in cm\nd = 60           # Distance between monitor and participant in cm\nr = 768          # Vertical resolution of the monitor\nsize_in_deg = 3. # The stimulus size in pixels\n# Calculate the number of degrees that correspond to a single pixel. This will\n# generally be a very small value, something like 0.03.\ndeg_per_px = degrees(atan2(.5 * h, d)) / (.5 * r)\nprint(f'{deg_per_px} degrees correspond to a single pixel')\n# Calculate the size of the stimulus in degrees\nsize_in_px = size_in_deg / deg_per_px\nprint(f'The size of the stimulus is {size_in_px} pixels and {size_in_deg} visual degrees')\n```\n": {
    "fr": "Vous verrez souvent que la taille des stimuli visuels est exprimée en degrés d'angle visuel (°). Les degrés visuels expriment l'angle entre les lignes droites des extrémités du stimulus jusqu'à la lentille de l'œil. Par conséquent, l'angle visuel est lié à la taille qu'un stimulus sous-tend sur la rétine, mais seulement indirectement : c'est un angle mesuré à partir de la lentille de l'œil, comme illustré dans %FigEye\n\n<notranslate>[TOC]</notranslate>\n\n<notranslate>\nfigure:\n id: FigEye\n source: fig-eye.png\n caption: Une illustration schématique des degrés d'angle visuel. (Image adaptée de [WikiMedia Commons](http://commons.wikimedia.org/wiki/File:Schematic_diagram_of_the_human_eye.svg).)\n</notranslate>\n\nLa raison d'utiliser cette mesure de taille quelque peu étrange est qu'elle reflète la taille perçue d'un stimulus, qui dans les expériences psychologiques est souvent plus importante que sa taille réelle. Par exemple, si vous présentez une image avec une largeur réelle de 100 pixels sur le moniteur, l'angle visuel peut correspondre à 3°. Si vous éloignez le moniteur, l'angle visuel de l'image diminuera à, disons, 2°. L'angle visuel reflète ainsi que la distance entre un stimulus et un observateur est importante.\n\nVoir aussi :\n\n- <http://en.wikipedia.org/wiki/Visual_angle>\n\n## Convertir les pixels en degrés visuels\n\nVous devez connaître trois choses pour convertir les pixels en degrés visuels :\n\n- `h` est la hauteur du moniteur en centimètres, que vous pouvez mesurer avec une règle. (par exemple, 25cm)\n- `d` est la distance entre le participant et le moniteur en centimètres, que vous pouvez mesurer avec une règle. (par exemple, 60cm)\n- `r` est la résolution verticale du moniteur en pixels, que vous pouvez trouver dans les paramètres d'affichage de votre système d'exploitation (par exemple, 768 px)\n\nVous pouvez calculer la taille angulaire de votre stimulus comme indiqué ci-dessous. Vous pouvez exécuter ce script dans la fenêtre de débogage d'OpenSesame. Bien sûr, vous devez remplacer toutes les valeurs pour qu'elles correspondent à votre configuration. Notez qu'un degré visuel unique correspond généralement à 30 - 60 pixels, selon la distance et la taille du moniteur. Inversement, un seul pixel correspond généralement à 0,01 à 0,03 degrés visuels. Si vous obtenez des valeurs qui sont bien en dehors de cette plage, vous avez probablement commis une erreur.\n\n```python\nfrom math import atan2, degrees\n\nh = 25           # Hauteur du moniteur en cm\nd = 60           # Distance entre le moniteur et le participant en cm\nr = 768          # Résolution verticale du moniteur\nsize_in_px = 100 # La taille du stimulus en pixels\n# Calculez le nombre de degrés qui correspondent à un seul pixel. Cela sera\n# généralement une valeur très petite, quelque chose comme 0,03.\ndeg_per_px = degrees(atan2(.5 * h, d)) / (.5 * r)\nprint(f'{deg_per_px} degrés correspondent à un seul pixel')\n# Calculez la taille du stimulus en degrés\nsize_in_deg = size_in_px * deg_per_px\nprint(f'La taille du stimulus est de {size_in_px} pixels et {size_in_deg} degrés visuels')\n```\n\n## Convertir les degrés visuels en pixels\n\nConvertir les degrés visuels en pixels est simplement l'inverse de la procédure décrite ci-dessus et peut être fait comme suit :\n\n```python\nfrom math import atan2, degrees\nh = 25           # Hauteur du moniteur en cm\nd = 60           # Distance entre le moniteur et le participant en cm\nr = 768          # Résolution verticale du moniteur\nsize_in_deg = 3. # La taille du stimulus en pixels\n# Calculez le nombre de degrés qui correspondent à un seul pixel. Cela sera\n# généralement une valeur très petite, quelque chose comme 0,03.\ndeg_per_px = degrees(atan2(.5 * h, d)) / (.5 * r)\nprint(f'{deg_per_px} degrés correspondent à un seul pixel')\n# Calculez la taille du stimulus en degrés\nsize_in_px = size_in_deg / deg_per_px\nprint(f'La taille du stimulus est de {size_in_px} pixels et {size_in_deg} degrés visuels')\n```\n"
  },
  "Kurt Lewin Institute Workshop 2020": {
    "fr": "Atelier de l'Institut Kurt Lewin 2020"
  },
  "Release notes for 2.8.2": {
    "fr": "Notes de version pour 2.8.2"
  },
  "OpenSesame 2.8.2 is the second maintenance release in the 2.8 series. If you are upgrading from 0.27.4 or earlier, please also read the [2.8.0 release notes].\n\n## Credits\n\nThanks to Daniel Schreij ([@dschreij](https://github.com/dschreij/)) for his code contributions (as always!).\n\n## Changelog\n\n### Improvements\n\n- Improve support for psycho backend on OSX\n- Improve support for multiprocessing on OSX\n- Open experiments by dropping on the overview area\n- Add fallback pool folder to facilitate versioning\n- Allow margins, spacing, and theme to be specified in `form_multiple_choice` plugin (#255)\n- Safely convert messages to unicode in `item.log()`\n- Fall back to temporary folder when the default logfile is not writable in quickrun mode\n\n### Bugs fixed\n\n- Fix autosave folder dialog on OSX (#250)\n- Fix sampler crashing on filenames with special characters (#244)\n- All items set `time_[item name]` variables (#243)\n- Do not crash on purely numeric text when using bi-direction language support (#253)\n- Correctly evaluate conditional statements with special characters\n- Fixed confusion in tab manager when saving while having an open and modified item script\n- Fix translation bug for non-ASCII str objects\n- Fix a unicode bug where exceptions with images with special-character paths where obscured\n\n### Windows packaging\n\n- Update included libraries. See `modules()` output below.\n- Includes a slightly patched version of PsychoPy 1.80.05 that addresses an important issue with keypress timestamps.\n\n~~~\nOpenSesame 2.8.2\nPython 2.7.6 (default, Nov 10 2013, 19:24:18) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 2.4.9\nQProgedit 1.3.2\nExpyriment 0.7.0 (Revision 7a6b73d; Python 2.7.6)\nNumPy 1.8.1\nPIL is available (version is unknown)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.7\nPyGame 1.9.1release\nPyglet 1.1.4\nPyOpenGL 3.0.2\nPyQt 4.10.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.4\nSciPy 0.13.3\n~~~\n\n[2.8.0 release notes]: /notes/2.8.0\n": {
    "fr": "OpenSesame 2.8.2 est la deuxième version de maintenance de la série 2.8. Si vous effectuez une mise à niveau à partir de 0.27.4 ou antérieur, veuillez également lire les [notes de version 2.8.0].\n\n## Crédits\n\nMerci à Daniel Schreij ([@dschreij](https://github.com/dschreij/)) pour ses contributions de code (comme toujours!).\n\n## Changelog\n\n### Améliorations\n\n- Améliorer le support pour le backend psycho sur OSX\n- Améliorer le support pour le multiprocessing sur OSX\n- Ouvrir les expériences en les déposant sur la zone \"aperçu\"\n- Ajouter un dossier de ressources par défaut pour faciliter la versioning\n- Autoriser les marges, l'espacement et le thème à être spécifiés dans le plugin `form_multiple_choice` (# 255)\n- Convertir en toute sécurité les messages en unicode dans `item.log()`\n- Utiliser un dossier temporaire lorsque le fichier de journal par défaut n'est pas modifiable en mode \"quickrun\"\n\n### Erreurs corrigées\n\n- Corriger le dialogue du dossier autosave sur OSX (# 250)\n- Corriger le crash du sampler sur les noms de fichiers avec des caractères spéciaux (# 244)\n- Tous les éléments définissent les variables `time_[nom de l'élément]` (# 243)\n- Ne pas planter sur un texte purement numérique lors de l'utilisation du support de langage bidirectionnel (# 253)\n- Évaluer correctement les instructions conditionnelles avec des caractères spéciaux\n- Correction de la confusion dans le gestionnaire d'onglets lors de la sauvegarde tout en ayant un script d'élément ouvert et modifié\n- Corriger le bug de traduction pour les objets str non-ASCII\n- Corriger un bug unicode où les exceptions avec des images ayant des chemins de caractères spéciaux étaient obscurcies\n\n### Packaging Windows\n\n- Mise à jour des bibliothèques incluses. Voir la sortie `modules()` ci-dessous.\n- Inclut une version légèrement corrigée de PsychoPy 1.80.05 qui traite un problème important avec les horodatages des touches.\n\n~~~\nOpenSesame 2.8.2\nPython 2.7.6 (default, Nov 10 2013, 19:24:18) [MSC v.1500 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 2.4.9\nQProgedit 1.3.2\nExpyriment 0.7.0 (Révision 7a6b73d; Python 2.7.6)\nNumPy 1.8.1\nPIL est disponible (la version est inconnue)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.7\nPyGame 1.9.1release\nPyglet 1.1.4\nPyOpenGL 3.0.2\nPyQt 4.10.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.4\nSciPy 0.13.3\n~~~\n\n[notes de version 2.8.0]: /notes/2.8.0"
  },
  "Release notes for 3.0.4": {
    "fr": "Notes de publication pour 3.0.4"
  },
  "OpenSesame 3.0.4 is the fourth maintenance release in the 3.0 series. It fixes a crucial regression that was introduced in 3.0.3, which caused sketchpad items to ignore the file pool.\n\nIf you are upgrading from OpenSesame 2.9.7 or earlier, please see the list of important changes in OpenSesame 3.0:\n\n- [Important changes in 3.0](/miscellaneous/important-changes-3/)\n\n### Bugs fixed\n\n- Fix a regression where sketchpad items didn't use the file pool.\n\n### Windows packaging\n\n~~~\nOpenSesame 3.0.4\nPython 2.7.10 (default, May 23 2015, 09:40:32) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 3.0.0\nQProgedit 3.2.0\nExpyriment  (Python 2.7.10)\nIPython 3.2.0\nNumPy 1.9.2\nPIL is available (version is unknown)\nPsychoPy 1.82.01\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.6.0a7\nPyglet 1.2.3\nPyOpenGL 3.1.0\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.6.2\nSciPy 0.15.1\n~~~\n": {
    "fr": "OpenSesame 3.0.4 est la quatrième version de maintenance de la série 3.0. Il corrige une régression cruciale introduite dans la version 3.0.3, qui provoquait l'ignorance du pool de fichiers par les éléments sketchpad.\n\nSi vous mettez à jour depuis OpenSesame 2.9.7 ou une version antérieure, veuillez consulter la liste des modifications importantes dans OpenSesame 3.0 :\n\n- [Modifications importantes dans la version 3.0](/miscellaneous/important-changes-3/)\n\n### Bugs corrigés\n\n- Correction d'une régression où les éléments sketchpad n'utilisaient pas le pool de fichiers.\n\n### Packaging Windows\n\n~~~\nOpenSesame 3.0.4\nPython 2.7.10 (default, May 23 2015, 09:40:32) [MSC v.1500 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 3.0.0\nQProgedit 3.2.0\nExpyriment  (Python 2.7.10)\nIPython 3.2.0\nNumPy 1.9.2\nPIL est disponible (la version est inconnue)\nPsychoPy 1.82.01\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.6.0a7\nPyglet 1.2.3\nPyOpenGL 3.1.0\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.6.2\nSciPy 0.15.1\n~~~"
  },
  "Mouse tracking": {
    "fr": "Suivi de la souris",
    "de": "Maus-Tracking"
  },
  "Mousetrap is a third-party plugin, and is not maintained by the OpenSesame team.\n{: .alert .alert-info}\n\n## About\n\nPascal Kieslich and Felix Henninger have developed the [mousetrap plugins](https://github.com/PascalKieslich/mousetrap-os) for OpenSesame [(Kieslich & Henninger, 2017)](https://dx.doi.org/10.3758/s13428-017-0900-z). These plugins allow you to track the movement of the mouse cursor, which has been used to investigate the time course of cognitive processes in many psychological domains [(Freeman, Dale, & Farmer, 2011)](https://dx.doi.org/10.3389/fpsyg.2011.00059).\n\nMousetrap offers two plugins for mouse tracking in OpenSesame that can be included in the experiment via drag-and-drop.\nThe [mousetrap response plugin](https://github.com/PascalKieslich/mousetrap-os/blob/master/plugins/mousetrap_response/mousetrap_response.md) tracks mouse movements while another stimulus (e.g., a sketchpad) is shown, analogous to a keyboard or mouse response item.\nThe [mousetrap form plugin](https://github.com/PascalKieslich/mousetrap-os/blob/master/plugins/mousetrap_form/mousetrap_form.md) allows for tracking of mouse movements in [custom forms](%link:manual/forms/custom%).\nBesides, both plugins also provide Python classes, which can be used in Python inline scripts for maximum customizability.\n\nOnce data have been collected with the plugins, the data can be processed, analyzed and visualized using the [mousetrap R package](http://pascalkieslich.github.io/mousetrap/).\n\n## Installation\n\nInformation about how to install the mousetrap plugin can be found on its [GitHub page](https://github.com/PascalKieslich/mousetrap-os#installation). A number of example experiments that demonstrate the basic features are available in the [examples folder](https://github.com/PascalKieslich/mousetrap-os/tree/master/examples#example-experiments).\n\n\nSee also:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>\n": {
    "fr": "Mousetrap est un plugin tiers et n'est pas maintenu par l'équipe OpenSesame.\n{: .alert .alert-info}\n\n## À propos\n\nPascal Kieslich et Felix Henninger ont développé les [plugins mousetrap](https://github.com/PascalKieslich/mousetrap-os) pour OpenSesame [(Kieslich & Henninger, 2017)](https://dx.doi.org/10.3758/s13428-017-0900-z). Ces plugins permettent de suivre les mouvements du curseur de la souris, ce qui a été utilisé pour étudier le déroulement temporel des processus cognitifs dans de nombreux domaines de la psychologie [(Freeman, Dale, & Farmer, 2011)](https://dx.doi.org/10.3389/fpsyg.2011.00059).\n\nMousetrap propose deux plugins pour le suivi de la souris dans OpenSesame qui peuvent être inclus dans l'expérience par glisser-déposer.\nLe [plugin mousetrap response](https://github.com/PascalKieslich/mousetrap-os/blob/master/plugins/mousetrap_response/mousetrap_response.md) suit les mouvements de la souris pendant qu'un autre stimulus (par exemple, un sketchpad) est affiché, de manière analogue à un élément de réponse au clavier ou à la souris.\nLe [plugin mousetrap form](https://github.com/PascalKieslich/mousetrap-os/blob/master/plugins/mousetrap_form/mousetrap_form.md) permet de suivre les mouvements de la souris dans des [formulaires personnalisés](%link:manual/forms/custom%).\nEn outre, les deux plugins fournissent également des classes Python, qui peuvent être utilisées dans des scripts inline Python pour une personnalisation maximale.\n\nUne fois que les données ont été collectées à l'aide des plugins, elles peuvent être traitées, analysées et visualisées en utilisant le [package mousetrap R](http://pascalkieslich.github.io/mousetrap/).\n\n## Installation\n\nVous trouverez des informations sur la manière d'installer le plugin mousetrap sur sa [page GitHub](https://github.com/PascalKieslich/mousetrap-os#installation). Un certain nombre d'expériences exemples qui démontrent les fonctionnalités de base sont disponibles dans le [dossier exemples](https://github.com/PascalKieslich/mousetrap-os/tree/master/examples#example-experiments).\n\n\nVoir aussi :\n\n- <https://rapunzel.cogsci.nl/manual/environment/>"
  },
  "Examples": {
    "fr": "Exemples"
  },
  "Example experiments are included with OpenSesame. A list of curated examples is available through Menu → Tools → Example experiments. You can also search for publicly available experiments on the OpenScienceFramework by using 'osexp' as search term.\n\n- <https://osf.io/search/?q=osexp>\n": {
    "fr": "Des exemples d'expériences sont inclus avec OpenSesame. Une liste d'exemples sélectionnés est disponible via Menu → Outils → Expériences exemples. Vous pouvez également rechercher des expériences publiques disponibles sur OpenScienceFramework en utilisant 'osexp' comme terme de recherche.\n\n- <https://osf.io/search/?q=osexp>"
  },
  "Runtime for Android": {
    "fr": "Durée d'exécution pour Android"
  },
  "\n__Important note:__ The OpenSesame runtime for Android is based on software by others that is no longer developed. As a result, we are unable to make sure that the runtime works with recent versions of Android. Windows 10 tablets with Intel processors are a good alternative.\n{: .alert .alert-warning}\n\n\n<notranslate>[TOC]</notranslate>\n\n\n## OpenSesame runtime for Android\n\n### Download\n\nYou can download the OpenSesame runtime for Android through the Google Play Store:\n\n<a href=\"https://play.google.com/store/apps/details?id=nl.cogsci.opensesame\" style=\"border:none;\">\n  <img alt=\"Get it on Google Play\"\n       src=\"https://developer.android.com/images/brand/en_generic_rgb_wo_45.png\" />\n</a>\n\n### Usage\n\nWhen you start the OpenSesame runtime, you will be asked where your experiments are located. By default, OpenSesame assumes that they are in the `/sdcard/` folder, or (if it exists) in the `/sdcard/Experiments/` folder. If you have no experiments on your device, pressing `enter` will show the example experiments that are bundled with the `.apk`.\n\nThe `Back` button serves the same purpose as the `Escape` key on regular systems, and will exit OpenSesame.\n\n### Supported devices\n\nOpenSesame is developed with the Nexus 4 and 9 as reference devices. In general, any device that runs Android 2.2. 'Froyo' or later appears to work.\n\n### Disabling automatic updates\n\nIf you are using the OpenSesame runtime for Android in a production environment (e.g., while you are running an experiment), it is recommended to disable the Auto-update feature of the Google Play Store, at least for OpenSesame. This will prevent the app from being updated and potentially changing its behavior. In case you need to downgrade to a previous version of the Android runtime, you can find the `.apk` files for previous releases [here](https://github.com/smathot/OpenSesame/releases).\n\n### Automatically start an experiment\n\nIf you want to directly launch a specific experiment when the OpenSesame runtime for Android is started, you can create a file called `opensesame-autorun.yml` in the `/sdcard/` folder of your device. This is a YAML file with the following structure:\n\n~~~\nexperiment: /sdcard/experiments/my_experiment.opensesame\nsubject_nr: 3\nlogfile: /sdcard/data/subject03.csv\n~~~\n\n## Developing experiments for Android\n\n### backend\n\nThe OpenSesame runtime for Android requires the *droid* backend.\n\n### Design tips\n\nImplement most user interactions through the MOUSE_RESPONSE item or TOUCH_RESPONSE plugin. In general, screen touches are registered as mouse clicks. Using keyboard input will work as well, but it will show and hide the virtual keyboard after every key that is entered, which looks messy.\n\nThe resolution for the DROID backend is fixed at 1280x800 (landscape). On Android, your experiment will be automatically scaled up or down depending on the resolution of the device, but the resolution that you design with is always 1280x800.\n\n### Debugging\n\nDebug output is written to `/sdcard/opensesame-debug.txt`.\n\n### Limitations\n\n- The SYNTH item and `openexp.synth` module are not functional.\n- The SAMPLER item and `openexp.sampler` module will ignore panning and pitching.\n\n## Know issue: Frozen or misbehaving virtual keyboard\n\nOn some devices, the default virtual keyboard is unresponsive (i.e. it shows but doesn't respond to taps) or doesn't respond normally. This appears to happen on phones with recent versions of Android. To work around this issue, you can install a third-party keyboard. Keyboards that have been reported to work are:\n\n- [GO Keyboard](https://play.google.com/store/apps/details?id=com.jb.emoji.gokeyboard&hl=en)\n- [Smart Keyboard Trial](https://play.google.com/store/apps/details?id=net.cdeguet.smartkeyboardtrial&hl=en)\n\n## Available Python modules\n\nBelow is a list of Python modules that should be available in the OpenSesame runtime for android. (This list is copied from the pgs4a now-defunct website.)": {
    "fr": "__Note importante :__ Le temps d'exécution d'OpenSesame pour Android est basé sur des logiciels développés par d'autres qui ne sont plus en développement. En conséquence, nous ne pouvons pas garantir que le temps d'exécution fonctionne avec les versions récentes d'Android. Les tablettes Windows 10 avec processeurs Intel sont une bonne alternative.\n{: .alert .alert-warning}\n\n<notranslate>[TOC]</notranslate>\n\n## Temps d'exécution d'OpenSesame pour Android\n\n### Téléchargement\n\nVous pouvez télécharger le temps d'exécution d'OpenSesame pour Android via le Google Play Store :\n\n<a href=\"https://play.google.com/store/apps/details?id=nl.cogsci.opensesame\" style=\"border:none;\">\n  <img alt=\"Get it on Google Play\"\n       src=\"https://developer.android.com/images/brand/en_generic_rgb_wo_45.png\" />\n</a>\n\n### Utilisation\n\nLorsque vous démarrez le temps d'exécution d'OpenSesame, on vous demandera où se trouvent vos expériences. Par défaut, OpenSesame suppose qu'elles se trouvent dans le dossier `/sdcard/` ou (s'il existe) dans le dossier `/sdcard/Experiments/`. Si vous n'avez pas d'expériences sur votre appareil, appuyer sur `entrée` affichera les expériences exemples incluses dans le fichier `.apk`.\n\nLe bouton `Retour` sert de touche `Échap` sur les systèmes classiques et permet de quitter OpenSesame.\n\n### Appareils pris en charge\n\nOpenSesame est développé avec les Nexus 4 et 9 comme appareils de référence. En général, tout appareil fonctionnant avec Android 2.2 \"Froyo\" ou ultérieur semble fonctionner.\n\n### Désactivation des mises à jour automatiques\n\nSi vous utilisez le temps d'exécution d'OpenSesame pour Android dans un environnement de production (par exemple, pendant que vous réalisez une expérience), il est recommandé de désactiver la fonction de mise à jour automatique du Google Play Store, au moins pour OpenSesame. Cela évitera que l'application soit mise à jour et change potentiellement son comportement. Si vous avez besoin de revenir à une version précédente du temps d'exécution Android, vous pouvez trouver les fichiers `.apk` des versions précédentes [ici](https://github.com/smathot/OpenSesame/releases).\n\n### Démarrage automatique d'une expérience\n\nSi vous souhaitez lancer directement une expérience spécifique au démarrage du temps d'exécution d'OpenSesame pour Android, vous pouvez créer un fichier appelé `opensesame-autorun.yml` dans le dossier `/sdcard/` de votre appareil. Il s'agit d'un fichier YAML avec la structure suivante :\n\n~~~\nexperiment: /sdcard/experiments/my_experiment.opensesame\nsubject_nr: 3\nlogfile: /sdcard/data/subject03.csv\n~~~\n\n## Développement d'expériences pour Android\n\n### Backend\n\nLe temps d'exécution d'OpenSesame pour Android nécessite le backend *droid*.\n\n### Conseils de conception\n\nMettez en œuvre la plupart des interactions utilisateur grâce à l'élément MOUSE_RESPONSE ou au plugin TOUCH_RESPONSE. En général, les actions sur l'écran sont enregistrées comme des clics de souris. L'utilisation de l'entrée au clavier fonctionnera également, mais cela affichera et masquera le clavier virtuel après chaque touche saisie, ce qui semble désordonné.\n\nLa résolution pour le backend DROID est fixée à 1280x800 (paysage). Sur Android, votre expérience sera automatiquement mise à l'échelle en fonction de la résolution de l'appareil, mais la résolution que vous concevez est toujours de 1280x800.\n\n### Débogage\n\nLa sortie de débogage est écrite dans `/sdcard/opensesame-debug.txt`.\n\n### Limitations\n\n- L'élément SYNTH et le module `openexp.synth` ne sont pas fonctionnels.\n- L'élément SAMPLER et le module `openexp.sampler` ignoreront les panoramiques et les hauteurs.\n\n## Problème connu : Clavier virtuel gelé ou défaillant\n\nSur certains appareils, le clavier virtuel par défaut ne répond pas (c'est-à-dire qu'il s'affiche mais ne répond pas aux appuis) ou ne répond pas normalement. Cela semble se produire sur les téléphones avec des versions récentes d'Android. Pour contourner ce problème, vous pouvez installer un clavier tiers. Les claviers qui ont été signalés comme fonctionnant sont :\n\n- [GO Keyboard](https://play.google.com/store/apps/details?id=com.jb.emoji.gokeyboard&hl=fr)\n- [Smart Keyboard Trial](https://play.google.com/store/apps/details?id=net.cdeguet.smartkeyboardtrial&hl=fr)\n\n## Modules Python disponibles\n\nVoici une liste des modules Python qui devraient être disponibles dans le temps d'exécution d'OpenSesame pour Android. (Cette liste est copiée depuis le site Web maintenant obsolète de pgs4a.)"
  },
  "~~~\npygame\npygame.base\npygame.bufferproxy\npygame.colordict\npygame.color\npygame.compat\npygame.constants\npygame.cursors\npygame.display\npygame.draw\npygame.event\npygame.fastevent\npygame.font\npygame.gfxdraw\npygame.imageext\npygame.image\npygame.joystick\npygame.key\npygame.locals\npygame.mask\npygame.mouse\npygame.overlay\npygame.rect\npygame.rwobject\npygame.sprite\npygame.surface\npygame.surflock\npygame.sysfont\npygame.time\npygame.transform\npygame.version\n_abcoll\nabc\naliases\narray\nast\natexit\nbase64\nbisect\nbinascii\ncalendar\ncmath\ncodecs\ncollections\ncompileall\ncontextlib\ncopy\ncopy_reg\ncStringIO\ncPickle\ndatetime\ndifflib\ndis\ndummy_threading\ndummy_thread\nencodings\nencodings.raw_unicode_escape\nencodings.utf_8\nencodings.zlib_codec\nerrno\nfcntl\nfnmatch\nfunctools\n__future__\ngenericpath\ngetopt\nglob\ngzip\nhashlib\nheapq\nhttplib\ninspect\nitertools\nkeyword\nlinecache\nmath\nmd5\nmimetools\nopcode\noptparse\nos\noperator\nparser\npickle\nplatform\nposix\nposixpath\npprint\npy_compile\npwd\nQueue\nrandom\nrepr\nre\nrfc822\nselect\nsets\nshlex\nshutil\nsite\nsocket\nsre_compile\nsre_constants\nsre_parse\nssl\nstat\nStringIO\nstring\nstruct\nsubprocess\nsymbol\nsymtable\nstrop\ntarfile\ntempfile\ntextwrap\n_threading_local\nthreading\ntime\ntokenize\ntoken\ntraceback\ntypes\nurllib\nurllib2\nurlparse\nUserDict\nwarnings\nweakref\nwebbrowser\nzipfile\nzipimport\nzlib\n~~~\n\n[google-play]: https://play.google.com/store/apps/details?id=nl.cogsci.opensesame\n[forum]: http://forum.cogsci.nl/index.php?p=/discussion/333/a-video-of-opensesame-running-natively-on-android\n[droid]: /backends/droid\n[pgs4a]: http://pygame.renpy.org/\n": {
    "fr": "~~~\npygame\npygame.base\npygame.bufferproxy\npygame.colordict\npygame.color\npygame.compat\npygame.constants\npygame.cursors\npygame.display\npygame.draw\npygame.event\npygame.fastevent\npygame.font\npygame.gfxdraw\npygame.imageext\npygame.image\npygame.joystick\npygame.key\npygame.locals\npygame.mask\npygame.mouse\npygame.overlay\npygame.rect\npygame.rwobject\npygame.sprite\npygame.surface\npygame.surflock\npygame.sysfont\npygame.time\npygame.transform\npygame.version\n_abcoll\nabc\naliases\narray\nast\natexit\nbase64\nbisect\nbinascii\ncalendrier\ncmath\ncodecs\ncollections\ncompileall\ncontextlib\ncopie\ncopy_reg\ncStringIO\ncPickle\ndatetime\ndifflib\ndis\ndummy_threading\ndummy_thread\nencodings\nencodings.raw_unicode_escape\nencodings.utf_8\nencodings.zlib_codec\nerrno\nfcntl\nfnmatch\nfunctools\n__future__\ngenericpath\ngetopt\nglob\ngzip\nhashlib\nheapq\nhttplib\ninspect\nitertools\nmot-clé\nlinecache\nmath\nmd5\nmimetools\nopcode\noptparse\nos\nopérateur\nparser\npickle\nplate-forme\nposix\nposixpath\npprint\npy_compile\npwd\nQueue\naléatoire\nrepr\nre\nrfc822\nsélectionner\nsets\nshlex\nshutil\nsite\nsocket\nsre_compile\nsre_constants\nsre_parse\nssl\nstat\nStringIO\nchaîne\nstruct\nsubprocess\nsymbole\nsymtable\nstrop\ntarfile\ntempfile\ntextwrap\n_threading_local\nthreading\ntemps\ntokenize\ntoken\ntraceback\ntypes\nurllib\nurllib2\nurlparse\nUserDict\navertissements\nweakref\nnavigateur Web\nzipfile\nzipimport\nzlib\n~~~\n\n[google-play]: https://play.google.com/store/apps/details?id=nl.cogsci.opensesame\n[forum]: http://forum.cogsci.nl/index.php?p=/discussion/333/a-video-of-opensesame-running-natively-on-android\n[droid]: /backends/droid\n[pgs4a]: http://pygame.renpy.org/"
  },
  "OpenSesame script": {
    "fr": "Script OpenSesame"
  },
  "<notranslate>[TOC]</notranslate>\n\n## About OpenSesame script\n\nOpenSesame script is a simple definitional language that defines an experiment. It is not a full fledged programming language, and does not include features such a `for` loops. The OpenSesame script is interpreted by an OpenSesame runtime environment.\n\nOpenSesame script is different from the Python scripts that are used in inline_script items. Python is a real programming language with all the flexibility and complexities that this entails. In contrast, OpenSesame script is used to define experiments in a simple, human-readable way.\n\n## General remarks\n\n### Keywords\n\nSome items, such as form_base and sketchpad accept keywords. Keywords are of the form `keyword=value`. Keywords are optional and should fall back to a default value.\n\n### Comments\n\nStrings preceded by a hash should be interpreted as comments.\n\n*Example*\n\n\t# This is a comment\n\n### Quotation\n\nQuotation is not necessary, except around strings that contain spaces or other forms of punctuation. So the following lines should be interpreted as identical:\n\n\tset my_var 'my_value'\n\tset my_var \"my_value\"\n\tset my_var my_value\n\nHowever, the following lines are not. In fact, the first line is not valid, because it has an unexpected third parameter.\n\n\tset my_var my value\n\tset my_var \"my value\"\n\n### Types\n\nThere are no types. No distinction is made between strings, integers, etc.\n\n### Item-specific syntax\n\nSome items have a specific syntax. This is indicated in the “Applies to” section for each of the keywords discussed below.\n\n### Resolving path names\n\nTODO\n\n## *define* statement\n\nStarts the definition of an item. After a define statement, all lines are indented by a single tab. The end of the item definition is the first string that is no longer indented. Nested define statements are not allowed.\n\n*Applies to*\n\nAll items\n\n*Format*\n\n\tdefine [item name] [item type]\n\t\t[item definition]\n\n*Parameters*\n\n|`item name`\t|the name of the item\t|\n|`item type`\t|the type of the item\t|\n\n*Example*\n\n\tdefine get_key keyboard_response\n\t\tset allowed_responses \"a;x\"\n\t\tset description \"Collects keyboard responses\"\n\t\tset timeout \"infinite\"\n\t\tset flush \"yes\"\n\n## *draw* statement\n\nDefines a visual element of a sketchpad or feedback item.\n\n*Applies to*\n\nsketchpad, feedback\n\n*Format*\n\nThe format depends on the element.\n\n\tdraw ellipse [left] [top] [width] [height] [keywords]\n\tdraw circle [x] [y] [radius] [keywords]\n\tdraw line [left] [right] [top] [bottom] [keywords]\n\tdraw arrow [left] [right] [top] [bottom] [keywords]\n\tdraw textline [x] [y] [text]\n\tdraw image [x] [y] [path]\n\tdraw gabor [x] [y]\n\tdraw noise [x] [y]\n\tdraw fixdot [x] [y]\n\n*Parameters*\n\n|`left` \t\t|the left-most x-coordinate\t\t|\n|`right`\t\t|the right-most x-coordinate\t|\n|`top`\t\t\t|the top y-coordinate\t\t\t|\n|`bottom`\t\t|the bottom y-coordinate\t\t|\n|`x` \t\t\t|the x-coordinate\t\t\t\t|\n|`y`\t\t\t|the y-coordinate\t\t\t\t|\n|`text` \t\t|text string\t\t\t\t\t|\n|`path` \t\t|the path to an image file\t\t|\n\n*Keywords*\n\nTODO\n\n*Example*\n\n\tdraw fixdot 0 0\n\n## *log* statement\n\nIndicates that a variable should be written to the log-file.\n\n*Applies to*\n\nlogger\n\n*Format*\n\n\tlog [variable name]\n\n*Parameters*\n\n|`variable name`\t\t|the name of a variable\t|\n\n*Example*\n\n\tlog response_time\n\n## *run* statement\n\nIndicates that an item should be run. In the case of the sequence, the order of the run statements determines the order in which items are called. In the case of the coroutines plugin all items are called at the same time.\n\n*Applies to*\n\nsequence\n\n*Format*\n\n\trun [item name] [optional: condition] [optional: disabled]\n\n*Parameters*\n\n|`item name`\t\t\t|the name of the item to run\t|\n|`condition` (optional)\t|the conditional statement, which determines the item is actually called. If no condition is provided, the item is always called.|\n\n*Example*\n\n\trun correct_feedback '[correct] = 1'\n\n## *set* statement\n\nDefines single-line variables.\n\n*Applies to*\n\nAll items\n\n*Format*\n\n\tset [variable name] [value]\n\n*Parameters*": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos du script OpenSesame\n\nLe script OpenSesame est un langage définitionnel simple qui définit une expérience. Ce n'est pas un langage de programmation à part entière et ne comprend pas de fonctionnalités telles que les boucles `for`. Le script OpenSesame est interprété par un environnement d'exécution OpenSesame.\n\nLe script OpenSesame est différent des scripts Python utilisés dans les éléments inline_script. Python est un véritable langage de programmation avec toute la flexibilité et les complexités que cela implique. En revanche, le script OpenSesame est utilisé pour définir des expériences de manière simple et lisible.\n\n## Remarques générales\n\n### Mots-clés\n\nCertains éléments, tels que form_base et sketchpad, acceptent des mots-clés. Les mots-clés sont de la forme `mot-clé=valeur`. Les mots-clés sont facultatifs et doivent revenir à une valeur par défaut.\n\n### Commentaires\n\nLes chaînes précédées d'un dièse doivent être interprétées comme des commentaires.\n\n*Exemple*\n\n\t# Ceci est un commentaire\n\n### Citation\n\nLa citation n'est pas nécessaire, sauf autour des chaînes contenant des espaces ou d'autres formes de ponctuation. Ainsi, les lignes suivantes doivent être interprétées comme identiques :\n\n\tset my_var 'my_value'\n\tset my_var \"my_value\"\n\tset my_var my_value\n\nCependant, les lignes suivantes ne le sont pas. En fait, la première ligne n'est pas valide, car elle a un troisième paramètre inattendu.\n\n\tset my_var my value\n\tset my_var \"my value\"\n\n### Types\n\nIl n'y a pas de types. Aucune distinction n'est faite entre les chaînes, les entiers, etc.\n\n### Syntaxe spécifique aux éléments\n\nCertains éléments ont une syntaxe spécifique. Ceci est indiqué dans la section \"S'applique à\" pour chacun des mots-clés discutés ci-dessous.\n\n### Résolution des noms de chemin\n\nTODO\n\n## Instruction *define*\n\nCommence la définition d'un élément. Après une instruction define, toutes les lignes sont indentées par une seule tabulation. La fin de la définition de l'élément est la première chaîne qui n'est plus indentée. Les instructions define imbriquées ne sont pas autorisées.\n\n*S'applique à*\n\nTous les éléments\n\n*Format*\n\n\tdefine [nom de l'élément] [type d'élément]\n\t\t[définition de l'élément]\n\n*Paramètres*\n\n|`nom de l'élément`\t| le nom de l'élément\t|\n|`type d'élément`\t| le type de l'élément\t|\n\n*Exemple*\n\n\tdefine get_key keyboard_response\n\t\tset allowed_responses \"a;x\"\n\t\tset description \"Collecte les réponses au clavier\"\n\t\tset timeout \"infini\"\n\t\tset flush \"oui\"\n\n## Instruction *draw*\n\nDéfinit un élément visuel d'un élément sketchpad ou feedback.\n\n*S'applique à*\n\nsketchpad, feedback\n\n*Format*\n\nLe format dépend de l'élément.\n\n\tdraw ellipse [gauche] [haut] [largeur] [hauteur] [mots-clés]\n\tdraw circle [x] [y] [rayon] [mots-clés]\n\tdraw line [gauche] [droite] [haut] [bas] [mots-clés]\n\tdraw arrow [gauche] [droite] [haut] [bas] [mots-clés]\n\tdraw textline [x] [y] [texte]\n\tdraw image [x] [y] [chemin]\n\tdraw gabor [x] [y]\n\tdraw noise [x] [y]\n\tdraw fixdot [x] [y]\n\n*Paramètres*\n\n|`gauche` \t\t|la coordonnée x la plus à gauche\t\t|\n|`droite`\t\t|la coordonnée x la plus à droite\t|\n|`haut`\t\t\t|la coordonnée y la plus haute\t\t\t|\n|`bas`\t\t\t|la coordonnée y la plus basse\t\t\t|\n|`x` \t\t\t|la coordonnée x\t\t\t\t\t\t|\n|`y`\t\t\t|la coordonnée y\t\t\t\t\t\t|\n|`texte` \t\t|chaîne de texte\t\t\t\t\t\t|\n|`chemin` \t\t|le chemin vers un fichier image\t\t|\n\n*Mots-clés*\n\nTODO\n\n*Exemple*\n\n\tdraw fixdot 0 0\n\n## Instruction *log*\n\nIndique qu'une variable doit être écrite dans le fichier de journal.\n\n*S'applique à*\n\nlogger\n\n*Format*\n\n\tlog [nom de la variable]\n\n*Paramètres*\n\n|`nom de la variable`\t\t| le nom d'une variable\t|\n\n*Exemple*\n\n\tlog response_time\n\n## Instruction *run*\n\nIndique qu'un élément doit être exécuté. Dans le cas de la séquence, l'ordre des instructions run détermine l'ordre dans lequel les éléments sont appelés. Dans le cas du plugin coroutines, tous les éléments sont appelés en même temps.\n\n*S'applique à*\n\nséquence\n\n*Format*\n\n\trun [nom de l'élément] [optionnel : condition] [optionnel : désactivé]\n\n*Paramètres*\n\n|`nom de l'élément`\t\t\t| le nom de l'élément à exécuter\t|\n|`condition` (facultatif)\t| l'instruction conditionnelle, qui détermine si l'élément est effectivement appelé. Si aucune condition n'est fournie, l'élément est toujours appelé.|\n\n*Exemple*\n\n\trun correct_feedback '[correct] = 1'\n\n## Instruction *set*\n\nDéfinit des variables monolignes.\n\n*S'applique à*\n\nTous les éléments\n\n*Format*\n\n\tset [nom de la variable] [valeur]\n\n*Paramètres*"
  },
  "|`variable name`\t|the variable name\t|\n|`value`\t\t\t|the variable value\t|\n\n*Example*\n\n\tset timeout 1000\n\n*Notes*\n\nMulti-line variables are defined using the `__[variable name]__` notation. This is mostly useful for items that require large blocks of text. Within an item definition, each line is preceded by a single tab, which should not be interpreted as part of the text. `__end__` indicates the end of the variable.\n\n*For example:*\n\n\t__my_variable__\n\tThis is the first line.\n\tThis is the second line.\n\t__end__\n\n## *setcycle* statement\n\nSimilar to the regular “set” statement, but sets a variable only during a specific cycle of a loop. This is the script equivalent of the loop table.\n\n*Applies to*\n\nLoop\n\n*Format*\n\n\tsetcycle [cycle #] [variable name] [variable value]\n\n*Parameters*\n\n|`Cycle #`\t\t\t|the number of the cycle, where 0 is the first\t|\n|`variable name` \t|the variable name\t\t\t\t\t\t\t\t|\n|`value`\t\t\t|the variable value\t\t\t\t\t\t\t\t|\n\n*Example*\n\n\tsetcycle 0 cue valid\n\n## *widget* statement\n\nAdds a widget (buttons, labels, etc.) to a form. Valid keywords depend on the type of widget. The widget statement is not strictly part of the core OpenSesame syntax, but is used by the form_base plugin.\n\n*Applies to*\n\nform_base (plugin)\n\n*Format*\n\n\twidget [column] [row] [column span] [row span] [widget type] [keywords]\n\n*Parameters*\n\n|`column`\t\t|the widget's column position in the form, where 0 is left-most\t\t\t\t\t\t\t\t|\n|`row`\t\t\t|the widget's row position in the form, where 0 is top\t\t\t\t\t\t\t\t\t\t|\n|`column span`\t|the number of columns that the widget occupies\t\t\t\t\t\t\t\t\t\t\t\t|\n|`row span`\t\t|the number of rows that the widget occupies\t\t\t\t\t\t\t\t\t\t\t\t|\n|`widget type`\t|'button', 'checkbox', 'image', 'image_button', 'label', 'rating_scale', or 'text_input'\t|\n\n*Keywords*\n\nTODO\n\n*Example*\n\n\twidget 0 0 1 1 label text='This is a label'\n": {
    "fr": "|`nom de variable`\t|le nom de la variable\t|\r\n|`valeur`\t\t\t|la valeur de la variable\t|\r\n\r\n*Exemple*\r\n\r\n\tdéfinir le délai d'attente 1000\r\n\r\n*Notes*\r\n\r\nLes variables multilignes sont définies en utilisant la notation `__[nom de variable]__`. Ceci est principalement utile pour les éléments qui nécessitent de grands blocs de texte. Dans une définition d'élément, chaque ligne est précédée d'une seule tabulation, qui ne doit pas être interprétée comme faisant partie du texte. `__end__` indique la fin de la variable.\r\n\r\n*Par exemple :*\r\n\r\n\t__ma_variable__\r\n\tCeci est la première ligne.\r\n\tCeci est la deuxième ligne.\r\n\t__end__\r\n\r\n## *setcycle* instruction\r\n\r\nSimilaire à l'instruction \"set\" régulière, mais définit une variable uniquement pendant un cycle spécifique d'une boucle. Il s'agit de l'équivalent en script du tableau de boucle.\r\n\r\n*S'applique à*\r\n\r\nBoucle\r\n\r\n*Format*\r\n\r\n\tsetcycle [numéro de cycle] [nom de variable] [valeur de variable]\r\n\r\n*Paramètres*\r\n\r\n|`Numéro de cycle`|le numéro du cycle, où 0 est le premier\t|\r\n|`nom de variable` |le nom de la variable\t\t\t\t\t\t\t|\r\n|`valeur`\t\t\t|la valeur de la variable\t\t\t\t\t\t\t|\r\n\r\n*Exemple*\r\n\r\n\tsetcycle 0 repère valide\r\n\r\n## *widget* instruction\r\n\r\nAjoute un widget (boutons, étiquettes, etc.) à un formulaire. Les mots-clés valides dépendent du type de widget. L'instruction widget ne fait pas strictement partie de la syntaxe de base d'OpenSesame, mais est utilisée par le plugin form_base.\r\n\r\n*S'applique à*\r\n\r\nform_base (plugin)\r\n\r\n*Format*\r\n\r\n\twidget [colonne] [rangée] [étendue de colonne] [étendue de rangée] [type de widget] [mots-clés]\r\n\r\n*Paramètres*\r\n\r\n|`colonne`\t\t|la position de la colonne du widget dans le formulaire, où 0 est le plus à gauche\t\t\t\t\t\t\t\t|\r\n|`rangée`\t\t|la position de la rangée du widget dans le formulaire, où 0 est le sommet\t\t\t\t\t\t\t\t\t\t|\r\n|`étendue de colonne`|le nombre de colonnes occupées par le widget\t\t\t\t\t\t\t\t\t\t\t\t|\r\n|`étendue de rangée`\t|le nombre de rangées occupées par le widget\t\t\t\t\t\t\t\t\t\t\t\t|\r\n|`type de widget`\t\t|'button', 'checkbox', 'image', 'image_button', 'label', 'rating_scale', or 'text_input'\t|\r\n\r\n*Mots-clés*\r\n\r\nTODO\r\n\r\n*Exemple*\r\n\r\n\twidget 0 0 1 1 label text='Ceci est une étiquette'"
  },
  "Integration with the Open Science Framework": {
    "fr": "Intégration avec le Open Science Framework"
  },
  "<notranslate>[TOC]</notranslate>\n\n## About\n\nThe OpenScienceFramework extension connects OpenSesame to the [Open Science Framework](https://osf.io) (OSF), which is a web platform for sharing, connecting, and streamlining scientific workflows. To use this extension, [you need an OSF account](https://osf.io/login/?sign_up=True).\n\nWith the OpenScienceFramework extension, you can:\n\n- Automatically save your experiment to the OSF\n- Automatically upload data to the OSF\n- Open experiments from the OSF\n- Share your experiment and data with other researchers, by giving them access through the OSF\n\n## Logging in to the OSF\n\nTo log into the OSF:\n\n- Create an account on <https://osf.io>. (You cannot create an account from within OpenSesame.)\n- In OpenSesame, click on the log-in button in the main toolbar, and enter your credentials.\n- Once logged in, you can open the OSF Explorer by clicking on your name where the login button used to be, and selecting *Show explorer*. The explorer will show an overview of all your OSF projects, and all repositories/ cloud services that are linked to your projects.\n\n## Linking an experiment to the OSF\n\nIf you link an experiment to the OSF, each time that you save the experiment in OpenSesame, a new version is also uploaded to the OSF.\n\nTo link an experiment:\n\n- Save the experiment on your computer.\n- Open the OSF explorer and select a folder or repository where you would like your experiment to be stored on the OSF. Right-click on this folder and select *Sync experiment to this folder*. The OSF node to which the experiment is linked will be shown at the top of the explorer.\n- The experiment is then uploaded to the selected location.\n- If you check *Always upload experiment on save*, a new version is automatically saved to OSF on each save; if you don't enable this option, you will be asked every time whether or not you want to do this.\n\nTo unlink an experiment:\n\n- Open the OSF explorer, and click the *Unlink* button next to the *Experiment linked to* link.\n\n## Linking data to the OSF\n\nIf you link data to the OSF, each time that data has been collected (normally after every experimental session), this data is also uploaded to the OSF.\n\nTo link data to the OSF:\n\n- Save the experiment on your computer.\n- Open the OSF explorer, right-click on the folder that you want the data to be uploaded to, and select *Sync data to this folder*. The OSF node that the data is linked to will be shown at the top of the explorer.\n- If you check *Always upload collected data*, data files will be automatically saved to OSF after they have been collected; if you don't enable this option, you will be asked every time whether or not you want to do this.\n\nTo unlink data from the OSF:\n\n- Open the OSF explorer, and click the *Unlink* button next to the *Data stored to* link.\n\n## Opening an experiment stored on the OSF\n\nTo open an experiment from the OSF:\n\n- Open the OSF explorer, and find the experiment.\n- Right-click on the experiment and select *Open experiment*.\n- Save the experiment on your computer.\n\n## Handling non-matching versions\n\nIf you open an experiment on your computer that is linked to the OSF, but differs from the version on the OSF, you will be asked what you want to do:\n\n- Use the version from your computer; or\n- Use the version from the OSF. If you choose to use the version from the OSF, it will be downloaded and overwrite the experiment on your computer.\n\n## Installing the OpenScienceFramework extension\n\nThe OpenScienceFramework extension is installed by default in the Windows package of OpenSesame. If the extension is not installed, you can install it as follows:\n\nFrom PyPi:\n\n~~~\npip install opensesame-extension-osf\n~~~\n\nIn an Anaconda environment\n\n~~~\nconda install -c cogsci opensesame-extension-osf\n~~~\n\nThe source code of the extension is available on GitHub:\n\n- <https://github.com/dschreij/opensesame-extension-osf>\n\nAnd for the `python-qosf` module, which is used by the extension:": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos\n\nL'extension OpenScienceFramework connecte OpenSesame au [Open Science Framework](https://osf.io) (OSF), qui est une plateforme web pour partager, connecter et rationaliser les flux de travail scientifiques. Pour utiliser cette extension, [vous devez avoir un compte OSF](https://osf.io/login/?sign_up=True).\n\nAvec l'extension OpenScienceFramework, vous pouvez :\n\n- Enregistrer automatiquement votre expérience sur l'OSF\n- Téléverser automatiquement les données sur l'OSF\n- Ouvrir des expériences depuis l'OSF\n- Partager votre expérience et vos données avec d'autres chercheurs, en leur donnant accès via l'OSF\n\n## Se connecter à l'OSF\n\nPour vous connecter à l'OSF :\n\n- Créez un compte sur <https://osf.io>. (Vous ne pouvez pas créer de compte depuis OpenSesame.)\n- Dans OpenSesame, cliquez sur le bouton de connexion dans la barre d'outils principale et entrez vos informations d'identification.\n- Une fois connecté, vous pouvez ouvrir l'Explorateur OSF en cliquant sur votre nom à l'endroit où se trouvait le bouton de connexion, puis en sélectionnant *Afficher l'explorateur*. L'explorateur affichera un aperçu de tous vos projets OSF et de tous les dépôts/services cloud liés à vos projets.\n\n## Lier une expérience à l'OSF\n\nSi vous liez une expérience à l'OSF, chaque fois que vous enregistrez l'expérience dans OpenSesame, une nouvelle version est également téléversée sur l'OSF.\n\nPour lier une expérience :\n\n- Enregistrez l'expérience sur votre ordinateur.\n- Ouvrez l'explorateur OSF et sélectionnez un dossier ou un dépôt où vous souhaitez que votre expérience soit stockée sur l'OSF. Faites un clic droit sur ce dossier et sélectionnez *Synchroniser l'expérience avec ce dossier*. Le nœud OSF auquel l'expérience est liée sera affiché en haut de l'explorateur.\n- L'expérience est ensuite téléversée à l'emplacement sélectionné.\n- Si vous cochez *Toujours téléverser l'expérience lors de l'enregistrement*, une nouvelle version est automatiquement enregistrée sur l'OSF à chaque enregistrement ; si vous ne cochez pas cette option, on vous demandera à chaque fois si vous souhaitez le faire ou non.\n\nPour dissocier une expérience :\n\n- Ouvrez l'explorateur OSF et cliquez sur le bouton *Dissocier* à côté du lien *Expérience liée à*.\n\n## Lier les données à l'OSF\n\nSi vous liez des données à l'OSF, chaque fois que des données sont collectées (normalement après chaque session expérimentale), ces données sont également téléversées sur l'OSF.\n\nPour lier les données à l'OSF :\n\n- Enregistrez l'expérience sur votre ordinateur.\n- Ouvrez l'explorateur OSF, faites un clic droit sur le dossier où vous souhaitez que les données soient téléversées, puis sélectionnez *Synchroniser les données avec ce dossier*. Le nœud OSF auquel les données sont liées sera affiché en haut de l'explorateur.\n- Si vous cochez *Toujours téléverser les données collectées*, les fichiers de données seront automatiquement enregistrés sur l'OSF après leur collecte ; si vous ne cochez pas cette option, on vous demandera à chaque fois si vous souhaitez le faire ou non.\n\nPour dissocier les données de l'OSF :\n\n- Ouvrez l'explorateur OSF et cliquez sur le bouton *Dissocier* à côté du lien *Données stockées dans*.\n\n## Ouvrir une expérience stockée sur l'OSF\n\nPour ouvrir une expérience depuis l'OSF :\n\n- Ouvrez l'explorateur OSF et trouvez l'expérience.\n- Faites un clic droit sur l'expérience et sélectionnez *Ouvrir l'expérience*.\n- Enregistrez l'expérience sur votre ordinateur.\n\n## Gérer les versions non concordantes\n\nSi vous ouvrez une expérience sur votre ordinateur liée à l'OSF, mais qui diffère de la version sur l'OSF, il vous sera demandé ce que vous voulez faire :\n\n- Utiliser la version de votre ordinateur ; ou\n- Utiliser la version de l'OSF. Si vous choisissez d'utiliser la version de l'OSF, elle sera téléchargée et remplacera l'expérience sur votre ordinateur.\n\n## Installer l'extension OpenScienceFramework\n\nL'extension OpenScienceFramework est installée par défaut dans le package Windows d'OpenSesame. Si l'extension n'est pas installée, vous pouvez l'installer de la manière suivante :\n\nDepuis PyPi :\n\n~~~\npip install opensesame-extension-osf\n~~~\n\nDans un environnement Anaconda\n\n~~~\nconda install -c cogsci opensesame-extension-osf\n~~~\n\nLe code source de l'extension est disponible sur GitHub :\n\n- <https://github.com/dschreij/opensesame-extension-osf>\n\nEt pour le module `python-qosf`, qui est utilisé par l'extension :"
  },
  "- <https://github.com/dschreij/python-qosf>\n": {
    "fr": "- <https://github.com/dschreij/python-qosf>"
  },
  "Welcome to the workshop *Introduction to experiment building with OpenSesame* as part of the KLI curriculum.\n\nWhere: University of Groningen\n\nWhen: January 20, 2020\n\nEC: 0.5\n\n\n<notranslate>\nfigure:\n id: FigKLI\n caption: |\n  KLI workshop 2020.\n source: KLI.png\n</notranslate>\n\n\n## Implicit Association Task\n\nThe implicit association task measures the strength of associations between concepts (e.g. young people and old people) and evaluations (e.g. good and bad). The idea is that making a response is easier (and therefore *faster*) when related items share the same response key.\n\nHere, we will measure the association between young and old, and good and bad. We hypothesize that young participants (subconsciously) associate positive words with young faces rather than with old faces.\n\n## Experimental hierarchy\n\nTo test this prediction, participants perform four blocks of trials (%Task)\n\n- __Block 1__ -- Participants categorize *words* as either *POSITIVE* or *NEGATIVE*. The category names appear at the top left and top right side of the screen, and participants press a button with their left or right hand to indicate to which category a centrally presented word belongs\n- __Block 2__ -- Participants categorize *faces* as *OLD* or *YOUNG*, again by making a left- or right-hand resonse\n- __Block 3__ -- Is a combination of block 1 and 2. In this example, the words *POSITVE* and *YOUNG* appear at the top left while the words *NEGATIVE* and *OLD* appear at the top right. Because we assume that (young) participants have a more positive attitude towards young faces, we call this mapping *congruent*\n- __Block 4__ -- Is again a combination of block 1 and 2, but this time the mapping is *incongruent*\n\n<notranslate>\nfigure:\n id: Task\n source: IAT-task.png\n caption: |\n  An overview of the four blocks of the implicit association task.\n</notranslate>\n\n## Prediction\n\nThe prediction is that participants have a preference for young people compared to old people, such that it is easier to categorize words when young and positive share a response key, and old and negative share a response key (as compared to the reverse mapping). This should result in *faster* responses in the congruent than in the incongruent block (%Prediction).\n\n<notranslate>\nfigure:\n id: Prediction\n source: prediction.png\n caption: |\n  We predict that participants find it easier to categorize words and faces if the categories *POSITIVE/YOUNG* and *NEGATIVE/OLD* are combined (as compared to the reverse).\n</notranslate>\n\n\n## Trial sequence\n\nIn order to test this prediction, we're going to create the following trial sequence (%TrialSequence):\n\n- Each trial starts with a __fixation point__ (500 ms)\n- Next, the __two category names__ appear on the upper left and right side of the screen.\n- The to-be-categorized __stimulus__ appears at the center\n- Participants indicate with a __key press__ whether the stimulus belongs to the category on the left or on the right\n- The variables of the current trial are __logged__\n\n<notranslate>\nfigure:\n id: TrialSequence\n source: trial_sequence.png\n caption: |\n  Schematic representation of a typical trial sequence of the (first block of the) IAT.\n</notranslate>\n\n## Launch OpenSesame\n\nWhen you start OpenSesame, you'll see a 'Get started!' tab, which shows you a list of templates as well as recently opened experiments (%GetStarted). To save some time, we'll use the 'Extended template'.\n\n<notranslate>\nfigure:\n id: GetStarted\n source: get-started.png\n caption: |\n  OpenSesame's welcome window. Here, we use the 'Extended template'.\n</notranslate>\n\nAfter opening the extended template, we save our experiment. To do this, click *File* -> *Save* (shortcut: `Ctrl+S`), browse to the appropriate folder and give your experiment a meaningful name.\n\n\n## Overview area\n\nThe *overview area* shows the hierarchical structure of our experiment. To simplify our structure, we start by deleting the practice block. In order to do so:": {
    "fr": "Bienvenue à l'atelier *Introduction à la création d'expériences avec OpenSesame* dans le cadre du programme KLI.\n\nOù : Université de Groningue\n\nQuand : 20 janvier 2020\n\nEC : 0,5\n\n## Tâche d'association implicite\n\nLa tâche d'association implicite mesure la force des associations entre les concepts (par ex., les jeunes et les personnes âgées) et les évaluations (par ex., bon et mauvais). L'idée est que donner une réponse est plus facile (et donc *plus rapide*) lorsque les éléments liés partagent la même touche de réponse.\n\nIci, nous mesurerons l'association entre les jeunes et les vieux, ainsi qu'entre le bien et le mal. Nous supposons que les jeunes participants (inconsciemment) associent des mots positifs aux visages jeunes plutôt qu'aux visages vieux.\n\n## Hiérarchie expérimentale\n\nPour tester cette prédiction, les participants effectuent quatre blocs d'essais (%Task)\n\n- __Bloc 1__ - Les participants classent les *mots* comme étant *POSITIFS* ou *NÉGATIFS*. Les noms des catégories apparaissent en haut à gauche et en haut à droite de l'écran, et les participants appuient sur un bouton avec leur main gauche ou droite pour indiquer à quelle catégorie appartient un mot présenté au centre\n- __Bloc 2__ - Les participants classent les *visages* comme *VIEUX* ou *JEUNES*, encore en faisant une réponse à gauche ou à droite\n- __Bloc 3__ - Est une combinaison des blocs 1 et 2. Dans cet exemple, les mots *POSITIF* et *JEUNE* apparaissent en haut à gauche tandis que les mots *NÉGATIF* et *VIEUX* apparaissent en haut à droite. Parce que nous supposons que les participants (jeunes) ont une attitude plus positive envers les visages jeunes, nous appelons cette correspondance *congruente*\n- __Bloc 4__ - Est à nouveau une combinaison des blocs 1 et 2, mais cette fois la correspondance est *incongruente*\n\n## Prédiction\n\nLa prédiction est que les participants ont une préférence pour les jeunes par rapport aux personnes âgées, de sorte qu'il est plus facile de classer les mots lorsque les jeunes et les positifs partagent une touche de réponse, et les vieux et les négatifs partagent une touche de réponse (par rapport à la correspondance inverse). Cela devrait entraîner des réponses *plus rapides* dans le bloc congruent que dans le bloc incongruent (%Prediction).\n\n## Séquence d'essai\n\nAfin de vérifier cette prédiction, nous allons créer la séquence d'essais suivante (%TrialSequence):\n\n- Chaque essai commence par un __point de fixation__ (500 ms)\n- Ensuite, les __deux noms de catégorie__ apparaissent en haut à gauche et en haut à droite de l'écran.\n- Le __stimulus__ à catégoriser apparaît au centre\n- Les participants indiquent par une __pression sur une touche__ si le stimulus appartient à la catégorie de gauche ou de droite\n- Les variables de l'essai en cours sont __enregistrées__\n\n## Lancement d'OpenSesame\n\nLorsque vous démarrez OpenSesame, vous verrez un onglet \"Get started!\" (Démarrer !), qui vous présente une liste de modèles ainsi que des expériences récemment ouvertes (%GetStarted). Pour gagner du temps, nous utiliserons le \"modèle étendu\".\n\nAprès avoir ouvert le modèle étendu, nous sauvegardons notre expérience. Pour ce faire, cliquez sur *File* -> *Save* (raccourci : `Ctrl+S`), accédez au dossier approprié et donnez un nom significatif à votre expérience.\n\n## Zone de présentation\n\nLa *zone de présentation* montre la structure hiérarchique de notre expérience. Pour simplifier notre structure, nous commençons par supprimer le bloc de pratique. Pour ce faire :"
  },
  "- Right click on the item called *practice loop*\n- Click 'Delete' (shortcut: `Del`)\n- Do the same for the *end_of_practice*' item\n\nThe overview area of your experiment should now look like this:\n\n<notranslate>\nfigure:\n id: Overview\n source: overview.png\n caption: |\n  The overview area of your experiment.\n</notranslate>\n\n## Block 1: word categorization\n\n### Step 1: Modify the block loop\n\nWe start by creating the first block of the IAT (Block 1 in %Task) in which participants have to categorize words as either positive or negative. Because we will create more than one block, the name *block_loop* is not so informative. So we rename it:\n\n- Right click on the *block_loop* item, choose rename (shortcut: `F2`), and call it *words_block_loop*\n\nNext, we want to define the following three variables in the *block_loop item*:\n\n- __stimulus__ -- The to-be-categorized word\n- __category__ -- The category that the word belongs to\n- __correct_response__ -- The response that participants are supposed to give\n\nTo create these variables:\n\n- Open the tab of the *words_block_loop* by clicking on it in the overview area\n- You'll initially see an empty table\n- Double click on the header of the first column (initially called 'empty_column') and call it 'stimulus'\n- Fill the first column with six positive and six negative words, one per row\n- Create a second column with the header 'category' and indicate to which category (*POSITIVE* or *NEGATIVE*) each stimulus belongs\n- Create a third column, call it *correct_response* and indicate the correct response for each stimulus\n- To determine the response rule, let's say that:\n    - The word *POSITIVE* will appear on the left side of the screen, whereas the word *NEGATIVE* will appear on the right side\n    - To indicate that a word belongs to the left side, participants have to press 'e', whereas for the right side, they have to press 'i'.\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- *correct_response* is a built-in variable which allows OpenSesame to keep track of participants' performance, such as 'acc' (for accuracy or percentage correct).\n\n</div>\n\nThe content of your *words_block_loop* should now look something like this:\n\n<notranslate>\nfigure:\n id: Overview\n source: words_block_loop.png\n caption: |\n  The loop table of the first block of the IAT contains the three experimental variables and their values.\n</notranslate>\n\n\n### Step 2: Modify the trial sequence\n\nAs shown in %TrialSequence, on every trial we want to:\n\n1. Show a fixation point\n2. Show the stimulus at the center and the two categories at either upper side of the screen\n3. Collect a keypress response\n4. Safe the variables to the output file\n\nThese four steps are called *events*, and we're going to realize them by using *items* in the *trial sequence*. But first, because the trial sequence will be slightly different for each block of the experiment (see %Task), let's rename it to *words_trial_sequence*.\n\nFor the first two events, we'll use `sketchpad` items. The advanced template already contains one sketchpad item. To append a second one:\n\n- Grab a `sketchpad` item from the *item toolbar*\n- Drag and drop it into the *words_trial_sequence*\n\n<notranslate>\nvideo:\n source: youtube\n id: DragDrop\n videoid: vvJewWTjlts\n width: 640\n height: 360\n caption: |\n  Dragging and dropping items.\n</notranslate>\n\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- To make a given item appear *after* another item, drop it *onto* this other item.\n\n</div>\n\n\n\nBy default, OpenSesame gives its items names such as *sketchpad*, *new_sketchpad* and *new_sketchpad_1*. Because these names are not informative, we rename the items into something more meaningful. To do so:\n\n- Right-click on the item in the overview area (shortcut: `F2`)\n- Choose 'Rename'\n- Respectively call the two `sketchpad` items *fixation* and *word*": {
    "fr": "- Cliquez avec le bouton droit sur l'élément appelé *practice loop*\n- Cliquez sur \"Supprimer\" (raccourci: `Suppr`)\n- Faites de même pour l'élément *end_of_practice*\n\nLa zone d'aperçu de votre expérience devrait maintenant ressembler à ceci :\n\n<notranslate>\nfigure:\n id: Overview\n source: overview.png\n caption: |\n  La zone d'aperçu de votre expérience.\n</notranslate>\n\n## Bloc 1 : catégorisation des mots\n\n### Étape 1 : Modifier la boucle de bloc\n\nNous commençons par créer le premier bloc du TAI (Bloc 1 dans %Task) dans lequel les participants doivent catégoriser les mots comme étant positifs ou négatifs. Comme nous créerons plusieurs blocs, le nom *block_loop* n'est pas très informatif. Nous le renommons donc :\n\n- Cliquez avec le bouton droit sur l'élément *block_loop*, choisissez renommer (raccourci : `F2`) et appelez-le *words_block_loop*\n\nEnsuite, nous voulons définir les trois variables suivantes dans l'élément *block_loop* :\n\n- __stimulus__ -- Le mot à catégoriser\n- __category__ -- La catégorie à laquelle appartient le mot\n- __correct_response__ -- La réponse que les participants sont censés donner\n\nPour créer ces variables :\n\n- Ouvrez l'onglet du *words_block_loop* en cliquant dessus dans la zone d'aperçu\n- Vous verrez initialement un tableau vide\n- Double-cliquez sur l'en-tête de la première colonne (initialement appelée 'empty_column') et appelez-la 'stimulus'\n- Remplissez la première colonne avec six mots positifs et six mots négatifs, un par ligne\n- Créez une deuxième colonne avec l'en-tête 'category' et indiquez à quelle catégorie (*POSITIVE* ou *NEGATIVE*) chaque stimulus appartient\n- Créez une troisième colonne, appelez-la *correct_response* et indiquez la réponse correcte pour chaque stimulus\n- Pour déterminer la règle de réponse, disons que :\n    - Le mot *POSITIVE* apparaîtra sur le côté gauche de l'écran, tandis que le mot *NEGATIVE* apparaîtra sur le côté droit\n    - Pour indiquer qu'un mot appartient au côté gauche, les participants doivent appuyer sur 'e', tandis que pour le côté droit, ils doivent appuyer sur 'i'.\n    \n<div class='info-box' markdown='1'>\n\n__Astuce__ -- *correct_response* est une variable intégrée qui permet à OpenSesame de suivre la performance des participants, telle que 'acc' (pour l'exactitude ou le pourcentage correct).\n\n</div>\n\nLe contenu de votre *words_block_loop* devrait maintenant ressembler à ceci :\n\n<notranslate>\nfigure:\n id: Overview\n source: words_block_loop.png\n caption: |\n  Le tableau de boucle du premier bloc du TAI contient les trois variables expérimentales et leurs valeurs.\n</notranslate>\n\n### Étape 2 : Modifier la séquence d'essai\n\nComme indiqué dans %TrialSequence, lors de chaque essai, nous voulons :\n\n1. Afficher un point de fixation\n2. Afficher le stimulus au centre et les deux catégories sur chaque côté supérieur de l'écran\n3. Recueillir une réponse par pression de touche\n4. Enregistrer les variables dans le fichier de sortie\n\nCes quatre étapes sont appelées *événements*, et nous allons les réaliser en utilisant des *éléments* dans la *séquence d'essai*. Mais d'abord, comme la séquence d'essai sera légèrement différente pour chaque bloc de l'expérience (voir %Task), renommons-la en *words_trial_sequence*.\n\nPour les deux premiers événements, nous utiliserons des objets `sketchpad`. Le modèle avancé contient déjà un objet sketchpad. Pour en ajouter un deuxième :\n\n- Prenez un élément `sketchpad` dans la *barre d'outils des éléments*\n- Faites-le glisser et déposez-le dans la *words_trial_sequence*\n\n<notranslate>\nvideo:\n source: youtube\n id: DragDrop\n videoid: vvJewWTjlts\n width: 640\n height: 360\n caption: |\n  Faire glisser et déposer les éléments.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Astuce__ -- Pour faire apparaître un élément *après* un autre élément, déposez-le *sur* cet autre élément.\n\n</div>\n\nPar défaut, OpenSesame donne à ses éléments des noms tels que *sketchpad*, *new_sketchpad* et *new_sketchpad_1*. Comme ces noms ne sont pas informatifs, nous renommons les éléments en quelque chose de plus significatif. Pour ce faire :\n\n- Faites un clic droit sur l'élément dans la zone d'aperçu (raccourci : `F2`)\n- Choisissez \"Renommer\"\n- Appelez respectivement les deux éléments `sketchpad` *fixation* et *word*"
  },
  "The two last events of the trial sequence (collecting the response and saving the data) are already represented by the `keyboard_response` item and the `logger` item, respectively.\n\nYour overview area should now look like this:\n\n\n\n<notranslate>\nfigure:\n id: OverviewWordBlock\n source: overview_words_block.png\n caption: |\n  New overview of (the first part of) the experiment.\n</notranslate>\n\n\n### Step 3: Modify the items in the trial sequence\n\n#### Fixation\n\nThe next step is to add content to the items in the trial sequence. We start with the `sketchpad` that represents the fixation point at the beginning of each trial.\n\n- Open the tab *fixation* by clicking on it in the overview area. Because we chose the 'Extended template', OpenSesame already created a fixation point for us. The only thing we need to change is how long the fixation dot will remain on screen\n- Click on the 'Duration' box and change its value to 500\n\n\n#### Word\n\n__Draw the category names__\n\nAfter the fixation point disappears, we want to show the two category names at the upper left and right side of the display (see %TrialSequence). To do so,\n\n- Open the *word* tab by clicking on it in the overview area\n- Select the `Draw textline` element from the black-and-white toolbar\n- Click somewhere in the upper left quandrant of the sketchpad\n- Type 'POSITIVE'\n- Repeat this procedure to make the word 'NEGATIVE' appear on the opposite site\n\n__Draw the stimulus__\n\nNext, we want to show the to-be-categorized stimulus at the center of the screen. Importantly, the stimulus is _*variable*_. This means that which word is shown, depends on which line from the *words_block_loop* is currently run. In order to let OpenSesame know that it can find the value of the word variable in the block loop, we use the *square-bracket syntax*. To do so:\n\n- Select the `draw textline` sketchpad element\n- Click on the center of the screen\n- Type:\n\n~~~ .python\n[stimulus]\n~~~\n\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- The word that you type between brackets should correspond exactly to the column header you created in the *word_block_loop*.\n\n</div>\n\nThis method is very convenient, because it avoids having to make separate sketchpads for each positive and negative word.\n\n__Change the duration__\n\nFinally, we change the duration of the current sketchpad to 0. This doesn't mean that the current sketchpad will be shown only 0 ms. Instead, because a `keyboard_response` item follows right after it, it will stay on screen until the participant pressed a key.\n\nYour sketchpad should now look like this:\n\n<notranslate>\nfigure:\n id: SketchpadWord\n source: sketchpad-word.png\n caption: |\n  The `sketchpad` item that is used to draw the category names and the stimulus to the display.\n</notranslate>\n\n\nIt's good practice to try to run your experiment often, such that you can debug it right away. At this point, let's do a test run by pressing one of the three 'run' arrows.\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- If you want to do a quick test run of your experiment, you might not have to run all items from a given block. To shorten the number of trials, you can do the following:\n\n- Open your block loop table\n- Change the value in the 'Repeat' box to something smaller than 1,00 (e.g. 0,1)\n- (On some systems, decimals are indicated by a comma rather than a period)\n- In our example, this means that OpenSesame will only run *one* row (randomly selected) instead of all 12 of them\n- Don't forget to put 'Repeat' back to 1,00 when you're done testing\n\n</div>\n\n\n## Experimental hierarchy": {
    "fr": "Les deux derniers événements de la séquence d'essai (collecte de la réponse et sauvegarde des données) sont déjà représentés par l'élément `keyboard_response` et l'élément `logger`, respectivement.\n\nVotre zone d'aperçu devrait maintenant ressembler à ceci :\n\n\n\n<notranslate>\nfigure:\n id: OverviewWordBlock\n source: overview_words_block.png\n caption: |\n  Nouvel aperçu de (la première partie de) l'expérience.\n</notranslate>\n\n\n### Étape 3 : Modifier les éléments de la séquence d'essai\n\n#### Fixation\n\nLa prochaine étape consiste à ajouter du contenu aux éléments de la séquence d'essai. Nous commençons par le `sketchpad` qui représente le point de fixation au début de chaque essai.\n\n- Ouvrez l'onglet *fixation* en cliquant dessus dans la zone d'aperçu. Parce que nous avons choisi le \"Modèle étendu\", OpenSesame a déjà créé un point de fixation pour nous. La seule chose que nous devons changer est la durée pendant laquelle le point de fixation restera à l'écran\n- Cliquez sur la case \"Durée\" et changez sa valeur en 500\n\n\n#### Mot\n\n__Dessinez les noms de catégorie__\n\nAprès la disparition du point de fixation, nous voulons afficher les deux noms de catégorie en haut à gauche et à droite de l'écran (voir %TrialSequence). Pour ce faire,\n\n- Ouvrez l'onglet *word* en cliquant dessus dans la zone d'aperçu\n- Sélectionnez l'élément `Draw textline` dans la barre d'outils noir et blanc\n- Cliquez quelque part dans le quadrant supérieur gauche du sketchpad\n- Tapez 'POSITIF'\n- Répétez cette procédure pour faire apparaître le mot 'NÉGATIF' sur le côté opposé\n\n__Dessinez le stimulus__\n\nEnsuite, nous voulons montrer le stimulus à catégoriser au centre de l'écran. Le stimulus est _*variable*_. Cela signifie que le mot affiché dépend de la ligne en cours d'exécution dans la boucle *words_block_loop*. Pour indiquer à OpenSesame que la valeur de la variable de mot se trouve dans la boucle de bloc, nous utilisons la *syntaxe des crochets*. Pour ce faire :\n\n- Sélectionnez l'élément `draw textline` du sketchpad\n- Cliquez sur le centre de l'écran\n- Tapez :\n\n~~~ .python\n[stimulus]\n~~~\n\n\n<div class='info-box' markdown='1'>\n\n__Astuce__ -- Le mot que vous tapez entre crochets doit correspondre exactement à l'en-tête de colonne que vous avez créé dans la boucle *word_block_loop*.\n\n</div>\n\nCette méthode est très pratique, car elle évite de devoir créer des sketchpads séparés pour chaque mot positif et négatif.\n\n__Changer la durée__\n\nEnfin, nous changeons la durée de ce sketchpad à 0. Cela ne signifie pas que le sketchpad actuel sera affiché seulement 0 ms. Au lieu de cela, comme un élément `keyboard_response` suit juste après, il restera à l'écran jusqu'à ce que le participant appuie sur une touche.\n\nVotre sketchpad devrait maintenant ressembler à ceci:\n\n<notranslate>\nfigure:\n id: SketchpadWord\n source: sketchpad-word.png\n caption: |\n  L'élément `sketchpad` utilisé pour dessiner les noms de catégorie et le stimulus sur l'affichage.\n</notranslate>\n\n\nIl est recommandé d'essayer de lancer votre expérience souvent, afin de pouvoir la déboguer immédiatement. À ce stade, faisons un essai en appuyant sur l'une des trois flèches \"exécuter\".\n\n<div class='info-box' markdown='1'>\n\n__Astuce__ -- Si vous voulez faire un test rapide de votre expérience, vous n'aurez peut-être pas besoin de lancer tous les éléments d'un bloc donné. Pour raccourcir le nombre d'essais, vous pouvez faire ce qui suit :\n\n- Ouvrez la table de votre boucle de bloc\n- Changez la valeur dans la case 'Répéter' en quelque chose de plus petit que 1,00 (par exemple, 0,1)\n- (Sur certains systèmes, les décimales sont indiquées par une virgule plutôt qu'un point)\n- Dans notre exemple, cela signifie qu'OpenSesame ne lancera qu'une seule ligne (sélectionnée aléatoirement) au lieu de toutes les 12\n- N'oubliez pas de remettre \"Répéter\" à 1,00 lorsque vous avez terminé les tests\n\n</div>\n\n\n## Hiérarchie expérimentale"
  },
  "\nThe IAT contains more blocks than the current one. It also contains a block in which pictures of faces have to be categorized as young or old, and two blocks that contain both tasks intermingled (see %Task). This means that we will have to create another three blocks of trials, each containing their own trial sequence. The hierarchical strcuture of the experiment therefore looks as follows (and when we're done programming, our overview area should resemble this):\n\n<notranslate>\nfigure:\n id: Hierarchy\n source: hierarchy.png\n caption: |\n  The experimental hierarchy of the IAT.\n</notranslate>\n\n## Block 2: face categorization\n\nLet's first concentrate ourselves on the face-categorization task. More precisely, we will\n\n- Create an additional block loop and trial sequence\n- Re-use everything that we can re-use from the previous part of the experiment\n- Add new variables and events that are specific to the face-categorization task\n\n### Step 4: Create an additional block_loop\n\n- Grab a `loop` item from the `item toolbar`\n- Drag and drop it to the overview area\n- To make the new block appear after the first one, drop it *onto* the `words_block_loop` item (see %AppendLoopAndSequence)\n- OpenSesame asks you whether you want to insert the current item *into* the `words_block_loop`, or *after*. Choose the latter\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- If you accidentally put the new item *into* the block loop, you can always undo this by pressing `Ctrl+Alt+Z`).\n\n</div>\n\n- Give the new loop a meaningful name, for example *faces_block_loop*\n\n### Step 5: Append a new trial sequence\n\nAlthough the trial sequence of the face-categorization task has some overlap with the word-categorization task, they are not identical. Therefore, we can't re-use the trial sequence that we previously made.\n\nIn order to make a new one:\n\n- Grab a `sequence` item from the item toolbar\n- Drop it *into* the *faces_block_loop*\n- This time, choose 'insert into' (see %AppendLoopAndSequence)\n- Rename the item as *faces_trial_sequence*\n\n<notranslate>\nvideo:\n source: youtube\n id: AppendLoopAndSequence\n videoid: PVcXdAN3rjM\n width: 640\n height: 360\n caption: |\n  Step 5 and 6: Adding block 2 and its corresponding trial sequence to the experiment.\n</notranslate>\n\n\n### Step 6: Choose the face stimuli\n\n\n__Download the face stimuli__\n\nIn the face equivalent of the task, we need images of six young and six old faces. To avoid gender biases from influencing our results, it seams best to use an equal number of male and female faces per category (here: three).\n\nYou can download an example set of stimuli (in JPG format) here:\n\n- %static:attachments/iat2020/face-stimuli.zip%\n\nIn most web browsers you can right-click the link and choose 'Save Link As' or a similar option. After you have downloaded these files (to your Downloads folder, for example), you can unzip them.\n\n__Add the JPG files to the file pool__\n\n- If the file pool is not already visible (by default on the right side of the window), click on the 'Show file pool' button in the main toolbar (shortcut: `Ctrl+P`).\n- Click on the plus sign in order to add files\n- Browse to your Downloads folder (or wherever you saved and unzipped the *face-stimuli* folder) and add the 12 JPG files.\n\nThe file pool should now look similar to %FacesBlockLoop\n\n### Step 7: Content of the loop table\n\nJust like in the previous part of the experiment (see Step 1), we need three columns to define the experimental variables: *stimulus*, *category*, and *correct_response*. The only difference is that this time the stimuli are the JPG files that we just added to the file pool.\n\nRegarding the correct_response, let's say that:\n\n- The *YOUNG* category appears at the left side of the screen, whereas the *OLD* category appears at the right\n- The response rule is as before\n\nCreate the aforementioned columns and make sure your block loop ends up looking like this:": {
    "fr": "L'IAT contient plus de blocs que celui actuel. Il contient également un bloc dans lequel des images de visages doivent être classées comme jeunes ou vieux, et deux blocs qui contiennent les deux tâches mélangées (voir %Task). Cela signifie que nous devrons créer trois autres blocs d'essais, chacun contenant sa propre séquence d'essais. La structure hiérarchique de l'expérience ressemble donc à ce qui suit (et lorsque nous aurons terminé la programmation, notre zone de vue d'ensemble devrait ressembler à ceci) :\n\n<notranslate>\nfigure :\n id: Hierarchy\n source: hierarchy.png\n caption: |\n  La hiérarchie expérimentale de l'IAT.\n</notranslate>\n\n## Bloc 2 : catégorisation des visages\n\nConcentrons-nous d'abord sur la tâche de catégorisation des visages. Plus précisément, nous allons :\n\n- Créer une boucle de blocs supplémentaire et une séquence d'essais\n- Réutiliser tout ce que nous pouvons réutiliser de la partie précédente de l'expérience\n- Ajouter de nouvelles variables et événements spécifiques à la tâche de catégorisation des visages\n\n### Étape 4 : Créer une boucle de blocs supplémentaire\n\n- Prenez un élément `loop` dans la `barre d'outils des éléments`\n- Faites-le glisser et déposez-le dans la zone de vue d'ensemble\n- Pour faire apparaître le nouveau bloc après le premier, déposez-le *sur* l'élément `words_block_loop` (voir %AppendLoopAndSequence)\n- OpenSesame vous demande si vous voulez insérer l'élément actuel *dans* le `words_block_loop`, ou *après*. Choisissez cette dernière option\n\n<div class='info-box' markdown='1'>\n\n__Astuce__ -- Si vous placez accidentellement le nouvel élément *dans* la boucle de blocs, vous pouvez toujours annuler cette opération en appuyant sur `Ctrl+Alt+Z`).\n\n</div>\n\n- Donnez un nom significatif à la nouvelle boucle, par exemple *faces_block_loop*\n\n### Étape 5 : Ajouter une nouvelle séquence d'essais\n\nBien que la séquence d'essais de la tâche de catégorisation des visages présente quelques chevauchements avec la tâche de catégorisation des mots, elles ne sont pas identiques. Par conséquent, nous ne pouvons pas réutiliser la séquence d'essais que nous avons précédemment créée.\n\nPour en créer une nouvelle :\n\n- Prenez un élément `sequence` dans la barre d'outils des éléments\n- Déposez-le *dans* le *faces_block_loop*\n- Cette fois, choisissez \"insérer dans\" (voir %AppendLoopAndSequence)\n- Renommez l'élément en *faces_trial_sequence*\n\n<notranslate>\nvideo :\n source: youtube\n id: AppendLoopAndSequence\n videoid : PVcXdAN3rjM\n width: 640\n height: 360\n caption: |\n  Étape 5 et 6 : Ajout du bloc 2 et de sa séquence d'essais correspondante à l'expérience.\n</notranslate>\n\n\n### Étape 6 : Choisir les stimuli des visages\n\n__Téléchargez les stimuli des visages__\n\nDans l'équivalent des visages de la tâche, nous avons besoin d'images de six visages jeunes et six visages âgés. Pour éviter que les biais de genre n'influencent nos résultats, il semble préférable d'utiliser un nombre égal de visages masculins et féminins par catégorie (ici : trois).\n\nVous pouvez télécharger un exemple de stimuli (au format JPG) ici :\n\n- %static:attachments/iat2020/face-stimuli.zip%\n\nDans la plupart des navigateurs web, vous pouvez cliquer avec le bouton droit sur le lien et choisir \"Enregistrer le lien sous\" ou une option similaire. Une fois que vous avez téléchargé ces fichiers (dans votre dossier Téléchargements, par exemple), vous pouvez les décompresser.\n\n__Ajoutez les fichiers JPG au pool de fichiers__\n\n- Si le pool de fichiers n'est pas déjà visible (par défaut sur le côté droit de la fenêtre), cliquez sur le bouton \"Afficher le pool de fichiers\" dans la barre d'outils principale (raccourci : `Ctrl+P`).\n- Cliquez sur le signe plus pour ajouter des fichiers\n- Parcourez votre dossier Téléchargements (ou l'endroit où vous avez enregistré et décompressé le dossier *face-stimuli*) et ajoutez les 12 fichiers JPG.\n\nLe pool de fichiers devrait maintenant ressembler à %FacesBlockLoop\n\n### Étape 7 : Contenu du tableau de boucle\n\nTout comme dans la partie précédente de l'expérience (voir l'étape 1), nous avons besoin de trois colonnes pour définir les variables expérimentales : *stimulus*, *category*, et *correct_response*. La seule différence est que cette fois les stimuli sont les fichiers JPG que nous venons d'ajouter au pool de fichiers.\n\nEn ce qui concerne la correct_response, disons que :\n\n- La catégorie *YOUNG* apparaît sur le côté gauche de l'écran, tandis que la catégorie *OLD* apparaît sur le côté droit\n- La règle de réponse est la même qu'auparavant\n\nCréez les colonnes mentionnées ci-dessus et assurez-vous que votre boucle de blocs ressemble à cela :"
  },
  "Doing things in parallel": {
    "fr": "Faire les choses en parallèle"
  },
  "Text": {
    "fr": "Texte"
  },
  "Release notes for 3.3.14": {
    "fr": "Notes de version pour 3.3.14"
  },
  "Release notes for 3.2.5": {
    "fr": "Notes de version pour 3.2.5"
  },
  "Release notes for 3.3.1": {
    "fr": "Notes de version pour 3.3.1"
  },
  "Release notes for 3.2.6": {
    "fr": "Notes de version pour 3.2.6",
    "de": "Versionshinweise für 3.2.6"
  },
  "Release notes for 0.27.4": {
    "fr": "Notes de version pour 0.27.4"
  },
  "Release notes for 3.2.1": {
    "fr": "Notes de version pour 3.2.1"
  },
  "Release notes for 3.1.4": {
    "fr": "Notes de version pour 3.1.4"
  },
  "Creating custom forms": {
    "fr": "Création de formulaires personnalisés"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.3.14 *Lentiform Loewenfeld* is the fourteenth maintenance release in the 3.3 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.3 series.\n\nIf you are upgrading from OpenSesame 3.2 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Robbert van der Mijn (%-- github: {user: robbertmijn} --%) for his work on the Mac OS package\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.3.14\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 767 } --% \n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 782 } --% \n\n\nopensesame-extension-osweb\n\n- Updated to 1.4.13.1\n\n\n## Packages\n\n### Windows Python 3.7 (standard)": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.3.14 *Lentiform Loewenfeld* est la quatorzième version de maintenance de la série 3.3. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sécurisée pour tous ceux qui utilisent la série 3.3.\n\nSi vous mettez à niveau depuis OpenSesame 3.2 ou une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Robbert van der Mijn (%-- github: {user: robbertmijn} --%) pour son travail sur le paquet Mac OS\n\n## Corrections de bugs et améliorations\n\nopensesame :\n\n- Mise à jour vers 3.3.14\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 767 } --% \n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 782 } --% \n\nopensesame-extension-osweb\n\n- Mise à jour vers 1.4.13.1\n\n## Paquets\n\n### Windows Python 3.7 (standard)"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.2.1 *Kafkaesque Koffka* is the first maintenance release in the 3.2 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.2 series.\n\nThe main reason for this quick maintenance release is an issue with variable properties of text elements in SKETCHPAD items.\n\nIf you are upgrading from OpenSesame 3.1 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.2.1\n- %-- github: { repo: \"smathot/opensesame\", issue: 580 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 581 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 583 } --%\n- Minor translation updates\n\ndatamatrix:\n\n- Updated to 0.8.1\n\n\n## Packages\n\n\n### Windows Python 2.7": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.2.1 *Kafkaesque Koffka* est la première version de maintenance de la série 3.2. Elle contient des corrections de bogues et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.2.\n\nLa principale raison de cette version de maintenance rapide est un problème avec les propriétés de variable des éléments de texte dans les éléments SKETCHPAD.\n\nSi vous effectuez une mise à niveau à partir d'OpenSesame 3.1 ou d'une version antérieure, veuillez consulter la liste des modifications importantes :\n\n- %link:important-changes-3%\n\n## Corrections de bogues et améliorations\n\nopensesame :\n\n- Mis à jour en 3.2.1\n- %-- github: { repo: \"smathot/opensesame\", issue: 580 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 581 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 583 } --%\n- Mises à jour mineures des traductions\n\ndatamatrix :\n\n- Mis à jour en 0.8.1\n\n## Packages\n\n### Windows Python 2.7"
  },
  "OpenSesame 0.27.4 is the fourth maintenance release in the 0.27 'Frisky Freud' series, and was released on September 13 2013. If you are upgrading from 0.26, please read the [0.27 release notes][].\n\nNew features and enhancements:\n\n- Chinese translation (`zh_CN`), contributed by Zhongquan Li and Gabriel Chan\n- HTML parsing is now optional in SKETCHPAD items\n\nBugs fixed:\n\n- Prevent key names like '[1]' to avoid variable errors\n- Fix `color` keyword argument in `canvas.arrow()`\n- Fix `advanced_delay` plugin to work with Unicode\n- Intercept `psychopy.core.quit()` to prevent PsychoPy from killing OpenSesame\n- Also prepare empty `canvas` objects in `xpyriment` backend\n- Fix many missing icons with `gnome` theme under Linux\n- Fix a bug where `self` was not properly registered in the run phase of INLINE_SCRIPT items\n\nWindows packaging:\n\n- All dependencies have been updated to most recent version\n- PyGame has been downgraded to 1.9.1 to prevent mouse issues\n\n[0.27 release notes]: /notes/0.27": {
    "fr": "OpenSesame 0.27.4 est la quatrième version de maintenance de la série 0.27 'Frisky Freud' et a été publiée le 13 septembre 2013. Si vous mettez à niveau depuis 0.26, veuillez lire les [notes de version 0.27][].\n\nNouvelles fonctionnalités et améliorations :\n\n- Traduction en chinois (`zh_CN`), fournie par Zhongquan Li et Gabriel Chan\n- L'analyse HTML est maintenant facultative dans les éléments SKETCHPAD\n\nBugs corrigés :\n\n- Empêcher les noms de clés comme '[1]' pour éviter les erreurs de variable\n- Corriger l'argument mot-clé `color` dans `canvas.arrow()`\n- Corriger le plugin `advanced_delay` pour fonctionner avec Unicode\n- Intercepter `psychopy.core.quit()` pour empêcher PsychoPy de tuer OpenSesame\n- Préparer également des objets `canvas` vides dans le backend `xpyriment`\n- Corriger de nombreuses icônes manquantes avec le thème `gnome` sous Linux\n- Corriger un bug où `self` n'était pas correctement enregistré dans la phase d'exécution des éléments INLINE_SCRIPT\n\nEmpaquetage Windows :\n\n- Toutes les dépendances ont été mises à jour à la version la plus récente\n- PyGame a été rétrogradé à 1.9.1 pour éviter les problèmes de souris\n\n[notes de version 0.27]: /notes/0.27"
  },
  "Mouse responses": {
    "fr": "Réponses de la souris"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.1.4 *Jazzy James* is the fourth maintenance release in the 3.1 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.1 series.\n\nIf you are upgrading from OpenSesame 3.0 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Amandine Rey (%-- github: {user: amandinerey} --%) for updating the French translation.\n- Daniel Schreij (%-- github: {user: dschreij} --%) for the Mac OS package.\n\n## Bug fixes and improvements\n\n- %-- github: { repo: \"smathot/opensesame\", issue: 469 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 474 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 478 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 479 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 480 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 482 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 483 } --%\n\n\n## Packages (Windows Python 2.7 package)\n\n### Updated\n\n- `python-qprogedit` has been updated to 4.0.6\n\n### Detailed package information": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.1.4 *Jazzy James* est la quatrième version de maintenance de la série 3.1. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.1.\n\nSi vous passez d'OpenSesame 3.0 ou d'une version antérieure, veuillez consulter la liste des modifications importantes :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Amandine Rey (%-- github: {user: amandinerey} --%) pour la mise à jour de la traduction française.\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour le paquet Mac OS.\n\n## Corrections de bugs et améliorations\n\n- %-- github: { repo: \"smathot/opensesame\", issue: 469 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 474 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 478 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 479 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 480 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 482 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 483 } --%\n\n## Paquets (paquet Windows Python 2.7)\n\n### Mis à jour\n\n- `python-qprogedit` a été mis à jour en 4.0.6\n\n### Informations détaillées sur les paquets"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.3.1 *Lentiform Loewenfeld* is the first maintenance release in the 3.3 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.3 series.\n\nIf you are upgrading from OpenSesame 3.2 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for his work on OSWeb, the Mac OS package, and bug fixes\n- Eduard Ort (%-- github: {user: eort} --%) for his work on the German translation\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.3.1\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 690 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 694 } --%\n\nrapunzel:\n\n- Updated to 0.4.5\n\nopensesame-extension-osweb\n\n- Updated to 1.3.8.0\n- %-- github: { repo: \"smathot/opensesame-extension-osweb\", issue: 17 } --%\n- %-- github: { repo: \"smathot/opensesame-extension-osweb\", issue: 19 } --%\n\nosweb\n\n- Updated to 1.3.8\n- %-- github: { repo: \"smathot/osweb\", issue: 2 } --%\n- %-- github: { repo: \"smathot/osweb\", issue: 3 } --%\n- %-- github: { repo: \"smathot/osweb\", issue: 6 } --%\n- %-- github: { repo: \"smathot/osweb\", issue: 8 } --%\n\nqdatamatrix:\n\n- Updated to 0.1.27\n\ndatamatrix\n\n- Updated to 0.10.16\n\npyqode.core\n\n- Updated to 2.15.0a5\n\nopensesame-plugin-media_player_mpy\n\n- Included 0.1.8\n- Fixes compatibility with OpenSesame 3.3\n\n\n## Packages\n\n\n### Python 3.7 (standard)": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.3.1 *Lentiform Loewenfeld* est la première version de maintenance de la série 3.3. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.3.\n\nSi vous mettez à niveau depuis OpenSesame 3.2 ou une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour son travail sur OSWeb, le package Mac OS, et les corrections de bugs\n- Eduard Ort (%-- github: {user: eort} --%) pour son travail sur la traduction allemande\n\n## Corrections de bugs et améliorations\n\nopensesame :\n\n- Mis à jour en 3.3.1\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 690 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 694 } --%\n\nrapunzel :\n\n- Mis à jour en 0.4.5\n\nopensesame-extension-osweb\n\n- Mis à jour en 1.3.8.0\n- %-- github: { repo: \"smathot/opensesame-extension-osweb\", issue: 17 } --%\n- %-- github: { repo: \"smathot/opensesame-extension-osweb\", issue: 19 } --%\n\nosweb\n\n- Mis à jour en 1.3.8\n- %-- github: { repo: \"smathot/osweb\", issue: 2 } --%\n- %-- github: { repo: \"smathot/osweb\", issue: 3 } --%\n- %-- github: { repo: \"smathot/osweb\", issue: 6 } --%\n- %-- github: { repo: \"smathot/osweb\", issue: 8 } --%\n\nqdatamatrix :\n\n- Mis à jour en 0.1.27\n\ndatamatrix\n\n- Mis à jour en 0.10.16\n\npyqode.core\n\n- Mis à jour en 2.15.0a5\n\nopensesame-plugin-media_player_mpy\n\n- Inclus 0.1.8\n- Corrige la compatibilité avec OpenSesame 3.3\n\n## Paquets\n\n### Python 3.7 (standard)"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.2.5 *Kafkaesque Koffka* is the fifth maintenance release in the 3.2 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.2 series.\n\nNotable improvements:\n\n- A new Japanese translation by Yuya Kinzuka (%-- github: {user: aldichollow} --%)\n- A revised Spanish translation by Roberto de Cecilio\n- `Canvas.show()` emits a warning when flipping took more than 16 ms\n- `Canvas.elements_at()` now uses proper geometry to check the borders of elements\n- A new standards-compliant logging system\n- Reduced start-up time by deferred loading of Jupyter Console\n\nIf you are upgrading from OpenSesame 3.1 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for his work on the Mac OS package\n- Yuya Kinzuka (%-- github: {user: aldichollow} --%) for contributing a Japanese translation\n- Roberto De Cecilio for revising the Spanish translation\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.2.5\n- %-- github: { repo: \"smathot/opensesame\", issue: 634 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 631 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 621 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 628 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 633 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 618 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 627 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 632 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 630 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 629 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 626 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 623 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 607 } --%\n\n\npython-datamatrix:\n\n- Updated to 0.9.4\n\n\npython-qnotifications:\n\n- Updated to 2.0.1\n\n\n## Packages\n\n\n### Windows Python 2.7": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.2.5 *Kafkaesque Koffka* est la cinquième version de maintenance de la série 3.2. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.2.\n\nAméliorations notables :\n\n- Une nouvelle traduction japonaise par Yuya Kinzuka (%-- github: {user: aldichollow} --%)\n- Une traduction espagnole révisée par Roberto de Cecilio\n- `Canvas.show()` émet un avertissement lorsque le basculement a pris plus de 16 ms\n- `Canvas.elements_at()` utilise désormais une géométrie appropriée pour vérifier les bordures des éléments\n- Un nouveau système de journalisation conforme aux normes\n- Réduction du temps de démarrage en chargeant différé de Jupyter Console\n\nSi vous mettez à jour depuis OpenSesame 3.1 ou une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour son travail sur le package Mac OS\n- Yuya Kinzuka (%-- github: {user: aldichollow} --%) pour avoir contribué à une traduction japonaise\n- Roberto De Cecilio pour avoir révisé la traduction espagnole\n\n\n## Corrections de bugs et améliorations\n\nopensesame :\n\n- Mise à jour en 3.2.5\n- %-- github: { repo : \"smathot/opensesame\", issue : 634 } --%\n- %-- github: { repo : \"smathot/opensesame\", issue : 631 } --%\n- %-- github: { repo : \"smathot/opensesame\", issue : 621 } --%\n- %-- github: { repo : \"smathot/opensesame\", issue : 628 } --%\n- %-- github: { repo : \"smathot/opensesame\", issue : 633 } --%\n- %-- github: { repo : \"smathot/opensesame\", issue : 618 } --%\n- %-- github: { repo : \"smathot/opensesame\", issue : 627 } --%\n- %-- github: { repo : \"smathot/opensesame\", issue : 632 } --%\n- %-- github: { repo : \"smathot/opensesame\", issue : 630 } --%\n- %-- github: { repo : \"smathot/opensesame\", issue : 629 } --%\n- %-- github: { repo : \"smathot/opensesame\", issue : 626 } --%\n- %-- github: { repo : \"smathot/opensesame\", issue : 623 } --%\n- %-- github: { repo : \"smathot/opensesame\", issue : 607 } --%\n\n\npython-datamatrix :\n\n- Mise à jour en 0.9.4\n\n\npython-qnotifications :\n\n- Mise à jour en 2.0.1\n\n\n## Packages\n\n### Windows Python 2.7"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.2.6 *Kafkaesque Koffka* is the sixth maintenance release in the 3.2 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.2 series.\n\nA notable addition in this release is the OSWeb extension. This allows you to run OpenSesame experiments online! For more information, see:\n\n- %link:manual/osweb/workflow%\n\nIf you are upgrading from OpenSesame 3.1 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for his work on OSWeb and the Mac OS package\n- Jaap Bos (%-- github: {user: shyras} --%) for his work on OSWeb\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.2.6\n- %-- github: { repo: \"smathot/opensesame\", issue: 635 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 636 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 638 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 639 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 641 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 642 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 646 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 647 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 648 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 649 } --%\n\n\n\npython-datamatrix:\n\n- Updated to 0.9.8\n\n\npython-qnotifications:\n\n- Updated to 2.0.2\n\n\npython-qtpip:\n\n- Updated to 0.2.0\n\n\nopensesame-extension-osweb:\n\n- Newly added 1.2.4.3\n\n\n## Packages\n\n\n### Windows Python 2.7": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.2.6 *Kafkaesque Koffka* est la sixième version de maintenance de la série 3.2. Elle contient des corrections de bogues et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.2.\n\nUn ajout notable dans cette version est l'extension OSWeb. Cela vous permet d'exécuter des expériences OpenSesame en ligne ! Pour plus d'informations, consultez :\n\n- %link:manual/osweb/workflow%\n\nSi vous mettez à niveau depuis OpenSesame 3.1 ou une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour son travail sur OSWeb et le paquet Mac OS\n- Jaap Bos (%-- github: {user: shyras} --%) pour son travail sur OSWeb\n\n\n## Corrections de bogues et améliorations\n\nopensesame :\n\n- Mis à jour en 3.2.6\n- %-- github: { repo: \"smathot/opensesame\", issue: 635 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 636 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 638 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 639 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 641 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 642 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 646 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 647 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 648 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 649 } --%\n\n\npython-datamatrix :\n\n- Mis à jour en 0.9.8\n\n\npython-qnotifications :\n\n- Mis à jour en 2.0.2\n\n\npython-qtpip :\n\n- Mis à jour en 0.2.0\n\n\nopensesame-extension-osweb :\n\n- Ajouté récemment 1.2.4.3\n\n## Paquets\n\n### Windows Python 2.7"
  },
  "<notranslate>[TOC]</notranslate>\n\n## How can I present text?\n\nThe most common way to show text is using a SKETCHPAD or FEEDBACK item. These allow you to enter text and other visual stimuli. For a questionnaire-like way to show text, you can use [forms](%link:manual/forms/about%).\n\n\n## HTML formatting\n\nYou can use a HTML tags, which you can simply insert into your text. You can use these tags everywhere: In SKETCHPAD items, in INLINE_SCRIPTs (provided you use the `Canvas` class), in forms, etc.\n\nExample:\n\n~~~ .html\nOpenSesame supports a sub-set of HTML tags:\n- <b>Bold face</b>\n- <i>Italic</i>\n- <u>Underline</u>\n\nIn addition, you can pass 'color', 'size', and 'style' as keywords to a 'span' tag:\n- <span style='color:red;'>Color</span>\n- <span style='font-size:32px;'>Font size</span>\n- <span style='font-family:serif;'>Font style</span>\n\nFinally, you can force newlines with the 'br' tag:\nLine 1<br>Line 2\n~~~\n\n\n## Variables and inline Python\n\nYou can embed variables in text using the `{...}` syntax. For example, the following:\n\n~~~ .python\nThe subject number is {subject_nr}\n~~~\n\n... might evaluate to (for subject 1):\n\n~~~ .python\nThe subject number is 1\n~~~\n\nYou can also embed Python expression. For example, the following:\n\n~~~ .python\nThe subject number modulo five is {subject_nr % 5}\n~~~\n\n... might evaluate to (for subject 7)\n\n~~~ .python\nThe subject number modulo five is 2\n~~~\n\n\n## Fonts\n\n### Default fonts\n\nYou can select one of the default fonts from the font-selection dialogs (%FigFontSelect). These fonts are included with OpenSesame and your experiment will therefore be fully portable when you use them.\n\n<notranslate>\nfigure:\n id: FigFontSelect\n source: font-selection-dialog.png\n caption: \"A number of default fonts, which are bundled with OpenSesame, can be selected through the font-selection dialogs.\"\n</notranslate>\n\nThe fonts have been renamed for clarity, but correspond to the following open-source fonts:\n\n|__Name in OpenSesame__\t\t|__Actual font__\t\t|\n|---------------------------|-----------------------|\n|`sans`\t\t\t\t\t\t|Droid Sans\t\t\t\t|\n|`serif`\t\t\t\t\t|Droid Serif\t\t\t|\n|`mono`\t\t\t\t\t\t|Droid Sans Mono\t\t|\n|`chinese-japanese-korean`\t|WenQuanYi Micro Hei\t|\n|`arabic`\t\t\t\t\t|Droid Arabic Naskh\t\t|\n|`hebrew`\t\t\t\t\t|Droid Sans Hebrew\t\t|\n|`hindi`\t\t\t\t\t|Lohit Hindi\t\t\t|\n\n### Selecting a custom font through the font-selection dialog\n\nIf you select 'other ...' in the font selection dialog, you can select any font that is available on your operating system. If you do this, your experiment is no longer fully portable, and will require that the selected font is installed on the system that you run your experiment on.\n\n### Placing a custom font in the file pool\n\nAnother way to use a custom font is to put a font file in the file pool. For example, if you place the font file `inconsolata.ttf` in the file pool, you can use this font in a SKETCHPAD item, like so:\n\n\tdraw textline 0.0 0.0 \"This will be inconsolata\" font_family=\"inconsolata\"\n\nNote that the font file must be a truetype `.ttf` file.\n": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## Comment présenter du texte ?\n\nLa manière la plus courante de montrer du texte est d'utiliser un élément SKETCHPAD ou FEEDBACK. Ceux-ci vous permettent d'entrer du texte et d'autres stimuli visuels. Pour une manière de type questionnaire de montrer du texte, vous pouvez utiliser [formulaires](%link:manual/forms/about%).\n\n\n## Formatage HTML\n\nVous pouvez utiliser des balises HTML, que vous pouvez simplement insérer dans votre texte. Vous pouvez utiliser ces balises partout : dans les éléments SKETCHPAD, INLINE_SCRIPT (à condition d'utiliser la classe \"Canvas\"), dans les formulaires, etc.\n\nExemple :\n\n~~~ .html\nOpenSesame prend en charge un sous-ensemble de balises HTML :\n- <b>Gras</b>\n- <i>Italique</i>\n- <u>Souligné</u>\n\nDe plus, vous pouvez passer \"color\", \"size\" et \"style\" comme mots-clés à une balise \"span\" :\n- <span style='color:red;'>Couleur</span>\n- <span style='font-size:32px;'>Taille de la police</span>\n- <span style='font-family:serif;'>Style de police</span>\n\nEnfin, vous pouvez forcer les sauts de ligne avec la balise \"br\" :\nLigne 1<br>Ligne 2\n~~~\n\n\n## Variables et Python en ligne\n\nVous pouvez intégrer des variables dans du texte en utilisant la syntaxe `{...}`. Par exemple, ce qui suit :\n\n~~~ .python\nLe numéro du sujet est {subject_nr}\n~~~\n\n... pourrait s'évaluer à (pour le sujet 1) :\n\n~~~ .python\nLe numéro du sujet est 1\n~~~\n\nVous pouvez également intégrer des expressions Python. Par exemple, ce qui suit :\n\n~~~ .python\nLe numéro du sujet modulo cinq est {subject_nr % 5}\n~~~\n\n... pourrait s'évaluer à (pour le sujet 7) :\n\n~~~ .python\nLe numéro du sujet modulo cinq est 2\n~~~\n\n\n## Polices de caractères\n\n### Polices par défaut\n\nVous pouvez sélectionner l'une des polices par défaut dans les boîtes de dialogue de sélection de police (%FigFontSelect). Ces polices sont incluses dans OpenSesame et votre expérience sera donc entièrement portable lorsque vous les utiliserez.\n\n<notranslate>\nfigure:\n id: FigFontSelect\n source: font-selection-dialog.png\n caption: \"Un certain nombre de polices par défaut, qui sont livrées avec OpenSesame, peuvent être sélectionnées via les boîtes de dialogue de sélection de police.\"\n</notranslate>\n\nLes polices ont été renommées pour plus de clarté, mais correspondent aux polices open-source suivantes :\n\n|__Nom dans OpenSesame__\t\t|__Police réelle__\t\t|\n|---------------------------|-----------------------|\n|`sans`\t\t\t\t\t\t|Droid Sans\t\t\t\t|\n|`serif`\t\t\t\t\t|Droid Serif\t\t\t|\n|`mono`\t\t\t\t\t\t|Droid Sans Mono\t\t|\n|`chinese-japanese-korean`\t|WenQuanYi Micro Hei\t|\n|`arabic`\t\t\t\t\t|Droid Arabic Naskh\t\t|\n|`hebrew`\t\t\t\t\t|Droid Sans Hebrew\t\t|\n|`hindi`\t\t\t\t\t|Lohit Hindi\t\t\t|\n\n### Sélectionner une police personnalisée grâce à la boîte de dialogue de sélection de police\n\nSi vous sélectionnez \"autre ...\" dans la boîte de dialogue de sélection de police, vous pouvez sélectionner n'importe quelle police disponible sur votre système d'exploitation. Si vous faites cela, votre expérience n'est plus entièrement portable et nécessitera que la police sélectionnée soit installée sur le système sur lequel vous exécutez votre expérience.\n\n### Placer une police personnalisée dans la file d'attente des fichiers\n\nUne autre façon d'utiliser une police personnalisée consiste à mettre un fichier de police dans le pool de fichiers. Par exemple, si vous placez le fichier de police `inconsolata.ttf` dans le pool de fichiers, vous pouvez utiliser cette police dans un élément SKETCHPAD, comme ceci :\n\n\tdraw textline 0.0 0.0 \"Ce sera inconsolata\" font_family=\"inconsolata\"\n\nNotez que le fichier de police doit être un fichier de type `.ttf`."
  },
  "Sona Systems": {
    "fr": "Systèmes Sona"
  },
  "\nCoroutines run multiple items in parallel—or, to be more exact, they run items in rapid alternation in a way that looks parallel. Not all items support coroutines.\n\n\n<notranslate>[TOC]</notranslate>\n\n\n## Using coroutines\n\nYou can use coroutines through the COROUTINES plugin (see %FigCoroutinesInterface).\n\n\n<notranslate>\nfigure:\n source: FigCoroutinesInterface.png\n caption: The interface of the coroutines plugin.\n id: FigCoroutinesInterface\n</notranslate>\n\n\nAs you can see, the COROUTINES plugin looks similar to the SEQUENCE item, but has a few extra options:\n\n- *Duration* indicates the total duration of the coroutines.\n- *End after item (optional)* indicates that the coroutines should end when a specific item has ended. This allows you, for example, to indicate that the coroutines should end when a key press has been collected, by selecting a KEYBOARD_RESPONSE item here.\n- Each item has a *Start time*. Most items also have an *End time*. The end time does not apply to one-shot items; for example, SKETCHPADs show a display and terminate immediately, so they have no end time.\n\nSpecifically, the example from %FigCoroutinesInterface (from the stop-signal-task example) does the following:\n\n- It shows a target display immediately.\n- If the `stop_after` variable is not empty, it shows the stop_signal display after an interval specified by the `stop_after` variable.\n- During the entire (2000 ms) interval, a keyboard response is collected.\n\nThe temporal flow is controlled by the COROUTINES plugin. Therefore, the timeout and duration values specified in the items are not used. For example, in %FigCoroutinesInterface, the KEYBOARD_RESPONSE will run for 2000 ms, regardless of the timeout that is specified in the item.\n\n\n## Supported items\n\nCurrently, the following items are supported (this list may not be exhaustive):\n\n- FEEDBACK\n- INLINE_SCRIPT\n- KEYBOARD_RESPONSE\n- LOGGER\n- MOUSE_RESPONSE\n- SAMPLER\n- SYNTH\n- SKETCHPAD\n\n\n## Using inline_script items in coroutines\n\nWhen you use an INLINE_SCRIPT item in a COROUTINES, the Run phase works a little differently from what you might be used to. Specifically, the Run phase is executed on every iteration of the COROUTINES. In addition, the Run phase should only contain code that takes very little time to execute; this is because time-consuming operations will block the COROUTINES, thus interfering with the timing of other items in the COROUTINES as well. To end the COROUTINES, you can raise an `AbortCoroutines()` exception.\n\nFor example, say that you have a COROUTINES with two KEYBOARD_RESPONSE items, *kb1* and *kb2*, and you want to run the COROUTINES until two key presses have been collected, with a timeout of 5000 ms. You could then create the following COROUTINES structure:\n\n\n<notranslate>\nfigure:\n source: FigCoroutinesTwoResponses.png\n caption: A coroutines that collects two keypress responses\n id: FigCoroutinesTwoResponses\n</notranslate>\n\nThe *check_responses* INLINE_SCRIPT would then first set both responses variables to an empty string in the Prepare phase:\n\n```python\n# This is executed at the start of the coroutines\nresponse_kb1 = ''\nresponse_kb2 = ''\n```\n\nAnd then, in the Run phase, check if both variables have been set, and abort the coroutines if this is the case:\n\n```python\n# Values that are not an empty string are True for Python\n# This code will be executed many times!\nif response_kb1 and response_kb2:\n    raise AbortCoroutines()\n```\n\n## Run-if expressions\n\nThe behavior of run-if expressions in COROUTINES is a bit different from that in SEQUENCE items. Specifically, run-if expressions in COROUTINES are evaluated during the prepare phase. See also:\n\n- %link:prepare-run%\n": {
    "fr": "Les coroutines exécutent plusieurs éléments en parallèle, ou, pour être plus précis, elles exécutent des éléments en rapide alternance d'une manière qui semble parallèle. Tous les éléments ne prennent pas en charge les coroutines.\n\n<notranslate>[TOC]</notranslate>\n\n## Utiliser des coroutines\n\nVous pouvez utiliser des coroutines grâce au plugin COROUTINES (voir %FigCoroutinesInterface).\n\n<notranslate>\nfigure:\n source: FigCoroutinesInterface.png\n caption: L'interface du plugin coroutines.\n id: FigCoroutinesInterface\n</notranslate>\n\nComme vous pouvez le voir, le plugin COROUTINES ressemble à l'élément SEQUENCE, mais présente quelques options supplémentaires :\n\n- *Duration* indique la durée totale des coroutines.\n- *End after item (optional)* indique que les coroutines doivent se terminer lorsqu'un élément spécifique est terminé. Cela vous permet, par exemple, d'indiquer que les coroutines doivent se terminer lorsqu'une touche a été recueillie, en sélectionnant un élément KEYBOARD_RESPONSE ici.\n- Chaque élément a un *Start time*. La plupart des éléments ont également un *End time*. Le temps de fin ne s'applique pas aux éléments à tir unique; par exemple, les SKETCHPAD affichent un écran et se terminent immédiatement, donc ils n'ont pas de temps de fin.\n\nPlus précisément, l'exemple de %FigCoroutinesInterface (de l'exemple de tâche de signal d'arrêt) fait ce qui suit :\n\n- Il montre une cible immédiatement.\n- Si la variable `stop_after` n'est pas vide, il affiche l'écran stop_signal après un intervalle spécifié par la variable `stop_after`.\n- Pendant tout l'intervalle (2000 ms), une réponse au clavier est recueillie.\n\nLe flux temporel est contrôlé par le plugin COROUTINES. Par conséquent, les valeurs de délai d'expiration et de durée spécifiées dans les éléments ne sont pas utilisées. Par exemple, dans %FigCoroutinesInterface, le KEYBOARD_RESPONSE s'exécutera pendant 2000 ms, quel que soit le délai d'expiration spécifié dans l'élément.\n\n## Éléments pris en charge\n\nActuellement, les éléments suivants sont pris en charge (cette liste peut ne pas être exhaustive) :\n\n- FEEDBACK\n- INLINE_SCRIPT\n- KEYBOARD_RESPONSE\n- LOGGER\n- MOUSE_RESPONSE\n- SAMPLER\n- SYNTH\n- SKETCHPAD\n\n## Utiliser des éléments inline_script dans les coroutines\n\nLorsque vous utilisez un élément INLINE_SCRIPT dans une COROUTINES, la phase Run fonctionne un peu différemment de ce à quoi vous pourriez être habitué. Plus précisément, la phase Run est exécutée à chaque itération des COROUTINES. De plus, la phase Run ne doit contenir que du code qui prend très peu de temps à exécuter ; en effet, les opérations longues bloqueront les COROUTINES, interférant ainsi avec le minutage des autres éléments des COROUTINES. Pour mettre fin aux COROUTINES, vous pouvez lever une exception `AbortCoroutines()`.\n\nPar exemple, disons que vous avez une COROUTINES avec deux éléments KEYBOARD_RESPONSE, *kb1* et *kb2*, et que vous voulez exécuter les COROUTINES jusqu'à ce que deux touches aient été recueillies, avec un délai d'expiration de 5000 ms. Vous pourriez alors créer la structure COROUTINES suivante :\n\n<notranslate>\nfigure:\n source: FigCoroutinesTwoResponses.png\n caption: Une coroutines qui recueille deux réponses par pression de touche\n id: FigCoroutinesTwoResponses\n</notranslate>\n\nL'élément INLINE_SCRIPT *check_responses* définira d'abord les deux variables de réponse sur une chaîne vide dans la phase de préparation :\n\n```python\n# Ceci est exécuté au début des coroutines\nresponse_kb1 = ''\nresponse_kb2 = ''\n```\n\nEt ensuite, dans la phase Run, vérifiez si les deux variables ont été définies, et abandonnez les coroutines si c'est le cas :\n\n```python\n# Les valeurs qui ne sont pas une chaîne vide sont vraies pour Python\n# Ce code sera exécuté plusieurs fois !\nif response_kb1 and response_kb2:\n    raise AbortCoroutines()\n```\n\n## Expressions run-if\n\nLe comportement des expressions run-if dans les COROUTINES est un peu différent de celui des éléments SEQUENCE. Plus précisément, les expressions run-if dans les COROUTINES sont évaluées pendant la phase de préparation. Voir aussi :\n\n- %link:prepare-run%"
  },
  "Using the form plugins": {
    "fr": "Utilisation des plugins de formulaire"
  },
  "Mouse responses are collected with the MOUSE_RESPONSE item. The MOUSE_RESPONSE is primarily intended to collect individual mouse clicks. If you want to collect mouse-cursor trajectories, take a look at the MOUSETRAP plugins:\n\n- %link:mousetracking%\n\n<notranslate>[TOC]</notranslate>\n\n\n## Response variables\n\nThe MOUSE_RESPONSE sets the standard response variables as described here:\n\n- %link:manual/variables%\n\n\n## Mouse-button names\n\nMouse buttons have a number (`1`, etc.) as well as a name (`left_button`, etc.). Both can be used to specify correct and allowed responses, but the `response` variable will be set to a number.\n\n- `left_button` corresponds to `1`\n- `middle_button` corresponds to `2`\n- `right_button` corresponds to `3`\n- `scroll_up` corresponds to `4`\n- `scroll_down` corresponds to `5`\n\n\n## Correct response\n\nThe *Correct response* field indicates which response is considered correct. After a correct response, the `correct` variable is automatically set to 1; after an incorrect response or a timeout (i.e. everything else), `correct` is set to 0; if no correct response is specified, `correct` is set to 'undefined'.\n\nYou can indicate the correct response in three main ways:\n\n- *Leave the field empty.* If you leave the *Correct response* field empty, OpenSesame will automatically check if a variable called `correct_response` has been defined, and, if so, use this variable for the correct response.\n- *Enter a literal value.* You can explicitly enter a response, such as 1. This is only useful if the correct response is fixed.\n- *Enter a variable name.* You can enter a variable, such as '{cr}'. In this case, this variable will be used for the correct response.\n\n\n## Allowed responses\n\nThe *Allowed responses* field indicates a list of allowed responses. All other responses will be ignored, except for 'Escape', which will pause the experiment. The allowed responses should be a semicolon-separated list of responses, such as '1;3' to allow the left and right mouse buttons. To accept all responses, leave the *Allowed responses* field empty.\n\n\n<notranslate>include: include/timeout.md--%\n\n## Coordinates and regions of interest (ROIs)\n\nThe `cursor_x` and `cursor_y` variables hold the location of the mouse click.\n\nIf you indicate a linked SKETCHPAD, the variable `cursor_roi` will hold a comma-separated list of names of elements that contain the clicked coordinate. In other words, elements on the SKETCHPAD automatically serve as regions of interest for the mouse click.\n\n<notranslate>\nvideo:\n source: youtube\n id: VidMouseROI\n videoid: 21cgX_zHDiA\n width: 640\n height: 360\n caption: |\n  Collecting mouse clicks and using regions of interest.\n</notranslate>\n\n## Collecting mouse responses in Python\n\nYou can use the `mouse` object to collect mouse responses in Python:\n\n- %link:manual/python/mouse%\n": {
    "fr": "Les réponses de la souris sont collectées avec l'élément MOUSE_RESPONSE. Le MOUSE_RESPONSE est principalement destiné à collecter des clics de souris individuels. Si vous souhaitez collecter des trajectoires de curseur de souris, jetez un œil aux plugins MOUSETRAP :\n\n- %link:mousetracking%\n\n<notranslate>[TOC]</notranslate>\n\n## Variables de réponse\n\nLe MOUSE_RESPONSE définit les variables de réponse standard comme décrit ici :\n\n- %link:manual/variables%\n\n## Noms des boutons de la souris\n\nLes boutons de la souris ont un numéro (`1`, etc.) ainsi qu'un nom (`left_button`, etc.). Les deux peuvent être utilisés pour spécifier des réponses correctes et autorisées, mais la variable `response` sera définie sur un nombre.\n\n- `left_button` correspond à `1`\n- `middle_button` correspond à `2`\n- `right_button` correspond à `3`\n- `scroll_up` correspond à `4`\n- `scroll_down` correspond à `5`\n\n## Réponse correcte\n\nLe champ *Réponse correcte* indique quelle réponse est considérée comme correcte. Après une réponse correcte, la variable `correct` est automatiquement définie sur 1 ; après une réponse incorrecte ou un délai d'attente (c'est-à-dire tout le reste), `correct` est défini sur 0 ; si aucune réponse correcte n'est spécifiée, `correct` est défini sur \"indéfini\".\n\nVous pouvez indiquer la réponse correcte de trois manières principales :\n\n- *Laissez le champ vide.* Si vous laissez le champ *Réponse correcte* vide, OpenSesame vérifiera automatiquement si une variable appelée `correct_response` a été définie et, si c'est le cas, utilisera cette variable pour la réponse correcte.\n- *Entrez une valeur littérale.* Vous pouvez entrer explicitement une réponse, comme 1. Ceci n'est utile que si la réponse correcte est fixe.\n- *Entrez un nom de variable.* Vous pouvez entrer une variable, comme '{cr}'. Dans ce cas, cette variable sera utilisée pour la réponse correcte.\n\n## Réponses autorisées\n\nLe champ *Réponses autorisées* indique une liste de réponses autorisées. Toutes les autres réponses seront ignorées, sauf \"Escape\", qui mettra en pause l'expérience. Les réponses autorisées doivent être une liste de réponses séparées par des points-virgules, comme \"1;3\" pour autoriser les boutons gauche et droit de la souris. Pour accepter toutes les réponses, laissez le champ *Réponses autorisées* vide.\n\n<notranslate>include: include/timeout.md--%</notranslate>\n\n## Coordonnées et régions d'intérêt (ROI)\n\nLes variables `cursor_x` et `cursor_y` conservent l'emplacement du clic de la souris.\n\nSi vous indiquez un SKETCHPAD lié, la variable `cursor_roi` contiendra une liste séparée par des virgules des noms des éléments qui contiennent la coordonnée cliquée. En d'autres termes, les éléments du SKETCHPAD servent automatiquement de régions d'intérêt pour le clic de souris.\n\n<notranslate>\nvideo:\n source: youtube\n id: VidMouseROI\n videoid: 21cgX_zHDiA\n width: 640\n height: 360\n caption: |\n  Collecte des clics de souris et utilisation des régions d'intérêt.\n</notranslate>\n\n## Collecte des réponses de la souris en Python\n\nVous pouvez utiliser l'objet `mouse` pour collecter des réponses de souris en Python :\n\n- %link:manual/python/mouse%"
  },
  "Joystick and gamepad": {
    "fr": "Joystick et manette"
  },
  "Joysticks and gamepads are supported through the JOYSTICK plugin.\n\n<notranslate>[TOC]</notranslate>\n\n<notranslate> include: include/api/joystick.md --%\n": {
    "fr": "Les joysticks et les manettes sont pris en charge via le plugin JOYSTICK.\n\n<notranslate>[TOC]</notranslate>\n\n<notranslate> include: include/api/joystick.md --%"
  },
  "Canvas functions": {
    "fr": "Fonctions de toile"
  },
  "A number of commonly used forms are available as ready-made plugins. These allow you to use common forms, without any need for scripting.\n\n- FORM_CONSENT is a simple digital consent form (disclaimer: some journals may require *written* consent)\n- FORM_MULTIPLE_CHOICE allows you to present multiple choice questions\n- FORM_TEXT_DISPLAY is a simple text display that you can use to show instructions etc.\n- FORM_TEXT_INPUT is a simple text input display that allows you to ask a question and collect a multi-character response from the participant\n\nThe FORM_BASE plugin is special. It allows you to define custom forms using OpenSesame script, as described here:\n\n- %link:manual/forms/custom%\n\n<notranslate>\nfigure:\n id: FigFormPlugins\n source: form-plugins.png\n caption: The FORM plugins in the item toolbar.\n</notranslate>\n": {
    "fr": "Un certain nombre de formulaires couramment utilisés sont disponibles sous forme de plugins prêts à l'emploi. Ceux-ci vous permettent d'utiliser des formulaires courants, sans avoir besoin de scripter.\n\n- FORM_CONSENT est un simple formulaire de consentement numérique (avertissement: certaines revues peuvent exiger un consentement *écrit*)\n- FORM_MULTIPLE_CHOICE vous permet de présenter des questions à choix multiples\n- FORM_TEXT_DISPLAY est un simple affichage de texte que vous pouvez utiliser pour montrer des instructions, etc.\n- FORM_TEXT_INPUT est un simple affichage de saisie de texte qui vous permet de poser une question et de recueillir une réponse de plusieurs caractères de la part du participant\n\nLe plugin FORM_BASE est spécial. Il vous permet de définir des formulaires personnalisés à l'aide du script OpenSesame, comme décrit ici :\n\n- %link:manual/forms/custom%\n\n<notranslate>\nfigure:\n id: FigFormPlugins\n source: form-plugins.png\n caption: Les plugins FORM dans la barre d'outils d'élément.\n</notranslate>"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About forms, geometries, and widgets\n\nA form is a set of widgets (buttons, labels, text-input fields, etc.) arranged into a grid with a particular geometry. In the image below you see an example of a 2 (columns) × 3 (rows) form. A form geometry is simple, and consists of the following properties:\n\n- *margins* ensure that the widgets do not touch the edge of the display. You can have different margins for the top, right, bottom, and left.\n- *spacing* ensure that the widgets do not touch each other. The horizontal and vertical spacing is the same.\n- There are one or more *rows*, possibly of different sizes.\n- There are one or more *columns*, possibly of different sizes.\n\n<notranslate>\nfigure:\n id: FigGeometry\n source: geometry.png\n caption: A schematic of FORM geometries.\n</notranslate>\n\nOf course, an empty form is no fun. So let's add the following widgets to create a simple question form:\n\n- A `label` that spans the two columns of the top row. We use this label to give a title to the form.\n- Another `label` that spans the two columns of the middle row. This label contains the actual question.\n- A `button` in the bottom right widget area. This button allows the user to give the $0.05 response.\n- Another `button` in the bottom left widget area. This button allows the user to give the $0.10 response.\n\n<notranslate>\nfigure:\n id: FigSchematicExample1\n source: schematic-example1.png\n caption: A schematic example FORM.\n</notranslate>\n\nThe images above are schematic examples. How this form actually looks in OpenSesame depends on your settings (notably your font and colors), but it may look something like this:\n\n<notranslate>\nfigure:\n id: FigExample1\n source: example1.png\n caption: A example FORM.\n</notranslate>\n\n## Creating custom forms\n\nThere are two ways to create custom forms. You can:\n\n- Use the FORM_BASE item, and specify your form using OpenSesame script.\n- Using Python in an INLINE_SCRIPT item. The Python way is slightly more flexible, but for most purposes both ways can be used.\n\n### Creating forms using OpenSesame script\n\nWe will create the form described above using OpenSesame script. First, drag the FORM_BASE plugin into your experiment. Click on the newly created item to open its tab. Next, click on the 'Edit script' button (with the terminal icon), in the top-right of the tab area. This will open the script editor. Enter the following script to generate the form described above (see the comments for explanations).\n\n~~~\n# Margins are defined as \"top;right;bottom;left\". Each value corresponds to a\n# margin in pixels.\nset margins \"50;100;50;100\"\n# The spacing is simply a value in pixels.\nset spacing \"25\"\n# The sizes of the rows are relative. \"1;2;1\" means that there are three rows,\n# where the middle one is twice as large as the bottom and top ones. So \"1;2;1\"\n# means exactly the same thing as \"3;6;3\". Please note that \"3\" does not mean\n# that there are three equally-sized rows (but \"1;1;1\" does).\nset rows \"1;2;1\"\n# Columns are defined in the same way. \"1;1\" simply means that there\n# are two columns of the same size.\nset cols \"1;1\"\n# Widgets are defined as follows:\n# widget [column] [row] [column span] [row span] [widget type] [keywords]\n#\n# The columns and rows start counting at 0. If you do not want to have your widget\n# span multiple columns and rows, you simply set the column and row span to 1.\nwidget 0 0 2 1 label text=\"Question\"\nwidget 0 1 2 1 label center=\"no\" text=\"A bat and a baseball together cost $1.10. The bat costs one dollar more than the ball. How much does the ball cost?\"\nwidget 0 2 1 1 button text=\"$0.10\"\nwidget 1 2 1 1 button text=\"$0.05\"\n~~~\n\n### Creating forms using Python inline script\n\nThe exact same form can be created using an INLINE_SCRIPT and a bit of Python code. You will notice that the Python code somewhat resembles the OpenSesame script shown above. This is no wonder: The FORM_BASE plugin essentially translates the OpenSesame script into Python code.": {
    "fr": "## À propos des formulaires, des géométries et des widgets\n\nUn formulaire est un ensemble de widgets (boutons, étiquettes, champs de saisie de texte, etc.) disposés dans une grille avec une géométrie particulière. Dans l'image ci-dessous, vous voyez un exemple d'un formulaire 2 (colonnes) × 3 (lignes). La géométrie d'un formulaire est simple et comprend les propriétés suivantes :\n\n- *les marges* garantissent que les widgets ne touchent pas le bord de l'affichage. Vous pouvez avoir des marges différentes pour le haut, la droite, le bas et la gauche.\n- *les espacements* garantissent que les widgets ne se touchent pas les uns les autres. L'espacement horizontal et vertical est le même.\n- Il y a une ou plusieurs *lignes*, éventuellement de différentes tailles.\n- Il y a une ou plusieurs *colonnes*, éventuellement de différentes tailles.\n\n<notranslate>\nfigure:\n id: FigGeometry\n source: geometry.png\n caption: Un schéma des géométries de FORMULAIRE.\n</notranslate>\n\nBien sûr, un formulaire vide n'est pas amusant. Ajoutons donc les widgets suivants pour créer un formulaire de question simple :\n\n- Une `étiquette` qui s'étend sur les deux colonnes de la rangée supérieure. Nous utilisons cette étiquette pour donner un titre au formulaire.\n- Une autre `étiquette` qui s'étend sur les deux colonnes de la rangée du milieu. Cette étiquette contient la question réelle.\n- Un `bouton` dans la zone de widget en bas à droite. Ce bouton permet à l'utilisateur de donner la réponse de 0,05 $.\n- Un autre `bouton` dans la zone de widget en bas à gauche. Ce bouton permet à l'utilisateur de donner la réponse de 0,10 $.\n\n<notranslate>\nfigure:\n id: FigSchematicExample1\n source: schematic-example1.png\n caption: Un exemple schématique de FORMULAIRE.\n</notranslate>\n\nLes images ci-dessus sont des exemples schématiques. À quoi ressemble réellement ce formulaire dans OpenSesame dépend de vos paramètres (notamment votre police et vos couleurs), mais cela peut ressembler à ceci :\n\n<notranslate>\nfigure:\n id: FigExample1\n source: example1.png\n caption: Un exemple de FORMULAIRE.\n</notranslate>\n\n## Créer des formulaires personnalisés\n\nIl y a deux façons de créer des formulaires personnalisés. Vous pouvez :\n\n- Utiliser l'élément FORM_BASE et spécifier votre formulaire à l'aide du script OpenSesame.\n- Utiliser Python dans un élément INLINE_SCRIPT. La méthode Python est légèrement plus flexible, mais pour la plupart des objectifs, les deux méthodes peuvent être utilisées.\n\n### Créer des formulaires en utilisant le script OpenSesame\n\nNous allons créer le formulaire décrit ci-dessus en utilisant le script OpenSesame. Tout d'abord, faites glisser le plugin FORM_BASE dans votre expérience. Cliquez sur l'élément créé pour ouvrir son onglet. Ensuite, cliquez sur le bouton \"Modifier le script\" (avec l'icône du terminal), en haut à droite de la zone des onglets. Cela ouvrira l'éditeur de script. Entrez le script suivant pour générer le formulaire décrit ci-dessus (voir les commentaires pour les explications).\n\n~~~\n# Les marges sont définies comme \"haut;droite;bas;gauche\". Chaque valeur correspond à une\n# marge en pixels.\nset margins \"50;100;50;100\"\n# L'espacement est simplement une valeur en pixels.\nset spacing \"25\"\n# Les tailles des lignes sont relatives. \"1;2;1\" signifie qu'il y a trois lignes,\n# où la ligne du milieu est deux fois plus grande que les lignes du bas et du haut. Donc, \"1;2;1\"\n# signifie exactement la même chose que \"3;6;3\". Veuillez noter que \"3\" ne signifie pas\n# qu'il y a trois lignes de même taille (mais \"1;1;1\" le fait).\nset rows \"1;2;1\"\n# Les colonnes sont définies de la même manière. \"1;1\" signifie simplement qu'il y\n# a deux colonnes de même taille.\nset cols \"1;1\"\n# Les widgets sont définis comme suit :\n# widget [colonne] [ligne] [largeur de colonne] [hauteur de ligne] [type de widget] [mots-clés]\n#\n# Les colonnes et les lignes commencent à compter à 0. Si vous ne voulez pas que votre widget\n# s'étende sur plusieurs colonnes et lignes, il vous suffit de définir la largeur et la hauteur de la ligne à 1.\nwidget 0 0 2 1 label text=\"Question\"\nwidget 0 1 2 1 label center=\"no\" text=\"Une batte et une balle de baseball coûtent ensemble 1,10 $. La batte coûte un dollar de plus que la balle. Combien coûte la balle ?\"\nwidget 0 2 1 1 button text=\"0,10 $\"\nwidget 1 2 1 1 button text=\"0,05 $\"\n~~~\n\n### Créer des formulaires en utilisant un script Python en ligne\n\nLe même formulaire peut être créé à l'aide d'un INLINE_SCRIPT et un peu de code Python. Vous remarquerez que le code Python ressemble un peu au script OpenSesame présenté ci-dessus. Ce n'est pas étonnant : le plugin FORM_BASE traduit essentiellement le script OpenSesame en code Python."
  },
  "Form variables": {
    "fr": "Variables de formulaire"
  },
  "<div class=\"cogsci-jsdoc\" markdown=\"1\">\n\n<notranslate> include: include/javascript-api/canvas.md --%\n\n</div>\n": {
    "fr": "<div class=\"cogsci-jsdoc\" markdown=\"1\">\n\n<notranslate> include: include/javascript-api/canvas.md --%\n\n</div>"
  },
  "Beginner tutorial: gaze cuing": {
    "fr": "Tutoriel débutant : orientation du regard"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About Sona Systems\n\nSona Systems is an online tool that many universities use for recruiting participants, granting course credit to student participants, etc.\n\nSee also:\n\n- <https://www.sona-systems.com/help/integration_test.aspx>\n\n\n## Create a study on JATOS\n\nFirst, import your experiment into JATOS, as described above. Next, go the Worker & Batch Manager, activate the General Multiple Worker, get a URL by clicking on Get Link, and copy it.\n\n\n## Create a study on Sona Systems\n\nNext, create a study on Sona Systems. Insert the JATOS study URL in the field labeled \"Study URL\". This will tell Sona Systems how to start the experiment. Importantly, add the following to the end of the URL (this will pass the participant's Sona ID to your experiment):\n\n```bash\n&SONA_ID=%SURVEY_CODE% \n```\n\nSona Systems does not use a Redirect URL. This means that Sona Systems will not automatically know whether or not the participant finished the study.\n\n\n## Register the Sona ID in your experiment\n\nEvery participant from Sona is identified by a unique ID. It's important to log this ID in your experiment, because this allows you to tell which participant from Sona corresponds to which entry in the JATOS results. You can do this by adding the script below in the Prepare phase of an `inline_javascript` item at the very start of your experiment.\n\nWhen running the experiment through Sona, this will make the Sona ID available as the experimental variable `sona_participant_id`. When the running the experiment in any other way (e.g. during testing), the variable `sona_participant_id` will be set to -1. \n\n\n```javascript\nif (window.jatos && jatos.urlQueryParameters.SONA_ID) {\n    console.log('Sona information is available')\n    vars.sona_participant_id = jatos.urlQueryParameters.SONA_ID\n} else {\n    console.log('Sona information is not available (setting value to -1)')\n    vars.sona_participant_id = -1\n}\nconsole.log('sona_participant_id = ' + vars.sona_participant_id)\n```\n\n\n## Automatically grant credits on study completion\n\nSona Systems provides a completion URL (client-side), which should be called when a study is succesfully completed, so that Sona Systems can grant credit to the participant (see %FigCompletionURL).\n\n<notranslate>\nfigure:\n id: FigCompletionURL\n source: completion-url.png\n caption: The completion URL in the Sona Systems study information.\n</notranslate>\n\nThe completion URL (client side) has three arguments in it:\n\n- `experiment_id` which identifies the study and is the same for all participants\n- `credit_token` which (apparently) changes when you change the study information, but is otherwise the same for all participants\n- `survey_code` which corresponds to the Sona Participant ID, and is therefore different for each participant\n\nCopy the completion URL, and replace the `XXX` by `[SONA_ID]`. Go to Study Properties on JATOS, and insert the resulting URL into the End Redirect URL field.\n\n<notranslate>\nfigure:\n id: FigEndRedirectURL\n source: end-redirect-url.png\n caption: The end-redirect URL in the JATOS study properties.\n</notranslate>\n": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n\n## À propos de Sona Systems\n\nSona Systems est un outil en ligne que de nombreuses universités utilisent pour recruter des participants, accorder des crédits de cours aux participants étudiants, etc.\n\nVoir aussi :\n\n- <https://www.sona-systems.com/help/integration_test.aspx>\n\n\n## Créer une étude sur JATOS\n\nD'abord, importez votre expérience dans JATOS, comme décrit ci-dessus. Ensuite, allez dans le Gestionnaire de travailleurs et de lots, activez le travailleur général multiple, obtenez une URL en cliquant sur Obtenir un lien, et copiez-la.\n\n\n## Créer une étude sur Sona Systems\n\nEnsuite, créez une étude sur Sona Systems. Insérez l'URL de l'étude JATOS dans le champ intitulé \"Study URL\". Cela indiquera à Sona Systems comment démarrer l'expérience. Importantly, ajoutez ce qui suit à la fin de l'URL (cela passera l'ID Sona du participant à votre expérience) :\n\n```bash\n&SONA_ID=%SURVEY_CODE% \n```\n\nSona Systems n'utilise pas d'URL de redirection. Cela signifie que Sona Systems ne saura pas automatiquement si le participant a terminé l'étude ou non.\n\n\n## Enregistrez l'ID Sona dans votre expérience\n\nChaque participant de Sona est identifié par un ID unique. Il est important de consigner cet ID dans votre expérience, car cela vous permet de savoir quel participant de Sona correspond à quelle entrée dans les résultats de JATOS. Vous pouvez le faire en ajoutant le script ci-dessous dans la phase de préparation d'un élément `inline_javascript` au tout début de votre expérience.\n\nLors de l'exécution de l'expérience via Sona, cela rendra l'ID Sona disponible en tant que variable expérimentale `sona_participant_id`. Lors de l'exécution de l'expérience d'une autre manière (par exemple pendant les tests), la variable `sona_participant_id` sera définie sur -1. \n\n```javascript\nif (window.jatos && jatos.urlQueryParameters.SONA_ID) {\n    console.log('Les informations Sona sont disponibles')\n    vars.sona_participant_id = jatos.urlQueryParameters.SONA_ID\n} else {\n    console.log('Les informations Sona ne sont pas disponibles (valeur fixée à -1)')\n    vars.sona_participant_id = -1\n}\nconsole.log('sona_participant_id = ' + vars.sona_participant_id)\n```\n\n## Accorder automatiquement des crédits à la fin de l'étude\n\nSona Systems fournit une URL de fin (côté client), qui doit être appelée lorsqu'une étude est terminée avec succès, afin que Sona Systems puisse accorder des crédits au participant (voir %FigCompletionURL).\n\n<notranslate>\nfigure:\n id: FigCompletionURL\n source: completion-url.png\n légende: L'URL de fin dans les informations de l'étude Sona Systems.\n</notranslate>\n\nL'URL de fin (côté client) a trois arguments :\n\n- `experiment_id` qui identifie l'étude et est la même pour tous les participants\n- `credit_token` qui (apparemment) change lorsque vous modifiez les informations de l'étude, mais est sinon la même pour tous les participants\n- `survey_code` qui correspond à l'ID de participant Sona, et est donc différent pour chaque participant\n\nCopiez l'URL de fin et remplacez les `XXX` par `[SONA_ID]`. Allez dans les propriétés de l'étude sur JATOS et insérez l'URL résultante dans le champ URL de fin de redirection.\n\n<notranslate>\nfigure:\n id: FigEndRedirectURL\n source: end-redirect-url.png\n légende: L'URL de fin de redirection dans les propriétés de l'étude JATOS.\n</notranslate>"
  },
  "Prolific": {
    "fr": "Prolific"
  },
  "~~~ .yaml\nname: opensesame_3.1.4-py2.7-win32-1\nchannels:\n- cogsci\n- defaults\ndependencies:\n- python==2.7.12\n- anaconda-client=1.4.0=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.4=py27_0\n- bzip2=1.0.6=vc9_3\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.0.3=py_0\n- psychopy=1.82.01=py27_0\n- pygame=1.9.2a0=py27_0\n- pyglet=1.2.4=py27_0\n- python-datamatrix=0.3.1=py_0 # updated in 3.1.3\n- python-fileinspector=1.0.2=py_0 # updated in 3.1.3\n- python-opensesame=3.1.4=py_0 # updated in 3.1.4\n- python-pseudorandom=0.2.2=py27_0\n- python-pygaze=0.6.0a21=py_0 # Updated in 3.1.3\n- python-qdatamatrix=0.1.9=py_0 # updated in 3.1.3\n- python-qnotifications=1.1.1=py_0 # updated in 3.1.3\n- python-qosf=1.1.8=py_0\n- python-qprogedit=4.0.6=py_0 # updated in 3.1.4\n- qscintilla2=2.9.1=py27_vc9_0\n- requests-oauthlib=0.6.1=py_0\n- webcolors=1.5=py27_0\n- configparser=3.5.0b2=py27_1\n- decorator=4.0.10=py27_0\n- entrypoints=0.2.2=py27_0\n- freetype=2.5.5=vc9_1\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- ipykernel=4.3.1=py27_0\n- ipython=4.2.0=py27_0\n- ipython_genutils=0.1.0=py27_0\n- ipywidgets=4.1.1=py27_0\n- jinja2=2.8=py27_1\n- jpeg=8d=vc9_0\n- jsonschema=2.5.1=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=4.3.0=py27_0\n- jupyter_console=4.1.1=py27_0\n- jupyter_core=4.1.0=py27_0\n- libpng=1.6.22=vc9_0\n- libtiff=4.0.6=vc9_2\n- markdown=2.6.6=py27_0\n- markupsafe=0.23=py27_2\n- mistune=0.7.2=py27_0\n- mkl=11.3.3=1\n- nbconvert=4.2.0=py27_0\n- nbformat=4.0.1=py27_0\n- notebook=4.2.1=py27_0\n- numpy=1.11.1=py27_0\n- openssl=1.0.2h=vc9_0\n- path.py=8.2.1=py27_0\n- pickleshare=0.5=py27_0\n- pillow=3.2.0=py27_1\n- pip=8.1.2=py27_0\n- pyflakes=1.2.3=py27_0\n- pygments=2.1.3=py27_0\n- pyopengl=3.1.1a1=np111py27_0\n- pyopengl-accelerate=3.1.1a1=np111py27_0\n- pyqt=4.11.4=py27_6\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.12=0\n- python-dateutil=2.5.3=py27_0\n- pytz=2016.4=py27_0\n- pyyaml=3.11=py27_4\n- pyzmq=15.2.0=py27_0\n- qt=4.8.7=vc9_8\n- qtawesome=0.3.3=py27_0\n- qtconsole=4.2.1=py27_0\n- qtpy=1.0.2=py27_0\n- requests=2.10.0=py27_0\n- scipy=0.17.1=np111py27_1\n- setuptools=23.0.0=py27_0\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.16.9=py27_2\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.4.0.2=py27_1\n- tornado=4.3=py27_1\n- traitlets=4.2.1=py27_0\n- vs2008_runtime=9.00.30729.1=2\n- wheel=0.29.0=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.8=vc9_3\n- pip:\n  - cffi==1.7.0\n  - expyriment==0.8.0 # Upgrade manually to 0.8.1.opensesame2\n  - imageio==1.5\n  - mediadecoder==0.1.5\n  - moviepy==0.2.2.11  \n  - opensesame-extension-osf==1.0.11\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-windows-launcher==0.4.1\n  - pycparser==2.14\n  - python-bidi==0.4.0\n  - sounddevice==0.3.3\n  - tqdm==4.7.6\n  - pyaudio==0.2.9 # Added in 3.1.3\n  - openpyxl==2.4.0 # Added in 3.1.3\nprefix: opensesame_3.1.4-py2.7-win32-1\n~~~\n": {
    "fr": "~~~ .yaml\nname: opensesame_3.1.4-py2.7-win32-1\nchannels:\n- cogsci\n- defaults\ndependencies:\n- python==2.7.12\n- anaconda-client=1.4.0=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.4=py27_0\n- bzip2=1.0.6=vc9_3\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.0.3=py_0\n- psychopy=1.82.01=py27_0\n- pygame=1.9.2a0=py27_0\n- pyglet=1.2.4=py27_0\n- python-datamatrix=0.3.1=py_0 # mis à jour dans 3.1.3\n- python-fileinspector=1.0.2=py_0 # mis à jour dans 3.1.3\n- python-opensesame=3.1.4=py_0 # mis à jour dans 3.1.4\n- python-pseudorandom=0.2.2=py27_0\n- python-pygaze=0.6.0a21=py_0 # Mis à jour dans 3.1.3\n- python-qdatamatrix=0.1.9=py_0 # mis à jour dans 3.1.3\n- python-qnotifications=1.1.1=py_0 # mis à jour dans 3.1.3\n- python-qosf=1.1.8=py_0\n- python-qprogedit=4.0.6=py_0 # mis à jour dans 3.1.4\n- qscintilla2=2.9.1=py27_vc9_0\n- requests-oauthlib=0.6.1=py_0\n- webcolors=1.5=py27_0\n- configparser=3.5.0b2=py27_1\n- decorator=4.0.10=py27_0\n- entrypoints=0.2.2=py27_0\n- freetype=2.5.5=vc9_1\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- ipykernel=4.3.1=py27_0\n- ipython=4.2.0=py27_0\n- ipython_genutils=0.1.0=py27_0\n- ipywidgets=4.1.1=py27_0\n- jinja2=2.8=py27_1\n- jpeg=8d=vc9_0\n- jsonschema=2.5.1=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=4.3.0=py27_0\n- jupyter_console=4.1.1=py27_0\n- jupyter_core=4.1.0=py27_0\n- libpng=1.6.22=vc9_0\n- libtiff=4.0.6=vc9_2\n- markdown=2.6.6=py27_0\n- markupsafe=0.23=py27_2\n- mistune=0.7.2=py27_0\n- mkl=11.3.3=1\n- nbconvert=4.2.0=py27_0\n- nbformat=4.0.1=py27_0\n- notebook=4.2.1=py27_0\n- numpy=1.11.1=py27_0\n- openssl=1.0.2h=vc9_0\n- path.py=8.2.1=py27_0\n- pickleshare=0.5=py27_0\n- pillow=3.2.0=py27_1\n- pip=8.1.2=py27_0\n- pyflakes=1.2.3=py27_0\n- pygments=2.1.3=py27_0\n- pyopengl=3.1.1a1=np111py27_0\n- pyopengl-accelerate=3.1.1a1=np111py27_0\n- pyqt=4.11.4=py27_6\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.12=0\n- python-dateutil=2.5.3=py27_0\n- pytz=2016.4=py27_0\n- pyyaml=3.11=py27_4\n- pyzmq=15.2.0=py27_0\n- qt=4.8.7=vc9_8\n- qtawesome=0.3.3=py27_0\n- qtconsole=4.2.1=py27_0\n- qtpy=1.0.2=py27_0\n- requests=2.10.0=py27_0\n- scipy=0.17.1=np111py27_1\n- setuptools=23.0.0=py27_0\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.16.9=py27_2\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.4.0.2=py27_1\n- tornado=4.3=py27_1\n- traitlets=4.2.1=py27_0\n- vs2008_runtime=9.00.30729.1=2\n- wheel=0.29.0=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.8=vc9_3\n- pip:\n  - cffi==1.7.0\n  - expyriment==0.8.0 # Mettre à jour manuellement vers 0.8.1.opensesame2\n  - imageio==1.5\n  - mediadecoder==0.1.5\n  - moviepy==0.2.2.11  \n  - opensesame-extension-osf==1.0.11\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-windows-launcher==0.4.1\n  - pycparser==2.14\n  - python-bidi==0.4.0\n  - sounddevice==0.3.3\n  - tqdm==4.7.6\n  - pyaudio==0.2.9 # Ajouté dans 3.1.3\n  - openpyxl==2.4.0 # Ajouté dans 3.1.3\nprefix: opensesame_3.1.4-py2.7-win32-1\n~~~"
  },
  "Implicit Association Task": {
    "fr": "Tâche d'Association Implicite"
  },
  "<notranslate>[TOC]</notranslate>\n\n## About form variables\n\nWhen you present a form with multiple `checkbox`es, you generally want to know which `checkbox` the user has checked. Similarly, when you present a form with two `button`s, you want to know which `button` the user has clicked. This information is available through variables that are automatically set when the user interacts with a form. You can specify yourself which response variables should be used. How this is done depends on how you have created your form.\n\n### In ready-made form plugins\n\nWhen you use one of the ready-made form plugins, such as FORM_TEXT_INPUT, you can specify the name of the response variable directly in the plugin controls.\n\n### In custom forms\n\nYou can use the `var` keyword to indicate which variable should be used. For example, the following OpenSesame script, which you can enter into a FORM_BASE plugin, indicates that the response from a `text_input` widget should be stored in a variable called `my_response_var`:\n\n```python\nwidget 0 0 1 1 text_input var=my_response_var\n```\n\nThe equivalent Python code is:\n\n~~~ .python\nmy_widget = TextInput(var='my_response_var')\n~~~\n\nSee also:\n\n- %link:manual/forms/widgets%\n\n## Widget-specific information\n\nEach widget uses its response variable in a slightly different way.\n\n### button\n\nThe `button` widget sets the response variable to 'yes' if it has been clicked and to 'no' if it has not.\n\n### checkbox\n\nThe `checkbox` widget sets the response variable to a semicolon-separated list of the text on all checkboxes that have been checked (for that variable), or 'no' if no `checkbox` has been checked (for that variable). This sounds a bit complicated, so let's see a few examples.\n\n```python\nwidget 0 0 1 1 checkbox group=\"1\" text=\"A\" var=\"my_response_var\"\nwidget 1 0 1 1 checkbox group=\"1\" text=\"B\" var=\"my_response_var\"\nwidget 1 1 1 1 button text=\"Next\"\n```\n\nHere there are two `checkbox`es with the text 'A' and 'B'. Both part of the same group, called '1'. Both have the same response variable, called `my_response_var`. If 'A' is checked, `my_response_var` will be 'A'. If 'B' is checked, `my_response_var` will be 'B'. If neither is checked, `my_response_var` will be 'no'. Note that only one `checkbox` in the same group can be checked, so `my_response_var` will *never* be 'A;B' in this example.\n\nNow let's consider the same script, with the sole difference that the two `checkbox`es are not part of a group:\n\n```python\nwidget 0 0 1 1 checkbox text=\"A\" var=\"my_response_var\"\nwidget 1 0 1 1 checkbox text=\"B\" var=\"my_response_var\"\nwidget 1 1 1 1 button text=\"Next\"\n```\n\nIn this case, the situation is much like described above, with the exception that both `checkbox`es can be checked at the same time, in which case `my_response_var` will be set to 'A;B'.\n\nYou cannot use the same response variable for `checkbox`es in different groups.\n\n### image\n\nVariables are not applicable to the `image` widget.\n\n### image_button\n\nThe `image_button` widget sets the response variable to 'yes' if it has been clicked and to 'no' if it has not.\n\n### label\n\nVariables are not applicable to the `label` widget.\n\n### rating_scale\n\nThe `rating_scale` widget sets the response variable to the number of the option that has been clicked, where '0' is the first option (zero-based indexing). If no option has been selected, the response variable is set to 'None'.\n\n### text_input\n\nThe `text_input` widget sets the response variable to the entered text.\n": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos des variables de formulaire\n\nLorsque vous présentez un formulaire avec plusieurs `checkbox`, vous voulez généralement savoir quelle `checkbox` l'utilisateur a coché. De même, lorsque vous présentez un formulaire avec deux `button`s, vous voulez savoir quel `button` l'utilisateur a cliqué. Cette information est disponible via des variables qui sont automatiquement définies lorsque l'utilisateur interagit avec un formulaire. Vous pouvez spécifier vous-même quelles variables de réponse doivent être utilisées. La manière dont cela se fait dépend de la manière dont vous avez créé votre formulaire.\n\n### Dans les plugins de formulaire prêts à l'emploi\n\nLorsque vous utilisez l'un des plugins de formulaire prêts à l'emploi, tels que FORM_TEXT_INPUT, vous pouvez spécifier le nom de la variable de réponse directement dans les contrôles du plugin.\n\n### Dans les formulaires personnalisés\n\nVous pouvez utiliser le mot-clé `var` pour indiquer quelle variable doit être utilisée. Par exemple, le script OpenSesame suivant, que vous pouvez entrer dans un plugin FORM_BASE, indique que la réponse d'un widget `text_input` doit être stockée dans une variable appelée `my_response_var` :\n\n```python\nwidget 0 0 1 1 text_input var=my_response_var\n```\n\nLe code Python équivalent est :\n\n~~~ .python\nmy_widget = TextInput(var='my_response_var')\n~~~\n\nVoir aussi :\n\n- %link:manuel/forms/widgets%\n\n## Informations spécifiques au widget\n\nChaque widget utilise sa variable de réponse d'une manière légèrement différente.\n\n### button\n\nLe widget `button` définit la variable de réponse sur 'yes' s'il a été cliqué et sur 'no' s'il ne l'a pas été.\n\n### checkbox\n\nLe widget `checkbox` définit la variable de réponse sur une liste séparée par des points-virgules du texte de toutes les cases à cocher qui ont été cochées (pour cette variable), ou sur 'no' si aucune `checkbox` n'a été cochée (pour cette variable). Cela peut sembler un peu compliqué, donc voyons quelques exemples.\n\n```python\nwidget 0 0 1 1 checkbox group=\"1\" text=\"A\" var=\"my_response_var\"\nwidget 1 0 1 1 checkbox group=\"1\" text=\"B\" var=\"my_response_var\"\nwidget 1 1 1 1 button text=\"Suivant\"\n```\n\nIci, il y a deux `checkbox` avec le texte 'A' et 'B'. Les deux font partie du même groupe, appelé '1'. Les deux ont la même variable de réponse, appelée `my_response_var`. Si 'A' est cochée, `my_response_var` sera 'A'. Si 'B' est cochée, `my_response_var` sera 'B'. Si aucune n'est cochée, `my_response_var` sera 'no'. Notez que seulement une `checkbox` dans le même groupe peut être cochée, donc `my_response_var` ne sera *jamais* 'A;B' dans cet exemple.\n\nConsiderons maintenant le même script, avec la seule différence que les deux `checkbox` ne font pas partie d'un groupe :\n\n```python\nwidget 0 0 1 1 checkbox text=\"A\" var=\"my_response_var\"\nwidget 1 0 1 1 checkbox text=\"B\" var=\"my_response_var\"\nwidget 1 1 1 1 button text=\"Suivant\"\n```\n\nDans ce cas, la situation est beaucoup comme décrit ci-dessus, à l'exception que les deux `checkbox` peuvent être cochées en même temps, auquel cas `my_response_var` sera définie sur 'A;B'.\n\nVous ne pouvez pas utiliser la même variable de réponse pour les `checkbox` dans différents groupes.\n\n### image\n\nLes variables ne sont pas applicables au widget `image`.\n\n### image_button\n\nLe widget `image_button` définit la variable de réponse sur 'yes' s'il a été cliqué et sur 'no' s'il ne l'a pas été.\n\n### label\n\nLes variables ne sont pas applicables au widget `label`.\n\n### rating_scale\n\nLe widget `rating_scale` définit la variable de réponse sur le numéro de l'option qui a été cliquée, où '0' est la première option (indexation à partir de zéro). Si aucune option n'a été sélectionnée, la variable de réponse est définie sur 'None'.\n\n### text_input\n\nLe widget `text_input` définit la variable de réponse sur le texte saisi."
  },
  "First, drag an INLINE_SCRIPT into your experiment. Select the newly created item to open its tab, and add the following script into the Run phase of the INLINE_SCRIPT item (see the comments for explanations).\n\n~~~ .python\n# Create a form\nform = Form(\n    cols=[1,1], rows=[1,2,1],\n    margins=(50,100,50,100), spacing=25\n)\n# Create four widgets\nlabelTitle = Label(text='Question')\nlabelQuestion = Label(\n    text='A bat and a baseball together cost $1.10. The bat costs one dollar more than the ball. How much does the ball cost?',\n    center=False\n)\nbutton5cts = Button(text='$0.05')\nbutton10cts = Button(text='$0.10')\n# Add the widgets to the form. The position in the form is indicated as a\n# (column, row) tuple.\nform.set_widget(labelTitle, (0,0), colspan=2)\nform.set_widget(labelQuestion, (0,1), colspan=2)\nform.set_widget(button5cts, (0,2))\nform.set_widget(button10cts, (1,2))\n# Execute the form! In this case, the form will return the text of the button that\n# was clicked. This is one way to get a return value out of the form. Another way\n# is to use the 'var' keyword, supported some of the widgets.\nbutton_clicked = form._exec()\n~~~\n\nIf you want a specific widget to receive the focus when the form is executed, you can use the `focus_wiget` keyword:\n\n~~~ .python\nbutton_clicked = form._exec(focus_widget=button5cts)\n~~~\n\n### Non-interactive forms\n\nUsually, a form will have an input field, a button, or some other interactive element. However, you can also use forms without having any interactive element. To do this in OpenSesame script, you set `only_render` to \"yes\":\n\n```python\nset only_render yes\n```\n\nTo this in a Python INLINE_SCRIPT, you call `form.render()`, instead of `form._exec()`.\n\n### Themes\n\nForms support theming. Currently, two themes are available: 'gray' and 'plain'. The 'gray' theme is the default. Although the 'gray' theme is already quite plain, the 'plain' theme is even more basic. You can choose a theme like this in OpenSesame script:\n\n```python\nset theme plain\n```\n\nAnd by using the `theme` keyword in Python inline script:\n\n~~~ .python\nform = Form(theme='plain')\n~~~\n\n### Available widgets and keywords\n\nFor a list of available widgets and keywords, see:\n\n- %link:manual/forms/widgets%\n\n### Validating input\n\nTo see how you can validate form input, see:\n\n- %link:manual/forms/validation%\n\n## Another example\n\nThe following OpenSesame script (in a FORM_BASE plugin) will produce a questionnaire of three rating scales plus a next button:\n\n```python\nset rows \"1;1;1;1;1\"\nset cols \"1;1\"\nwidget 0 0 2 1 label text=\"Indicate how much you agree with the following statements\"\nwidget 0 1 1 1 label center=\"no\" text=\"Forms are easy\"\nwidget 1 1 1 1 rating_scale var=\"question1\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 2 1 1 label center=\"no\" text=\"I like data\"\nwidget 1 2 1 1 rating_scale var=\"question2\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 3 1 1 label center=\"no\" text=\"I like questionnaires\"\nwidget 1 3 1 1 rating_scale var=\"question3\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 4 2 1 button text=\"Next\"\n```\n\nThe following Python inline_script will produce the same questionnaire.": {
    "fr": "Tout d'abord, faites glisser un INLINE_SCRIPT dans votre expérience. Sélectionnez l'élément nouvellement créé pour ouvrir son onglet et ajoutez le script suivant dans la phase d'exécution de l'élément INLINE_SCRIPT (voir les commentaires pour les explications).\n\n~~~ .python\n# Créer un formulaire\nform = Form(\n    cols=[1,1], rows=[1,2,1],\n    margins=(50,100,50,100), spacing=25\n)\n# Créer quatre widgets\nlabelTitle = Label(text='Question')\nlabelQuestion = Label(\n    text='Une chauve-souris et une balle de baseball coûtent ensemble 1,10 $. La chauve-souris coûte un dollar de plus que la balle. Combien coûte la balle ?',\n    center=False\n)\nbutton5cts = Button(text='0,05 $')\nbutton10cts = Button(text='0,10 $')\n# Ajouter les widgets au formulaire. La position dans le formulaire est indiquée sous la forme\n# d'un tuple (colonne, ligne).\nform.set_widget(labelTitle, (0,0), colspan=2)\nform.set_widget(labelQuestion, (0,1), colspan=2)\nform.set_widget(button5cts, (0,2))\nform.set_widget(button10cts, (1,2))\n# Exécuter le formulaire! Dans ce cas, le formulaire renverra le texte du bouton\n# qui a été cliqué. C'est une façon d'obtenir une valeur de retour du formulaire. Une autre façon\n# est d'utiliser le mot-clé 'var', pris en charge par certains des widgets.\nbutton_clicked = form._exec()\n~~~\n\nSi vous voulez qu'un widget spécifique reçoive le focus lorsque le formulaire est exécuté, vous pouvez utiliser le mot-clé `focus_wiget` :\n\n~~~ .python\nbutton_clicked = form._exec(focus_widget=button5cts)\n~~~\n\n### Formulaires non interactifs\n\nHabituellement, un formulaire aura un champ de saisie, un bouton ou un autre élément interactif. Cependant, vous pouvez également utiliser des formulaires sans avoir d'élément interactif. Pour ce faire dans un script OpenSesame, définissez `only_render` sur \"yes\" :\n\n```python\nset only_render yes\n```\n\nPour ce faire dans un script Python INLINE_SCRIPT, vous appelez `form.render()`, au lieu de `form._exec()`.\n\n### Thèmes\n\nLes formulaires prennent en charge le thème. Actuellement, deux thèmes sont disponibles: 'gray' et 'plain'. Le thème 'gray' est celui par défaut. Bien que le thème 'gray' soit déjà assez clair, le thème 'plain' est encore plus basique. Vous pouvez choisir un thème comme celui-ci dans OpenSesame script:\n\n```python\nset theme plain\n```\n\nEt en utilisant le mot-clé `theme` dans un script Python en ligne:\n\n~~~ .python\nform = Form(theme='plain')\n~~~\n\n### Widgets et mots-clés disponibles\n\nPour une liste des widgets et mots-clés disponibles, consultez:\n\n- %link:manual/forms/widgets%\n\n### Valider la saisie\n\nPour voir comment vous pouvez valider la saisie d'un formulaire, consultez:\n\n- %link:manual/forms/validation%\n\n## Autre exemple\n\nLe script OpenSesame suivant (dans un plugin FORM_BASE) produira un questionnaire de trois échelles d'évaluation plus un bouton suivant:\n\n```python\nset rows \"1;1;1;1;1\"\nset cols \"1;1\"\nwidget 0 0 2 1 label text=\"Indiquez dans quelle mesure vous êtes d'accord avec les affirmations suivantes\"\nwidget 0 1 1 1 label center=\"no\" text=\"Les formulaires sont faciles\"\nwidget 1 1 1 1 rating_scale var=\"question1\" nodes=\"D'accord;Ne sais pas;Pas d'accord\"\nwidget 0 2 1 1 label center=\"no\" text=\"J'aime les données\"\nwidget 1 2 1 1 rating_scale var=\"question2\" nodes=\"D'accord;Ne sais pas;Pas d'accord\"\nwidget 0 3 1 1 label center=\"no\" text=\"J'aime les questionnaires\"\nwidget 1 3 1 1 rating_scale var=\"question3\" nodes=\"D'accord;Ne sais pas;Pas d'accord\"\nwidget 0 4 2 1 button text=\"Suivant\"\n```\n\nLe script Python en ligne suivant produira le même questionnaire."
  },
  "<notranslate>[TOC]</notranslate>\n\n## About OpenSesame\n\nOpenSesame is a program for easy of development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface. For advanced users, OpenSesame supports Python scripting (not covered in this tutorial).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a simple but complete psychological experiment using OpenSesame [(Mathôt, Schreij, & Theeuwes, 2012; Mathôt & March, 2022)][references]. You will use mainly the graphical user interface of OpenSesame (i.e., no Python inline coding), although you will make small modifications to the OpenSesame script. This tutorial takes approximately one hour.\n\n## Resources\n\n- __Download__ -- This tutorial assumes that you are running OpenSesame version 4.0.0 or later. To check which version you are running, see the bottom right of the 'Get started' tab (see %FigGetStarted). You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ -- A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ -- A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n\n## The experiment\n\nIn this tutorial, you will create a gaze-cuing experiment as introduced by [Friesen and Kingstone (1998)][references]. In this experiment, a face is presented in the center of the screen (%FigGazeCuing). This face looks either to the right or to the left. A target letter (an 'F' or an 'H') is presented to the left or right of the face. A distractor stimulus (the letter 'X') is presented on the other side of the face. The task is to indicate as quickly as possible whether the target letter is an 'F' or an 'H'. In the congruent condition, the face looks at the target. In the incongruent condition, the face looks at the distractor. As you may have guessed, the typical finding is that participant respond faster in the congruent condition than in the incongruent condition, even though the direction of gaze is not predictive of the target location. This shows that our attention is automatically guided by other people's gaze, even in situations where this doesn't serve any purpose. (And even when the face is just a smiley!)\n\n<notranslate>\nfigure:\n id: FigGazeCuing\n source: gaze-cuing.png\n caption: |\n  The gaze-cuing paradigm [(Friesen and Kingstone, 1998)][references] that you will implement in this tutorial. This example depicts a trial in the incongruent condition, because the smiley looks at the distractor ('X') and not at the target ('F').\n</notranslate>\n\nThe experiment consists of a practice and an experimental phase. Visual feedback will be presented after every block of trials. A sound will be played after every incorrect response.\n\n## Experimental design\n\nThis design:\n\n- is *within-subject*, because all participants do all conditions\n- is *fully crossed* (or full-factorial), because all combinations of conditions occur\n- has three factors (or factors):\n    - *gaze side* with two levels (left, right)\n    - *target side* with two levels (left, right)\n    - *target letter* with two levels (F, H)\n- has N subjects\n\n\nSee also %DesignScreencast for an explanation of the logic and design of the experiment:\n\n\n<notranslate>\nvideo:\n source: youtube\n id: DesignScreencast\n videoid: aWvibRH6D4E\n width: 640\n height: 360\n caption: |\n  An explanation of the experimental logic and design.\n</notranslate>\n\n\n## Step 1: Create the main sequence": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos d'OpenSesame\n\nOpenSesame est un programme pour faciliter le développement d'expériences comportementales en psychologie, neurosciences et économie expérimentale. Pour les débutants, OpenSesame offre une interface graphique complète et point-and-click. Pour les utilisateurs avancés, OpenSesame prend en charge les scripts Python (non couverts dans ce tutoriel).\n\nOpenSesame est disponible gratuitement sous la [Licence publique générale v3][gpl].\n\n## À propos de ce tutoriel\n\nCe tutoriel montre comment créer une expérience psychologique simple mais complète en utilisant OpenSesame [(Mathôt, Schreij et Theeuwes, 2012; Mathôt & March, 2022)][references]. Vous utiliserez principalement l'interface utilisateur graphique d'OpenSesame (c'est-à-dire sans codage Python), bien que vous apportiez de petites modifications au script OpenSesame. Ce tutoriel prend environ une heure.\n\n## Ressources\n\n- __Téléchargement__ -- Ce tutoriel suppose que vous exécutez la version 4.0.0 d'OpenSesame ou ultérieure. Pour vérifier la version que vous utilisez, consultez le coin inférieur droit de l'onglet \"Commencer\" (voir %FigGetStarted). Vous pouvez télécharger la version la plus récente d'OpenSesame depuis:\n\t- %link:download%\n- __Documentation__ -- Un site de documentation dédié est disponible à l'adresse :\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ -- Un forum d'assistance est disponible à l'adresse :\n\t- <http://forum.cogsci.nl/>\n\n## L'expérience\n\nDans ce tutoriel, vous allez créer une expérience de guidage du regard comme indiqué par [Friesen et Kingstone (1998)][references]. Dans cette expérience, un visage est présenté au centre de l'écran (%FigGazeCuing). Ce visage regarde soit à droite, soit à gauche. Une lettre cible (un 'F' ou un 'H') est présentée à gauche ou à droite du visage. Un stimulus distracteur (la lettre 'X') est présenté de l'autre côté du visage. La tâche consiste à indiquer le plus rapidement possible si la lettre cible est un 'F' ou un 'H'. Dans la condition congruente, le visage regarde la cible. Dans la condition incongruente, le visage regarde le distracteur. Comme vous l'avez peut-être deviné, la constatation typique est que les participants répondent plus rapidement dans la condition congruente que dans la condition incongruente, même si la direction du regard n'est pas prédictive de l'emplacement de la cible. Cela montre que notre attention est automatiquement guidée par le regard des autres, même dans des situations où cela ne sert à rien. (Et même quand le visage est juste un smiley!)\n\n<notranslate>\nfigure:\n id: FigGazeCuing\n source: gaze-cuing.png\n caption: |\n  Le paradigme de guidage du regard [(Friesen et Kingstone, 1998)][references] que vous allez mettre en œuvre dans ce tutoriel. Cet exemple représente un essai dans la condition incongruente, car le smiley regarde le distracteur ('X') et non la cible ('F').\n</notranslate>\n\nL'expérience se compose d'une phase d'entraînement et d'une phase expérimentale. Un retour visuel sera présenté après chaque bloc d'essais. Un son sera joué après chaque réponse incorrecte.\n\n## Conception expérimentale\n\nCette conception :\n\n- est *intrasujet*, car tous les participants font toutes les conditions\n- est *entièrement croisée* (ou factorielle complète), car toutes les combinaisons de conditions se produisent\n- a trois facteurs (ou facteurs) :\n    - *côté du regard* avec deux niveaux (gauche, droite)\n    - *côté cible* avec deux niveaux (gauche, droite)\n    - *lettre cible* avec deux niveaux (F, H)\n- a N sujets\n\nVoir également %DesignScreencast pour une explication de la logique et de la conception de l'expérience:\n\n<notranslate>\nvideo:\n source: youtube\n id: DesignScreencast\n videoid: aWvibRH6D4E\n width: 640\n height: 360\n caption: |\n  Une explication de la logique expérimentale et de la conception.\n</notranslate>\n\n## Étape 1 : Créer la séquence principale"
  },
  "~~~ .python\nform = Form(cols=[1,1], rows=[1,1,1,1,1])\ntitle = Label(\n    text='Indicate how much you agree with the following statement'\n)\nquestion1 = Label(text='Forms are easy', center=False)\nquestion2 = Label(text='I like data', center=False)\nquestion3 = Label(text='I like questionnaires', center=False)\nratingScale1 = RatingScale(\n    var='question1',\n    nodes=['Agree', u\"Don't know\", 'Disagree']\n)\nratingScale2 = RatingScale(\n    var='question2',\n    nodes=['Agree', u\"Don't know\", 'Disagree']\n)\nratingScale3 = RatingScale(var='question3',\n    nodes=['Agree', u\"Don't know\", 'Disagree'])\nnextButton = Button(text='Next')\nform.set_widget(title, (0, 0), colspan=2)\nform.set_widget(question1, (0, 1))\nform.set_widget(question2, (0, 2))\nform.set_widget(question3, (0, 3))\nform.set_widget(ratingScale1, (1, 1))\nform.set_widget(ratingScale2, (1, 2))\nform.set_widget(ratingScale3, (1, 3))\nform.set_widget(nextButton, (0, 4), colspan=2)\nform._exec()\n~~~\n\nThe resulting form looks something like this. (The exact appearance depends on your font, colors, etc.)\n\n<notranslate>\nfigure:\n id: FigExample2\n source: example2.png\n caption: Another example FORM.\n</notranslate>\n": {
    "fr": "~~~ .python\nform = Form(cols=[1,1], rows=[1,1,1,1,1])\ntitle = Label(\n    text=\"Indiquez dans quelle mesure vous êtes d'accord avec l'affirmation suivante\"\n)\nquestion1 = Label(text='Les formulaires sont faciles', center=False)\nquestion2 = Label(text=\"J'aime les données\", center=False)\nquestion3 = Label(text=\"J'aime les questionnaires\", center=False)\nratingScale1 = RatingScale(\n    var='question1',\n    nodes=['D\\'accord', \"Ne sais pas\", 'Pas d\\'accord']\n)\nratingScale2 = RatingScale(\n    var='question2',\n    nodes=['D\\'accord', \"Ne sais pas\", 'Pas d\\'accord']\n)\nratingScale3 = RatingScale(var='question3',\n    nodes=['D\\'accord', \"Ne sais pas\", 'Pas d\\'accord']\n)\nnextButton = Button(text='Suivant')\nform.set_widget(title, (0, 0), colspan=2)\nform.set_widget(question1, (0, 1))\nform.set_widget(question2, (0, 2))\nform.set_widget(question3, (0, 3))\nform.set_widget(ratingScale1, (1, 1))\nform.set_widget(ratingScale2, (1, 2))\nform.set_widget(ratingScale3, (1, 3))\nform.set_widget(nextButton, (0, 4), colspan=2)\nform._exec()\n~~~\n\nLe formulaire résultant ressemble à ceci. (L'apparence exacte dépend de votre police, couleurs, etc.)\n\n<notranslate>\nfigure :\n id: FigExample2\n source: example2.png\n caption: Un autre exemple de FORMULAIRE.\n</notranslate>"
  },
  "Validating form input": {
    "fr": "Validation de l'entrée du formulaire"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About Prolific\n\n[Prolific](https://prolific.co/) is a commercial tool for recruiting participants for research. To run OSWeb experiments on Prolific, you need to follow the steps explained below.\n\nSee also:\n\n- <http://www.jatos.org/Use-Prolific.html>\n\n\n## Create a study on JATOS\n\nFirst, import your experiment into JATOS, as described above. Next, go the Worker & Batch Manager, activate the General Multiple Worker, get a URL by clicking on Get Link, and copy it (%FigJatosURL).\n\n\n<notranslate>\nfigure:\n id: FigJatosURL\n source: jatos-url.png\n caption: Get a study URL from JATOS.\n</notranslate>\n\n\n\n## Create a study on Prolific\n\nNext, create a study on Prolific. Under Study Details (%FigProlific), insert the JATOS study URL in the field labeled \"What is the URL of your study?\". This will tell Prolific how to start the experiment. Importantly, add the following to the end of the URL (this will pass important information from Prolific to your experiment):\n\n{% raw %}\n```bash\n&PROLIFIC_PID={{%PROLIFIC_PID%}}&STUDY_ID={{%STUDY_ID%}}&SESSION_ID={{%SESSION_ID%}}\n```\n{% endraw %}\n\nWhen the experiment is finished, Prolific needs to know about it. For this purpose, Prolific uses an End Redirect URL, which is listed in the field labeled \"To prove that participants have completed your study …\". Copy this End Redirect URL. Also check the box labeled \"I've set up my study to redirect to this url at the end\".\n\n<notranslate>\nfigure:\n id: FigProlific\n source: prolific.png\n caption: Study details on Prolific.\n</notranslate>\n\n\n\n## Set an End Redirect URL in JATOS\n\nNow go back to JATOS, and open the Properties of your study (%FigJatosProperties). There, paste the End Redirect URL that you have copied from Prolific in the field labeled \"End Redirect URL\". This will tell JATOS that the participant should be redirected back to Prolific when the experiment is finished, so that Prolific knows that the participant completed the experiment.\n\n\n<notranslate>\nfigure:\n id: FigJatosProperties\n source: jatos-properties.png\n caption: Set the End Redirect URL in JATOS.\n</notranslate>\n\n\n## Register Prolific information in your experiment\n\nEvery participant from Prolific is identified by a unique ID. It's important to log this ID in your experiment, because this allows you to tell which participant from Prolific corresponds to which entry in the JATOS results. You can do this by adding the script below in the Prepare phase of an `inline_javascript` item at the very start of your experiment.\n\nWhen running the experiment through Prolific, this will make the Prolific ID available as the experimental variable `prolific_participant_id`. When the running the experiment in any other way (e.g. during testing), the variable `prolific_participant_id` will be set to -1. The same logic applied to the Prolific Study ID (`prolific_study_id`) and the Prolific Session ID (`prolific_session_id`).\n\n\n```javascript\nif (window.jatos && jatos.urlQueryParameters.PROLIFIC_PID) {\n    console.log('Prolific information is available')\n    vars.prolific_participant_id = jatos.urlQueryParameters.PROLIFIC_PID\n    vars.prolific_study_id = jatos.urlQueryParameters.STUDY_ID\n    vars.prolific_session_id = jatos.urlQueryParameters.SESSION_ID\n} else {\n    console.log('Prolific information is not available (setting values to -1)')\n    vars.prolific_participant_id = -1\n    vars.prolific_study_id = -1\n    vars.prolific_session_id = -1\n}\nconsole.log('prolific_participant_id = ' + vars.prolific_participant_id)\nconsole.log('prolific_study_id = ' + vars.prolific_study_id)\nconsole.log('prolific_session_id = ' + vars.prolific_session_id)\n```\n\n\n## Test the study": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de Prolific\n\n[Prolific](https://prolific.co/) est un outil commercial pour recruter des participants pour la recherche. Pour exécuter des expériences OSWeb sur Prolific, vous devez suivre les étapes expliquées ci-dessous.\n\nVoir aussi :\n\n- <http://www.jatos.org/Use-Prolific.html>\n\n## Créer une étude sur JATOS\n\nD'abord, importez votre expérience dans JATOS, comme décrit ci-dessus. Ensuite, allez dans le Gestionnaire de travailleurs et de lots, activez le travailleur général multiple, obtenez une URL en cliquant sur Obtenir le lien et copiez-la (%FigJatosURL).\n\n<notranslate>\nfigure :\n id: FigJatosURL\n source: jatos-url.png\n légende : Obtenir une URL d'étude de JATOS.\n</notranslate>\n\n## Créer une étude sur Prolific\n\nEnsuite, créez une étude sur Prolific. Sous Détails de l'étude (%FigProlific), insérez l'URL de l'étude JATOS dans le champ étiqueté «Quelle est l'URL de votre étude ?». Cela indiquera à Prolific comment démarrer l'expérience. Importamment, ajoutez ce qui suit à la fin de l'URL (cela transmettra des informations importantes de Prolific à votre expérience) :\n\n{% raw %}\n```bash\n&PROLIFIC_PID={{%PROLIFIC_PID%}}&STUDY_ID={{%STUDY_ID%}}&SESSION_ID={{%SESSION_ID%}}\n```\n{% endraw %}\n\nLorsque l'expérience est terminée, Prolific doit en être informé. À cette fin, Prolific utilise une URL de redirection de fin, qui est répertoriée dans le champ étiqueté «Pour prouver que les participants ont terminé votre étude ...». Copiez cette URL de redirection de fin. Cochez également la case étiquetée \"J'ai configuré mon étude pour rediriger vers cette url à la fin\".\n\n<notranslate>\nfigure:\n id: FigProlific\n source: prolific.png\n légende: Détails de l'étude sur Prolific.\n</notranslate>\n\n## Définir une URL de redirection de fin dans JATOS\n\nRevenez maintenant à JATOS, et ouvrez les Propriétés de votre étude (%FigJatosProperties). Collez-y l'URL de redirection de fin que vous avez copiée de Prolific dans le champ étiqueté \"End Redirect URL\". Cela indiquera à JATOS que le participant doit être redirigé vers Prolific lorsque l'expérience est terminée, afin que Prolific sache que le participant a terminé l'expérience.\n\n<notranslate>\nfigure:\n id: FigJatosProperties\n source: jatos-properties.png\n légende: Définir l'URL de redirection de fin dans JATOS.\n</notranslate>\n\n## Enregistrer les informations Prolific dans votre expérience\n\nChaque participant de Prolific est identifié par un identifiant unique. Il est important de consigner cet identifiant dans votre expérience, car cela vous permet de savoir quel participant de Prolific correspond à quelle entrée dans les résultats JATOS. Vous pouvez le faire en ajoutant le script ci-dessous dans la phase de préparation d'un élément `inline_javascript` au tout début de votre expérience.\n\nLors de l'exécution de l'expérience via Prolific, cela rendra l'ID Prolific disponible sous forme de variable expérimentale `prolific_participant_id`. Lors de l'exécution de l'expérience de toute autre manière (par exemple lors des tests), la variable `prolific_participant_id` sera définie sur -1. La même logique s'applique à l'ID d'étude Prolific (`prolific_study_id`) et à l'ID de session Prolific (`prolific_session_id`).\n\n```javascript\nif (window.jatos && jatos.urlQueryParameters.PROLIFIC_PID) {\n    console.log('Les informations Prolific sont disponibles')\n    vars.prolific_participant_id = jatos.urlQueryParameters.PROLIFIC_PID\n    vars.prolific_study_id = jatos.urlQueryParameters.STUDY_ID\n    vars.prolific_session_id = jatos.urlQueryParameters.SESSION_ID\n} else {\n    console.log('Les informations Prolific ne sont pas disponibles (valeurs définies à -1)')\n    vars.prolific_participant_id = -1\n    vars.prolific_study_id = -1\n    vars.prolific_session_id = -1\n}\nconsole.log('prolific_participant_id = ' + vars.prolific_participant_id)\nconsole.log('prolific_study_id = ' + vars.prolific_study_id)\nconsole.log('prolific_session_id = ' + vars.prolific_session_id)\n```\n\n## Tester l'étude"
  },
  "Go back to the Study Details page on Prolific. At the bottom of the page, there is a Preview button. This allows you to test the experiment by acting as a participant yourself. Don't forget to check the JATOS results to make sure that the experiment has successfully finished, and that all the necessary information (including the Prolific information) has been logged!\n": {
    "fr": "Retournez sur la page Détails de l'étude sur Prolific. En bas de la page, il y a un bouton Aperçu. Cela vous permet de tester l'expérience en agissant comme un participant vous-même. N'oubliez pas de vérifier les résultats JATOS pour vous assurer que l'expérience s'est terminée avec succès et que toutes les informations nécessaires (y compris les informations Prolific) ont été enregistrées !"
  },
  "Questionnaires in OSWeb": {
    "fr": "Questionnaires dans OSWeb",
    "de": "Fragebögen in OSWeb"
  },
  "\nTo validate a form, pass a function with the `validator` keyword to `Form()`. In the example below, `my_form_validator()` is used in this way. A validator function should not expect any arguments, and should return a `bool` to indicate whether or not the form validates. If the form does not validate, no error message is shown, but the form simply stays open.\n\nIn addition, you can validate (or filter) input to a `TextInput` widget to exclude certain characters as input. To do so, pass a function with the `key_filter` keyword to `TextInput()`. In the example below, `filter_digits()` is used in this way. A key-filter function should accept a single argument, which corresponds to a single key press, and should return a `bool` to indicate whether or not the key is accepted as input.\n\n~~~ .python\ndef my_form_validator():\n    \"\"\"Checks whether both the gender and age fields have been filled out\"\"\"\n    return gender != 'no' and age != ''\n\n\ndef filter_digits(ch):\n    \"\"\"Allows only digit characters as input\"\"\"\n    return ch in '0123456789'\n\n\n# Define all widgets\nbutton_ok = Button(text='Ok')\nlabel_gender= Label('Your gender')\ncheckbox_male = Checkbox(text='Male', group='gender', var='gender')\ncheckbox_female = Checkbox(text='Female', group='gender', var='gender')\nlabel_age = Label('Your age')\n# Specify a key filter so that only digits are accepted as text input\ninput_age = TextInput(stub='Age here …', var='age', key_filter=filter_digits)\n# Build the form. Specify a validator function to make sure that the form is\n# completed.\nmy_form = Form(validator=my_form_validator, rows=[1,1,1], cols=[1,1,1])\nmy_form.set_widget(label_gender, (0, 0))\nmy_form.set_widget(checkbox_male, (1, 0))\nmy_form.set_widget(checkbox_female, (2, 0))\nmy_form.set_widget(label_age, (0, 1))\nmy_form.set_widget(input_age, (1, 1), colspan=2)\nmy_form.set_widget(button_ok, (1, 2))\nmy_form._exec()\n~~~\n": {
    "fr": "Pour valider un formulaire, passez une fonction avec le mot-clé `validator` à `Form()`. Dans l'exemple ci-dessous, `my_form_validator()` est utilisé de cette manière. Une fonction de validation ne doit pas attendre d'arguments et doit renvoyer un `bool` pour indiquer si le formulaire est valide ou non. Si le formulaire n'est pas valide, aucun message d'erreur n'est affiché, mais le formulaire reste simplement ouvert.\n\nDe plus, vous pouvez valider (ou filtrer) la saisie dans un widget `TextInput` pour exclure certains caractères en entrée. Pour ce faire, passez une fonction avec le mot-clé `key_filter` à `TextInput()`. Dans l'exemple ci-dessous, `filter_digits()` est utilisé de cette manière. Une fonction de filtre de clés doit accepter un seul argument, correspondant à une seule pression de touche, et doit renvoyer un `bool` pour indiquer si la touche est acceptée en entrée.\n\n~~~ .python\ndef my_form_validator():\n    \"\"\"Vérifie si les champs sexe et âge sont remplis\"\"\"\n    return gender != 'no' and age != ''\n\n\ndef filter_digits(ch):\n    \"\"\"Accepte uniquement les caractères numériques en entrée\"\"\"\n    return ch in '0123456789'\n\n\n# Définition de tous les widgets\nbutton_ok = Button(text='Ok')\nlabel_gender= Label('Votre sexe')\ncheckbox_male = Checkbox(text='Homme', group='gender', var='gender')\ncheckbox_female = Checkbox(text='Femme', group='gender', var='gender')\nlabel_age = Label('Votre âge')\n# Spécifiez un filtre de clés pour que seuls les chiffres soient acceptés en entrée de texte\ninput_age = TextInput(stub='Âge ici …', var='age', key_filter=filter_digits)\n# Construire le formulaire. Spécifiez une fonction de validation pour vous assurer que le formulaire est\n# terminé.\nmy_form = Form(validator=my_form_validator, rows=[1,1,1], cols=[1,1,1])\nmy_form.set_widget(label_gender, (0, 0))\nmy_form.set_widget(checkbox_male, (1, 0))\nmy_form.set_widget(checkbox_female, (2, 0))\nmy_form.set_widget(label_age, (0, 1))\nmy_form.set_widget(input_age, (1, 1), colspan=2)\nmy_form.set_widget(button_ok, (1, 2))\nmy_form._exec()\n~~~"
  },
  "Custom HTML forms": {
    "fr": "Formulaires HTML personnalisés"
  },
  "\n## Implicit Association Task\n\nThe implicit association task measures the strength of associations between concepts (e.g. young people and old people) and evaluations (e.g. good and bad). The idea is that making a response is easier (and therefore *faster*) when related items share the same response key.\n\nHere, we will measure the association between young and old, and good and bad. We hypothesize that young participants (subconsciously) associate positive words with young faces rather than with old faces.\n\n\n## Tutorial screencast\n\nThis tutorial is also available as a screencast:\n\n<notranslate>\nvideo:\n source: youtube\n id: Screencast\n videoid: zd-nxgGOGlE\n width: 640\n height: 360\n caption: |\n  A screencast of the IAT tutorial.\n</notranslate>\n\n\n\n## Experimental hierarchy\n\nTo test this prediction, participants perform four blocks of trials (%Task)\n\n- __Block 1__ -- Participants categorize *words* as either *POSITIVE* or *NEGATIVE*. The category names appear at the top left and top right side of the screen, and participants press a button with their left or right hand to indicate to which category a centrally presented word belongs\n- __Block 2__ -- Participants categorize *faces* as *OLD* or *YOUNG*, again by making a left- or right-hand resonse\n- __Block 3__ -- Is a combination of block 1 and 2. In this example, the words *POSITVE* and *YOUNG* appear at the top left while the words *NEGATIVE* and *OLD* appear at the top right. Because we assume that (young) participants have a more positive attitude towards young faces, we call this mapping *congruent*\n- __Block 4__ -- Is again a combination of block 1 and 2, but this time the mapping is *incongruent*\n\n<notranslate>\nfigure:\n id: Task\n source: IAT-task.png\n caption: |\n  An overview of the four blocks of the implicit association task.\n</notranslate>\n\n## Prediction\n\nThe prediction is that participants have a preference for young people compared to old people, such that it is easier to categorize words when young and positive share a response key, and old and negative share a response key (as compared to the reverse mapping). This should result in *faster* responses in the congruent than in the incongruent block (%Prediction).\n\n<notranslate>\nfigure:\n id: Prediction\n source: prediction.png\n caption: |\n  We predict that participants find it easier to categorize words and faces if the categories *POSITIVE/YOUNG* and *NEGATIVE/OLD* are combined (as compared to the reverse).\n</notranslate>\n\n\n## Trial sequence\n\nIn order to test this prediction, we're going to create the following trial sequence (%TrialSequence):\n\n- Each trial starts with a __fixation point__ (500 ms)\n- Next, the __two category names__ appear on the upper left and right side of the screen.\n- The to-be-categorized __stimulus__ appears at the center\n- Participants indicate with a __key press__ whether the stimulus belongs to the category on the left or on the right\n- The variables of the current trial are __logged__\n\n<notranslate>\nfigure:\n id: TrialSequence\n source: trial_sequence.png\n caption: |\n  Schematic representation of a typical trial sequence of the (first block of the) IAT.\n</notranslate>\n\n## Launch OpenSesame\n\nWhen you start OpenSesame, you'll see a 'Get started!' tab, which shows you a list of templates as well as recently opened experiments (%GetStarted). To save some time, we'll use the 'Extended template'.\n\n<notranslate>\nfigure:\n id: GetStarted\n source: get-started.png\n caption: |\n  OpenSesame's welcome window. Here, we use the 'Extended template'.\n</notranslate>\n\nAfter opening the extended template, we save our experiment. To do this, click *File* -> *Save* (shortcut: `Ctrl+S`), browse to the appropriate folder and give your experiment a meaningful name.\n\n\n## Overview area\n\nThe *overview area* shows the hierarchical structure of our experiment. To simplify our structure, we start by deleting the practice block. In order to do so:": {
    "fr": "## Tâche d'association implicite\n\nLa tâche d'association implicite mesure la force des associations entre les concepts (par exemple, les jeunes et les personnes âgées) et les évaluations (par exemple, bon et mauvais). L'idée est que donner une réponse est plus facile (et donc *plus rapide*) lorsque des éléments liés partagent la même touche de réponse.\n\nIci, nous mesurerons l'association entre les jeunes et les vieux, et les bonnes et les mauvaises choses. Nous faisons l'hypothèse que les jeunes participants associent (inconsciemment) les mots positifs aux visages jeunes plutôt qu'aux visages âgés.\n\n## Didacticiel sous forme de screencast\n\nCe didacticiel est également disponible sous forme de screencast :\n\n<notranslate>\nvideo:\n source: youtube\n id: Screencast\n videoid: zd-nxgGOGlE\n width: 640\n height: 360\n caption: |\n  Un screencast du didacticiel IAT.\n</notranslate>\n\n## Hiérarchie expérimentale\n\nPour tester cette prédiction, les participants réalisent quatre blocs d'essais (%Task)\n\n- __Bloc 1__ - Les participants catégorisent les *mots* comme *POSITIFS* ou *NÉGATIFS*. Les noms de catégories apparaissent en haut à gauche et en haut à droite de l'écran, et les participants appuient sur un bouton avec leur main gauche ou droite pour indiquer à quelle catégorie appartient un mot présenté au centre.\n- __Bloc 2__ - Les participants catégorisent les *visages* comme *VIEUX* ou *JEUNES*, à nouveau en effectuant une réponse de la main gauche ou droite.\n- __Bloc 3__ - Est une combinaison des blocs 1 et 2. Dans cet exemple, les mots *POSITIFS* et *JEUNES* apparaissent en haut à gauche tandis que les mots *NÉGATIFS* et *VIEUX* apparaissent en haut à droite. Comme nous supposons que les participants (jeunes) ont une attitude plus positive envers les visages jeunes, nous appelons cette correspondance *congruente*.\n- __Bloc 4__ - Est de nouveau une combinaison des blocs 1 et 2, mais cette fois la correspondance est *incongruente*.\n\n<notranslate>\nfigure:\n id: Task\n source: IAT-task.png\n caption: |\n  Aperçu des quatre blocs de la tâche d'association implicite.\n</notranslate>\n\n## Prédiction\n\nLa prédiction est que les participants ont une préférence pour les jeunes par rapport aux personnes âgées, de sorte qu'il est plus facile de catégoriser les mots lorsque les jeunes et les positifs partagent une touche de réponse, et les vieux et les négatifs partagent une touche de réponse (par rapport au mappage inverse). Cela devrait entraîner des réponses *plus rapides* dans le bloc congruent que dans le bloc incongruent (%Prediction).\n\n<notranslate>\nfigure:\n id: Prediction\n source: prediction.png\n caption: |\n  Nous prédisons que les participants trouveront plus facile de catégoriser les mots et les visages si les catégories *POSITIF/ JEUNE* et *NÉGATIF/ VIEUX* sont combinées (par rapport à l'inverse).\n</notranslate>\n\n## Séquence d'essai\n\nAfin de tester cette prédiction, nous allons créer la séquence d'essai suivante (%TrialSequence) :\n\n- Chaque essai commence par un __point de fixation__ (500 ms)\n- Ensuite, les __deux noms de catégorie__ apparaissent en haut à gauche et à droite de l'écran.\n- Le __stimulus__ à catégoriser apparaît au centre\n- Les participants indiquent par une __touche__ si le stimulus appartient à la catégorie de gauche ou de droite\n- Les variables de l'essai en cours sont __enregistrées__\n\n<notranslate>\nfigure:\n id: TrialSequence\n source: trial_sequence.png\n caption: |\n  Représentation schématique d'une séquence d'essai typique de la (premier bloc de la) IAT.\n</notranslate>\n\n## Lancer OpenSesame\n\nLorsque vous démarrez OpenSesame, vous verrez un onglet \"Commencer !\", qui vous montre une liste de modèles ainsi que des expériences récemment ouvertes  (%GetStarted). Pour gagner du temps, nous utiliserons le modèle \"Extended\".\n\n<notranslate>\nfigure:\n id: GetStarted\n source: get-started.png\n caption: |\n  Fenêtre de bienvenue d'OpenSesame. Ici, nous utilisons le modèle \"Extended\".\n</notranslate>\n\nAprès avoir ouvert le modèle étendu, nous enregistrons notre expérience. Pour ce faire, cliquez sur *File* -> *Save* (raccourci : `Ctrl+S`), naviguez jusqu'au dossier approprié et donnez un nom significatif à votre expérience.\n\n## Zone de présentation\n\nLa *zone de présentation* montre la structure hiérarchique de notre expérience. Pour simplifier notre structure, nous commençons par supprimer le bloc de pratique. Pour ce faire :"
  },
  "\n## Forms and custom HTML\n\nForms and custom HTML are supported as of OSWeb 1.4\n{:.page-notification}\n\nYou can use the form plugins as described here:\n\n- %link:manual/forms/about%\n\nThe FORM_BASE plugin is *not* supported in OSWeb. Instead, you can use the INLINE_HTML item to implement custom HTML forms, as described here:\n\n- %link:manual/forms/html%\n\n\n## Linking to a different platform\n\nAs an alternative, you can implement a questionnaire using another platform, such as [LimeSurvey](https://www.limesurvey.org/), and then link to this questionnaire from your OSWeb experiment. The video below shows how to do this in such a way that you can tell afterwards which questionnaire data belongs to which OSWeb data.\n\n<notranslate>\nvideo:\n source: youtube\n id: BeginnerTutorial\n videoid: 1WvTUQr0JL0\n width: 640\n height: 360\n caption: |\n  Combining OSWeb and LimeSurvey.\n</notranslate>\n": {
    "fr": "\n## Formulaires et HTML personnalisé\n\nLes formulaires et le HTML personnalisé sont pris en charge à partir d'OSWeb 1.4\n{:.page-notification}\n\nVous pouvez utiliser les plugins de formulaire comme décrit ici :\n\n- %link:manual/forms/about%\n\nLe plugin FORM_BASE n'est *pas* pris en charge dans OSWeb. Au lieu de cela, vous pouvez utiliser l'élément INLINE_HTML pour implémenter des formulaires HTML personnalisés, comme décrit ici :\n\n- %link:manual/forms/html%\n\n## Lier à une autre plateforme\n\nEn alternative, vous pouvez implémenter un questionnaire en utilisant une autre plateforme, comme [LimeSurvey](https://www.limesurvey.org/), puis lier ce questionnaire à votre expérience OSWeb. La vidéo ci-dessous montre comment faire cela de manière à ce que vous puissiez identifier par la suite quelles données de questionnaire appartiennent à quelles données OSWeb.\n\n<notranslate>\nvideo:\n source: youtube\n id: BeginnerTutorial\n videoid: 1WvTUQr0JL0\n width: 640\n height: 360\n caption: |\n  Combiner OSWeb et LimeSurvey.\n</notranslate>"
  },
  "OSWeb": {
    "fr": "OSWeb"
  },
  "When you start OpenSesame, you see the 'Get started!' tab (%FigGetStarted). A list of templates is shown below 'Start a new experiment'. These templates provide convenient starting points for new experiments. After you saved an experiment the first time, recently opened experiments are shown under 'Continue with a recent experiment'. At the bottom of the page there are links to the documentation (which includes this tutorial), the community forum, and a page with professional (paid) support options. And of course a link where you can buy us a cup of coffee to help us stay awake while we are working on providing the best free software!\n\n<notranslate>\nfigure:\n id: FigGetStarted\n source: get-started.png\n caption: |\n  The 'Get started' dialog on OpenSesame start-up.\n</notranslate>\n\nClick on 'Default template' to start with a minimal experimental template.\n\nBy default there is a main SEQUENCE, which is simply called *experiment*. Click on *experiment* in the overview area (by default on the left side, see %FigInterface) to open its controls in the tab area. The *experiment* SEQUENCE consists of two items: a `notepad` called *getting started* and a SKETCHPAD called *welcome*.\n\nWe don't need these two items. Remove *getting_started* by right-clicking on it in the overview area and selecting 'Delete' (shortcut: `Del`). Remove *welcome* in the same way. The *experiment* SEQUENCE is now empty.\n\n<notranslate>\nfigure:\n id: FigInterface\n source: interface.png\n caption: \"The default layout of the OpenSesame interface.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Names vs types__ -- Items in OpenSesame have a name and a type. The name and type can be the same, but they are usually not. For example, a SKETCHPAD item can have the name *my_target_sketchpad*. To make this distinction clear, we will use `monospace` to indicate item types, and *italics* to indicate names.\n\n__Tip__ -- The 'Extended template' is a good starting point for many experiments. It already contains the basic structure of a trial-based experiment.\n\n__Tip__ -- You can click on the Help icons in the top right of an item's tab to get context-sensitive help.\n\n__Tip__ -- Save (shortcut: `Ctrl+S`) your experiment often! In the unfortunate (and unlikely) event of data loss, you will often be able to recover your work from the back-ups that are created automatically, by default, every 10 minutes (Menu → Tools → Open backup folder).\n\n__Tip__ -- Unless you have used 'Permanently delete' (shortcut: `Shift+Del`), deleted items are still available in the 'Unused items' bin, until you select 'Permanently delete unused items' in the 'Unused items' tab. You can re-add deleted items to a SEQUENCE by dragging them out of the 'Unused items' bin to somewhere in your experiment.\n\n__Tip__ -- %FigExperimentStructure schematically shows the structure of the experiment that you will create. If you get confused during the tutorial, you can refer to %FigExperimentStructure to see where you are.\n\n<notranslate>\nfigure:\n id: FigExperimentStructure\n source: experiment-structure.png\n caption: |\n  A schematic representation of the structure of the 'Gaze cuing' experiment. The item types are in bold face, item names in regular face.\n</notranslate>\n\n</div>\n\n__Append a form_text_display item for the instruction display__\n\nAs the name suggests, a `form_text_display` is a form that displays text. We are going to use a `form_text_display` to give instructions to the participant at the beginning of the experiment.\n\nClick on *experiment* in the overview area to open its controls in the tab area. You will see an empty SEQUENCE. Drag a `form_text_display` from the item toolbar (under 'Form', see %FigInterface) onto the *experiment* SEQUENCE in the tab area. When you let go, a new `form_text_display` item will be inserted into the SEQUENCE. (We will get back to this in Step 12.)\n\n<div class='info-box' markdown='1'>\n\n__Background box__": {
    "fr": "Lorsque vous démarrez OpenSesame, vous voyez l'onglet 'Commencer !' (%FigGetStarted). Une liste de modèles est affichée sous \"Démarrer une nouvelle expérience\". Ces modèles constituent des points de départ pratiques pour les nouvelles expériences. Une fois que vous avez enregistré une expérience pour la première fois, les expériences récemment ouvertes sont affichées sous \"Continuer avec une expérience récente\". Au bas de la page, il y a des liens vers la documentation (qui comprend ce tutoriel), le forum de la communauté et une page avec des options de support professionnel (payant). Et bien sûr, un lien où vous pouvez nous acheter une tasse de café pour nous aider à rester éveillé pendant que nous travailons à fournir le meilleur logiciel gratuit !\n\n<notranslate>\nfigure:\n id: FigGetStarted\n source: get-started.png\n caption: |\n  La boîte de dialogue 'Commencer' lors du démarrage d'OpenSesame.\n</notranslate>\n\nCliquez sur 'Modèle par défaut' pour commencer avec un modèle expérimental minimal.\n\nPar défaut, il y a une SEQUENCE principale, simplement appelée *experiment*. Cliquez sur *experiment* dans la zone d'aperçu (par défaut sur le côté gauche, voir %FigInterface) pour ouvrir ses commandes dans la zone d'onglets. La SEQUENCE *experiment* est composée de deux éléments : un `notepad` appelé *getting started* et un SKETCHPAD appelé *welcome*.\n\nNous n'avons pas besoin de ces deux éléments. Supprimez *getting_started* en faisant un clic droit dessus dans la zone d'aperçu et en sélectionnant \"Supprimer\" (raccourci : `Del`). Supprimez *welcome* de la même manière. La SEQUENCE *experiment* est maintenant vide.\n\n<notranslate>\nfigure:\n id: FigInterface\n source: interface.png\n caption: \"La disposition par défaut de l'interface OpenSesame.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Encart d'information__\n\n__Noms vs types__ -- Les éléments dans OpenSesame ont un nom et un type. Le nom et le type peuvent être les mêmes, mais ils ne le sont généralement pas. Par exemple, un élément SKETCHPAD peut avoir le nom *my_target_sketchpad*. Pour rendre cette distinction claire, nous utiliserons `monospace` pour indiquer les types d'éléments et *italique* pour indiquer les noms.\n\n__Astuce__ -- Le \"Modèle étendu\" est un bon point de départ pour de nombreuses expériences. Il contient déjà la structure de base d'une expérience basée sur des essais.\n\n__Astuce__ -- Vous pouvez cliquer sur les icônes d'aide en haut à droite d'un onglet d'élément pour obtenir de l'aide contextuelle.\n\n__Astuce__ -- Enregistrez (raccourci : `Ctrl+S`) votre expérience souvent ! En cas de perte de données malheureuse (et improbable), vous pourrez souvent récupérer votre travail à partir des sauvegardes créées automatiquement, par défaut, toutes les 10 minutes (Menu → Outils → Ouvrir le dossier de sauvegarde).\n\n__Astuce__ -- À moins que vous n'ayez utilisé \"Supprimer définitivement\" (raccourci : `Shift+Del`), les éléments supprimés sont toujours disponibles dans la corbeille \"Éléments inutilisés\", jusqu'à ce que vous sélectionniez \"Supprimer définitivement les éléments inutilisés\" dans l'onglet \"Éléments inutilisés\". Vous pouvez rajouter les éléments supprimés à une SEQUENCE en les faisant glisser hors de la corbeille \"Éléments inutilisés\" vers un endroit de votre expérience.\n\n__Astuce__ -- %FigExperimentStructure montre schématiquement la structure de l'expérience que vous allez créer. Si vous êtes perdu pendant le tutoriel, vous pouvez vous référer à %FigExperimentStructure pour voir où vous en êtes.\n\n<notranslate>\nfigure:\n id: FigExperimentStructure\n source: experiment-structure.png\n caption: |\n  Une représentation schématique de la structure de l'expérience \"Gaze cuing\". Les types d'éléments sont en caractères gras, les noms d'éléments en caractères ordinaires.\n</notranslate>\n\n</div>\n\n__Ajoutez un élément form_text_display pour l'affichage des instructions__\n\nComme son nom l'indique, un `form_text_display` est un formulaire qui affiche du texte. Nous allons utiliser un `form_text_display` pour donner des instructions au participant au début de l'expérience.\n\nCliquez sur *experiment* dans la zone d'aperçu pour ouvrir ses commandes dans la zone d'onglets. Vous verrez une SEQUENCE vide. Faites glisser un `form_text_display` depuis la barre d'outils des éléments (sous \"Form\", voir %FigInterface) dans la SEQUENCE *experiment* de la zone d'onglets. Lorsque vous relâchez, un nouvel élément `form_text_display` sera inséré dans la SEQUENCE. (Nous y reviendrons à l'étape 12.)\n\n<div class='info-box' markdown='1'>\n\n__Encart d'information__"
  },
  "\nThe INLINE_HTML item allows you to implement forms using custom HTML.\n\n- The `name` attribute of `input` tags corresponds to an experimental variable. Therefore, the text that is entered into the text input of Example 1 will be stored as the experimental variable `text_response`.\n- For `checkbox` and `radio` elements, you can use the `id` attribute to assign a specific value to the associated experimental variable.\n- You can use the `required` attribute to indicate that a form cannot be submitted before a field has been filled out.\n- The form is closed when the participant clicks on an input of type submit.\n- To include images from the file pool in a custom HTML form, first retrieve the URL to the file, assign it to an experimental variable, and then use this variable as the source for the `<img>` tag (see Example 3).\n\n\nExample 1:\n\nA very basic text input form:\n\n```html\n<input type='text' name='text_response'>\n<input type='submit' value='click here to continue'>\n```\n\nExample 2:\n\nA form with multiple radio buttons:\n\n```html\n<p>Please select your age:</p>\n<input type=\"radio\" id=\"age1\" name=\"age\" value=\"30\" required>\n<label for=\"age1\">0 - 30</label><br>\n<input type=\"radio\" id=\"age2\" name=\"age\" value=\"60\">\n<label for=\"age2\">31 - 60</label><br>  \n<input type=\"radio\" id=\"age3\" name=\"age\" value=\"100\">\n<label for=\"age3\">61 - 100</label><br><br>\n<input type=\"submit\" value=\"Submit\">\n```\n\nExample 3:\n\nYou can include variable references (except within `<script>` tags, where curly braces are simply interpreted as part of JavaScript code):\n\n```html\n<p>You age group is {age}</p>\n<input type='submit' value='ok'>\n```\n\nExample 4:\n\nYou can JavaScript through `<script>` tags. For example, you can get an image from the file pool and assign to an initially empty `<img>` tag like this:\n\n```html\n<img id='capybara'>\n<input type='submit' value='ok'>\n\n<script>\ndocument.getElementById('capybara').src = pool['capybara.png'].data.src\n</script>\n```\n": {
    "fr": "L'élément INLINE_HTML vous permet de mettre en place des formulaires en utilisant du HTML personnalisé.\n\n- L'attribut `name` des balises `input` correspond à une variable expérimentale. Par conséquent, le texte saisi dans l'entrée de texte de l'exemple 1 sera stocké en tant que variable expérimentale `text_response`.\n- Pour les éléments `checkbox` et `radio`, vous pouvez utiliser l'attribut `id` pour attribuer une valeur spécifique à la variable expérimentale associée.\n- Vous pouvez utiliser l'attribut `required` pour indiquer qu'un formulaire ne peut être soumis avant qu'un champ ait été complété.\n- Le formulaire est fermé lorsque le participant clique sur une entrée de type submit.\n- Pour inclure des images provenant de la réserve de fichiers dans un formulaire HTML personnalisé, commencez par récupérer l'URL du fichier, attribuez-le à une variable expérimentale, puis utilisez cette variable comme source pour la balise `<img>` (voir exemple 3).\n\nExemple 1 :\n\nUn formulaire de saisie de texte très basique :\n\n```html\n<input type='text' name='text_response'>\n<input type='submit' value='cliquez ici pour continuer'>\n```\n\nExemple 2 :\n\nUn formulaire avec plusieurs boutons radio :\n\n```html\n<p>Veuillez sélectionner votre âge :</p>\n<input type=\"radio\" id=\"age1\" name=\"age\" value=\"30\" required>\n<label for=\"age1\">0 - 30</label><br>\n<input type=\"radio\" id=\"age2\" name=\"age\" value=\"60\">\n<label for=\"age2\">31 - 60</label><br>  \n<input type=\"radio\" id=\"age3\" name=\"age\" value=\"100\">\n<label for=\"age3\">61 - 100</label><br><br>\n<input type=\"submit\" value=\"Envoyer\">\n```\n\nExemple 3 :\n\nVous pouvez inclure des références de variables (excepté dans les balises `<script>`, où les accolades sont simplement interprétées comme faisant partie du code JavaScript) :\n\n```html\n<p>Votre tranche d'âge est {age}</p>\n<input type='submit' value='ok'>\n```\n\nExemple 4 :\n\nVous pouvez utiliser JavaScript via les balises `<script>`. Par exemple, vous pouvez obtenir une image de la réserve de fichiers et l'attribuer à une balise `<img>` initialement vide comme ceci :\n\n```html\n<img id='capybara'>\n<input type='submit' value='ok'>\n\n<script>\ndocument.getElementById('capybara').src = pool['capybara.png'].data.src\n</script>\n```"
  },
  "About forms": {
    "fr": "À propos des formulaires"
  },
  "Forms are simple interactive displays that can be used to implement questionnaires, instructions, text input displays, etc. You can use forms in four ways.\n\n- Use the form plugins, such as FORM_TEXT_INPUT, which offer ready-made forms. This is the easiest, but least flexible way of using forms. This works both on the desktop and in a browser.\n\t- %link:manual/forms/readymade%\n- Define custom forms using OpenSesame script and the form_base plugin. This offers considerable flexibility, and does not require any real programming skills. This only works on the desktop.\n\t- %link:manual/forms/custom%\n- Create custom forms using Python inline script. This offers the most flexibility, but requires some knowledge of Python programming. This only works on the desktop.\n\t- %link:manual/forms/custom%\n- Create custom forms using HTML code. This only works when running experiments in a browser with OSWeb.\n\t- %link:manual/forms/html%\n\n<notranslate>\nfigure:\n id: FigAbout\n source: about.png\n caption: An example form.\n</notranslate>\n": {
    "fr": "Les formulaires sont des affichages interactifs simples qui peuvent être utilisés pour mettre en œuvre des questionnaires, des instructions, des affichages de saisie de texte, etc. Vous pouvez utiliser les formulaires de quatre manières.\n\n- Utilisez les plugins de formulaires, tels que FORM_TEXT_INPUT, qui proposent des formulaires prêts à l'emploi. C'est la manière la plus simple, mais la moins flexible d'utiliser des formulaires. Ceci fonctionne à la fois sur le bureau et dans un navigateur.\n\t- %link:manual/forms/readymade%\n- Définissez des formulaires personnalisés en utilisant le script OpenSesame et le plugin form_base. Cela offre une flexibilité considérable et ne nécessite pas de réelles compétences en programmation. Cela fonctionne uniquement sur le bureau.\n\t- %link:manual/forms/custom%\n- Créez des formulaires personnalisés en utilisant du script Python inline. Cela offre la plus grande flexibilité, mais nécessite des connaissances en programmation Python. Cela fonctionne uniquement sur le bureau.\n\t- %link:manual/forms/custom%\n- Créez des formulaires personnalisés en utilisant du code HTML. Cela ne fonctionne que lors de l'exécution d'expériences dans un navigateur avec OSWeb.\n\t- %link:manual/forms/html%\n\n<notranslate>\nfigure:\n id: FigAbout\n source: about.png\n caption: Exemple de formulaire.\n</notranslate>"
  },
  "Form widgets and keywords": {
    "fr": "Widgets de formulaire et mots-clés"
  },
  "\nThe IAT contains more blocks than the current one. It also contains a block in which pictures of faces have to be categorized as young or old, and two blocks that contain both tasks intermingled (see %Task). This means that we will have to create another three blocks of trials, each containing their own trial sequence. The hierarchical strcuture of the experiment therefore looks as follows (and when we're done programming, our overview area should resemble this):\n\n<notranslate>\nfigure:\n id: Hierarchy\n source: hierarchy.png\n caption: |\n  The experimental hierarchy of the IAT.\n</notranslate>\n\n## Block 2: face categorization\n\nLet's first concentrate ourselves on the face-categorization task. More precisely, we will\n\n- Create an additional block loop and trial sequence\n- Re-use everything that we can re-use from the previous part of the experiment\n- Add new variables and events that are specific to the face-categorization task\n\n### Step 4: Create an additional block_loop\n\n- Grab a `loop` item from the `item toolbar`\n- Drag and drop it to the overview area\n- To make the new block appear after the first one, drop it *onto* the `words_block_loop` item (see %AppendLoopAndSequence)\n- OpenSesame asks you whether you want to insert the current item *into* the `words_block_loop`, or *after*. Choose the latter\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- If you accidentally put the new item *into* the block loop, you can always undo this by pressing `Ctrl+Alt+Z`).\n\n</div>\n\n- Give the new loop a meaningful name, for example *faces_block_loop*\n\n### Step 5: Append a new trial sequence\n\nAlthough the trial sequence of the face-categorization task has some overlap with the word-categorization task, they are not identical. Therefore, we can't re-use the trial sequence that we previously made.\n\nIn order to make a new one:\n\n- Grab a `sequence` item from the item toolbar\n- Drop it *into* the *faces_block_loop*\n- This time, choose 'insert into' (see %AppendLoopAndSequence)\n- Rename the item as *faces_trial_sequence*\n\n<notranslate>\nvideo:\n source: youtube\n id: AppendLoopAndSequence\n videoid: PVcXdAN3rjM\n width: 640\n height: 360\n caption: |\n  Step 5 and 6: Adding block 2 and its corresponding trial sequence to the experiment.\n</notranslate>\n\n\n### Step 6: Choose the face stimuli\n\n\n__Download the face stimuli__\n\nIn the face equivalent of the task, we need images of six young and six old faces. To avoid gender biases from influencing our results, it seams best to use an equal number of male and female faces per category (here: three).\n\nYou can download an example set of stimuli (in JPG format) here:\n\n- %static:attachments/iat/face-stimuli.zip%\n\nIn most web browsers you can right-click the link and choose 'Save Link As' or a similar option. After you have downloaded these files (to your Downloads folder, for example), you can unzip them.\n\n__Add the JPG files to the file pool__\n\n- If the file pool is not already visible (by default on the right side of the window), click on the 'Show file pool' button in the main toolbar (shortcut: `Ctrl+P`).\n- Click on the plus sign in order to add files\n- Browse to your Downloads folder (or wherever you saved and unzipped the *face-stimuli* folder) and add the 12 JPG files.\n\nThe file pool should now look similar to %FacesBlockLoop\n\n### Step 7: Content of the loop table\n\nJust like in the previous part of the experiment (see Step 1), we need three columns to define the experimental variables: *stimulus*, *category*, and *correct_response*. The only difference is that this time the stimuli are the JPG files that we just added to the file pool.\n\nRegarding the correct_response, let's say that:\n\n- The *YOUNG* category appears at the left side of the screen, whereas the *OLD* category appears at the right\n- The response rule is as before\n\nCreate the aforementioned columns and make sure your block loop ends up looking like this:": {
    "fr": "L'IAT contient plus de blocs que celui actuel. Il contient également un bloc dans lequel des images de visages doivent être catégorisées comme jeunes ou vieux, et deux blocs contenant les deux tâches mélangées (voir %Task). Cela signifie que nous devons créer trois autres blocs d'essais, chacun contenant sa propre séquence d'essais. La structure hiérarchique de l'expérience se présente donc comme suit (et lorsque nous aurons terminé la programmation, notre zone d'aperçu devrait ressembler à ceci) :\n\n<notranslate>\nfigure :\n id: Hierarchy\n source: hierarchy.png\n caption: |\n  La hiérarchie expérimentale de l'IAT.\n</notranslate>\n\n## Bloc 2 : catégorisation des visages\n\nConcentrons-nous d'abord sur la tâche de catégorisation des visages. Plus précisément, nous allons :\n\n- Créer une boucle de blocs supplémentaire et une séquence d'essais\n- Réutiliser tout ce que nous pouvons réutiliser de la partie précédente de l'expérience\n- Ajouter de nouvelles variables et événements spécifiques à la tâche de catégorisation des visages\n\n### Étape 4 : Créer une boucle de blocs supplémentaire\n\n- Prenez un élément `loop` dans la `item toolbar`\n- Glissez-déposez-le sur la zone d'aperçu\n- Pour que le nouveau bloc apparaisse après le premier, déposez-le *sur* l'élément `words_block_loop` (voir %AppendLoopAndSequence)\n- OpenSesame vous demande si vous souhaitez insérer l'élément actuel *dans* le `words_block_loop`, ou *après*. Choisissez ce dernier\n\n<div class='info-box' markdown='1'>\n\n__Conseil__ -- Si vous mettez par erreur le nouvel élément *dans* la boucle de bloc, vous pouvez toujours annuler cette action en appuyant sur `Ctrl+Alt+Z`).\n\n</div>\n\n- Donnez un nom significatif à la nouvelle boucle, par exemple *faces_block_loop*\n\n### Étape 5 : Ajouter une nouvelle séquence d'essais\n\nBien que la séquence d'essais de la tâche de catégorisation des visages présente certaines similitudes avec la tâche de catégorisation des mots, elles ne sont pas identiques. Par conséquent, nous ne pouvons pas réutiliser la séquence d'essais que nous avons créée précédemment.\n\nPour en créer une nouvelle :\n\n- Prenez un élément `sequence` dans la barre d'outils des éléments\n- Déposez-le *dans* le *faces_block_loop*\n- Cette fois-ci, choisissez \"insérer dans\" (voir %AppendLoopAndSequence)\n- Renommez l'élément en *faces_trial_sequence*\n\n<notranslate>\nvideo :\n source: youtube\n id : AppendLoopAndSequence\n videoid: PVcXdAN3rjM\n width: 640\n height: 360\n caption: |\n  Étape 5 et 6: Ajout du bloc 2 et de sa séquence d'essais correspondante à l'expérience.\n</notranslate>\n\n\n### Étape 6 : Choisissez les stimuli de visage\n\n__Téléchargez les stimuli de visage__\n\nDans l'équivalent du visage de la tâche, nous avons besoin d'images de six visages jeunes et six visages vieux. Pour éviter que les biais de genre n'influencent nos résultats, il semble préférable d'utiliser un nombre égal de visages masculins et féminins par catégorie (ici : trois).\n\nVous pouvez télécharger un ensemble d'exemples de stimuli (au format JPG) ici :\n\n- %static:attachments/iat/face-stimuli.zip%\n\nDans la plupart des navigateurs web, vous pouvez cliquer avec le bouton droit de la souris sur le lien et choisir \"Enregistrer le lien sous\" ou une option similaire. Après avoir téléchargé ces fichiers (dans votre dossier Téléchargements, par exemple), vous pouvez les décompresser.\n\n__Ajoutez les fichiers JPG au fichier pool__\n\n- Si le fichier pool n'est pas déjà visible (par défaut sur le côté droit de la fenêtre), cliquez sur le bouton \"Afficher le fichier pool\" dans la barre d'outils principale (raccourci : `Ctrl+P`).\n- Cliquez sur le signe plus pour ajouter des fichiers\n- Parcourez votre dossier Téléchargements (ou l'endroit où vous avez enregistré et décompressé le dossier *face-stimuli*) et ajoutez les 12 fichiers JPG.\n\nLe fichier pool devrait maintenant ressembler à %FacesBlockLoop\n\n### Étape 7 : Contenu du tableau de boucle\n\nTout comme dans la partie précédente de l'expérience (voir l'étape 1), nous avons besoin de trois colonnes pour définir les variables expérimentales : *stimulus*, *categorie* et *reponse_correcte*. La seule différence est que cette fois-ci, les stimuli sont les fichiers JPG que nous venons d'ajouter au fichier pool.\n\nEn ce qui concerne la réponse correcte, disons que :\n\n- La catégorie *JEUNE* apparaît du côté gauche de l'écran, tandis que la catégorie *VIEUX* apparaît du côté droit\n- La règle de réponse est la même qu'auparavant\n\nCréez les colonnes mentionnées ci-dessus et assurez-vous que votre boucle de blocs ressemble à ceci:"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About OSWeb\n\nOSWeb is an online runtime for OpenSesame experiments. That is, it is a JavaScript library that interprets and executes OpenSesame experiments.\n\n\n## The OSWeb extension\n\nThe OSWeb extension for OpenSesame (%FigOSWebExtension) allows you to test experiments in a browser, and to export experiments in a format that you can import into [JATOS](%url:jatos%).\n\n\n<notranslate>\nfigure:\n id: FigOSWebExtension\n source: osweb-extension.png\n caption: The OSWeb extension for OpenSesame.\n</notranslate>\n\n\n## Testing in a browser\n\n- In OpenSesame, open the OSWeb extension (Menu → Tools → OSWeb).\n- The extension will perform a simple (and incomplete) check to see if your experiment appears to be compatible with OSWeb.\n- If no problems are detected, click 'Test experiment in external browser', or click on the corresponding button in the main toolbar.\n- This will open the experiment in your default browser so that you can check if the experiment runs as expected (%FigTestRun).\n- You can also click the 'Run in browser' button in the main toolbar (Alt+Ctrl+W)\n\n\n<notranslate>\nfigure:\n id: FigTestRun\n source: testrun.png\n caption: The welcome screen of OSWeb when testing the experiment in a browser.\n</notranslate>\n\n\n## Debugging\n\nFirst, make sure that your experiment only uses supported functionality, as described below. Next, run the experiment in the traditional (non-browser) way in OpenSesame. This will give you the most informative error messages that you can use for debugging.\n\nIf your experiment uses only supported functionality and runs normally in OpenSesame, then you can use the browser console to see JavaScript error messages. These are much less informative than OpenSesame's error messages, but they can still be helpful. Each browser has a different way to access the console. In Chrome, you can access the console by right-clicking somewhere, selecting Inspect (`Ctrl+Shift+I`), and then switching to the Console tab (see %FigChromeConsole). In Firefox, you can access the console by clicking on the Menu icon in the top right and then selecting Web Developer → Web Console (`Ctrl+Shift+I`).\n\nIf you're using INLINE_JAVASCRIPT items in your experiment, the browser console is also a powerful way to debug your scripts, as described here:\n\n- %link:manual/javascript/about%\n\n\n<notranslate>\nfigure:\n id: FigChromeConsole\n source: chrome-console.png\n caption: Chrome's browser console.\n</notranslate>\n\n\n\n## Supported functionality\n\nYou can check whether your experiment is compatible with OSWeb using the Compatibility Check (%FigOSWebExtension). This compatibility check is fairly superficial. A more complete overview of supported functionality can be found below.\n\n__Important__: A lot of supported functionality was added in OSWeb 1.4. Therefore, check your version of OSWeb against the version notes in the list below.\n\n- `advanced_delay`\n- `feedback`\n    - See `sketchpad`\n- `form_consent` (supported >= v1.4)\n- `form_text_display` (supported >= 1.4)\n- `form_text_input` (supported >= 1.4)\n    - Unsupported: fullscreen mode\n- `form_multiple_choice` (supported >= 1.4)\n- `inline_html` (supported >= 1.4)\n- `inline_javascript`\n- `keyboard`\n    - Unsupported: key release\n    - Unsupported: HSV, HSL, and CIELab color spaces\n- `logger`\n- `loop`\n    - Unsupported: resume after break\n    - Unsupported: Disabling of evaluate on first cycle\n    - Unsupported: constraints (pseudorandomization)\n    - Supported >= 1.4: file source\n- `mouse`\n    - Unsupported: mouse release\n    - Unsupported: linked sketchpad\n- `notepad`\n- `repeat_cycle`\n- `reset_feedback`\n- `sampler`\n    - Supported >= 1.4.12: panning, pitch, and fade in\n    - Supported >= 1.4.12: Sound playback on Safari on Mac OS or any browser on iOS\n    - Unsupported: stop after\n- `sequence`\n- `sketchpad`\n    - Unsupported: named elements\n    - Supported >= 1.4: image rotation\n    - Unsupported: HSV, HSL, and CIELab color spaces\n- `touch_response`": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n\n## À propos d'OSWeb\n\nOSWeb est un environnement d'exécution en ligne pour les expériences OpenSesame. C'est-à-dire, une bibliothèque JavaScript qui interprète et exécute les expériences OpenSesame.\n\n\n## L'extension OSWeb\n\nL'extension OSWeb pour OpenSesame (%FigOSWebExtension) vous permet de tester les expériences dans un navigateur et d'exporter les expériences dans un format que vous pouvez importer dans [JATOS](%url:jatos%).\n\n\n<notranslate>\nfigure:\n id: FigOSWebExtension\n source: osweb-extension.png\n caption: L'extension OSWeb pour OpenSesame.\n</notranslate>\n\n\n## Tests dans un navigateur\n\n- Dans OpenSesame, ouvrez l'extension OSWeb (Menu → Outils → OSWeb).\n- L'extension effectuera une vérification simple (et incomplète) pour voir si votre expérience semble être compatible avec OSWeb.\n- Si aucun problème n'est détecté, cliquez sur 'Tester l'expérience dans un navigateur externe' ou cliquez sur le bouton correspondant dans la barre d'outils principale.\n- Cela ouvrira l'expérience dans votre navigateur par défaut afin que vous puissiez vérifier si l'expérience fonctionne comme prévu (%FigTestRun).\n- Vous pouvez également cliquer sur le bouton 'Exécuter dans un navigateur' dans la barre d'outils principale (Alt+Ctrl+W)\n\n<notranslate>\nfigure:\n id: FigTestRun\n source: testrun.png\n caption: L'écran de bienvenue d'OSWeb lors du test de l'expérience dans un navigateur.\n</notranslate>\n\n\n## Débogage\n\nTout d'abord, assurez-vous que votre expérience n'utilise que les fonctionnalités prises en charge, comme décrit ci-dessous. Ensuite, exécutez l'expérience de manière traditionnelle (hors navigateur) dans OpenSesame. Cela vous donnera les messages d'erreur les plus informatifs que vous pouvez utiliser pour le débogage.\n\nSi votre expérience n'utilise que des fonctionnalités prises en charge et fonctionne normalement dans OpenSesame, vous pouvez utiliser la console du navigateur pour voir les messages d'erreur JavaScript. Ces messages sont beaucoup moins informatifs que les messages d'erreur d'OpenSesame, mais ils peuvent toujours être utiles. Chaque navigateur a une manière différente d'accéder à la console. Dans Chrome, vous pouvez accéder à la console en faisant un clic droit quelque part, en sélectionnant Inspecter (`Ctrl+Shift+I`) puis en passant à l'onglet Console (voir % FigChromeConsole). Dans Firefox, vous pouvez accéder à la console en cliquant sur l'icône du menu en haut à droite, puis en sélectionnant Développeur Web → Console Web (`Ctrl+Shift+I`).\n\nSi vous utilisez des éléments INLINE_JAVASCRIPT dans votre expérience, la console du navigateur est également un moyen puissant de déboguer vos scripts, comme décrit ici :\n\n- %link:manual/javascript/about%\n\n<notranslate>\nfigure:\n id: FigChromeConsole\n source: chrome-console.png\n caption: La console du navigateur Chrome.\n</notranslate>\n\n\n\n## Fonctionnalités prises en charge\n\nVous pouvez vérifier si votre expérience est compatible avec OSWeb en utilisant la vérification de compatibilité (%FigOSWebExtension). Cette vérification de compatibilité est assez superficielle. Un aperçu plus complet des fonctionnalités prises en charge se trouve ci-dessous.\n\n__Important__: Beaucoup de fonctionnalités prises en charge ont été ajoutées dans OSWeb 1.4. Par conséquent, vérifiez votre version d'OSWeb par rapport aux notes de version dans la liste ci-dessous.\n\n- `advanced_delay`\n- `feedback`\n    - Voir `sketchpad`\n- `form_consent` (supported >= v1.4)\n- `form_text_display` (supported >= 1.4)\n- `form_text_input` (supported >= 1.4)\n    - Non pris en charge : mode plein écran\n- `form_multiple_choice` (supported >= 1.4)\n- `inline_html` (supported >= 1.4)\n- `inline_javascript`\n- `keyboard`\n    - Non pris en charge : relâchement des touches\n    - Non pris en charge : espaces colorimétriques HSV, HSL et CIELab\n- `logger`\n- `loop`\n    - Non pris en charge : reprise après une pause\n    - Non pris en charge : désactivation de l'évaluation lors du premier cycle\n    - Non pris en charge : contraintes (pseudo-randomisation)\n    - Pris en charge >= 1.4 : source de fichier\n- `mouse`\n    - Non pris en charge : relâchement de la souris\n    - Non pris en charge : sketchpad lié\n- `notepad`\n- `repeat_cycle`\n- `reset_feedback`\n- `sampler`\n    - Pris en charge >= 1.4.12 : panoramique, hauteur et fondu\n    - Pris en charge >= 1.4.12 : lecture du son sur Safari sur Mac OS ou sur n'importe quel navigateur sur iOS\n    - Non pris en charge : arrêter après\n- `sequence`\n- `sketchpad`\n    - Non pris en charge : éléments nommés\n    - Pris en charge >= 1.4 : rotation de l'image\n    - Non pris en charge : espaces colorimétriques HSV, HSL et CIELab\n- `touch_response`"
  },
  "__Tip__ -- You can drag items into the overview area and into SEQUENCE tabs.\n\n__Tip__ -- If a drop action is ambiguous, a pop-up menu will ask you what you want to do.\n\n__Tip__ -- A `form_text_display` only shows text. If you require images etc., you can use a SKETCHPAD item. We will meet the SKETCHPAD in Step 5.\n\n</div>\n\n__Append a loop item, containing a new sequence item, for the practice phase__\n\nWe need to append a LOOP item to the *experiment* SEQUENCE. We will use this LOOP for the practice phase of the experiment. Click on the *experiment* SEQUENCE to open its controls in the tab area.\n\nDrag the LOOP item from the item toolbar into the SEQUENCE just the way you added the `form_text_display`. New items are inserted below the item that they are dropped on, so if you drop the new LOOP onto the previously created `form_text_display`, it will appear where you want it: after the `form_text_display`. But don't worry if you drop a new item in the wrong place, because you can always re-order things later.\n\nBy itself, a LOOP does not do anything. A LOOP always needs another item to run. Therefore, you have to fill the new LOOP item with another item. (If you view the loop item, you will also see a warning: 'No item selected'.) Drag a SEQUENCE item from the item toolbar onto the LOOP item. A pop-up menu will appear, asking you whether you want to insert the SEQUENCE after or into the LOOP item. Select 'Insert into new_loop'. (We will get back to this in Step 2.)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a LOOP item?__ -- A LOOP is an item that adds structure to your experiment. It repeatedly runs another item, typically a SEQUENCE. A LOOP is also the place where you will usually define your independent variables, that is, those variables that you manipulate in your experiment.\n\n__What is a SEQUENCE item?__ -- A SEQUENCE item also adds structure to your experiment. As the name suggests, a SEQUENCE runs multiple other items one after another.\n\n__The LOOP-SEQUENCE structure__ -- You often want to repeat a sequence of events. To do this, you will need a LOOP item that contains a SEQUENCE item. By itself, a SEQUENCE does not repeat. It simply starts with the first item and ends with the last item. By 'wrapping' a LOOP item around the SEQUENCE, you can repeat the SEQUENCE multiple times. For example, a single trial usually corresponds to a single SEQUENCE called *trial_sequence*. A LOOP (often called *block_loop*) around this *trial_sequence* would then constitute a single block of trials. Similarly, but at another level of the experiment, a SEQUENCE (often called *block_sequence*) may contain a single block of trials, followed by a FEEDBACK display. A *practice_phase* LOOP around this 'block' SEQUENCE would then constitute the practice phase of the experiment. This may seem a bit abstract right now, but as you follow this tutorial, you will become familiar with the use of LOOPs and SEQUENCEs.\n\n__Tip__ -- For more information about SEQUENCEs and LOOPs, see:\n\n- %link:loop%\n- %link:sequence%\n\n</div>\n\n__Append a new form_text_display item for the end-of-practice message__\n\nAfter the practice phase, we want to inform the participant that the real experiment will begin. For this we need another `form_text_display`. Go back to the *experiment* SEQUENCE, and drag a `form_text_display` from the item toolbar onto the LOOP item. The same pop-up menu will appear as before. This time, select 'Insert after new_loop'. (We will get back to this in Step 12.)\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- Don't worry if you have accidentally changed a LOOP's item to run. You can undo this easily by clicking the 'Undo' button in the toolbar (`Ctrl+Shift+Z`).\n\n</div>\n\n__Append a new loop item, containing the previously created sequence, for the experimental phase__\n\nWe need a LOOP item for the experimental phase, just like for the practice phase. Therefore, drag a LOOP from the item toolbar menu onto *_form_text_display*.": {
    "fr": "__Conseil__ -- Vous pouvez faire glisser des éléments dans la zone d'aperçu et dans les onglets SEQUENCE.\n\n__Conseil__ -- Si une action de largage est ambiguë, un menu contextuel vous demandera ce que vous voulez faire.\n\n__Conseil__ -- Un `form_text_display` n'affiche que du texte. Si vous avez besoin d'images, etc., vous pouvez utiliser un élément SKETCHPAD. Nous rencontrerons le SKETCHPAD à l'étape 5.\n\n</div>\n\n__Ajoutez un élément de boucle, contenant un nouvel élément de séquence, pour la phase de pratique__\n\nNous devons ajouter un élément LOOP à la séquence *experiment*. Nous utiliserons cette boucle pour la phase de pratique de l'expérience. Cliquez sur la séquence *experiment* pour ouvrir ses contrôles dans la zone des onglets.\n\nFaites glisser l'élément LOOP depuis la barre d'outils des éléments dans la séquence, comme vous l'avez fait pour le `form_text_display`. Les nouveaux éléments sont insérés sous l'élément sur lequel ils sont déposés. Par conséquent, si vous déposez la nouvelle boucle sur le `form_text_display` précédemment créé, elle apparaîtra là où vous le voulez : après le `form_text_display`. Mais ne vous inquiétez pas si vous déposez un nouvel élément au mauvais endroit, car vous pouvez toujours réorganiser les choses plus tard.\n\nUn LOOP, en soi, ne fait rien. Un LOOP a toujours besoin d'un autre élément pour fonctionner. Par conséquent, vous devez remplir le nouvel élément LOOP avec un autre élément. (Si vous consultez l'élément LOOP, vous verrez également un avertissement : 'Aucun élément sélectionné'.) Faites glisser un élément SEQUENCE depuis la barre d'outils des éléments sur l'élément LOOP. Un menu contextuel apparaîtra, vous demandant si vous voulez insérer la SEQUENCE après ou dans l'élément LOOP. Sélectionnez \"Insérer dans new_loop\". (Nous reviendrons sur cette question à l'étape 2.)\n\n<div class = 'info-box' markdown = '1'>\n\n__Boîte d'informations__\n\n__Qu'est-ce qu'un élément LOOP?__ -- Un LOOP est un élément qui ajoute de la structure à votre expérience. Il exécute de manière répétitive un autre élément, généralement une séquence. Un LOOP est également l'endroit où vous définirez habituellement vos variables indépendantes, c'est-à-dire les variables que vous manipulez dans votre expérience.\n\n__Qu'est-ce qu'un élément SEQUENCE?__ -- Un élément SEQUENCE ajoute également de la structure à votre expérience. Comme son nom l'indique, une SEQUENCE exécute plusieurs autres éléments les uns après les autres.\n\n__Structure LOOP-SEQUENCE__ -- Vous voulez souvent répéter une séquence d'événements. Pour ce faire, vous aurez besoin d'un élément LOOP contenant un élément SEQUENCE. Une SEQUENCE, à elle seule, ne se répète pas. Elle commence simplement par le premier élément et se termine par le dernier. En \"enveloppant\" un élément LOOP autour de la SEQUENCE, vous pouvez répéter la SEQUENCE plusieurs fois. Par exemple, un essai unique correspond généralement à une SEQUENCE unique appelée *trial_sequence*. Un LOOP (souvent appelé *block_loop*) autour de cette *trial_sequence* constituerait alors un seul bloc d'essais. De même, mais à un autre niveau de l'expérience, une SEQUENCE (souvent appelée *block_sequence*) peut contenir un seul bloc d'essais, suivi d'un affichage FEEDBACK. Une boucle *practice_phase* autour de cette séquence \"bloc\" constituerait alors la phase de pratique de l'expérience. Cela peut sembler un peu abstrait pour l'instant, mais au fur et à mesure que vous suivrez ce tutoriel, vous vous familiariserez avec l'utilisation des LOOPs et des SEQUENCEs.\n\n__Conseil__ -- Pour plus d'informations sur les SEQUENCEs et LOOPs, voir :\n\n- %link:loop%\n- %link:sequence%\n\n</div>\n\n__Ajoutez un nouvel élément form_text_display pour le message de fin de la phase de pratique__\n\nAprès la phase de pratique, nous voulons informer le participant que la véritable expérience commencera. Pour cela, nous avons besoin d'un autre `form_text_display`. Revenez à la séquence *experiment* et faites glisser un` form_text_display` depuis la barre d'outils des éléments sur l'élément LOOP. Le même menu contextuel apparaîtra qu'auparavant. Cette fois-ci, sélectionnez \"Insérer après new_loop\". (Nous reviendrons sur cette question à l'étape 12.)\n\n<div class = 'info-box' markdown = '1'>\n\n__Conseil__ -- Ne vous inquiétez pas si vous avez accidentellement changé l'élément à exécuter d'une boucle. Vous pouvez facilement annuler cela en cliquant sur le bouton \"Annuler\" dans la barre d'outils (`Ctrl+Shift+Z`).\n\n</div>\n\n__Ajoutez un nouvel élément de boucle, contenant la séquence précédemment créée, pour la phase expérimentale__\n\nNous avons besoin d'un élément LOOP pour la phase expérimentale, tout comme pour la phase de pratique. Par conséquent, faites glisser un LOOP depuis le menu de la barre d'outils des éléments sur * _ form_text_display *."
  },
  "\nThe compatibility check may also indicate errors of the following type:\n\n```bash\nThe prepare phase for item new_logger is called multiple times in a row\nThe run phase for item new_logger is called multiple times in a row\n```\n\nThis error results from how the experiment is structured, and specifically the use of linked copies. It's not always easy to understand where this error comes from, but you can read more about the prepare-run strategy in [this article](%url:prepare-run%). As a workaround, you can put the problematic items in a dummy LOOP, that is, a LOOP that simply calls the item once.\n\n\n## Supported browsers\n\nThe following combinations of browser and operating systems have been tested with the latest version of OSWeb. Older browser versions, operating systems, and versions of OSWeb may work, but have not undergone recent testing. Certain extensions, such as Ad blockers or Script blockers, may prevent OSWeb from running.\n\n### Fully supported\n\n- Chrome >= 101 (Windows 11, Mac OS Monterey, Ubuntu 22.04, Android 12.0)\n- Edge >= 101 (Windows 11, Mac OS Monterey)\n- Firefox >= 99 (Windows 11, Mac OS Monterey, Ubuntu 22.04, Android 12.0)\n- Opera >= 86 (Windows 11) \n- Chromium >= 101 (iOS 15.2)\n- Firefox >= 99 (iOS 15.2)\n- Opera >= 86 (Mac OS Monterey) \n- Safari >= 15 (iOS 15.2, Mac OS Monterey)\n\n### Unsupported\n\n- Internet Explorer >= 11 (Windows 10) \n\n\n\n## Upgrading OSWeb\n\nOSWeb is under active development. If you want to make sure that you're running the latest version, you can upgrade the OSWeb extension, which is called `opensesame-extension-osweb`. As of OpenSesame 3.3, you can do this by running the following command in the console:\n\n```bash\nconda update opensesame-extension-osweb -c cogsci -c conda-forge -y\n```\n\nOr:\n\n```bash\npip install opensesame-extension-osweb --upgrade\n```\n\nSee also:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>\n\n\n## Including external JavaScript packages\n\nNew in OSWeb v1.4.6.1\n{:.page-notification}\n\nYou can include external JavaScript packages by entering URLs to these packages (one URL per line) in the input field labeled 'External JavaScript libraries'. These packages are then included with `<script>` tags in the head of the HTML.\n\nFor example, you can include [WebGazer](%url:webgazer%) for in-browser by entering the following link:\n\n```\nhttps://webgazer.cs.brown.edu/webgazer.js\n```\n": {
    "fr": "La vérification de compatibilité peut également indiquer des erreurs du type suivant :\n\n```bash\nLa phase de préparation pour l'élément new_logger est appelée plusieurs fois de suite\nLa phase d'exécution pour l'élément new_logger est appelée plusieurs fois de suite\n```\n\nCette erreur provient de la structure de l'expérience, et plus précisément de l'utilisation de copies liées. Il n'est pas toujours facile de comprendre d'où vient cette erreur, mais vous pouvez en savoir plus sur la stratégie de préparation-exécution dans [cet article](%url:prepare-run%). En guise de solution temporaire, vous pouvez mettre les éléments problématiques dans une boucle factice, c'est-à-dire une boucle qui appelle simplement l'élément une fois.\n\n## Navigateurs pris en charge\n\nLes combinaisons de navigateurs et de systèmes d'exploitation suivantes ont été testées avec la dernière version d'OSWeb. Les versions antérieures des navigateurs, des systèmes d'exploitation et des versions d'OSWeb peuvent fonctionner, mais n'ont pas été testées récemment. Certaines extensions, telles que les bloqueurs de publicités ou les bloqueurs de scripts, peuvent empêcher OSWeb de fonctionner.\n\n### Complètement pris en charge\n\n- Chrome >= 101 (Windows 11, Mac OS Monterey, Ubuntu 22.04, Android 12.0)\n- Edge >= 101 (Windows 11, Mac OS Monterey)\n- Firefox >= 99 (Windows 11, Mac OS Monterey, Ubuntu 22.04, Android 12.0)\n- Opera >= 86 (Windows 11)\n- Chromium >= 101 (iOS 15.2)\n- Firefox >= 99 (iOS 15.2)\n- Opera >= 86 (Mac OS Monterey)\n- Safari >= 15 (iOS 15.2, Mac OS Monterey)\n\n### Non pris en charge\n\n- Internet Explorer >= 11 (Windows 10)\n\n## Mise à jour d'OSWeb\n\nOSWeb est en développement actif. Si vous souhaitez vous assurer que vous utilisez la dernière version, vous pouvez mettre à jour l'extension OSWeb, appelée `opensesame-extension-osweb`. À partir d'OpenSesame 3.3, vous pouvez le faire en exécutant la commande suivante dans la console :\n\n```bash\nconda update opensesame-extension-osweb -c cogsci -c conda-forge -y\n```\n\nOu :\n\n```bash\npip install opensesame-extension-osweb --upgrade\n```\n\nVoir aussi :\n\n- <https://rapunzel.cogsci.nl/manual/environment/>\n\n## Inclure des bibliothèques JavaScript externes\n\nNouveau dans OSWeb v1.4.6.1\n{:.page-notification}\n\nVous pouvez inclure des bibliothèques JavaScript externes en saisissant les URL de ces bibliothèques (une URL par ligne) dans le champ de saisie intitulé 'Bibliothèques JavaScript externes'. Ces bibliothèques sont ensuite incluses avec des balises `<script>` dans l'en-tête du HTML.\n\nPar exemple, vous pouvez inclure [WebGazer](%url:webgazer%) pour un navigateur en entrant le lien suivant :\n\n```\nhttps://webgazer.cs.brown.edu/webgazer.js\n```"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## Screenshot\n\n<notranslate>\nfigure:\n id: FigWidgets\n source: widgets.png\n caption: A list of available FORM widgets.\n</notranslate>\n\n\n## Widgets and keywords\n\nAll keywords are optional, instead otherwise indicated.\n\n### Form\n\nThe `cols` and `rows` keywords can either be single `int` values, in which case they specify the number of equally sized columns and rows, or lists of `int`, in which case they specify the relative sizes of each column and row. For more information about form geometry, see:\n\n- %link:manual/forms/custom%\n\nThe `validator` keyword can be used to validate form input. For more information, see:\n\n- %link:manual/forms/validation%\n\n(In OpenSesame script, you do not need to explicitly create a form.)\n\nPython script:\n\n~~~ .python\nform = Form(\n    cols=2, rows=2, spacing=10, margins=(100, 100, 100, 100), theme='gray',\n    timeout=None, clicks=False, validator=None\n)\nbutton = Button(text='Ok!')\nform.set_widget(button, (0, 0))\nform._exec()\n~~~\n\n\n### button / Button\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 button text=\"Click me!\" center=yes frame=yes var=response\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nbutton = Button(text='Click me!', frame=True, center=True, var='response')\nform.set_widget(button, (0, 0))\nform._exec()\n~~~\n\n\n### checkbox / Checkbox\n\nIf a group is specified, checking one checkbox from that group will uncheck all other checkboxes from that group. Checkboxes that are part of a group cannot be unchecked, except by clicking on another checkbox in that group.\n\nThe `group` keyword also affects how variables are stored, as described here:\n\n- %link:manual/forms/variables%\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 checkbox group=group text=\"Option 1\"\nwidget 0 1 1 1 checkbox group=group text=\"Option 2\"\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\ncheckbox1 = Checkbox(text='Option 1', group='group')\ncheckbox2 = Checkbox(text='Option 2', group='group')\nform.set_widget(checkbox1, (0, 0))\nform.set_widget(checkbox2, (0, 1))\nform._exec()\n~~~\n\n\n### image / ImageWidget\n\nThe Python object is called `ImageWidget` to distinguish it from the `Image` canvas element.\n\nOpenSesame script:\n\n~~~python\n# Only path is a required keyword\nwidget 0 0 1 1 image path=\"my_image.png\" adjust=yes frame=no\n~~~\n\nPython script:\n\n~~~ .python\n# Only path is a required keyword\nform = Form()\nimage = ImageWidget(path=pool['my_image.png'], adjust=True, frame=False)\nform.set_widget(image, (0, 0))\nform._exec()\n~~~\n\n\n### image_button / ImageButton\n\nThe `image_id` keyword is used to identify the image button when it is clicked. If no `image_id` is provided, the path to the image is used as id.\n\nOpenSesame script:\n\n~~~python\n# Only path is a required keyword\nwidget 0 0 1 1 image_button path=\"my_image.png\" adjust=yes frame=no image_id=my_image var=response\n~~~\n\nPython script:\n\n~~~ .python\n# Only path is a required keyword\nform = Form()\nimage_button = ImageButton(\n    path=pool['my_image.png'], adjust=True, frame=False,\n    image_id='my_image', var='response'\n)\nform.set_widget(image_button, (0, 0))\nform._exec()\n~~~\n\n\n### label / Label\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 label text=\"My text\" frame=no center=yes\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nlabel = Label(text='My text', frame=False, center=True)\nform.set_widget(label, (0,0))\nform._exec()\n~~~\n\n\n### rating_scale / RatingScale\n\nThe `nodes` keyword can be an `int` or a semicolon-separated list of labels. If `nodes` is an `int`, it specified the number of (unlabeled) nodes.\n\nThe `default` keyword indicates which node number is selected by default, where the first node is 0.\n\nOpenSesame script:\n\n~~~python\nwidget 0 1 1 1 rating_scale var=response nodes=\"Agree;Don't know;Disagree\" click_accepts=no orientation=horizontal var=response default=0\n~~~\n\nPython script:": {
    "fr": "\n<notranslate>[TOC]</notranslate>\n\n\n## Capture d'écran\n\n<notranslate>\nfigure :\n id : FigWidgets\n source : widgets.png\n légende : Liste des widgets FORM disponibles.\n</notranslate>\n\n\n## Widgets et mots-clés\n\nTous les mots-clés sont facultatifs, sauf indication contraire.\n\n### Formulaire\n\nLes mots-clés `cols` et `rows` peuvent être des valeurs simples `int`, auquel cas ils spécifient le nombre de colonnes et de rangées de taille égale, ou des listes d'`int`, auquel cas ils spécifient les tailles relatives de chaque colonne et rangée. Pour plus d'informations sur la géométrie des formulaires, consultez :\n\n- %link:manuel/forms/custom%\n\nLe mot-clé `validator` peut être utilisé pour valider les entrées du formulaire. Pour plus d'informations, consultez :\n\n- %link:manuel/forms/validation%\n\n(Dans le script OpenSesame, il n'est pas nécessaire de créer explicitement un formulaire.)\n\nScript Python :\n\n~~~ .python\nformulaire = Formulaire(\n    cols=2, rows=2, espacement=10, marges=(100, 100, 100, 100), thème='gris',\n    délai=None, clics=False, validateur=None\n)\nbouton = Bouton(texte='Ok!')\nformulaire.set_widget(bouton, (0, 0))\nformulaire._exec()\n~~~\n\n\n### bouton / Bouton\n\nScript OpenSesame :\n\n~~~python\nwidget 0 0 1 1 bouton texte=\"Cliquez sur moi!\" centre=oui cadre=oui var=réponse\n~~~\n\nScript Python:\n\n~~~ .python\nformulaire = Formulaire()\nbouton = Bouton(texte=\"Cliquez sur moi!\", cadre=True, centre=True, var='réponse')\nformulaire.set_widget(bouton, (0, 0))\nformulaire._exec()\n~~~\n\n\n### case à cocher / Case à cocher\n\nSi un groupe est spécifié, cocher une case dans ce groupe décochera toutes les autres cases de ce groupe. Les cases à cocher faisant partie d'un groupe ne peuvent pas être décochées, sauf en cliquant sur une autre case à cocher de ce groupe.\n\nLe mot-clé `groupe` influence également la manière dont les variables sont stockées, comme décrit ici :\n\n- %link:manuel/forms/variables%\n\nScript OpenSesame :\n\n~~~python\nwidget 0 0 1 1 case à cocher groupe=groupe texte=\"Option 1\"\nwidget 0 1 1 1 case à cocher groupe=groupe texte=\"Option 2\"\n~~~\n\nScript Python :\n\n~~~ .python\nformulaire = Formulaire()\ncaseacocher1 = Case à cocher(texte='Option 1', groupe='groupe')\ncaseacocher2 = Case à cocher(texte='Option 2', groupe='groupe')\nformulaire.set_widget(caseacocher1, (0, 0))\nformulaire.set_widget(caseacocher2, (0, 1))\nformulaire._exec()\n~~~\n\n\n### image / ImageWidget\n\nL'objet Python est appelé `ImageWidget` pour le distinguer de l'élément de toile `Image`.\n\nScript OpenSesame :\n\n~~~python\n# Seul le chemin est un mot-clé requis\nwidget 0 0 1 1 image chemin=\"mon_image.png\" ajustement=oui cadre=non\n~~~\n\nScript Python :\n\n~~~ .python\n# Seul le chemin est un mot-clé requis\nformulaire = Formulaire()\nimage = ImageWidget(chemin=pool['mon_image.png'], ajustement=True, cadre=False)\nformulaire.set_widget(image, (0, 0))\nformulaire._exec()\n~~~\n\n\n### bouton_image / Bouton image\n\nLe mot-clé `image_id` est utilisé pour identifier le bouton image lorsqu'il est cliqué. Si aucun `image_id` n'est fourni, le chemin d'accès à l'image est utilisé comme identifiant.\n\nScript OpenSesame :\n\n~~~python\n# Seul le chemin est un mot-clé requis\nwidget 0 0 1 1 bouton_image chemin=\"mon_image.png\" ajustement=oui cadre=non image_id=mon_image var=réponse\n~~~\n\nScript Python :\n\n~~~ .python\n# Seul le chemin est un mot-clé requis\nformulaire = Formulaire()\nbouton_image = Bouton_image(\n    chemin=pool['mon_image.png'], ajustement=oui, cadre=non,\n    image_id='mon_image', var='réponse'\n)\nformulaire.set_widget(bouton_image, (0, 0))\nformulaire._exec()\n~~~\n\n\n### étiquette / Étiquette\n\nScript OpenSesame :\n\n~~~python\nwidget 0 0 1 1 étiquette texte=\"Mon texte\" cadre=non centre=oui\n~~~\n\nScript Python :\n\n~~~ .python\nformulaire = Formulaire()\nétiquette = Étiquette(texte='Mon texte', cadre=False, centre=True)\nformulaire.set_widget(étiquette, (0, 0))\nformulaire._exec()\n~~~\n\n\n### échelle_d'évaluation / Échelle d'évaluation\n\nLe mot-clé `noeuds` peut être un `int` ou une liste de libellés séparés par des points-virgules. Si `noeuds` est un `int`, il spécifie le nombre de nœuds (non étiquetés).\n\nLe mot-clé `par défaut` indique quel numéro de nœud est sélectionné par défaut, où le premier nœud est 0.\n\nScript OpenSesame :\n\n~~~python\nwidget 0 1 1 1 échelle_d'évaluation var=réponse noeuds=\"D'accord;Ne sais pas;Désaccord\" click_accepts=non orientation=horizontal var=réponse default=0\n~~~\n\nScript Python:"
  },
  "<notranslate>\nfigure:\n id: FacesBlockLoop\n source: faces_block_loop.png\n caption: |\n  Content of the file pool and the loop table corresponding to Block 2 (categorizing faces) of the IAT.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- The values in the column *stimulus* should correspond exactly to the names of the files in the file pools. Otherwise, OpenSesame won't be able to find the JPGs if we're going to refer to them later.\n\n</div>\n\n### Step 8: Modify the trial sequence\n\nRight now, our new trial sequence is still empty. We need to fill it with the following events (see %TrialSequence):\n\n1. Show a fixation dot for 500 ms\n2. Show a picture of a face, along with the two category names (*OLD* and *YOUNG*)\n3. Collect a keyboard response\n4. Write all variables to the output file\n\n__Copy re-usable items__\n\nEvent 1, 3 and 4 are identical to the word part of the experiment. We can therefore re-use the corresponding items by copying them. To do this:\n\n- Right click on *fixation* (as part of the *words_trial_sequence*) in the overview area\n- Choose 'copy (linked)', because we want to create another occurrence of the same item\n- Right click on *faces_trial_sequence* (i.e., the new sequence)\n- Choose 'Paste'\n- Choose 'Insert into...'\n- Repeat this procedure for the items *keyboard_response* and *logger* (see %LinkedCopies)\n\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- If the order of the items in the sequence is messed up, you can correct this by dragging and dropping\n\n__Tip__ -- If you accidentally dropped a copy somewhere else in the overview area (i.e., outside the trial sequence that you targeted), you can always undo this by pressing `Ctrl+Alt+Z`\n\n</div>\n\n\n<notranslate>\nvideo:\n source: youtube\n id: LinkedCopies\n videoid: _vDGpPsSqIY\n width: 640\n height: 360\n caption: |\n  Using linked copies.\n</notranslate>\n\n### Step 9: Create the face display\n\nFinally, we need to create a new `sketchpad` item to show the face stimuli. To do so:\n\n- Grab a `sketchpad` item from the overview area\n- Drop it into the *faces_trial_sequence*\n- Make sure it appears right after the fixation dot\n- Rename the item as *face*\n\nRight now, your overview area should resemble this:\n\n\n<notranslate>\nfigure:\n id: OverviewBlock1-2.png\n source: overview-area-with-face-block.png\n caption: |\n  Overview area after having added all items to the *faces_trial_sequence*.\n</notranslate>\n\n### Step 10: Configure the content of the face sketchpad\n\n__Draw the category names__\n\n- As before, show the two categories (here: *YOUNG* in the upper left, and *OLD* in the upper right quandrant) by using the `Draw textline` element\n- Set the duration of the sketchpad to 0 ms\n\n__Show the face stimulus__\n\nNext, we want to show a picture of a face at the center of the screen. As before, the stimulus is *variable*, such that which face is shown depends on the row in the block loop that is currently run. Therefore, we will use the `square-bracket syntax` again. But first:\n\n- Select the `Draw image` sketchpad element\n- Click on the center\n- Select one of the jpg files\n\nNext, we want to make the jpg file variable rather than static. To do this, we need to make a tiny adjustment to the *script* of the sketchpad item:\n\n- Click on the 'Select view' button at the top-right of the *face* tab and select 'View script'. You will now see the script that corresponds to the sketchpad that we have just created:\n\n~~~ .python\nset duration 0\nset description \"Displays stimuli\"\ndraw image center=1 file=\"of1.jpg\" scale=1 show_if=always x=0 y=0 z_index=0\ndraw textline center=1 color=white font_bold=no font_family=mono font_italic=no font_size=30 html=yes show_if=always text=\"YOUNG<br />\" x=-320 y=-192 z_index=0\ndraw textline center=1 color=white font_bold=no font_family=mono font_italic=no font_size=30 html=yes show_if=always text=OLD x=320 y=-192 z_index=0\n~~~": {
    "fr": "<notranslate>\nfigure:\n id: FacesBlockLoop\n source: faces_block_loop.png\n caption: |\n  Contenu du pool de fichiers et du tableau de boucles correspondant au Bloc 2 (catégorisation des visages) de l'IAT.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Astuce__ -- Les valeurs de la colonne *stimulus* doivent correspondre exactement aux noms des fichiers dans les pools de fichiers. Sinon, OpenSesame ne pourra pas trouver les JPG si nous devons nous y référer plus tard.\n\n</div>\n\n### Étape 8 : Modifier la séquence d'essai\n\nPour l'instant, notre nouvelle séquence d'essai est encore vide. Nous devons la remplir avec les événements suivants (voir %TrialSequence) :\n\n1. Afficher un point de fixation pendant 500 ms\n2. Montrer une photo d'un visage, avec les deux noms de catégories (*OLD* et *YOUNG*)\n3. Collecter une réponse au clavier\n4. Écrire toutes les variables dans le fichier de sortie\n\n__Copier les éléments réutilisables__\n\nLes événements 1, 3 et 4 sont identiques à la partie mot de l'expérience. Nous pouvons donc réutiliser les éléments correspondants en les copiant. Pour ce faire :\n\n- Faites un clic droit sur *fixation* (dans *words_trial_sequence*) dans la zone d'aperçu\n- Choisissez 'copy (linked)', car nous voulons créer une autre occurrence du même élément\n- Faites un clic droit sur *faces_trial_sequence* (c'est-à-dire la nouvelle séquence)\n- Choisissez 'Coller'\n- Choisissez 'Insérer dans...'\n- Répétez cette procédure pour les éléments *keyboard_response* et *logger* (voir %LinkedCopies)\n\n<div class='info-box' markdown='1'>\n\n__Astuce__ -- Si l'ordre des éléments dans la séquence est mélangé, vous pouvez le corriger en faisant glisser et déposer\n\n__Astuce__ -- Si vous avez accidentellement déposé une copie ailleurs dans la zone d'aperçu (c'est-à-dire en dehors de la séquence d'essai que vous visiez), vous pouvez toujours annuler cette action en appuyant sur `Ctrl+Alt+Z`\n\n</div>\n\n<notranslate>\nvideo:\n source: youtube\n id: LinkedCopies\n videoid: _vDGpPsSqIY\n width: 640\n height: 360\n caption: |\n  Utilisation de copies liées.\n</notranslate>\n\n### Étape 9 : Créer l'affichage du visage\n\nEnfin, nous devons créer un nouvel élément `sketchpad` pour afficher les stimuli du visage. Pour ce faire :\n\n- Prenez un élément `sketchpad` dans la zone d'aperçu\n- Déposez-le dans le *faces_trial_sequence*\n- Assurez-vous qu'il apparaisse juste après le point de fixation\n- Renommez l'élément en *face*\n\nÀ présent, votre zone d'aperçu doit ressembler à ceci :\n\n<notranslate>\nfigure:\n id: OverviewBlock1-2.png\n source: overview-area-with-face-block.png\n caption: |\n  Zone d'aperçu après avoir ajouté tous les éléments dans le *faces_trial_sequence*.\n</notranslate>\n\n### Étape 10 : Configurer le contenu du sketchpad de visage\n\n__Dessiner les noms des catégories__\n\n- Comme auparavant, montrez les deux catégories (ici : *YOUNG* dans le quadrant supérieur gauche, et *OLD* dans le quadrant supérieur droit) en utilisant l'élément `Draw textline`\n- Réglez la durée du sketchpad sur 0 ms\n\n__Afficher le stimulus de visage__\n\nEnsuite, nous voulons montrer une image d'un visage au centre de l'écran. Comme auparavant, le stimulus est *variable*, de sorte que le visage affiché dépend de la ligne dans la boucle de bloc qui est actuellement exécutée. Par conséquent, nous utiliserons à nouveau la `syntaxe à crochets`. Mais d'abord :\n\n- Sélectionnez l'élément `Draw image` du sketchpad\n- Cliquez sur le centre\n- Sélectionnez l'un des fichiers jpg\n\nEnsuite, nous voulons rendre le fichier jpg variable plutôt que statique. Pour ce faire, nous devons apporter une petite modification au *script* de l'élément sketchpad :\n\n- Cliquez sur le bouton 'Select view' en haut à droite de l'onglet *face* et sélectionnez 'View script'. Vous verrez maintenant le script correspondant au sketchpad que nous venons de créer :\n\n~~~ .python\nset duration 0\nset description \"Displays stimuli\"\ndraw image center=1 file=\"of1.jpg\" scale=1 show_if=always x=0 y=0 z_index=0\ndraw textline center=1 color=white font_bold=no font_family=mono font_italic=no font_size=30 html=yes show_if=always text=\"YOUNG<br />\" x=-320 y=-192 z_index=0\ndraw textline center=1 color=white font_bold=no font_family=mono font_italic=no font_size=30 html=yes show_if=always text=OLD x=320 y=-192 z_index=0\n~~~"
  },
  "~~~ .python\nform = Form()\nrating_scale = RatingScale(\n    nodes=['Agree', u\"Don't know\", 'Disagree'], click_accepts=False,\n    orientation='horizontal', var='response', default=0\n)\nform.set_widget(rating_scale, (0, 0))\nform._exec()\n~~~\n\n\n### text_input / TextInput\n\nThe `stub` keyword indicates placeholder text that is shown when no text has been entered. The `key_filter` keyword, available only in Python, specifies a function to filter key presses. This is described in more detail under:\n\n- %link:manual/forms/validation%\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 text_input text=\"Initial text\" frame=yes center=no stub=\"Type here …\" return_accepts=yes var=response\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\ntext_input = TextInput(\n    text='Initial text', frame=True, center=False, stub='Type here …',\n    return_accepts=True, var='response', key_filter=my_filter_function\n)\nform.set_widget(text_input, (0, 0))\nform._exec()\n~~~\n": {
    "fr": "~~~ .python\nform = Form()\nrating_scale = RatingScale(\n    nodes=['D'accord', u\"Je ne sais pas\", 'Pas d'accord'], click_accepts=False,\n    orientation='horizontal', var='response', default=0\n)\nform.set_widget(rating_scale, (0, 0))\nform._exec()\n~~~\n\n\n### text_input / TextInput\n\nLe mot-clé `stub` indique du texte de remplissage qui est affiché lorsqu'aucun texte n'a été saisi. Le mot-clé `key_filter`, disponible uniquement en Python, spécifie une fonction pour filtrer les pressions de touches. Ceci est décrit plus en détail sous :\n\n- %link:manual/forms/validation%\n\nScript OpenSesame :\n\n~~~python\nwidget 0 0 1 1 text_input text=\"Texte initial\" frame=yes center=no stub=\"Tapez ici …\" return_accepts=yes var=response\n~~~\n\nScript Python :\n\n~~~ .python\nform = Form()\ntext_input = TextInput(\n    text='Texte initial', frame=True, center=False, stub='Tapez ici …',\n    return_accepts=True, var='response', key_filter=my_filter_function\n)\nform.set_widget(text_input, (0, 0))\nform._exec()\n~~~"
  },
  "The newly created LOOP (called *new_loop_1*) is empty, and should be filled with a SEQUENCE, just like the LOOP we created before. However, because the trials of the practice and experimental phase are identical, they can use the same SEQUENCE. Therefore, instead of dragging a new SEQUENCE from the item toolbar, you can re-use the *existing* one (i.e. create a linked copy).\n\nTo do this, right-click on the previously created *new_sequence*, and select 'Copy (linked)'. Now, right-click on *new_loop_1* and select 'Paste'. In the pop-up menu that appears, select 'Insert into new_loop 1'.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ — There is an important distinction between *linked* and *unlinked* copies. If you create a linked copy of an item, you create another occurrence of the same item. Therefore, if you modify the original item, the linked copy will change as well. In contrast, if you create an unlinked copy of an item, the copy will be initially look identical (except for its name), but you can edit the original without affecting the unlinked copy, and vice versa.\n\n</div>\n\n__Append a new form_text_display item, for the goodbye message__\n\nWhen the experiment is finished, we should say goodbye to the participant. For this we need another `form_text_display` item. Go back to the *experiment* SEQUENCE, and drag a `form_text_display` from the item toolbar onto *new_loop_1*. In the pop-up menu that appears, select 'Insert after new_loop_1'. (We will get back to this in Step 12.)\n\n__Give the new items sensible names__\n\nBy default, new items have names like *new_sequence* and *new_form_text_display_2*. It is good practice to give items sensible names. This makes it much easier to understand the structure of the experiment. If you want, you can also add a description to each item. Item names must consist of alphanumeric characters and/or underscores.\n\n- Select *new_form_text_display* in the overview area, double-click on its label in the top of the tab area and rename the item to *instructions*. (Overview-area shortcut: `F2`)\n- Rename *new_loop* to *practice_loop*.\n- Rename *new_sequence* to *block_sequence*. Because you have re-used this item in *new_loop_1*, the name automatically changes there as well. (This illustrates why it is efficient to create linked copies whenever this is possible.)\n- Rename *new_form_text_display_1* to *end_of_practice*.\n- Rename *new_loop_1* to *experimental_loop*.\n- Rename *new_form_text_display_2* to *end_of_experiment*.\n\n__Give the whole experiment a sensible name__\n\nThe experiment in its entirety also has a title and a description. Click on 'New experiment' in the overview area. You can rename the experiment in the same way as you renamed its items. The title currently is 'New experiment'. Rename the experiment to 'Tutorial: Gaze cuing'. Unlike item names, the experiment title may contain spaces etc.\n\nThe overview area of your experiment now looks like %FigStep1. This would be a good time to save your experiment (shortcut: `Ctrl+S`).\n\n<notranslate>\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of the step 1.\n</notranslate>\n\n\n## Step 2: Create the block sequence\n\nClick on *block_sequence* in the overview. At the moment this SEQUENCE is empty. We want *block sequence* to consist of a block of trials, followed by a  FEEDBACK display. For this we need to do the following:\n\n__Append a reset_feedback item to reset the feedback variables__\n\nWe don't want our feedback to be confounded by key presses that participants have made during the instruction phase or previous blocks of trials. Therefore, we start each block of trials by resetting the feedback variables. To do this we need a `reset_feedback` item. Grab `reset_feedback` from the item toolbar (under 'Response collection') and drag it onto *block_sequence*.\n\n__Append a new loop, containing a new sequence, for a block of trials__": {
    "fr": "La nouvelle BOUCLE (appelée *new_loop_1*) est vide et doit être remplie avec une SÉQUENCE, tout comme la BOUCLE que nous avons créée précédemment. Cependant, comme les essais de la phase de pratique et expérimentale sont identiques, ils peuvent utiliser la même SÉQUENCE. Par conséquent, au lieu de faire glisser une nouvelle SEQUENCE à partir de la barre d'outils, vous pouvez réutiliser celle *existante* (c'est-à-dire créer une copie liée).\n\nPour ce faire, faites un clic droit sur la *new_sequence* précédemment créée et sélectionnez \"Copier (lié)\". Maintenant, faites un clic droit sur *new_loop_1* et sélectionnez \"Coller\". Dans le menu contextuel qui apparaît, sélectionnez \"Insérer dans new_loop_1\".\n\n<div class='info-box' markdown='1'>\n\n__Boîte d'arrière-plan__\n\n__Astuce__ : Il existe une distinction importante entre les copies *liées* et *non liées*. Si vous créez une copie liée d'un élément, vous créez une autre occurrence du même élément. Par conséquent, si vous modifiez l'élément original, la copie liée changera également. En revanche, si vous créez une copie non liée d'un élément, la copie sera initialement identique (sauf pour son nom), mais vous pouvez modifier l'original sans affecter la copie non liée, et vice versa.\n\n</div>\n\n__Ajoutez un nouvel élément form_text_display pour le message d'au revoir__\n\nLorsque l'expérience est terminée, nous devons dire au revoir au participant. Pour cela, nous avons besoin d'un autre élément `form_text_display`. Revenez à la SÉQUENCE *expérimentale* et faites glisser un `form_text_display` depuis la barre d'outils sur *new_loop_1*. Dans le menu contextuel qui apparaît, sélectionnez \"Insérer après new_loop_1\" (nous reviendrons à cela à l'étape 12).\n\n__Donnez aux nouveaux éléments des noms significatifs__\n\nPar défaut, les nouveaux éléments ont des noms tels que *new_sequence* et *new_form_text_display_2*. Il est recommandé de donner des noms significatifs aux éléments. Cela facilite grandement la compréhension de la structure de l'expérience. Si vous le souhaitez, vous pouvez également ajouter une description à chaque élément. Les noms des éléments doivent être composés de caractères alphanumériques et/ou de tirets bas.\n\n- Sélectionnez *new_form_text_display* dans la zone d'aperçu, double-cliquez sur son étiquette en haut de la zone des onglets et renommez l'élément *instructions*. (Raccourci zone d'aperçu : `F2`)\n- Renommez *new_loop* en *practice_loop*.\n- Renommez *new_sequence* en *block_sequence*. Comme vous avez réutilisé cet élément dans *new_loop_1*, le nom change automatiquement là aussi. (Cela illustre pourquoi il est efficace de créer des copies liées chaque fois que cela est possible.)\n- Renommez *new_form_text_display_1* en *end_of_practice*.\n- Renommez *new_loop_1* en *experimental_loop*.\n- Renommez *new_form_text_display_2* en *end_of_experiment*.\n\n__Donnez à toute l'expérience un nom significatif__\n\nL'expérience dans son ensemble a également un titre et une description. Cliquez sur \"Nouvelle expérience\" dans la zone d'aperçu. Vous pouvez renommer l'expérience de la même manière que vous avez renommé ses éléments. Le titre actuel est \"Nouvelle expérience\". Renommez l'expérience en \"Tutoriel : Gaze cuing\". Contrairement aux noms des éléments, le titre de l'expérience peut contenir des espaces, etc.\n\nLa zone d'aperçu de votre expérience ressemble maintenant à %FigStep1. Ce serait un bon moment pour sauvegarder votre expérience (raccourci : `Ctrl+S`).\n\n<notranslate>\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  La zone d'aperçu à la fin de l'étape 1.\n</notranslate>\n\n\n## Étape 2 : Créer la séquence de bloc\n\nCliquez sur *block_sequence* dans l'aperçu. Pour l'instant, cette SEQUENCE est vide. Nous voulons que *block_sequence* se compose d'un bloc d'essais, suivi d'un affichage FEEDBACK. Pour cela, nous devons faire ce qui suit : \n\n__Ajoutez un élément reset_feedback pour réinitialiser les variables de retour__\n\nNous ne voulons pas que notre retour soit biaisé par les touches que les participants ont appuyées pendant la phase d'instruction ou les blocs d'essais précédents. Par conséquent, nous commençons chaque bloc d'essais en réinitialisant les variables de retour. Pour ce faire, il nous faut un élément `reset_feedback`. Prenez `reset_feedback` dans la barre d'outils (sous \"Collecte de réponses\") et faites-le glisser sur *block_sequence*.\n\n__Ajoutez une nouvelle boucle, contenant une nouvelle séquence, pour un bloc d'essais__"
  },
  "- The only thing that we need to do is replace the string 'of1.jpg' with `[stimulus]`. This means that OpenSesame uses the variable `[stimulus]` (which contains all the JPG names) to determine which image should be shown.\n\n\n~~~ .python\nset duration 0\nset description \"Displays stimuli\"\ndraw image center=1 file=[stimulus] scale=1 show_if=always x=0 y=0 z_index=0\ndraw textline center=1 color=white font_bold=no font_family=mono font_italic=no font_size=30 html=yes show_if=always text=\"YOUNG<br />\" x=-320 y=-192 z_index=0\ndraw textline center=1 color=white font_bold=no font_family=mono font_italic=no font_size=30 html=yes show_if=always text=OLD x=320 y=-192 z_index=0\n~~~\n\n- Click 'apply and close'\n\nNext, it's time to test whether your experiment works up to this point.\n\n\n## The mixed blocks\n\n### Congruent mapping\n\nThe third block is a mix of block 1 and 2, such that participants have to categorize both words and faces. The mapping is *congruent*, such that *POSITIVE* words and *YOUNG* faces require a left hand response, whereas *NEGATIVE* words and *OLD* faces require a right hand response (see %Task).\n\n### Step 11: Create a third block loop and trial sequence\n\nIn order to create the third block of the IAT, we need to:\n\n- Create a new block loop (and rename it to *congruent_block_loop*) (cf. Step 4)\n- Create a new trial sequence (within the new block loop) and call it *congruent_trial_sequence* (cf. Step 5).\n\nYour experimental overview should now look like so (%OverviewWithCongruent):\n\n<notranslate>\nfigure:\n id: OverviewWithCongruent\n source: overview_with_congruent_loop.png\n caption: |\n  Experimental overview after having inserted a third block loop and trial sequence.\n</notranslate>\n\n### Step 12: Fill the *congruent_block_loop*\n\nThe content of the congruent block loop is very similar to the word and the face block loop, except that it now contains both types of stimuli. Therefore:\n\n- Copy-paste the content of the *word_block_loop* to the congruent_block_loop. This will take up row 1 to 12\n- Do the same for the content of the *faces_block_loop*. This will take up row 13 to 24\n- (Make sure you don't copy the column headers twice)\n\n### Step 13: Fill the *congruent_trial_sequence*\n\n- As in Step 8, copy the items *fixation*, *keyboard_response* and *logger* to the new trial sequence\n- Unfortunately, we can't use copies of the *word* sketchpad and the *face* sketchpad, because we want to show *both* categories (i.e. POSITIVE vs NEGATIVE and YOUNG vs OLD) on the left and right side of the display\n- Therefore, we append a new `sketchpad` item to the congruent_trial_sequence and call it *congruent_stimulus*\n- Make sure that the new sketchpad appears right after the fixation point, and before the `keyboard_response item`\n\nYour experimental overview should now look like this (%OverviewWithCongruent):\n\n<notranslate>\nfigure:\n id: OverviewWithCongruent\n source: overview_congruent_filled_in.png\n caption: |\n  Experimental overview after having filled in the trial sequence of the congruent block.\n</notranslate>\n\n### Step 14: Adjust the content of the *congruent_sketchpad*\n\nOpen the tab of the *congruent_stimulus* sketchpad and change its duration to 0 instead of 'keypress'.\n\n__Category names__\n\n- Make sure that both category names appear on the upper left and right side of the screen (see %Task). Use the following mapping:\n    - The category names *POSITIVE* and *YOUNG* appear at the left side\n    - *NEGATIVE* and *OLD* appear at the right side\n\n__Word stimuli__\n\nDraw the word stimulus at the center of the screen in the same way as we did for block 1 (see Step 3). Use the `square-bracket syntax'.\n\n__Face stimuli__\n\nDraw the face stimulus at the center of the screen in the same way as we did for block 2 (see Step 9).Add\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- Don't worry if your sketchpad looks messy. We will take care of that shortly.\n\n</div>\n\n\n## Step 15: Using Show-if statements": {
    "fr": "- La seule chose que nous devons faire est de remplacer la chaîne 'of1.jpg' par `[stimulus]`. Cela signifie qu'OpenSesame utilise la variable `[stimulus]` (qui contient tous les noms de JPG) pour déterminer quelle image doit être affichée.\n\n~~~ .python\nset duration 0\nset description \"Affiche les stimuli\"\ndraw image center=1 file=[stimulus] scale=1 show_if=toujours x=0 y=0 z_index=0\ndraw textline center=1 color=white font_bold=no font_family=mono font_italic=no font_size=30 html=yes show_if=toujours text=\"JEUNE<br />\" x=-320 y=-192 z_index=0\ndraw textline center=1 color=white font_bold=no font_family=mono font_italic=no font_size=30 html=yes show_if=toujours text=VIEUX x=320 y=-192 z_index=0\n~~~\n\n- Cliquez sur 'appliquer et fermer'\n\nEnsuite, il est temps de tester si votre expérience fonctionne jusqu'à ce point.\n\n\n## Les blocs mixtes\n\n### Correspondance congruente\n\nLe troisième bloc est un mélange des blocs 1 et 2, de sorte que les participants doivent catégoriser à la fois les mots et les visages. La correspondance est *congruente*, de sorte que les mots *POSITIFS* et les visages *JEUNES* nécessitent une réponse de la main gauche, tandis que les mots *NÉGATIFS* et les visages *VIEUX* nécessitent une réponse de la main droite (voir %Task).\n\n### Étape 11 : Créer une troisième boucle de bloc et une séquence d'essai\n\nAfin de créer le troisième bloc du IAT, nous devons :\n\n- Créer une nouvelle boucle de bloc (et la renommer en *congruent_block_loop*) (cf. Étape 4)\n- Créer une nouvelle séquence d'essai (à l'intérieur de la nouvelle boucle de bloc) et l'appeler *congruent_trial_sequence* (cf. Étape 5).\n\nVotre vue d'ensemble expérimentale devrait maintenant ressembler à ceci (%OverviewWithCongruent) :\n\n<notranslate>\nfigure:\n id: OverviewWithCongruent\n source: overview_with_congruent_loop.png\n caption: |\n  Vue d'ensemble expérimentale après avoir inséré une troisième boucle de bloc et une séquence d'essai.\n</notranslate>\n\n### Étape 12 : Remplir la *congruent_block_loop*\n\nLe contenu de la boucle de bloc congruent est très similaire à la boucle de bloc de mot et de visage, sauf qu'il contient maintenant les deux types de stimuli. Par conséquent :\n\n- Copiez-collez le contenu du *word_block_loop* dans le congruent_block_loop. Cela prendra les rangées 1 à 12\n- Faites de même pour le contenu du *faces_block_loop*. Cela prendra les rangées 13 à 24\n- (Assurez-vous de ne pas copier les en-têtes de colonne deux fois)\n\n### Étape 13 : Remplir la *congruent_trial_sequence*\n\n- Comme à l'étape 8, copiez les éléments *fixation*, *keyboard_response* et *logger* dans la nouvelle séquence d'essai\n- Malheureusement, nous ne pouvons pas utiliser des copies du *word* sketchpad et du *face* sketchpad, car nous voulons montrer *les deux* catégories (c'est-à-dire POSITIF vs NÉGATIF et JEUNE vs VIEUX) sur le côté gauche et droit de l'affichage\n- Par conséquent, nous ajoutons un nouvel élément `sketchpad` à la congruent_trial_sequence et l'appelons *congruent_stimulus*\n- Assurez-vous que le nouveau sketchpad apparaît juste après le point de fixation, et avant l'élément `keyboard_response`\n\nVotre vue d'ensemble expérimentale devrait maintenant ressembler à ceci (%OverviewWithCongruent) :\n\n<notranslate>\nfigure:\n id: OverviewWithCongruent\n source: overview_congruent_filled_in.png\n caption: |\n  Vue d'ensemble expérimentale après avoir rempli la séquence d'essai du bloc congruent.\n</notranslate>\n\n### Étape 14 : Ajustez le contenu du *congruent_sketchpad*\n\nOuvrez l'onglet du *congruent_stimulus* sketchpad et changez sa durée à 0 au lieu de 'keypress'.\n\n__Noms de catégorie__\n\n- Assurez-vous que les deux noms de catégorie apparaissent en haut à gauche et à droite de l'écran (voir %Task). Utilisez le mappage suivant :\n    - Les noms de catégorie *POSITIF* et *JEUNE* apparaissent sur le côté gauche\n    - *NÉGATIF* et *VIEUX* apparaissent sur le côté droit\n\n__Stimuli de mots__\n\nDessinez le stimulus de mot au centre de l'écran de la même manière que nous l'avons fait pour le bloc 1 (voir l'étape 3). Utilisez la syntaxe `à base de crochets`.\n\n__Stimuli de visage__\n\nDessinez le stimulus de visage au centre de l'écran de la même manière que nous l'avons fait pour le bloc 2 (voir l'étape 9).Ajouter\n\n<div class='info-box' markdown='1'>\n\n__Conseil__ -- Ne vous inquiétez pas si votre sketchpad semble désordonné. Nous nous occuperons de cela sous peu.\n\n</div>\n\n\n## Étape 15 : Utilisation des déclarations Show-if"
  },
  "Release notes": {
    "fr": "Notes de version"
  },
  "Notation for experimental design": {
    "fr": "Notation pour la conception expérimentale"
  },
  "Release notes for 3.0.3": {
    "fr": "Notes de version pour 3.0.3"
  },
  "Release notes for 0.27.2": {
    "fr": "Notes de mise à jour pour 0.27.2",
    "de": "Versionshinweise für 0.27.2"
  },
  "Release notes for 3.0.7": {
    "fr": "Notes de publication pour 3.0.7"
  },
  "Release notes for 3.3.2": {
    "fr": "Notes de publication pour 3.3.2"
  },
  "Release notes for 0.27.3": {
    "fr": "Notes de publication pour 0.27.3"
  },
  "Release notes for 2.9.3": {
    "fr": "Notes de version pour 2.9.3"
  },
  "Release notes for 3.3.10": {
    "fr": "Notes de version pour 3.3.10"
  },
  "Release notes for 2.9.7": {
    "fr": "Notes de publication pour 2.9.7"
  },
  "OpenSesame 0.27.3 is the third maintenance release in the 0.27 'Frisky Freud' series, and was released on July 9 2013. If you are upgrading from 0.26, please read the [0.27 release notes][].\n\nNew features and enhancements:\n\n- French translation, contributed by Romain Monfollet\n- Add `screen` parameter to psycho backend settings\n- Provide more detailed version information through `modules()`\n\nBugs fixed:\n\n- Fix many Unicode errors\n- Fix variable setting in checkbox form widgets\n- Forms respect item/ experiment background and foreground\n- Fix a bug where `self` always referred to the first INLINE_SCRIPT of the experiment\n- Allow custom fonts in legacy backend\n\nWindows packaging:\n\n- Use Python 2.7.5\n- All dependencies have been updated to most recent version\n\n[0.27 release notes]: /notes/0.27\n": {
    "fr": "OpenSesame 0.27.3 est la troisième version de maintenance de la série 0.27 'Frisky Freud' et a été publiée le 9 juillet 2013. Si vous passez de la version 0.26, veuillez lire les [notes de la version 0.27][].\n\nNouvelles fonctionnalités et améliorations :\n\n- Traduction française, contribuée par Romain Monfollet\n- Ajout du paramètre `screen` aux paramètres du backend psycho\n- Fournir des informations de version plus détaillées via `modules()`\n\nBugs corrigés :\n\n- Correction de nombreuses erreurs Unicode\n- Correction du réglage des variables dans les widgets de formulaire à cases à cocher\n- Les formulaires respectent l'arrière-plan et l'avant-plan de l'élément / expérience\n- Correction d'un bug où `self` faisait toujours référence au premier INLINE_SCRIPT de l'expérience\n- Autoriser les polices personnalisées dans le backend de legacy\n\nPackaging Windows :\n\n- Utilisation de Python 2.7.5\n- Toutes les dépendances ont été mises à jour vers la version la plus récente\n\n[Notes de la version 0.27]: /notes/0.27"
  },
  "Release notes for 3.3.5": {
    "fr": "Notes de version pour 3.3.5"
  },
  "OpenSesame 0.27.2 is the second maintenance release in the 0.27 'Frisky Freud' series. If you are upgrading from 0.26, please read the [0.27 release notes][].\n\nImportant note:\n\t\n- The behavior of variables in inline_script items has changed slightly. Even though this is unlikely to affect existing experiments, you may want to read the notes regarding 'shared variables' [here](/python/about/).\n\nNew features and enhancements:\n\n- Support for Android ([link](/getting-opensesame/android/))\n- Add `mouse.set_pos()` and `mouse.get_pressed()` functions\n- Add new plugin API ([link](/plugins/create/))\n- Support Markdown for help files\n- Add touch_response plugin\n\nBugs fixed:\n\n- Warn when form widgets are too small\n- Allow 0 ms timeout in `mouse` objects\n- Allow variably defined foreground color in sketchpad\n- Expose more variables to variable inspector\n- Change name in script tab on name change\n- Fix translation issues in Gabor and noise patches\n- Allow capitalization changes when renaming items\n- Fix many Unicode errors\n- Fix a bug that caused editor fonts to be stuck on Arial (Ubuntu 13.04)\n\nWindows packaging:\n\n- Use Python 2.7.4\n- All dependencies have been updated to most recent version\n\n[0.27 release notes]: /notes/0.27\n": {
    "fr": "OpenSesame 0.27.2 est la deuxième version de maintenance de la série 0.27 'Frisky Freud'. Si vous mettez à niveau depuis la version 0.26, veuillez lire les [notes de version 0.27][].\n\nNote importante :\n\t\n- Le comportement des variables dans les éléments inline_script a légèrement changé. Bien que cela soit peu susceptible d'affecter les expériences existantes, vous pouvez consulter les notes concernant les 'variables partagées' [ici](/python/about/).\n\nNouvelles fonctionnalités et améliorations :\n\n- Support pour Android ([lien](/getting-opensesame/android/))\n- Ajout des fonctions `mouse.set_pos()` et `mouse.get_pressed()`\n- Ajout de la nouvelle API de plugin ([lien](/plugins/create/))\n- Support de Markdown pour les fichiers d'aide\n- Ajout du plugin touch_response\n\nBugs corrigés :\n\n- Avertissement lorsque les widgets de formulaire sont trop petits\n- Autoriser un délai de 0 ms dans les objets `mouse`\n- Autoriser une couleur d'avant-plan définie de manière variable dans sketchpad\n- Exposer plus de variables à l'inspecteur de variables\n- Changer le nom dans l'onglet de script lors du changement de nom\n- Correction des problèmes de traduction dans les patches Gabor et de bruit\n- Autoriser les changements de capitalisation lors du renommage des éléments\n- Correction de nombreuses erreurs Unicode\n- Corriger un bug qui faisait que les polices de l'éditeur restaient bloquées sur Arial (Ubuntu 13.04)\n\nPackaging Windows :\n\n- Utilisation de Python 2.7.4\n- Toutes les dépendances ont été mises à jour vers la version la plus récente\n\n[notes de version 0.27]: /notes/0.27"
  },
  "Release notes for 3.3.13": {
    "fr": "Notes de version pour 3.3.13"
  },
  "OpenSesame 2.9.3 is the third maintenance release in the 2.9 series. If you are upgrading from 2.8.3 or earlier, please also read the [2.9.0 release notes].\n\n## Changelog\n\n### Bugs fixed\n\n- Font size was specified in points instead of pixels in GUI\n- Legacy backend crashed when specifying system font in general properties\n- Show arrow-size field in sketchpad\n- Fix a bug where description changes weren't applied\n\n### Improvements\n\n- Allow descriptions to wrap over multiple lines for better screen use\n- Massively improved performance for large experiments (#305)\n\n### Windows packaging\n\n~~~\nOpenSesame 2.9.2\nPython 2.7.8 (default, Jun 30 2014, 16:03:49) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 2.4.10\nQProgedit 2.1.0\nExpyriment  (Revision ; Python 2.7.8)\nNumPy 1.9.1\nPIL is available (version is unknown)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.5.0~opensesame3\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.3\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.5.2\nSciPy 0.14.0\n~~~\n\n[2.9.0 release notes]: /notes/2.9.0/\n": {
    "fr": "OpenSesame 2.9.3 est la troisième version de maintenance de la série 2.9. Si vous mettez à niveau à partir de 2.8.3 ou une version antérieure, veuillez également lire les [notes de version 2.9.0].\n\n## Journal des modifications\n\n### Bugs corrigés\n\n- La taille de la police était spécifiée en points au lieu de pixels dans l'interface graphique\n- Le backend hérité se bloquait lors de la spécification de la police système dans les propriétés générales\n- Afficher le champ de la taille de la flèche dans Sketchpad\n- Correction d'un bug où les modifications de description n'étaient pas appliquées\n\n### Améliorations\n\n- Autoriser les descriptions à s'enrouler sur plusieurs lignes pour une meilleure utilisation de l'écran\n- Amélioration massive des performances pour les grandes expériences (#305)\n\n### Packaging Windows\n\n~~~\nOpenSesame 2.9.2\nPython 2.7.8 (default, Jun 30 2014, 16:03:49) [MSC v.1500 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 2.4.10\nQProgedit 2.1.0\nExpyriment  (Révision ; Python 2.7.8)\nNumPy 1.9.1\nPIL est disponible (la version est inconnue)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.5.0~opensesame3\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.3\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.5.2\nSciPy 0.14.0\n~~~\n\n[notes de version 2.9.0]: /notes/2.9.0/"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.3.2 *Lentiform Loewenfeld* is the second maintenance release in the 3.3 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.3 series.\n\nIf you are upgrading from OpenSesame 3.2 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for his work on OSWeb, the Mac OS package, and bug fixes\n- Yavor Ivanov (%-- github: {user: yarski} --%) for his work on OSWeb and Prolific\n- Eduard Ort (%-- github: {user: eort} --%) for his work on the German translation\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.3.2\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 694 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 695 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 696 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 697 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 698 } --%\n\nrapunzel:\n\n- Updated to 0.4.6\n- %-- github: { repo: \"smathot/rapunzel\", issue: 7 } --%\n- %-- github: { repo: \"smathot/rapunzel\", issue: 8 } --%\n- %-- github: { repo: \"smathot/rapunzel\", issue: 9 } --%\n- %-- github: { repo: \"smathot/rapunzel\", issue: 11 } --%\n\npyqode.core\n\n- Updated to 2.16.0\n\nopensesame-plugin-media_player_mpy\n\n- Updated to 0.1.9\n- %-- github: { repo: \"dschreij/opensesame-plugin-media_player_mpy\", issue: 9 } --%\n\nWindows installer:\n\n- Fix .osexp file-type icon\n\n\n## Packages\n\n\n### Python 3.7 (standard)": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.3.2 *Lentiform Loewenfeld* est la deuxième version de maintenance de la série 3.3. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.3.\n\nSi vous passez de OpenSesame 3.2 ou antérieur, veuillez consulter la liste des modifications importantes :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour son travail sur OSWeb, le package Mac OS, et les corrections de bugs\n- Yavor Ivanov (%-- github: {user: yarski} --%) pour son travail sur OSWeb et Prolific\n- Eduard Ort (%-- github: {user: eort} --%) pour son travail sur la traduction allemande\n\n## Corrections de bugs et améliorations\n\nopensesame :\n\n- Mis à jour en 3.3.2\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 694 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 695 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 696 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 697 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 698 } --%\n\nrapunzel :\n\n- Mis à jour en 0.4.6\n- %-- github: { repo: \"smathot/rapunzel\", issue: 7 } --%\n- %-- github: { repo: \"smathot/rapunzel\", issue: 8 } --%\n- %-- github: { repo: \"smathot/rapunzel\", issue: 9 } --%\n- %-- github: { repo: \"smathot/rapunzel\", issue: 11 } --%\n\npyqode.core\n\n- Mis à jour en 2.16.0\n\nopensesame-plugin-media_player_mpy\n\n- Mis à jour en 0.1.9\n- %-- github: { repo: \"dschreij/opensesame-plugin-media_player_mpy\", issue: 9 } --%\n\nInstallateur Windows :\n\n- Correction de l'icône de type de fichier .osexp\n\n## Paquets\n\n### Python 3.7 (standard)"
  },
  "OpenSesame 2.9.7 is the seventh maintenance release in the 2.9 series. If you are upgrading from 2.8.3 or earlier, please also read the [2.9.0 release notes].\n\n## Credits\n\nThanks to Jarik den Hartog ([@JdenHartog](https://github.com/JdenHartog)) for his code contributions.\n\n## Changes\n\n### Improvements\n\n- Add append menu to overview and sequence\n- Add permanently delete menu option to unused items\n\n### Bugs fixed\n\n- Use px (not pt) as units in font GUI\n- Explicitly set window type in psycho backend (#331)\n- Fix recursion errors in drag-and-drop\n- Restore structure when a drag is canceled (#337)\n- Fix inconsistent folding/unfolding behavior in overview area (#336)\n- Fix missing debug output on Android (#346)\n- Allow uppercase text input on Android (#341)\n- Allow external links in notification dialog (#340)\n- Fix drag-and-drop between different instances of OpenSesame (#338)\n- Fix a crash when dropping an item onto an unused item (#343)\n- Fix a crash on Android when there are filenames with special characters in the file pool (#345)\n\n### Windows packaging\n\n~~~\nOpenSesame 2.9.7\nPython 2.7.8 (default, Jun 30 2014, 16:03:49) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 2.4.10\nQProgedit 2.1.0\nExpyriment  (Revision ; Python 2.7.8)\nNumPy 1.9.1\nPIL is available (version is unknown)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.5.0~opensesame3\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.3\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.5.2\nSciPy 0.14.0\n~~~\n\n[2.9.0 release notes]: /notes/2.9.0/\n": {
    "fr": "OpenSesame 2.9.7 est la septième version de maintenance de la série 2.9. Si vous effectuez une mise à niveau depuis 2.8.3 ou une version antérieure, veuillez également lire les [notes de version 2.9.0].\n\n## Crédits\n\nMerci à Jarik den Hartog ([@JdenHartog](https://github.com/JdenHartog)) pour ses contributions au code.\n\n## Changements\n\n### Améliorations\n\n- Ajouter un menu pour ajouter un élément à la vue d'ensemble et à la séquence\n- Ajouter une option de menu pour la suppression définitive des éléments non utilisés\n\n### Bogues corrigés\n\n- Utiliser px (pas pt) comme unités dans la GUI des polices\n- Définir explicitement le type de fenêtre dans le backend psycho (#331)\n- Corriger les erreurs de récursion dans le glisser-déposer\n- Restaurer la structure lorsqu'un glisser-déposer est annulé (#337)\n- Corriger un comportement incohérent de pliage/dépliage dans la zone d'aperçu (#336)\n- Corriger la sortie de débogage manquante sur Android (#346)\n- Autoriser la saisie de texte en majuscules sur Android (#341)\n- Autoriser les liens externes dans la boîte de dialogue de notification (#340)\n- Corriger le glisser-déposer entre différentes instances d'OpenSesame (#338)\n- Corriger un plantage lors du dépôt d'un élément sur un élément non utilisé (#343)\n- Corriger un plantage sur Android lorsque des noms de fichiers contenant des caractères spéciaux sont présents dans le pool de fichiers (#345)\n\n### Compilation pour Windows\n\n~~~\nOpenSesame 2.9.7\nPython 2.7.8 (default, Jun 30 2014, 16:03:49) [MSC v.1500 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 2.4.10\nQProgedit 2.1.0\nExpyriment  (Révision ; Python 2.7.8)\nNumPy 1.9.1\nPIL est disponible (la version est inconnue)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.5.0~opensesame3\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.3\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.5.2\nSciPy 0.14.0\n~~~\n\n[Notes de version 2.9.0]: /notes/2.9.0/"
  },
  "Release notes for 2.8.1": {
    "fr": "Notes de version pour 2.8.1"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.3.5 *Lentiform Loewenfeld* is the fifth maintenance release in the 3.3 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.3 series. A notable fix in this release is for an issue where FORM_BASE items crashed when opening an experiment.\n\nIf you are upgrading from OpenSesame 3.2 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for his work on the Mac OS package\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.3.5\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 725 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 726 } --%\n\n\npyqode.core\n\n- Updated to 3.0.9\n\n\n## Packages\n\n\n### Python 3.7 (standard)": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.3.5 *Lentiform Loewenfeld* est la cinquième version de maintenance de la série 3.3. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.3. Un correctif notable dans cette version concerne un problème où les éléments FORM_BASE se bloquaient lors de l'ouverture d'une expérience.\n\nSi vous passez de OpenSesame 3.2 ou une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour son travail sur le package Mac OS\n\n## Corrections de bugs et améliorations\n\nopensesame:\n\n- Mis à jour vers 3.3.5\n- %-- github: {repo: \"smathot/OpenSesame\", issue: 725 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 726 } --%\n\npyqode.core\n\n- Mis à jour vers 3.0.9\n\n## Paquets\n\n### Python 3.7 (standard)"
  },
  "OpenSesame 3.0.3 is the third maintenance release in the 3.0 series. If you are upgrading from OpenSesame 2.9.7 or earlier, please see the list of important changes in OpenSesame 3.0:\n\n- [Important changes in 3.0](/miscellaneous/important-changes-3/)\n\n## Credits\n\nThanks to Eduard Ort ([@eort](https://github.com/eort)) and Igor Gnatenko ([@ignatenkobrain](https://github.com/ignatenkobrain)) for their code contributions.\n\n## Changes\n\n### Improvements\n\n- Fix templates for Python 3\n- Fix Exception handling for multiprocess_runner in Python 3\n- Update German translation (de_DE)\n- Update droid template to API 2 (avoids warning)\n\n### Bugs fixed\n\n- Fix Python-3 compatibility for script validator\n- Restore overview area when drop fails (#361)\n- Warn on missing `__end__` statements in OpenSesame script (#364)\n- Don't be greedy when parsing YAML front matter (#369)\n- Fix external_runner (#371)\n- Improve handling of variably defined font and sketchpad element settings (#372)\n- Don't crash when moving sketchpad elements with variably defined positions (#373)\n- Don't crash when copy-pasting in loop table when no cells are selected (#374)\n- Fall back to z_index=0 when an invalid z_index has been specified for sketchpad elements (#375)\n- Don't crash on empty filename in image element in sketchpad (#377)\n- Fix recursion error in overview area with multiple linked copies (#376)\n- Don't try to copy and edit non copyable/editable treeitems\n- Don't crash when failing to get size information for file pool\n- Catch invalid variable names in logger script\n- Don't allow editing run-if statement of top-level sequence in sequence-view\n- Fix gabor and noise-patch elements\n\n### Windows packaging\n\n~~~\nOpenSesame 3.0.3\nPython 2.7.10 (default, May 23 2015, 09:40:32) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 3.0.0\nQProgedit 3.2.0\nExpyriment  (Python 2.7.10)\nIPython 3.2.0\nNumPy 1.9.2\nPIL is available (version is unknown)\nPsychoPy 1.82.01\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.6.0a7\nPyglet 1.2.3\nPyOpenGL 3.1.0\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.6.2\nSciPy 0.15.1\n~~~\n": {
    "fr": "OpenSesame 3.0.3 est la troisième version de maintenance de la série 3.0. Si vous effectuez une mise à niveau à partir d'OpenSesame 2.9.7 ou d'une version antérieure, veuillez consulter la liste des modifications importantes dans OpenSesame 3.0 :\n\n- [Modifications importantes dans 3.0](/miscellaneous/important-changes-3/)\n\n## Crédits\n\nMerci à Eduard Ort ([@eort](https://github.com/eort)) et Igor Gnatenko ([@ignatenkobrain](https://github.com/ignatenkobrain)) pour leurs contributions de code.\n\n## Changements\n\n### Améliorations\n\n- Correction des modèles pour Python 3\n- Correction de la gestion des exceptions pour multiprocess_runner en Python 3\n- Mise à jour de la traduction allemande (de_DE)\n- Mise à jour du modèle droid vers l'API 2 (évite les avertissements)\n\n### Bugs corrigés\n\n- Correction de la compatibilité Python-3 pour le validateur de scripts\n- Restaurer la zone d'aperçu lorsque le dépôt échoue (#361)\n- Avertir sur les déclarations `__end__` manquantes dans OpenSesame script (#364)\n- Ne pas être gourmand lors de l'analyse de la matière YAML (#369)\n- Correction de external_runner (#371)\n- Améliorer la gestion des paramètres définis de manière variable pour la police et les éléments du sketchpad (#372)\n- Ne pas planter lors du déplacement des éléments du sketchpad avec des positions définies de manière variable (#373)\n- Ne pas planter lors de la copie-collage dans la table des boucles lorsque aucune cellule n'est sélectionnée (#374)\n- Revenir à z_index=0 lorsqu'un z_index invalide a été spécifié pour les éléments du sketchpad (#375)\n- Ne pas planter sur un nom de fichier vide dans l'élément image du sketchpad (#377)\n- Correction de l'erreur de récursion dans la zone d'aperçu avec plusieurs copies liées (#376)\n- Ne pas essayer de copier et modifier les treeitems non copiables/modifiables\n- Ne pas planter lors de l'échec de l'obtention des informations de taille pour le pool de fichiers\n- Attrapez les noms de variables invalides dans le script du logger\n- Ne pas autoriser la modification de l'instruction run-if de la séquence de niveau supérieur dans la vue de séquence\n- Correction des éléments gabor et noise-patch\n\n### Packaging Windows\n\n~~~\nOpenSesame 3.0.3\nPython 2.7.10 (default, May 23 2015, 09:40:32) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 3.0.0\nQProgedit 3.2.0\nExpyriment  (Python 2.7.10)\nIPython 3.2.0\nNumPy 1.9.2\nPIL is available (version is unknown)\nPsychoPy 1.82.01\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.6.0a7\nPyglet 1.2.3\nPyOpenGL 3.1.0\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.6.2\nSciPy 0.15.1\n~~~\n"
  },
  "Release notes for 3.3.0": {
    "fr": "Notes de version pour 3.3.0"
  },
  "- [4.0.0](%url:notes%/../400)\n- [3.3.14](%url:notes%/../3314)\n- [3.3.13](%url:notes%/../3313)\n- [3.3.12](%url:notes%/../3312)\n- [3.3.11](%url:notes%/../3311)\n- [3.3.10](%url:notes%/../3310)\n- [3.3.9](%url:notes%/../339)\n- [3.3.8](%url:notes%/../338)\n- [3.3.7](%url:notes%/../337)\n- [3.3.6](%url:notes%/../336)\n- [3.3.5](%url:notes%/../335)\n- [3.3.4](%url:notes%/../334)\n- [3.3.3](%url:notes%/../333)\n- [3.3.2](%url:notes%/../332)\n- [3.3.1](%url:notes%/../331)\n- [3.3.0](%url:notes%/../330)\n- [3.2.8](%url:notes%/../328)\n- [3.2.7](%url:notes%/../327)\n- [3.2.6](%url:notes%/../326)\n- [3.2.5](%url:notes%/../325)\n- [3.2.4](%url:notes%/../324)\n- [3.2.3](%url:notes%/../323)\n- [3.2.2](%url:notes%/../322)\n- [3.2.1](%url:notes%/../321)\n- [3.2.0](%url:notes%/../320)\n- [3.1.9](%url:notes%/../319)\n- [3.1.8](%url:notes%/../318)\n- [3.1.7](%url:notes%/../317)\n- [3.1.6](%url:notes%/../316)\n- [3.1.5](%url:notes%/../315)\n- [3.1.4](%url:notes%/../314)\n- [3.1.3](%url:notes%/../313)\n- [3.1.2](%url:notes%/../312)\n- [3.1.1](%url:notes%/../311)\n- [3.1.0](%url:notes%/../310)\n- [3.0.7](%url:notes%/../307)\n- [3.0.6](%url:notes%/../306)\n- [3.0.5](%url:notes%/../305)\n- [3.0.4](%url:notes%/../304)\n- [3.0.3](%url:notes%/../303)\n- [3.0.2](%url:notes%/../302)\n- [3.0.1](%url:notes%/../301)\n- [3.0.0](%url:notes%/../300)\n- [2.9.7](%url:notes%/../297)\n- [2.9.6](%url:notes%/../296)\n- [2.9.5](%url:notes%/../295)\n- [2.9.4](%url:notes%/../294)\n- [2.9.3](%url:notes%/../293)\n- [2.9.2](%url:notes%/../292)\n- [2.9.1](%url:notes%/../291)\n- [2.9.0](%url:notes%/../290)\n- [2.8.3](%url:notes%/../283)\n- [2.8.2](%url:notes%/../282)\n- [2.8.1](%url:notes%/../281)\n- [2.8.0](%url:notes%/../280)\n- [0.27.4](%url:notes%/../0274)\n- [0.27.3](%url:notes%/../0273)\n- [0.27.2](%url:notes%/../0272)\n- [0.27.1](%url:notes%/../0271)\n": {
    "fr": "- [4.0.0](%url:notes%/../400)\n- [3.3.14](%url:notes%/../3314)\n- [3.3.13](%url:notes%/../3313)\n- [3.3.12](%url:notes%/../3312)\n- [3.3.11](%url:notes%/../3311)\n- [3.3.10](%url:notes%/../3310)\n- [3.3.9](%url:notes%/../339)\n- [3.3.8](%url:notes%/../338)\n- [3.3.7](%url:notes%/../337)\n- [3.3.6](%url:notes%/../336)\n- [3.3.5](%url:notes%/../335)\n- [3.3.4](%url:notes%/../334)\n- [3.3.3](%url:notes%/../333)\n- [3.3.2](%url:notes%/../332)\n- [3.3.1](%url:notes%/../331)\n- [3.3.0](%url:notes%/../330)\n- [3.2.8](%url:notes%/../328)\n- [3.2.7](%url:notes%/../327)\n- [3.2.6](%url:notes%/../326)\n- [3.2.5](%url:notes%/../325)\n- [3.2.4](%url:notes%/../324)\n- [3.2.3](%url:notes%/../323)\n- [3.2.2](%url:notes%/../322)\n- [3.2.1](%url:notes%/../321)\n- [3.2.0](%url:notes%/../320)\n- [3.1.9](%url:notes%/../319)\n- [3.1.8](%url:notes%/../318)\n- [3.1.7](%url:notes%/../317)\n- [3.1.6](%url:notes%/../316)\n- [3.1.5](%url:notes%/../315)\n- [3.1.4](%url:notes%/../314)\n- [3.1.3](%url:notes%/../313)\n- [3.1.2](%url:notes%/../312)\n- [3.1.1](%url:notes%/../311)\n- [3.1.0](%url:notes%/../310)\n- [3.0.7](%url:notes%/../307)\n- [3.0.6](%url:notes%/../306)\n- [3.0.5](%url:notes%/../305)\n- [3.0.4](%url:notes%/../304)\n- [3.0.3](%url:notes%/../303)\n- [3.0.2](%url:notes%/../302)\n- [3.0.1](%url:notes%/../301)\n- [3.0.0](%url:notes%/../300)\n- [2.9.7](%url:notes%/../297)\n- [2.9.6](%url:notes%/../296)\n- [2.9.5](%url:notes%/../295)\n- [2.9.4](%url:notes%/../294)\n- [2.9.3](%url:notes%/../293)\n- [2.9.2](%url:notes%/../292)\n- [2.9.1](%url:notes%/../291)\n- [2.9.0](%url:notes%/../290)\n- [2.8.3](%url:notes%/../283)\n- [2.8.2](%url:notes%/../282)\n- [2.8.1](%url:notes%/../281)\n- [2.8.0](%url:notes%/../280)\n- [0.27.4](%url:notes%/../0274)\n- [0.27.3](%url:notes%/../0273)\n- [0.27.2](%url:notes%/../0272)\n- [0.27.1](%url:notes%/../0271)"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.3.13 *Lentiform Loewenfeld* is the thirteenth maintenance release in the 3.3 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.3 series.\n\nIf you are upgrading from OpenSesame 3.2 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Robbert van der Mijn (%-- github: {user: robbertmijn} --%) for his work on the Mac OS package\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.3.13\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 780 } --% \n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 781 } --% \n\n\nosweb:\n\n- Updated to 1.4.13\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 96 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 97 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 98 } --% \n\n\nopensesame-extension-osweb\n\n- Updated to 1.4.13.0\n\n\npsychopy\n\n- Updated to 2022.1.4\n\n\nrapunzel:\n\n- Updated to 0.5.42\n\n\ndatamatrix:\n\n- Updated to 0.15.3\n\n\nopensesame-plugin-psychopy\n\n- Updated to 0.6.2\n\n\npyqode.core\n\n- Updated to 3.2.35\n\n\npyqode.python\n\n- Updated to 3.2.4\n\n\n## Packages\n\n### Windows Python 3.7 (standard)": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.3.13 *Lentiform Loewenfeld* est la treizième version de maintenance de la série 3.3. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.3.\n\nSi vous mettez à niveau depuis OpenSesame 3.2 ou une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Robbert van der Mijn (%-- github: {user: robbertmijn} --%) pour son travail sur le package Mac OS\n\n## Corrections de bugs et améliorations\n\nopensesame :\n\n- Mise à jour vers 3.3.13\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 780 } --% \n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 781 } --% \n\nosweb :\n\n- Mise à jour vers 1.4.13\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 96 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 97 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 98 } --% \n\nopensesame-extension-osweb :\n\n- Mise à jour vers 1.4.13.0\n\npsychopy :\n\n- Mise à jour vers 2022.1.4\n\nrapunzel :\n\n- Mise à jour vers 0.5.42\n\ndatamatrix :\n\n- Mise à jour vers 0.15.3\n\nopensesame-plugin-psychopy :\n\n- Mise à jour vers 0.6.2\n\npyqode.core :\n\n- Mise à jour vers 3.2.35\n\npyqode.python :\n\n- Mise à jour vers 3.2.4\n\n## Packages\n\n### Windows Python 3.7 (standard)"
  },
  "Release notes for 3.1.5": {
    "fr": "Notes de publication pour 3.1.5"
  },
  "OpenSesame 3.0.7 is the seventh maintenance release in the 3.0 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.0 series.\n\nIf you are upgrading from OpenSesame 2.9.7 or earlier, please see the list of important changes in OpenSesame 3.0:\n\n- [Important changes in 3.0](/miscellaneous/important-changes-3/)\n\n### Bugs fixed\n\n- Fix 'sound' duration in sampler and sketchpad (#401)\n- Correctly escape slashes in OpenSesame syntax (#403)\n- Don't crash on viewing remote urls ending in .md\n- Fix crashing help menu when off-line (#395)\n\n### Improvements\n\n- Preserve cursor position when switching to and from inline_script items (#390)\n- Give better error message when missing end-of-block line for multiline variables\n\n### Windows packaging\n\nPython 2.7 release (recommended):\n\n~~~\nOpenSesame 3.0.7\nPython 2.7.10 (default, May 23 2015, 09:40:32) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 3.0.0\nQProgedit 3.2.2\nExpyriment  (Python 2.7.10)\nIPython 3.2.0\nNumPy 1.9.2\nPIL is available (version is unknown)\nPsychoPy 1.82.01\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.6.0a10\nPyglet 1.2.3\nPyOpenGL 3.1.0\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.6.2\nSciPy 0.15.1\n~~~\n\nPython 3.4 release (experimental):\n\n~~~\nOpenSesame 3.0.7\nPython 3.4.3 (v3.4.3:9b73f1c3e601, Feb 24 2015, 22:43:06) [MSC v.1600 32 bit (Intel)]\nOpenCV is not available\nOpenCV 2 is not available\nQProgedit 3.2.2\nExpyriment is not available (or version is unknown)\nIPython 4.0.0\nNumPy 1.9.3\nPIL is available (version is unknown)\nPsychoPy not available (or version is unknown)\nPyAudio 0.2.9\nPyGame 1.9.2a0\nPyGaze is not available\nPyglet not available (or version is unknown)\nPyOpenGL 3.1.1b1\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.4.0\npython-markdown 2.6.2\nSciPy 0.16.1\n~~~\n\n### Mac OS packaging\n\n~~~\nOpenSesame 3.0.7\nPython 2.7.11 |Continuum Analytics, Inc.| (default, Dec 6 2015, 18:57:58)\n[GCC 4.2.1 (Apple Inc. build 5577)]\nOpenCV is not available\nOpenCV2 3.1.0\nQProgedit 3.2.2\nExpyriment 0.8.0-41-g147b7d7 (Python 2.7.11)\nIPython 4.1.2\nNumPy 1.10.4\nPIL is available (version is unknown)\nPsychoPy 1.82.01\nPyAudio 0.2.7\nPyGame 1.9.2a0\nPyGaze is not available\nPyglet 1.2.4\nPyOpenGL 3.1.1a1\nPyQt 4.11.4\nPySerial 3.0.1\npython-bidi 0.4.0\npython-markdown 2.6.5\nSciPy 0.17.0\n~~~~\n": {
    "fr": "OpenSesame 3.0.7 est la septième version de maintenance de la série 3.0. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.0.\n\nSi vous passez de OpenSesame 2.9.7 ou une version antérieure, veuillez consulter la liste des changements importants dans OpenSesame 3.0 :\n\n- [Changements importants dans la version 3.0](/miscellaneous/important-changes-3/)\n\n### Bugs corrigés\n\n- Correction de la durée 'sound' dans sampler et sketchpad (#401)\n- Échapper correctement les barres obliques dans la syntaxe OpenSesame (#403)\n- Ne pas planter en affichant des URL distantes se terminant par .md\n- Correction du crash du menu d'aide hors ligne (#395)\n\n### Améliorations\n\n- Conserver la position du curseur lors du passage d'un élément inline_script à un autre (#390)\n- Donner un meilleur message d'erreur lorsqu'il manque une fin de ligne de bloc pour les variables multilignes\n\n### Packaging Windows\n\nVersion Python 2.7 (recommandée) :\n\n~~~\nOpenSesame 3.0.7\nPython 2.7.10 (default, May 23 2015, 09:40:32) [MSC v.1500 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 3.0.0\nQProgedit 3.2.2\nExpyriment  (Python 2.7.10)\nIPython 3.2.0\nNumPy 1.9.2\nPIL est disponible (la version est inconnue)\nPsychoPy 1.82.01\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.6.0a10\nPyglet 1.2.3\nPyOpenGL 3.1.0\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.6.2\nSciPy 0.15.1\n~~~\n\nVersion Python 3.4 (expérimentale) :\n\n~~~\nOpenSesame 3.0.7\nPython 3.4.3 (v3.4.3:9b73f1c3e601, Feb 24 2015, 22:43:06) [MSC v.1600 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV 2 n'est pas disponible\nQProgedit 3.2.2\nExpyriment n'est pas disponible (ou la version est inconnue)\nIPython 4.0.0\nNumPy 1.9.3\nPIL est disponible (la version est inconnue)\nPsychoPy non disponible (ou la version est inconnue)\nPyAudio 0.2.9\nPyGame 1.9.2a0\nPyGaze n'est pas disponible\nPyglet non disponible (ou la version est inconnue)\nPyOpenGL 3.1.1b1\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.4.0\npython-markdown 2.6.2\nSciPy 0.16.1\n~~~\n\n### Packaging Mac OS\n\n~~~\nOpenSesame 3.0.7\nPython 2.7.11 |Continuum Analytics, Inc.| (default, Dec 6 2015, 18:57:58)\n[GCC 4.2.1 (Apple Inc. build 5577)]\nOpenCV n'est pas disponible\nOpenCV2 3.1.0\nQProgedit 3.2.2\nExpyriment 0.8.0-41-g147b7d7 (Python 2.7.11)\nIPython 4.1.2\nNumPy 1.10.4\nPIL est disponible (version inconnue)\nPsychoPy 1.82.01\nPyAudio 0.2.7\nPyGame 1.9.2a0\nPyGaze n'est pas disponible\nPyglet 1.2.4\nPyOpenGL 3.1.1a1\nPyQt 4.11.4\nPySerial 3.0.1\npython-bidi 0.4.0\npython-markdown 2.6.5\nSciPy 0.17.0\n~~~~"
  },
  "Release notes for 3.1.3": {
    "fr": "Notes de version pour 3.1.3"
  },
  "<notranslate>[TOC]</notranslate>\n\n## About\n\nOpenSesame 3.3.0 *Lentiform Loewenfeld* is a major new release with many new features and improvements. A detailed changelog is therefore not available; however, a list of most important changes can be found here:\n\n- %link:important-changes-3%\n\n## Credits\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for extensive code contributions\n- Cherie Zhou (%-- github: {user: cherieai} --%) for updating the Chinese (`zh_CN`) translation \n- Aytaç Karabay (%-- github: {user: aytackarabay} --%) for updating the Turkish (`tr_TR`) translation \n\n\n## Known issues\n\n- The `media_player_mpy` extension is broken\n\n\n## List of libraries included with Windows packages\n\n\n### Python 3.7 (standard)": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos\n\nOpenSesame 3.3.0 *Lentiform Loewenfeld* est une nouvelle version majeure avec de nombreuses nouvelles fonctionnalités et améliorations. Un journal des modifications détaillé n'est donc pas disponible ; cependant, une liste des changements les plus importants peut être trouvée ici :\n\n- %link:important-changes-3%\n\n## Crédits\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour d'importantes contributions de code\n- Cherie Zhou (%-- github: {user: cherieai} --%) pour la mise à jour de la traduction chinoise (`zh_CN`)\n- Aytaç Karabay (%-- github: {user: aytackarabay} --%) pour la mise à jour de la traduction turque (`tr_TR`)\n\n## Problèmes connus\n\n- L'extension `media_player_mpy` est défectueuse\n\n## Liste des bibliothèques incluses dans les packages Windows\n\n### Python 3.7 (standard)"
  },
  "Going from an abstract research question to a concrete experimental design can be difficult. You can clarify the design for yourself by writing it down in formal notation. There are many such notations, but here we will use the one proposed by [Rouanet and Lepine (1977)][references]. This notation is simple, yet flexible enough to cover most experimental designs that you will encounter in real life.\n\n<notranslate>[TOC]</notranslate>\n\n## The basic notation\n\nIn this notation, conditions (or factors) are denoted by a single letter, with a small number that indicates how many levels there are. For example, if you have three stimulus durations, you might indicate this as D<sub>3</sub>. A special condition is 'subject'. If you have *N* subjects, you indicate this as <u>S</u><sub>N</sub>. It might sound strange to refer to subject as a condition, but, in a sense, that's exactly what it is.\n\nThere are two operators:\n\n- &lt; &gt; indicates 'boxing in', typically used for conditions that are varied between subjects\n- × indicated 'crossing', typically used for conditions that are varied within subjects\n\nThere are often multiple ways to write an experimental design. For example, you can omit conditions that are not relevant to your research question, such as whether a stimulus appears on the left or right side of the display.\n\n## Within-subject designs\n\nIn a within-subject design, all participants do all conditions. This the most powerful kind of design, because it doesn't suffer much from variability between participants: You can compare the performance of a participant in condition A with his or her performance in condition B.\n\nConsider a Posner cuing paradigm [(Posner, 1980)][references], in which an arrow points to the left or right side of the display. The arrow is followed by a target, which also appears on the left or right side of the display. We thus have two conditions that are varied within participants:\n\n- *cue side* with two levels (left, right), or C<sub>2</sub>\n- *target side* with two levels (left, right), or T<sub>2</sub>\n\nWe can write this design as <u>S</u><sub>N</sub>×C<sub>2</sub>×T<sub>2</sub>\n\n## Between-subject designs\n\nIn a between-subject design, different participants do different experimental conditions. This is less powerful than a within-subject design, because differences between participants are an important source of noise: If the performance of participant 1 in condition A is better than that of participant 2 in condition B, you don't know whether this due to a condition effect, or simply because participant 1 tends to perform better than participant 2. For this reason, between-subject designs require a large number of participants.\n\nConsider [Bargh's (1996)][references] famous (and controversial) social-priming experiment in which some participants read words that are associated with old age (e.g. 'retired'), whereas other participants read age-neutral words (e.g. 'thirsty').\n\nWe thus have one condition that is varied between participants:\n\n- *prime type* with two levels (old, neutral), or P<sub>2<sub>\n\nWe can write this design as <u>S</u><sub>N</sub> &lt; P<sub>2</sub> &gt;\n\nRouanet and Lepine call this *emboîtement*, or 'boxing in'. This simply means that both levels of P have their own group of N subjects. Therefore, the total number of subjects is 2*N.\n\n## Complicated designs\n\nOccasionally, you will encounter more complicated designs that are not easily classified as either within- or between-subject. Psycholinguistic experiments are good examples of this.\n\nLet's consider a semantic priming experiment, in which a target word is preceded either by a semantically related prime (e.g. 'garden' -> 'flower' or 'cat' -> 'dog') or an unrelated prime (e.g. 'money' -> 'flower' or 'yes' -> 'dog'). To avoid that a participant sees one word multiple times, you can 'rotate' the conditions between words:": {
    "fr": "Passer d'une question de recherche abstraite à un plan expérimental concret peut être difficile. Vous pouvez clarifier le plan pour vous-même en l'écrivant dans une notation formelle. Il existe de nombreuses notations, mais ici nous utiliserons celle proposée par [Rouanet et Lepine (1977)][références]. Cette notation est simple, mais suffisamment flexible pour couvrir la plupart des plans expérimentaux que vous rencontrerez dans la réalité.\n\n<notranslate>[TOC]</notranslate>\n\n## La notation de base\n\nDans cette notation, les conditions (ou facteurs) sont indiquées par une seule lettre, avec un petit nombre qui indique le nombre de niveaux. Par exemple, si vous avez trois durées de stimulus, vous pouvez l'indiquer comme D<sub>3</sub>. Une condition spéciale est 'sujet'. Si vous avez *N* sujets, vous indiquez cela comme <u>S</u><sub>N</sub>. Cela peut paraître étrange de se référer au sujet comme une condition, mais, en un sens, c'est exactement ce que c'est.\n\nIl y a deux opérateurs :\n\n- &lt; &gt; indique \"boxing in\", généralement utilisé pour les conditions qui varient entre les sujets\n- × indique \"croisement\", généralement utilisé pour les conditions qui varient au sein des sujets\n\nIl y a souvent plusieurs façons d'écrire un plan expérimental. Par exemple, vous pouvez omettre les conditions qui ne sont pas pertinentes pour votre question de recherche, telles que si un stimulus apparaît sur le côté gauche ou droit de l'affichage.\n\n## Plans intra-sujet\n\nDans un plan intra-sujet, tous les participants réalisent toutes les conditions. C'est le type de plan le plus puissant, car il ne souffre pas beaucoup de la variabilité entre les participants : Vous pouvez comparer la performance d'un participant dans la condition A avec sa performance dans la condition B.\n\nConsidérons un paradigme d'orientation de Posner [(Posner, 1980)][références], dans lequel une flèche pointe vers le côté gauche ou droit de l'écran. La flèche est suivie d'une cible, qui apparaît également sur le côté gauche ou droit de l'écran. Nous avons donc deux conditions qui varient au sein des participants :\n\n- *côté d'orientation* avec deux niveaux (gauche, droite) ou C<sub>2</sub>\n- *côté cible* avec deux niveaux (gauche, droite) ou T<sub>2</sub>\n\nNous pouvons écrire ce plan comme <u>S</u><sub>N</sub>×C<sub>2</sub>×T<sub>2</sub>\n\n## Plans inter-sujet\n\nDans un plan inter-sujet, différents participants réalisent différentes conditions expérimentales. Ce plan est moins puissant qu'un plan intra-sujet, car les différences entre les participants sont une source importante de bruit : Si la performance du participant 1 dans la condition A est meilleure que celle du participant 2 dans la condition B, vous ne savez pas si cela est dû à un effet de condition ou simplement parce que le participant 1 a tendance à mieux performer que le participant 2. Pour cette raison, les plans inter-sujet nécessitent un grand nombre de participants.\n\nPrenons l'expérience célèbre (et controversée) de [Bargh (1996)][références] sur l'amorçage social, dans laquelle certains participants lisent des mots associés à la vieillesse (par exemple, \"retraité\"), tandis que d'autres participants lisent des mots neutres (par exemple, \"assoiffé\").\n\nNous avons donc une condition qui varie entre les participants :\n\n- *type d'amorce* avec deux niveaux (vieux, neutre) ou P<sub>2<sub>\n\nNous pouvons écrire ce plan comme <u>S</u><sub>N</sub> &lt; P<sub>2</sub> &gt;\n\nRouanet et Lepine appellent cela l'*emboîtement*, ou \"boxing in\". Cela signifie simplement que les deux niveaux de P ont leur propre groupe de N sujets. Par conséquent, le nombre total de sujets est de 2*N.\n\n## Plans compliqués\n\nOccasionnellement, vous rencontrerez des plans plus compliqués qui ne sont pas facilement classés comme étant intra- ou inter-sujet. Les expériences en psycholinguistique sont de bons exemples de cela.\n\nPrenons en considération une expérience d'amorçage sémantique, dans laquelle un mot cible est précédé soit par une amorce sémantiquement liée (par exemple, \"jardin\" -> \"fleur\" ou \"chat\" -> \"chien\") ou une amorce non liée (par exemple, \"argent\" -> \"fleur\" ou \"oui\" -> \"chien\"). Pour éviter que le participant voie un mot plusieurs fois, vous pouvez \"faire tourner\" les conditions entre les mots :"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.3.10 *Lentiform Loewenfeld* is the tenth maintenance release in the 3.3 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.3 series.\n\nOne notable change is the addition of a Mac OS package for ARM-based MacBooks. Thanks %-- github: {user: robbertmijn} --%!\n\nA second notable change is the update to OSWeb 1.4, which includes numerous improvements for online experiments:\n\n- Many improvements to the inline_javascript item to bring it closer to the Python API:\n    - [Canvas](%url:manual/javascript/canvas%) support for programmatically creating displays\n    - [Common functions](%url:manual/javascript/common%) such as `xy_circle()`\n    - `pool` object for access to the file pool\n    - `persistent` object for sharing variables and functions between scripts\n- Support for `.csv` files as source for loop tables\n- Support for all [color specifications](%url:manual/python/canvas%), including HSL, HSV, and LAB color spaces\n- Support for form plugins (except FORM_BASE)\n- Support for custom [HTML forms](%url:manual/forms/html%) through the new INLINE_HTML item)\n- Customizable welcome text (on the first screen that is shown)\n\n\nIf you are upgrading from OpenSesame 3.2 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for his work on the Mac OS package\n- Robbert van der Mijn (%-- github: {user: robbertmijn} --%) for his work on the Mac OS package\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.3.10\n\n\nrapunzel:\n\n- Updated to 0.5.29\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 33 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 35 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 36 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 37 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 38 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 39 } --%\n\n\nopensesame-extension-osweb\n\n- Updated to 1.4.0.0\n- %-- github: { repo: \"open-cogsci/opensesame-extension-osweb\", issue: 27 } --% \n- %-- github: { repo: \"open-cogsci/opensesame-extension-osweb\", issue: 28 } --% \n\nosweb:\n\n- Updated to 1.4.0\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 69 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 66 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 64 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 26 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 25 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 15 } --% \n\n\npyqode.core:\n\n- Updated to 3.2.18\n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 12 } --% \n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 13 } --% \n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 14 } --% \n\n\npython-datamatrix\n\n- Updated to 0.12.0\n\n\npython-qdatamatrix\n\n- Updated to 0.1.31\n- %-- github: { repo: \"open-cogsci/python-qdatamatrix\", issue: 8 } --%\n\n\npython-pygaze\n\n- Updated to 0.7.3\n\n\npsychopy:\n\n- Updated to 2021.1.2\n\n\npyqode.language_server (megapack only)\n\n- Updated to 0.1.14\n\n\n## Packages\n\n\n### Python 3.7 (standard)": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n\n## À propos de cette mise à jour\n\nOpenSesame 3.3.10 *Lentiform Loewenfeld* est la dixième version de maintenance de la série 3.3. Elle contient des corrections de bogues et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.3.\n\nUn changement notable est l'ajout d'un paquet Mac OS pour les MacBooks basés sur ARM. Merci %-- github: {user: robbertmijn} --%!\n\nUn deuxième changement notable est la mise à jour vers OSWeb 1.4, qui inclut de nombreuses améliorations pour les expériences en ligne :\n\n- De nombreuses améliorations apportées à l'élément inline_javascript pour le rapprocher de l'API Python :\n    - Support du [Canvas](%url:manual/javascript/canvas%) pour la création programmatique d'affichages\n    - [Fonctions communes](%url:manual/javascript/common%) telles que `xy_circle()`\n    - Objet `pool` pour accéder au pool de fichiers\n    - Objet `persistent` pour partager des variables et des fonctions entre les scripts\n- Support des fichiers `.csv` comme source pour les tables de boucle\n- Support de toutes les [spécifications de couleur](%url:manual/python/canvas%), y compris les espaces colorimétriques HSL, HSV et LAB\n- Support des plugins de formulaire (sauf FORM_BASE)\n- Support des [formulaires HTML personnalisés](%url:manual/forms/html%) grâce au nouvel élément INLINE_HTML)\n- Texte de bienvenue personnalisable (sur le premier écran qui est affiché)\n\n\nSi vous mettez à niveau à partir de OpenSesame 3.2 ou une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour son travail sur le paquet Mac OS\n- Robbert van der Mijn (%-- github: {user: robbertmijn} --%) pour son travail sur le paquet Mac OS\n\n\n## Corrections de bogues et améliorations\n\nopensesame :\n\n- Mis à jour vers 3.3.10\n\n\nrapunzel :\n\n- Mis à jour vers 0.5.29\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 33 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 35 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 36 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 37 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 38 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 39 } --%\n\n\nopensesame-extension-osweb:\n\n- Mis à jour vers 1.4.0.0\n- %-- github: { repo: \"open-cogsci/opensesame-extension-osweb\", issue: 27 } --% \n- %-- github: { repo: \"open-cogsci/opensesame-extension-osweb\", issue: 28 } --% \n\nosweb :\n\n- Mis à jour vers 1.4.0\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 69 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 66 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 64 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 26 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 25 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 15 } --% \n\n\npyqode.core :\n\n- Mis à jour vers 3.2.18\n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 12 } --% \n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 13 } --% \n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 14 } --% \n\n\npython-datamatrix\n\n- Mis à jour vers 0.12.0\n\n\npython-qdatamatrix\n\n- Mis à jour vers 0.1.31\n- %-- github: { repo: \"open-cogsci/python-qdatamatrix\", issue: 8 } --%\n\n\npython-pygaze\n\n- Mis à jour vers 0.7.3\n\n\npsychopy :\n\n- Mis à jour vers 2021.1.2\n\n\npyqode.language_server (uniquement megapack)\n\n- Mis à jour vers 0.1.14\n\n\n## Paquets\n\n\n### Python 3.7 (standard)"
  },
  "OpenSesame 2.8.1 is the first maintenance release in the 2.8 series. If you are upgrading from 0.27.4 or earlier, please also read the [2.8.0 release notes].\n\n## Credits\n\nWith thanks to Daniel Schreij and Ronald Sprouse for their code contributions.\n\n## Changelog\n\n### Bugs fixed\n\n- Do not choke on translations in font-selection dialog\n- Fix buffer-flush issue in srbox plugin (#234)\n- Correctly parse non-Unix line separators in text_display plugin (#237)\n- Saner focus and event-handling in script view.\n- Initial jitter_mode value in advanced_delay plugin (#238)\n- Fix crash on special characters in experiment title with legacy backend\n\n### Improvements\n\n- Validate form geometry (#222)\n- Improvements to joystick plugin\n- Flush keyboard during sound playback to catch 'Escape' presses (#227)\n- Sort comboboxes alphabetically (#233)\n- Sort items alphabetically in OpenSesame script (#236)\n- Improved validation of conditional statements (#235)\n- Debug window respects QProgEdit theme\n- Store filename-only logfiles relative to experiment folder (#161)\n- Use one-tab mode by default\n\n### Windows packaging\n\n- Update included libraries. See `modules()` output below.\n\n~~~\nOpenSesame 2.8.1\nPython 2.7.6 (default, Nov 10 2013, 19:24:18) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 2.4.7\nQProgedit 1.2.2\nExpyriment 0.7.0 (Revision 7a6b73d; Python 2.7.6)\nNumPy 1.8.0\nPIL is available (version is unknown)\nPsychoPy 1.80.00\nPyAudio 0.2.7\nPyGame 1.9.1release\nPyglet 1.1.4\nPyOpenGL 3.0.2\nPyQt 4.10.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.3.1\nSciPy 0.13.3\n~~~\n\n[2.8.0 release notes]: /notes/2.8.0\n": {
    "fr": "OpenSesame 2.8.1 est la première version de maintenance de la série 2.8. Si vous effectuez une mise à niveau à partir de 0.27.4 ou d'une version antérieure, veuillez également lire les [notes de la version 2.8.0].\n\n## Crédits\n\nAvec nos remerciements à Daniel Schreij et Ronald Sprouse pour leurs contributions de code.\n\n## Changelog\n\n### Bugs corrigés\n\n- Ne pas bloquer sur les traductions dans la boîte de dialogue de sélection de la police\n- Résoudre le problème de vidage du tampon dans le plugin srbox (#234)\n- Analyser correctement les séparateurs de lignes non Unix dans le plugin text_display (#237)\n- Meilleure gestion de la mise au point et des événements dans la vue de script.\n- Valeur initiale de jitter_mode dans le plugin advanced_delay (#238)\n- Corrige le crash sur les caractères spéciaux dans le titre de l'expérience avec le backend legacy\n\n### Améliorations\n\n- Valider la géométrie du formulaire (#222)\n- Améliorations apportées au plugin joystick\n- Vider le clavier pendant la lecture du son pour détecter les appuis sur 'Echap' (#227)\n- Trier les comboboxes par ordre alphabétique (#233)\n- Trier les éléments par ordre alphabétique dans le script OpenSesame (#236)\n- Validation améliorée des instructions conditionnelles (#235)\n- La fenêtre de débogage respecte le thème QProgEdit\n- Enregistrez les fichiers journaux à nom de fichier unique par rapport au dossier de l'expérience (#161)\n- Utiliser le mode un onglet par défaut\n\n### Empaquetage Windows\n\n- Mettre à jour les bibliothèques incluses. Voir la sortie `modules()` ci-dessous.\n\n~~~\nOpenSesame 2.8.1\nPython 2.7.6 (default, Nov 10 2013, 19:24:18) [MSC v.1500 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 2.4.7\nQProgedit 1.2.2\nExpyriment 0.7.0 (Révision 7a6b73d; Python 2.7.6)\nNumPy 1.8.0\nPIL est disponible (la version est inconnue)\nPsychoPy 1.80.00\nPyAudio 0.2.7\nPyGame 1.9.1release\nPyglet 1.1.4\nPyOpenGL 3.0.2\nPyQt 4.10.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.3.1\nSciPy 0.13.3\n~~~\n\n[notes de la version 2.8.0]: /notes/2.8.0"
  },
  "Release notes for 2.9.4": {
    "fr": "Notes de version pour 2.9.4"
  },
  "OpenSesame 2.9.4 is the fourth maintenance release in the 2.9 series. If you are upgrading from 2.8.3 or earlier, please also read the [2.9.0 release notes]. This release mainly addresses a critical regression that was introduced in 2.9.3.\n\n## Changelog\n\n### Bugs fixed\n\n- Prevent indirect recursion errors in overview area.\n- Don't crash on empty loop items.\n\n### Windows packaging\n\n~~~\nOpenSesame 2.9.4\nPython 2.7.8 (default, Jun 30 2014, 16:03:49) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 2.4.10\nQProgedit 2.1.0\nExpyriment  (Revision ; Python 2.7.8)\nNumPy 1.9.1\nPIL is available (version is unknown)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.5.0~opensesame3\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.3\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.5.2\nSciPy 0.14.0\n~~~\n\n[2.9.0 release notes]: /notes/2.9.0/\n": {
    "fr": "OpenSesame 2.9.4 est la quatrième mise à jour de maintenance de la série 2.9. Si vous effectuez une mise à niveau à partir de la version 2.8.3 ou antérieure, veuillez également lire les [notes de version 2.9.0]. Cette version aborde principalement une régression critique qui a été introduite dans la version 2.9.3.\n\n## Journal des modifications\n\n### Bugs corrigés\n\n- Empêcher les erreurs de récursion indirecte dans la zone d'aperçu.\n- Ne pas planter sur des éléments de boucle vides.\n\n### Packaging pour Windows\n\n~~~\nOpenSesame 2.9.4\nPython 2.7.8 (par défaut, 30 juin 2014, 16:03:49) [MSC v.1500 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 2.4.10\nQProgedit 2.1.0\nExpyriment (Révision ; Python 2.7.8)\nNumPy 1.9.1\nPIL est disponible (la version est inconnue)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.5.0~opensesame3\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.3\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.5.2\nSciPy 0.14.0\n~~~\n\n[Notes de version 2.9.0]: /notes/2.9.0/"
  },
  "Release notes for 3.0.1": {
    "fr": "Notes de version pour 3.0.1"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.1.5 *Jazzy James* is the fifth maintenance release in the 3.1 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.1 series.\n\nIf you are upgrading from OpenSesame 3.0 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for the Mac OS package, and his implementation of truly unfilled circles\n- Jarik den Hartog (%-- github: {user: JdenHartog} --%) for improving the System Information extension\n- Wouter Kruijne (%-- github: {user: wkruijne} --%) for fixing docstrings\n\n## Bug fixes and improvements\n\nOpenSesame:\n\n- Updated to 3.1.5\n- Speed up quick switcher\n- Free unused `canvas` objects from memory (were blocked by a cyclic reference)\n- %-- github: { repo: \"smathot/opensesame\", issue: 505 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 504 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 503 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 502 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 499 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 493 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 492 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 491 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 488 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 485 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 484 } --%\n\npython-qdatamatrix\n\n- Updated to 0.4.4\n- Speed up copy-pasting\n- %-- github: { repo: \"smathot/python-qdatamatrix\", issue: 3 } --%\n\nQProgEdit\n\n- Updated to 4.0.9\n- %-- github: { repo: \"smathot/QProgEdit\", issue: 19 } --%\n\npython-datamatrix\n\n- Updated to 0.4.4\n\nopensesame-extension-osf\n\n- Updated to 1.0.12\n- %-- github: { repo: \"dschreij/opensesame-extension-osf\", issue: 12 } --%\n\n## Packages (Windows Python 2.7 package)\n\n### New\n\n- `fastnumbers` 1.0.0\n- `prettytable` 0.7.2\n\n### Detailed package information": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.1.5 *Jazzy James* est la cinquième version de maintenance de la série 3.1. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.1.\n\nSi vous passez d'OpenSesame 3.0 ou d'une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour le paquet Mac OS et son implémentation de cercles véritablement non remplis\n- Jarik den Hartog (%-- github: {user: JdenHartog} --%) pour l'amélioration de l'extension System Information\n- Wouter Kruijne (%-- github: {user: wkruijne} --%) pour la correction des docstrings\n\n## Corrections de bugs et améliorations\n\nOpenSesame :\n\n- Mis à jour en 3.1.5\n- Accélérer le commutateur rapide\n- Libérer les objets `canvas` inutilisés de la mémoire (bloqués par une référence cyclique)\n- %-- github: { repo: \"smathot/opensesame\", issue: 505 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 504 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 503 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 502 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 499 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 493 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 492 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 491 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 488 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 485 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 484 } --%\n\npython-qdatamatrix\n\n- Mis à jour en 0.4.4\n- Accélérer le copier-coller\n- %-- github: { repo: \"smathot/python-qdatamatrix\", issue: 3 } --%\n\nQProgEdit\n\n- Mis à jour en 4.0.9\n- %-- github: { repo: \"smathot/QProgEdit\", issue: 19 } --%\n\npython-datamatrix\n\n- Mis à jour en 0.4.4\n\nopensesame-extension-osf\n\n- Mis à jour en 1.0.12\n- %-- github: { repo: \"dschreij/opensesame-extension-osf\", issue: 12 } --%\n\n## Paquets (Windows Python 2.7 package)\n\n### Nouveau\n\n- `fastnumbers` 1.0.0\n- `prettytable` 0.7.2\n\n### Informations détaillées sur les paquets"
  },
  "- Odd participants (1, 3, 5, etc.) do rotation A:\n    - 'flower' is in the related condition\n    - 'dog' is in the unrelated condition\n- Even participants (2, 4, 6, etc.) do rotation B:\n    - 'flower' is in the unrelated condition\n    - 'dog' is in the related condition\n\nWe thus have two conditions:\n\n- *prime type* with two levels (related, unrelated), or P<sub>2</sub>; this is varied within subjects\n- *rotation* with two levels (A, B), or R<sub>2</sub>; this is varied between participants\n\nTherefore, the design is <u>S</u><sub>n</sub> &lt; R<sub>2</sub> &gt; × P<sub>2</sub>\n\n## Limitations\n\nThis notation has several limitations, including:\n\n- You cannot indicate how often certain conditions occur. For example, in a Posner cuing task, valid trials (i.e. cue and target on the same side) generally occur more often than invalid trials (i.e. cue and target on opposite side). This cannot be written down in the notation described here.\n- It is difficult to indicate the role of 'item' in a design. For example, in the design under [Complicated designs], the target word plays a role that is similar to that of participant. It is possible to write an item-centric design or a participant-centric design (as in the example), but I have not found a way to satisfactorily do both.\n\n## References\n\n<div class=\"reference\" markdown=\"1\">\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. *Journal of Personality and Social Psychology*, *71*(2), 230.\n\nPosner, M. I. (1980). Orienting of attention. *Quarterly Journal of Experimental Psychology*, *32*(1), 3–25. doi:10.1080/00335558008248231\n\nRouanet, H., & Lepine, D. (1977). Structures linéaires et analyse des comparaisons. *Mathématiques et Sciences Humaines*, *56*, 5–46. Retrieved from: <http://www.numdam.org/item?id=MSH_1977__56__5_0>\n\n</div>\n": {
    "fr": "- Les participants impairs (1, 3, 5, etc.) font la rotation A :\n    - 'fleur' est dans la condition liée\n    - 'chien' est dans la condition non liée\n- Les participants pairs (2, 4, 6, etc.) font la rotation B :\n    - 'fleur' est dans la condition non liée\n    - 'chien' est dans la condition liée\n\nNous avons donc deux conditions :\n\n- *type d'amorce* avec deux niveaux (lié, non lié), ou P<sub>2</sub> ; ceci est varié au sein des sujets\n- *rotation* avec deux niveaux (A, B), ou R<sub>2</sub> ; ceci est varié entre les participants\n\nPar conséquent, le plan est <u>S</u><sub>n</sub> &lt; R<sub>2</sub> &gt; × P<sub>2</sub>\n\n## Limitations\n\nCette notation a plusieurs limitations, notamment :\n\n- Vous ne pouvez pas indiquer combien de fois certaines conditions se produisent. Par exemple, dans une tâche de guidage Posner, les essais valides (c'est-à-dire l'indice et la cible du même côté) se produisent généralement plus souvent que les essais invalides (c'est-à-dire l'indice et la cible sur des côtés opposés). Ceci ne peut pas être écrit dans la notation décrite ici.\n- Il est difficile d'indiquer le rôle de 'l'élément' dans un plan. Par exemple, dans le plan sous [Conceptions compliquées], le mot cible joue un rôle similaire à celui du participant. Il est possible d'écrire un plan centré sur l'élément ou un plan centré sur le participant (comme dans l'exemple), mais je n'ai pas trouvé de moyen de faire les deux de manière satisfaisante.\n\n## Références\n\n<div class=\"reference\" markdown=\"1\">\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticité du comportement social : effets directs de la construction du trait et de l'activation des stéréotypes sur l'action. *Journal of Personality and Social Psychology*, *71*(2), 230.\n\nPosner, M. I. (1980). Orientation de l'attention. *Quarterly Journal of Experimental Psychology*, *32*(1), 3–25. doi:10.1080/00335558008248231\n\nRouanet, H., & Lepine, D. (1977). Structures linéaires et analyse des comparaisons. *Mathématiques et Sciences Humaines*, *56*, 5–46. Extrait de : <http://www.numdam.org/item?id=MSH_1977__56__5_0>\n\n</div>"
  },
  "Release notes for 2.9.2": {
    "fr": "Notes de version pour 2.9.2"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.1.3 *Jazzy James* is the third maintenance release in the 3.1 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.1 series.\n\nIf you are upgrading from OpenSesame 3.0 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Eduard Ort (%-- github: {user: eort} --%) for his code contributions and updating the German translation.\n- Tomi Lüke (%-- github: {user: researchtool} --%) for updating the German translation.\n- Ryo Tachinaba for working on the Japanese translation.\n- Jarik den Hartog (%-- github: {user: JdenHartog} --%) for updating the docstrings.\n- Amandine Rey (%-- github: {user: amandinerey} --%) for updating the French translation.\n- Wouter Kruijne (%-- github: {user: wkruijne} --%) for his code contributions.\n\n\n## Bug fixes and improvements\n\n- %-- github: { repo: \"smathot/opensesame\", issue: 405 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 444 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 445 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 446 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 447 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 448 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 449 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 450 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 451 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 452 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 455 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 456 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 457 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 458 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 459 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 460 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 462 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 462 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 465 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 470 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 472 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 473 } --%\n\n## Packages (Windows Python 2.7 package)\n\n### Updated\n\n- `opensesame-extenstion-osf` has been updated to 1.0.11\n- `python-datamatrix` has been updated to 0.3.1\n- `python-fileinspector` has been updated to 1.0.2\n- `python-pygaze` has been updated to 0.6.0a21\n- `python-qdatamatrix` has been updated to 0.1.9\n- `python-qnotifications` has been updated to 1.1.1\n- `python-qprogedit` has been updated to 4.0.5\n\n### New\n\n- `openpyxl` has been added\n- `pyaudio` has been added\n\n### Detailed package information": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.1.3 *Jazzy James* est la troisième version de maintenance de la série 3.1. Elle contient des corrections de bugs et des améliorations mineures et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.1.\n\nSi vous passez de OpenSesame 3.0 ou d'une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Eduard Ort (%-- github: {user: eort} --%) pour ses contributions au code et la mise à jour de la traduction allemande.\n- Tomi Lüke (%-- github: {user: researchtool} --%) pour la mise à jour de la traduction allemande.\n- Ryo Tachinaba pour son travail sur la traduction japonaise.\n- Jarik den Hartog (%-- github: {user: JdenHartog} --%) pour la mise à jour des docstrings.\n- Amandine Rey (%-- github: {user: amandinerey} --%) pour la mise à jour de la traduction française.\n- Wouter Kruijne (%-- github: {user: wkruijne} --%) pour ses contributions au code.\n\n## Corrections de bugs et améliorations\n\n- %-- github: { repo: \"smathot/opensesame\", issue: 405 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 444 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 445 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 446 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 447 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 448 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 449 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 450 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 451 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 452 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 455 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 456 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 457 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 458 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 459 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 460 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 462 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 462 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 465 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 470 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 472 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 473 } --%\n\n## Paquets (Windows Python 2.7 package)\n\n### Mis à jour\n\n- `opensesame-extenstion-osf` a été mis à jour en 1.0.11\n- `python-datamatrix` a été mis à jour en 0.3.1\n- `python-fileinspector` a été mis à jour en 1.0.2\n- `python-pygaze` a été mis à jour en 0.6.0a21\n- `python-qdatamatrix` a été mis à jour en 0.1.9\n- `python-qnotifications` a été mis à jour en 1.1.1\n- `python-qprogedit` a été mis à jour en 4.0.5\n\n### Nouveau\n\n- `openpyxl` a été ajouté\n- `pyaudio` a été ajouté\n\n### Informations détaillées sur les paquets"
  },
  "OpenSesame 3.0.1 is the first maintenance release in the 3.0 series. If you are upgrading from OpenSesame 2.9.7 or earlier, please see the list of important changes in OpenSesame 3.0:\n\n- [Important changes in 3.0](/miscellaneous/important-changes-3/)\n\n## Credits\n\nThanks to Jarik den Hartog ([@JdenHartog](https://github.com/JdenHartog)) for his code contributions.\n\n## Changes\n\n### Improvements\n\n- Give more informative error messages when using invalid variable names\n- Update auto_example plugin\n- Ignore 'undefined name' warnings when validating Python code (requires QProgEdit >= 3.1.0)\n- Update srbox plugin and add require_state_change_option\n- Add explanation how to suppress bug_report messages\n\n### Bugs fixed\n\n- Fix crash on fallback_console reset\n- Catch syntax warnings in inline_script items\n- Fix deleting items from pool\n\n### Windows packaging\n\n~~~\nOpenSesame 3.0.1\nPython 2.7.10 (default, May 23 2015, 09:40:32) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 3.0.0\nQProgedit 3.1.0\nExpyriment  (Python 2.7.10)\nIPython 3.2.0\nNumPy 1.9.2\nPIL is available (version is unknown)\nPsychoPy 1.82.01\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.6.0a3\nPyglet 1.2.3\nPyOpenGL 3.1.0\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.6.2\nSciPy 0.15.1\n~~~\n": {
    "fr": "OpenSesame 3.0.1 est la première version de maintenance de la série 3.0. Si vous mettez à niveau depuis OpenSesame 2.9.7 ou une version antérieure, veuillez consulter la liste des modifications importantes dans OpenSesame 3.0 :\n\n- [Modifications importantes dans la version 3.0](/miscellaneous/important-changes-3/)\n\n## Crédits\n\nMerci à Jarik den Hartog ([@JdenHartog](https://github.com/JdenHartog)) pour ses contributions de code.\n\n## Changements\n\n### Améliorations\n\n- Donner des messages d'erreur plus informatifs lors de l'utilisation de noms de variables invalides\n- Mettre à jour le plugin auto_example\n- Ignorer les avertissements \"undefined name\" lors de la validation du code Python (nécessite QProgEdit >= 3.1.0)\n- Mettre à jour le plugin srbox et ajouter require_state_change_option\n- Ajouter une explication sur comment supprimer les messages bug_report\n\n### Bugs corrigés\n\n- Corriger le crash lors de la réinitialisation du fallback_console\n- Capturer les avertissements de syntaxe dans les éléments inline_script\n- Corriger la suppression d'éléments du pool\n\n### Conditionnement pour Windows\n\n~~~\nOpenSesame 3.0.1\nPython 2.7.10 (default, May 23 2015, 09:40:32) [MSC v.1500 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 3.0.0\nQProgedit 3.1.0\nExpyriment  (Python 2.7.10)\nIPython 3.2.0\nNumPy 1.9.2\nPIL est disponible (la version est inconnue)\nPsychoPy 1.82.01\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.6.0a3\nPyglet 1.2.3\nPyOpenGL 3.1.0\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.6.2\nSciPy 0.15.1\n~~~"
  },
  "Release notes for 3.2.8": {
    "fr": "Notes de version pour 3.2.8"
  },
  "File format (.osexp)": {
    "fr": "Format de fichier (.osexp)"
  },
  "Timing": {
    "fr": "Temps"
  },
  "OpenSesame 2.9.2 is the second maintenance release in the 2.9 series. If you are upgrading from 2.8.3 or earlier, please also read the [2.9.0 release notes].\n\n## Credits\n\nThanks to Timo Lüke for updating the German translation, and Alberto Hernández Sande for contributing a Spanish translation.\n\n## Changelog\n\n### Bugs fixed\n\n- Fix numeric textline elements in sketchpad (#292)\n- 'Reset feedback variables' option restored in feedback item (#297)\n- Safely print unicode debug output (convert to ascii)\n- Fix unicode bug in opensesamerun gui\n- Convert backspace key to key name (#286)\n- Fix a bug with variably defined properties of circle elements in sketchpad GUI (#300)\n- Fix circle properties in xpyriment backend (#299)\n- Fix a bug with variably defined properties of Gabor and noise patches in sketchpad GUI\n- Fix a bug when permanently deleting an item that is present in multiple sequence items\n\n### Improvements\n\n- Use better fallback image in sketchpad\n- Deprecate transparent variable management (#294)\n- Add custom icon to debian packaging (#296)\n- Form_base plugin shows script by default (#298)\n- Add custom icon to debian packaging\n- Deprecate transparent variable management option\n- More comprehensive translation possible\n- Hide xpyriment-gst backend (not ready for production)\n- Custom cursor in sketchpad for increased visibility\n- Indicate whether python-bidi is available in general properties tab\n- List variables in alphabetical order in OpenSesame script\n- Add PsychoPy API menu to help extension\n\n### Translation updates\n\n- German translation updated (de_DE)\n- Add Spanish translation (es_ES)\n\n### Windows packaging\n\n- Include wx for PsychoPy monitor center (#295)\n- Include quest staircase plugins\n- Update included libraries. See `modules()` output below.\n- Includes a snapshot of PyGaze (0.5.0~opensesame-3)\n- Includes a slightly patched version of PsychoPy 1.80.05 that addresses an important issue with keypress timestamps. (Unchanged from 2.8.2.)\n\n~~~\nOpenSesame 2.9.2\nPython 2.7.8 (default, Jun 30 2014, 16:03:49) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 2.4.10\nQProgedit 2.1.0\nExpyriment  (Revision ; Python 2.7.8)\nNumPy 1.9.1\nPIL is available (version is unknown)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.5.0~opensesame3\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.3\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.5.2\nSciPy 0.14.0\n~~~\n\n[2.9.0 release notes]: /notes/2.9.0/\n": {
    "fr": "OpenSesame 2.9.2 est la deuxième version de maintenance de la série 2.9. Si vous mettez à niveau à partir de 2.8.3 ou une version antérieure, veuillez également lire les [notes de version 2.9.0].\n\n## Crédits\n\nMerci à Timo Lüke pour la mise à jour de la traduction allemande, et à Alberto Hernández Sande pour sa contribution à la traduction espagnole.\n\n## Journal des modifications\n\n### Bugs corrigés\n\n- Correction des éléments de ligne de texte numérique dans sketchpad (#292)\n- Option \"Réinitialiser les variables de feedback\" restaurée dans l'élément de feedback (#297)\n- Impression sécurisée de la sortie de débogage unicode (conversion en ascii)\n- Correction d'un bug unicode dans l'interface graphique d'opensesamerun\n- Convertir la touche de retour arrière en nom de touche (#286)\n- Correction d'un bug avec les propriétés définies de manière variable des éléments de cercle dans l'interface graphique de sketchpad (#300)\n- Correction des propriétés de cercle dans le backend xpyriment (#299)\n- Correction d'un bug avec les propriétés définies de manière variable des patches Gabor et bruit dans l'interface graphique de sketchpad\n- Correction d'un bug lors de la suppression définitive d'un élément présent dans plusieurs éléments de séquence\n\n### Améliorations\n\n- Utilisation d'une meilleure image de secours dans sketchpad\n- Dépréciation de la gestion transparente des variables (#294)\n- Ajout d'une icône personnalisée à l'emballage Debian (#296)\n- Le plugin Form_base affiche le script par défaut (#298)\n- Ajout d'une icône personnalisée à l'emballage Debian\n- Option de gestion des variables transparentes dépréciée\n- Traduction plus complète possible\n- Masquer le backend xpyriment-gst (pas prêt pour la production)\n- Curseur personnalisé dans sketchpad pour une meilleure visibilité\n- Indiquer si python-bidi est disponible dans l'onglet des propriétés générales\n- Liste des variables dans l'ordre alphabétique dans le script OpenSesame\n- Ajouter le menu API PsychoPy à l'extension d'aide\n\n### Mises à jour des traductions\n\n- Mise à jour de la traduction allemande (de_DE)\n- Ajout de la traduction espagnole (es_ES)\n\n### Emballage pour Windows\n\n- Inclure wx pour PsychoPy monitor center (#295)\n- Inclure les plugins quest staircase\n- Mettre à jour les bibliothèques incluses. Voir la sortie `modules()` ci-dessous.\n- Inclut un instantané de PyGaze (0.5.0~opensesame-3)\n- Inclut une version légèrement corrigée de PsychoPy 1.80.05 qui traite un problème important avec les horodatages des touches. (Inchangé depuis 2.8.2.)\n\n~~~\nOpenSesame 2.9.2\nPython 2.7.8 (default, Jun 30 2014, 16:03:49) [MSC v.1500 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 2.4.10\nQProgedit 2.1.0\nExpyriment (Révision; Python 2.7.8)\nNumPy 1.9.1\nPIL est disponible (la version est inconnue)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.5.0~opensesame3\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.3\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.5.2\nSciPy 0.14.0\n~~~\n\n[Notes de version 2.9.0]: /notes/2.9.0/"
  },
  "Release notes for 0.27.1": {
    "fr": "Notes de version pour 0.27.1"
  },
  "PyGaze (eye tracking)": {
    "fr": "PyGaze (suivi du regard)"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.2.8 *Kafkaesque Koffka* is the eight maintenance release in the 3.2 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.2 series.\n\nIf you are upgrading from OpenSesame 3.1 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for his work on OSWeb, the Mac OS package, and bug fixes\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.2.8\n- %-- github: { repo: \"smathot/opensesame\", issue: 660 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 662 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 663 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 665 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 667 } --%\n\npython-qosf:\n\n- Updated to 1.3.0\n\nopensesame-extension-osf:\n\n- Updated to 1.2.0\n\nopensesame-extension-osweb:\n\n- Updated to 1.3.3.0\n\n\n## Packages\n\n\n### Windows Python 2.7": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.2.8 *Kafkaesque Koffka* est la huitième version de maintenance de la série 3.2. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.2.\n\nSi vous effectuez une mise à niveau à partir d'OpenSesame 3.1 ou d'une version antérieure, veuillez consulter la liste des changements importants:\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour son travail sur OSWeb, le paquet Mac OS, et les corrections de bugs\n\n## Corrections de bugs et améliorations\n\nopensesame:\n\n- Mis à jour en 3.2.8\n- %-- github: { repo: \"smathot/opensesame\", issue: 660 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 662 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 663 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 665 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 667 } --%\n\npython-qosf:\n\n- Mis à jour en 1.3.0\n\nopensesame-extension-osf:\n\n- Mis à jour en 1.2.0\n\nopensesame-extension-osweb:\n\n- Mis à jour en 1.3.3.0\n\n## Paquets\n\n### Windows Python 2.7"
  },
  "<notranslate>[TOC]</notranslate>\n\n## The .osexp format\n\nOpenSesame experiments are saved in `.osexp` format. What a `.osexp` file is depends on whether there are files included with the experiment, that is, whether or not the file pool is empty.\n\n## If the file pool is empty\n\nIf the file pool is empty, the experiment is saved as a plain-text file. This file is utf-8 encoded and uses Unix-style line endings. You can edit and view this file in most text editors.\n\nThe OpenSesame-script syntax is described here:\n\n- %link:opensesame-script%\n\n## If the file pool is not empty\n\nIf there are files in the file pool, the experiment is saved as a `.tar.gz` file, which is a `.zip`-like file format. Within this file, you will find the following:\n\n- `script.opensesame` is the experimental script, in the same format as described above\n- `pool/` is a folder that contains all the files in the file pool. Any non-ascii characters in the file names are replaced by `U+XXXX` strings.\n\n## What happened to the .opensesame and .opensesame.tar.gz formats?\n\nYou can still open the `.opensesame` and `.opensesame.tar.gz` format, which was used for OpenSesame <= 2.9.X. However, you can no longer save experiments in this format.\n": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## Le format .osexp\n\nLes expériences OpenSesame sont enregistrées au format `.osexp`. Ce qu'est un fichier `.osexp` dépend de la présence ou non de fichiers inclus dans l'expérience, c'est-à-dire si la réserve de fichiers est vide ou non.\n\n## Si la réserve de fichiers est vide\n\nSi la réserve de fichiers est vide, l'expérience est enregistrée sous la forme d'un fichier texte brut. Ce fichier est encodé en utf-8 et utilise des fins de ligne au style Unix. Vous pouvez modifier et afficher ce fichier dans la plupart des éditeurs de texte.\n\nLa syntaxe OpenSesame-script est décrite ici :\n\n- %link:opensesame-script%\n\n## Si la réserve de fichiers n'est pas vide\n\nSi des fichiers se trouvent dans la réserve de fichiers, l'expérience est enregistrée en tant que fichier `.tar.gz`, qui est un format de fichier similaire à `.zip`. Dans ce fichier, vous trouverez ce qui suit :\n\n- `script.opensesame` est le script expérimental, dans le même format que décrit ci-dessus\n- `pool/` est un dossier qui contient tous les fichiers de la réserve de fichiers. Tous les caractères non-ascii dans les noms de fichiers sont remplacés par des chaînes `U+XXXX`.\n\n## Qu'est-il arrivé aux formats .opensesame et .opensesame.tar.gz ?\n\nVous pouvez toujours ouvrir les formats `.opensesame` et `.opensesame.tar.gz`, qui étaient utilisés pour OpenSesame <= 2.9.X. Cependant, vous ne pouvez plus enregistrer des expériences dans ce format."
  },
  "Repeat_cycle": {
    "fr": "cycle_de_répétition"
  },
  "Running from source": {
    "fr": "Exécution à partir du code source"
  },
  "Attentional-blink tutorial (advanced)": {
    "fr": "Tutoriel sur le clignotement attentionnel (avancé)"
  },
  "This plug-in allows you to repeat cycles from a `loop`. Most commonly, this will be to repeat a trial when a participant made a mistake or was too slow.\n\nFor example, to repeat all trials on which a response was slower than 3000 ms, you can add a `repeat_cycle` item after (typically) the `keyboard_response` and add the following repeat-if statement:\n\n```bash\n[response_time] > 3000\n```\n\nYou can also force a cycle to be repeated by setting the variable `repeat_cycle` to 1 in an `inline_script`, like so:\n\n```python\nvar.repeat_cycle = 1\n```\n": {
    "fr": "Ce plug-in vous permet de répéter les cycles d'une `loop`. Le plus souvent, cela sera pour répéter un essai lorsqu'un participant a fait une erreur ou était trop lent.\n\nPar exemple, pour répéter tous les essais sur lesquels une réponse a été plus lente que 3000 ms, vous pouvez ajouter un élément `repeat_cycle` après (généralement) le `keyboard_response` et ajouter l'instruction suivante de répétition si :\n\n```bash\n[response_time] > 3000\n```\n\nVous pouvez également forcer un cycle à être répété en définissant la variable `repeat_cycle` à 1 dans un `inline_script`, comme ceci :\n\n```python\nvar.repeat_cycle = 1\n```"
  },
  "Touch response": {
    "fr": "Réponse tactile"
  },
  "OpenSesame 0.27.1 is the first maintenance release in the 0.27 'Frisky Freud' series. If you are upgrading from 0.26, please read the [0.27 release notes][].\n\nBugs fixed:\n\n- Fix numeric values in form checkboxes\n- Do not show start-up tab when opening a file directly\n- Catch errors due to missing closing quotations when editing a sketchpad element\n- Fix `super()` error in form plugins\n- Fix variable background color in sketchpad item\n- Catch recursion errors in general script\n- More comprehensive HTML and font implementation in psycho and legacy backends\n- Do not interpret special character sequences in script\n- Fix joystick plugin\n- Fix `exp.get_file()` in opensesamerun\n- Fix option splitting by return in form_multiple_choice plugin\n- Fix a bug where timeouts where always counted as incorrect\n\nWindows packaging:\n\n- Include joystick plugin\n\nUbuntu/ Debian packaging:\n\n- Include joystick plugin\n- Include repeat_cycle plugin\n\n[0.27 release notes]: /notes/0.27\n": {
    "fr": "OpenSesame 0.27.1 est la première version de maintenance de la série 0.27 'Frisky Freud'. Si vous effectuez une mise à niveau depuis la version 0.26, veuillez lire les [notes de version 0.27][].\n\nBugs corrigés :\n\n- Correction des valeurs numériques dans les cases à cocher des formulaires\n- Ne pas afficher l'onglet de démarrage lors de l'ouverture d'un fichier directement\n- Intercepter les erreurs dues aux guillemets manquants lors de l'édition d'un élément sketchpad\n- Corriger l'erreur `super()` dans les plugins de formulaire\n- Corriger la couleur d'arrière-plan variable dans l'élément sketchpad\n- Intercepter les erreurs de récursivité dans le script général\n- Implémentation HTML et de police plus complète dans les backends psycho et legacy\n- Ne pas interpréter les séquences de caractères spéciaux dans le script\n- Corriger le plugin joystick\n- Corriger `exp.get_file()` dans opensesamerun\n- Corriger la séparation des options par retour dans le plugin form_multiple_choice\n- Corriger un bug où les délais d'attente étaient toujours comptés comme incorrects\n\nPackaging pour Windows :\n\n- Inclure le plugin joystick\n\nPackaging pour Ubuntu/Debian :\n\n- Inclure le plugin joystick\n- Inclure le plugin repeat_cycle\n\n[notes de version 0.27]: /notes/0.27"
  },
  "Release notes for 3.0.0": {
    "fr": "Notes de version pour 3.0.0"
  },
  "The `touch_response` plug-in allows you to work with touch responses (or mouse clicks) in an easy way, by dividing the display into rows and columns. Each response is encoded by a single number, which corresponds to the position counting from left-to-right and top-down. For example, if you have specified 2 columns and 3 rows, the display is divided into the following response regions:\n\n```bash\n1\t2\n3\t4\n5\t6\n```\n\nSimilarly, if you have specified 4 columns and 1 row, the display is sliced horizontally into the following response regions:\n\n```bash\n1\t2\t3\t4\n```\n": {
    "fr": "Le plug-in `touch_response` vous permet de travailler facilement avec les réponses tactiles (ou les clics de souris) en divisant l'affichage en lignes et colonnes. Chaque réponse est codée par un seul nombre, qui correspond à la position en comptant de gauche à droite et de haut en bas. Par exemple, si vous avez spécifié 2 colonnes et 3 lignes, l'affichage est divisé en les zones de réponse suivantes :\n\n```bash\n1\t2\n3\t4\n5\t6\n```\n\nDe même, si vous avez spécifié 4 colonnes et 1 ligne, l'affichage est divisé horizontalement en les zones de réponse suivantes :\n\n```bash\n1\t2\t3\t4\n```"
  },
  "Quest staircase next": {
    "fr": "Prochaine marche de la méthode des QUEST"
  },
  "Processes a response and updates the Quest test value.\n": {
    "fr": "Traite une réponse et met à jour la valeur du test Quest."
  },
  "Quest staircase init": {
    "fr": "Init de l'escalier Quest"
  },
  "Initializes a new Quest staircase procedure.\n": {
    "fr": "Initialise une nouvelle procédure de l'escalier Quest."
  },
  "Visual world": {
    "fr": "Monde visuel"
  },
  "~~~ .yaml\nname: opensesame_3.1.5-py2.7-win32-1\nchannels:\n- cogsci\n- defaults\ndependencies:\n- python==2.7.12\n- anaconda-client=1.4.0=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.4=py27_0\n- bzip2=1.0.6=vc9_3\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.0.3=py_0\n- psychopy=1.82.01=py27_0\n- pygame=1.9.2a0=py27_0\n- pyglet=1.2.4=py27_0\n- python-datamatrix=0.4.4=py_0 # updated in 3.1.5\n- python-fileinspector=1.0.2=py_0 # updated in 3.1.3\n- python-opensesame=3.1.5=py_0 # updated in 3.1.5\n- python-pseudorandom=0.2.2=py27_0\n- python-pygaze=0.6.0a21=py_0 # Updated in 3.1.3\n- python-qdatamatrix=0.1.13=py_0 # updated in 3.1.5\n- python-qnotifications=1.1.1=py_0 # updated in 3.1.3\n- python-qosf=1.1.8=py_0\n- python-qprogedit=4.0.9=py_0 # updated in 3.1.5\n- qscintilla2=2.9.1=py27_vc9_0\n- requests-oauthlib=0.6.1=py_0\n- webcolors=1.5=py27_0\n- configparser=3.5.0b2=py27_1\n- decorator=4.0.10=py27_0\n- entrypoints=0.2.2=py27_0\n- freetype=2.5.5=vc9_1\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- ipykernel=4.3.1=py27_0\n- ipython=4.2.0=py27_0\n- ipython_genutils=0.1.0=py27_0\n- ipywidgets=4.1.1=py27_0\n- jinja2=2.8=py27_1\n- jpeg=8d=vc9_0\n- jsonschema=2.5.1=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=4.3.0=py27_0\n- jupyter_console=4.1.1=py27_0\n- jupyter_core=4.1.0=py27_0\n- libpng=1.6.22=vc9_0\n- libtiff=4.0.6=vc9_2\n- markdown=2.6.6=py27_0\n- markupsafe=0.23=py27_2\n- mistune=0.7.2=py27_0\n- mkl=11.3.3=1\n- nbconvert=4.2.0=py27_0\n- nbformat=4.0.1=py27_0\n- notebook=4.2.1=py27_0\n- numpy=1.11.1=py27_0\n- openssl=1.0.2h=vc9_0\n- path.py=8.2.1=py27_0\n- pickleshare=0.5=py27_0\n- pillow=3.2.0=py27_1\n- pip=8.1.2=py27_0\n- pyflakes=1.2.3=py27_0\n- pygments=2.1.3=py27_0\n- pyopengl=3.1.1a1=np111py27_0\n- pyopengl-accelerate=3.1.1a1=np111py27_0\n- pyqt=4.11.4=py27_6\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.12=0\n- python-dateutil=2.5.3=py27_0\n- pytz=2016.4=py27_0\n- pyyaml=3.11=py27_4\n- pyzmq=15.2.0=py27_0\n- qt=4.8.7=vc9_8\n- qtawesome=0.3.3=py27_0\n- qtconsole=4.2.1=py27_0\n- qtpy=1.0.2=py27_0\n- requests=2.10.0=py27_0\n- scipy=0.17.1=np111py27_1\n- setuptools=23.0.0=py27_0\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.16.9=py27_2\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.4.0.2=py27_1\n- tornado=4.3=py27_1\n- traitlets=4.2.1=py27_0\n- vs2008_runtime=9.00.30729.1=2\n- wheel=0.29.0=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.8=vc9_3\n- pip:\n  - cffi==1.7.0\n  - expyriment==0.8.0 # Upgrade manually to 0.8.1.opensesame2\n  - imageio==1.5\n  - mediadecoder==0.1.5\n  - moviepy==0.2.2.11  \n  - opensesame-extension-osf==1.0.12\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-windows-launcher==0.4.1\n  - pycparser==2.14\n  - python-bidi==0.4.0\n  - sounddevice==0.3.3\n  - tqdm==4.7.6\n  - pyaudio==0.2.9 # Added in 3.1.3\n  - openpyxl==2.4.0 # Added in 3.1.3\n  - fastnumbers==1.0.0 # Added in 3.1.5\n  - prettytable==0.7.2 # Added in 3.1.5\nprefix: opensesame_3.1.5-py2.7-win32-1\n~~~\n": {
    "fr": "~~~ .yaml\nname: opensesame_3.1.5-py2.7-win32-1\nchannels:\n- cogsci\n- defaults\ndependencies:\n- python==2.7.12\n- anaconda-client=1.4.0=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.4=py27_0\n- bzip2=1.0.6=vc9_3\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.0.3=py_0\n- psychopy=1.82.01=py27_0\n- pygame=1.9.2a0=py27_0\n- pyglet=1.2.4=py27_0\n- python-datamatrix=0.4.4=py_0 # mis à jour dans 3.1.5\n- python-fileinspector=1.0.2=py_0 # mis à jour dans 3.1.3\n- python-opensesame=3.1.5=py_0 # mis à jour dans 3.1.5\n- python-pseudorandom=0.2.2=py27_0\n- python-pygaze=0.6.0a21=py_0 # Mis à jour dans 3.1.3\n- python-qdatamatrix=0.1.13=py_0 # mis à jour dans 3.1.5\n- python-qnotifications=1.1.1=py_0 # mis à jour dans 3.1.3\n- python-qosf=1.1.8=py_0\n- python-qprogedit=4.0.9=py_0 # mis à jour dans 3.1.5\n- qscintilla2=2.9.1=py27_vc9_0\n- requests-oauthlib=0.6.1=py_0\n- webcolors=1.5=py27_0\n- configparser=3.5.0b2=py27_1\n- decorator=4.0.10=py27_0\n- entrypoints=0.2.2=py27_0\n- freetype=2.5.5=vc9_1\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- ipykernel=4.3.1=py27_0\n- ipython=4.2.0=py27_0\n- ipython_genutils=0.1.0=py27_0\n- ipywidgets=4.1.1=py27_0\n- jinja2=2.8=py27_1\n- jpeg=8d=vc9_0\n- jsonschema=2.5.1=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=4.3.0=py27_0\n- jupyter_console=4.1.1=py27_0\n- jupyter_core=4.1.0=py27_0\n- libpng=1.6.22=vc9_0\n- libtiff=4.0.6=vc9_2\n- markdown=2.6.6=py27_0\n- markupsafe=0.23=py27_2\n- mistune=0.7.2=py27_0\n- mkl=11.3.3=1\n- nbconvert=4.2.0=py27_0\n- nbformat=4.0.1=py27_0\n- notebook=4.2.1=py27_0\n- numpy=1.11.1=py27_0\n- openssl=1.0.2h=vc9_0\n- path.py=8.2.1=py27_0\n- pickleshare=0.5=py27_0\n- pillow=3.2.0=py27_1\n- pip=8.1.2=py27_0\n- pyflakes=1.2.3=py27_0\n- pygments=2.1.3=py27_0\n- pyopengl=3.1.1a1=np111py27_0\n- pyopengl-accelerate=3.1.1a1=np111py27_0\n- pyqt=4.11.4=py27_6\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.12=0\n- python-dateutil=2.5.3=py27_0\n- pytz=2016.4=py27_0\n- pyyaml=3.11=py27_4\n- pyzmq=15.2.0=py27_0\n- qt=4.8.7=vc9_8\n- qtawesome=0.3.3=py27_0\n- qtconsole=4.2.1=py27_0\n- qtpy=1.0.2=py27_0\n- requests=2.10.0=py27_0\n- scipy=0.17.1=np111py27_1\n- setuptools=23.0.0=py27_0\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.16.9=py27_2\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.4.0.2=py27_1\n- tornado=4.3=py27_1\n- traitlets=4.2.1=py27_0\n- vs2008_runtime=9.00.30729.1=2\n- wheel=0.29.0=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.8=vc9_3\n- pip:\n  - cffi==1.7.0\n  - expyriment==0.8.0 # Mettre à jour manuellement vers 0.8.1.opensesame2\n  - imageio==1.5\n  - mediadecoder==0.1.5\n  - moviepy==0.2.2.11\n  - opensesame-extension-osf==1.0.12\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-windows-launcher==0.4.1\n  - pycparser==2.14\n  - python-bidi==0.4.0\n  - sounddevice==0.3.3\n  - tqdm==4.7.6\n  - pyaudio==0.2.9 # Ajouté dans 3.1.3\n  - openpyxl==2.4.0 # Ajouté dans 3.1.3\n  - fastnumbers==1.0.0 # Ajouté dans 3.1.5\n  - prettytable==0.7.2 # Ajouté dans 3.1.5\nprefix: opensesame_3.1.5-py2.7-win32-1\n~~~"
  },
  "Release notes for 3.1.6": {
    "fr": "Notes de publication pour 3.1.6",
    "de": "Versionshinweise für 3.1.6"
  },
  "OpenSesame 3.0.0 *Interactive Ising* is a major new release with many new features and improvement. A detailed changelog is therefore not available. However, a list of most important changes can be found here:\n\n- [/miscellaneous/important-changes-3/](/miscellaneous/important-changes-3/)\n\n### Windows packaging\n\n~~~\nOpenSesame 3.0.0\nPython 2.7.10 (default, May 23 2015, 09:40:32) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 3.0.0\nQProgedit 3.0.1\nExpyriment  (Python 2.7.10)\nIPython 3.2.0\nNumPy 1.9.2\nPIL is available (version is unknown)\nPsychoPy 1.82.01\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.6.0a1\nPyglet 1.2.3\nPyOpenGL 3.1.0\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.6.2\nSciPy 0.15.1\n~~~\n": {
    "fr": "OpenSesame 3.0.0 *Interactive Ising* est une nouvelle version majeure avec de nombreuses nouvelles fonctionnalités et améliorations. Un journal des modifications détaillé n'est donc pas disponible. Cependant, une liste des changements les plus importants peut être trouvée ici :\n\n- [/miscellaneous/important-changes-3/](/miscellaneous/important-changes-3/)\n\n### Packaging Windows\n\n~~~\nOpenSesame 3.0.0\nPython 2.7.10 (default, May 23 2015, 09:40:32) [MSC v.1500 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 3.0.0\nQProgedit 3.0.1\nExpyriment  (Python 2.7.10)\nIPython 3.2.0\nNumPy 1.9.2\nPIL est disponible (la version est inconnue)\nPsychoPy 1.82.01\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.6.0a1\nPyglet 1.2.3\nPyOpenGL 3.1.0\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.6.2\nSciPy 0.15.1\n~~~"
  },
  "~~~ .yaml\nname: opensesame_3.1.3-py2.7-win32-1\nchannels:\n- cogsci\n- defaults\ndependencies:\n- python==2.7.12\n- anaconda-client=1.4.0=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.4=py27_0\n- bzip2=1.0.6=vc9_3\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.0.3=py_0\n- psychopy=1.82.01=py27_0\n- pygame=1.9.2a0=py27_0\n- pyglet=1.2.4=py27_0\n- python-datamatrix=0.3.1=py_0 # updated in 3.1.3\n- python-fileinspector=1.0.2=py_0 # updated in 3.1.3\n- python-opensesame=3.1.3=py_0 # updated in 3.1.3\n- python-pseudorandom=0.2.2=py27_0\n- python-pygaze=0.6.0a21=py_0 # Updated in 3.1.3\n- python-qdatamatrix=0.1.9=py_0 # updated in 3.1.3\n- python-qnotifications=1.1.1=py_0 # updated in 3.1.3\n- python-qosf=1.1.8=py_0\n- python-qprogedit=4.0.5=py_0 # updated in 3.1.3\n- qscintilla2=2.9.1=py27_vc9_0\n- requests-oauthlib=0.6.1=py_0\n- webcolors=1.5=py27_0\n- configparser=3.5.0b2=py27_1\n- decorator=4.0.10=py27_0\n- entrypoints=0.2.2=py27_0\n- freetype=2.5.5=vc9_1\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- ipykernel=4.3.1=py27_0\n- ipython=4.2.0=py27_0\n- ipython_genutils=0.1.0=py27_0\n- ipywidgets=4.1.1=py27_0\n- jinja2=2.8=py27_1\n- jpeg=8d=vc9_0\n- jsonschema=2.5.1=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=4.3.0=py27_0\n- jupyter_console=4.1.1=py27_0\n- jupyter_core=4.1.0=py27_0\n- libpng=1.6.22=vc9_0\n- libtiff=4.0.6=vc9_2\n- markdown=2.6.6=py27_0\n- markupsafe=0.23=py27_2\n- mistune=0.7.2=py27_0\n- mkl=11.3.3=1\n- nbconvert=4.2.0=py27_0\n- nbformat=4.0.1=py27_0\n- notebook=4.2.1=py27_0\n- numpy=1.11.1=py27_0\n- openssl=1.0.2h=vc9_0\n- path.py=8.2.1=py27_0\n- pickleshare=0.5=py27_0\n- pillow=3.2.0=py27_1\n- pip=8.1.2=py27_0\n- pyflakes=1.2.3=py27_0\n- pygments=2.1.3=py27_0\n- pyopengl=3.1.1a1=np111py27_0\n- pyopengl-accelerate=3.1.1a1=np111py27_0\n- pyqt=4.11.4=py27_6\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.12=0\n- python-dateutil=2.5.3=py27_0\n- pytz=2016.4=py27_0\n- pyyaml=3.11=py27_4\n- pyzmq=15.2.0=py27_0\n- qt=4.8.7=vc9_8\n- qtawesome=0.3.3=py27_0\n- qtconsole=4.2.1=py27_0\n- qtpy=1.0.2=py27_0\n- requests=2.10.0=py27_0\n- scipy=0.17.1=np111py27_1\n- setuptools=23.0.0=py27_0\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.16.9=py27_2\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.4.0.2=py27_1\n- tornado=4.3=py27_1\n- traitlets=4.2.1=py27_0\n- vs2008_runtime=9.00.30729.1=2\n- wheel=0.29.0=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.8=vc9_3\n- pip:\n  - cffi==1.7.0\n  - expyriment==0.8.0 # Upgrade manually to 0.8.1.opensesame2\n  - imageio==1.5\n  - mediadecoder==0.1.5\n  - moviepy==0.2.2.11  \n  - opensesame-extension-osf==1.0.11\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-windows-launcher==0.4.1\n  - pycparser==2.14\n  - python-bidi==0.4.0\n  - sounddevice==0.3.3\n  - tqdm==4.7.6\n  - pyaudio==0.2.9 # Added in 3.1.3\n  - openpyxl==2.4.0 # Added in 3.1.3\nprefix: opensesame_3.1.3-py2.7-win32-1\n~~~\n": {
    "fr": "~~~ .yaml\nname: opensesame_3.1.3-py2.7-win32-1\nchannels:\n- cogsci\n- defaults\ndependencies:\n- python==2.7.12\n- anaconda-client=1.4.0=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.4=py27_0\n- bzip2=1.0.6=vc9_3\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.0.3=py_0\n- psychopy=1.82.01=py27_0\n- pygame=1.9.2a0=py27_0\n- pyglet=1.2.4=py27_0\n- python-datamatrix=0.3.1=py_0 # mis à jour dans 3.1.3\n- python-fileinspector=1.0.2=py_0 # mis à jour dans 3.1.3\n- python-opensesame=3.1.3=py_0 # mis à jour dans 3.1.3\n- python-pseudorandom=0.2.2=py27_0\n- python-pygaze=0.6.0a21=py_0 # Mis à jour dans 3.1.3\n- python-qdatamatrix=0.1.9=py_0 # mis à jour dans 3.1.3\n- python-qnotifications=1.1.1=py_0 # mis à jour dans 3.1.3\n- python-qosf=1.1.8=py_0\n- python-qprogedit=4.0.5=py_0 # mis à jour dans 3.1.3\n- qscintilla2=2.9.1=py27_vc9_0\n- requests-oauthlib=0.6.1=py_0\n- webcolors=1.5=py27_0\n- configparser=3.5.0b2=py27_1\n- decorator=4.0.10=py27_0\n- entrypoints=0.2.2=py27_0\n- freetype=2.5.5=vc9_1\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- ipykernel=4.3.1=py27_0\n- ipython=4.2.0=py27_0\n- ipython_genutils=0.1.0=py27_0\n- ipywidgets=4.1.1=py27_0\n- jinja2=2.8=py27_1\n- jpeg=8d=vc9_0\n- jsonschema=2.5.1=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=4.3.0=py27_0\n- jupyter_console=4.1.1=py27_0\n- jupyter_core=4.1.0=py27_0\n- libpng=1.6.22=vc9_0\n- libtiff=4.0.6=vc9_2\n- markdown=2.6.6=py27_0\n- markupsafe=0.23=py27_2\n- mistune=0.7.2=py27_0\n- mkl=11.3.3=1\n- nbconvert=4.2.0=py27_0\n- nbformat=4.0.1=py27_0\n- notebook=4.2.1=py27_0\n- numpy=1.11.1=py27_0\n- openssl=1.0.2h=vc9_0\n- path.py=8.2.1=py27_0\n- pickleshare=0.5=py27_0\n- pillow=3.2.0=py27_1\n- pip=8.1.2=py27_0\n- pyflakes=1.2.3=py27_0\n- pygments=2.1.3=py27_0\n- pyopengl=3.1.1a1=np111py27_0\n- pyopengl-accelerate=3.1.1a1=np111py27_0\n- pyqt=4.11.4=py27_6\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.12=0\n- python-dateutil=2.5.3=py27_0\n- pytz=2016.4=py27_0\n- pyyaml=3.11=py27_4\n- pyzmq=15.2.0=py27_0\n- qt=4.8.7=vc9_8\n- qtawesome=0.3.3=py27_0\n- qtconsole=4.2.1=py27_0\n- qtpy=1.0.2=py27_0\n- requests=2.10.0=py27_0\n- scipy=0.17.1=np111py27_1\n- setuptools=23.0.0=py27_0\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.16.9=py27_2\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.4.0.2=py27_1\n- tornado=4.3=py27_1\n- traitlets=4.2.1=py27_0\n- vs2008_runtime=9.00.30729.1=2\n- wheel=0.29.0=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.8=vc9_3\n- pip:\n  - cffi==1.7.0\n  - expyriment==0.8.0 # Mettre à jour manuellement à 0.8.1.opensesame2\n  - imageio==1.5\n  - mediadecoder==0.1.5\n  - moviepy==0.2.2.11  \n  - opensesame-extension-osf==1.0.11\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-windows-launcher==0.4.1\n  - pycparser==2.14\n  - python-bidi==0.4.0\n  - sounddevice==0.3.3\n  - tqdm==4.7.6\n  - pyaudio==0.2.9 # Ajouté dans 3.1.3\n  - openpyxl==2.4.0 # Ajouté dans 3.1.3\nprefix: opensesame_3.1.3-py2.7-win32-1\n~~~"
  },
  "Release notes for 3.3.7": {
    "fr": "Notes de version pour 3.3.7"
  },
  "This page describes various issues related to timing, and provides benchmark results and tips for testing your own system. If you experience problems with timing, please take the time to read this page. Many issues are resolved by taking into account things such as stimulus preparation and the properties of your monitor.\n\n<notranslate>[TOC]</notranslate>\n\n## Is OpenSesame capable of millisecond precision timing?\n\nThe short answer is: yes. The long answer is the rest of this page.\n\n\n## Important considerations for time-critical experiments\n\n### Check your timing!\n\nOpenSesame allows you to control your experimental timing very accurately. But this does not guarantee accurate timing in every specific experiment! For any number of reasons, many of which are described on this page, you may experience issues with timing. Therefore, in time-critical experiments you should always check whether the timing in your experiment is as intended. The easiest way to do this is by checking the display timestamps reported by OpenSesame.\n\nEvery SKETCHPAD item has a variable called `time_[sketchpad name]` that contains the timestamp of the last time that the SKETCHPAD was shown. Therefore, if you want the SKETCHPAD *target* to be shown for 100 ms, followed by the SKETCHPAD *mask*, you should verify that `time_mask` - `time_target` is indeed 100. When using Python inline code, you can make use of the fact that `canvas.show()` returns the display timestamp.\n\n\n### Understanding your monitor\n\nComputer monitors refresh periodically. For example, if the refresh rate of your monitor is 100 Hz, the display is refreshed every 10 ms (1000 ms / 100 Hz). This means that a visual stimulus is always presented for a duration that is a multiple of 10 ms, and you will not be able to present a stimulus for, say, 5 or 37 ms. The most common refresh rate is 60 Hz (= 16.67 ms refresh cycle), although monitors with much higher refresh rates are sometimes used for experimental systems.\n\nIn %VidRefresh you can see what a monitor refresh looks like in slow motion. On CRT monitors (i.e. non-flatscreen, center) the refresh is a single pixel that traces across the monitor from left to right and top to bottom. Therefore, only one pixel is lighted at a time, which is why CRT monitors flicker slightly. On LCD or TFT monitors (flatscreen, left and right) the refresh is a 'flood fill' from top to bottom. Therefore, LCD and TFT monitors do not flicker. (Unless you present a flickering stimulus, of course.)\n\n<notranslate>\nvideo:\n id: VidRefresh\n source: vimeo\n videoid: 24216910\n width: 640\n height: 240\n caption: A slow-motion video of the refresh cycle on CRT (center) and LCD/ TFT monitors. Video courtesy of Jarik den Hartog and the VU University Amsterdam technical support staff.\n</notranslate>\n\nIf a new stimulus display is presented while the refresh cycle is halfway, you will observe 'tearing'. That is, the upper half of the monitor will show the old display, while the lower part will show the new display. This is generally considered undesirable, and therefore a new display should be presented at the exact moment that the refresh cycle starts from the top. This is called 'synchronization to the vertical refresh' or simply 'v-sync'. When v-sync is enabled, tearing is no longer visible, because the tear coincides with the upper edge of the monitor. However, v-sync does not change anything about the fact that a monitor does not refresh instantaneously and will therefore always, for some time, show both the old and the new display.": {
    "fr": "Cette page décrit divers problèmes liés au timing et fournit des résultats de tests et des conseils pour tester votre propre système. Si vous rencontrez des problèmes de timing, veuillez prendre le temps de lire cette page. De nombreux problèmes sont résolus en tenant compte de choses telles que la préparation des stimuli et les propriétés de votre écran.\n\n<notranslate>[TOC]</notranslate>\n\n## OpenSesame est-il capable de gérer le temps avec une précision en millisecondes ?\n\nLa réponse courte est : oui. La réponse longue est le reste de cette page.\n\n## Considérations importantes pour les expériences sensibles au temps\n\n### Vérifiez votre timing !\n\nOpenSesame vous permet de contrôler très précisément le timing de vos expériences. Mais cela ne garantit pas un timing précis dans chaque expérience spécifique ! Pour diverses raisons, dont beaucoup sont décrites sur cette page, vous pouvez rencontrer des problèmes de timing. Par conséquent, dans les expériences sensibles au temps, vous devez toujours vérifier si le timing de votre expérience est conforme à ce qui est prévu. La façon la plus simple de le faire est de vérifier les horodatages d'affichage rapportés par OpenSesame.\n\nChaque élément SKETCHPAD possède une variable appelée `time_[sketchpad name]` qui contient l'horodatage de la dernière fois que le SKETCHPAD a été montré. Par conséquent, si vous voulez que le SKETCHPAD *cible* soit montré pendant 100 ms, suivi du SKETCHPAD *masque*, vous devez vérifier que `time_mask` - `time_target` est bien de 100. Lors de l'utilisation de code Python inline, vous pouvez utiliser le fait que `canvas.show()` renvoie l'horodatage d'affichage.\n\n### Comprendre votre écran\n\nLes écrans d'ordinateur se rafraîchissent périodiquement. Par exemple, si le taux de rafraîchissement de votre écran est de 100 Hz, l'écran se rafraîchit toutes les 10 ms (1000 ms / 100 Hz). Cela signifie qu'un stimulus visuel est toujours présenté pendant une durée multiple de 10 ms et que vous ne pourrez pas présenter un stimulus pendant, par exemple, 5 ou 37 ms. Le taux de rafraîchissement le plus courant est de 60 Hz (= cycle de rafraîchissement de 16,67 ms), bien que des écrans avec des taux de rafraîchissement beaucoup plus élevés soient parfois utilisés pour les systèmes expérimentaux.\n\nDans %VidRefresh, vous pouvez voir à quoi ressemble un rafraîchissement d'écran au ralenti. Sur les écrans CRT (c'est-à-dire non à écran plat, au centre), le rafraîchissement est un seul pixel qui se déplace sur l'écran de gauche à droite et de haut en bas. Par conséquent, un seul pixel est allumé à la fois, c'est pourquoi les écrans CRT scintillent légèrement. Sur les écrans LCD ou TFT (à écran plat, à gauche et à droite), le rafraîchissement est un \"remplissage progressif\" de haut en bas. Les écrans LCD et TFT ne scintillent donc pas. (À moins que vous ne présentiez un stimulus clignotant, bien sûr.)\n\n<notranslate>\nvideo:\n id: VidRefresh\n source: vimeo\n videoid: 24216910\n width: 640\n height: 240\n caption: Une vidéo au ralenti du cycle de rafraîchissement sur les écrans CRT (centre) et LCD/TFT. Vidéo avec l'aimable autorisation de Jarik den Hartog et du personnel de support technique de l'Université VU d'Amsterdam.\n</notranslate>\n\nSi un nouvel affichage de stimulus est présenté pendant que le cycle de rafraîchissement est à mi-chemin, vous observerez un \"déchirement\". C'est-à-dire que la moitié supérieure de l'écran affiche l'ancien affichage, tandis que la partie inférieure affiche le nouvel affichage. Ceci est généralement considéré comme indésirable et, par conséquent, un nouvel affichage doit être présenté au moment précis où le cycle de rafraîchissement commence par le haut. Ceci est appelé \"synchronisation avec le rafraîchissement vertical\" ou simplement \"v-sync\". Lorsque le v-sync est activé, le déchirement n'est plus visible, car il coïncide avec le bord supérieur de l'écran. Cependant, le v-sync ne change rien au fait qu'un écran ne se rafraîchit pas instantanément et affiche donc toujours, pendant un certain temps, à la fois l'ancien et le nouvel affichage."
  },
  "This page describes how to set up a complete Python environment on your computer, so that you can run OpenSesame directly from the source code.\n\n<notranslate>[TOC]</notranslate>\n\n## Download source code\n\nDownload the source code of the latest stable release from GitHub:\n\n- <https://github.com/smathot/OpenSesame/releases>\n\nYou can also download a development snapshot of the code. To obtain a reasonable stable snapshot, download from the `master` branch. To get the latest, greatest, and potentially very unstable snapshot, download from the the branch that corresponds to the major version of OpenSesane (e.g., `heisenberg` for 2.9, `ising` for 3.0).\n\n- <https://github.com/smathot/OpenSesame/>\n\n## Dependencies\n\n### Icon theme\n\nIf you run OpenSesame directly from source, the icon theme is not included. OpenSesame uses two icon themes: [MokaSesame](https://github.com/smathot/moka-icon-theme/tree/MokaSesame), a fork of Moka, and [Faba](https://github.com/snwh/faba-icon-theme).\n\nIt's possible to compile these icon themes yourself, but you can also download precompiled themes from here:\n\n- http://forum.cogsci.nl/uploads/editor/we/p1y3i4qm70ch.zip\n\nPlace the `Faba` and `MokaSesame` folders as subfolders of `opensesame_resources/theme/default/`.\n\n### Required\n\nThe following packages are required to run a minimal version of the OpenSesame GUI, with only support for the [legacy] backend, no sound support, and no plugin support.\n\n- [Python](http://www.python.org) is the programming language in which OpenSesame is created. The following versions of Python are supported:\n\t- Python 2.7 (default)\n    - OpenSesame >= 3.0.0 supports Python >= 3.4\n- [PyGame](http://www.pygame.org) is a library that is used for graphics and sound.\n- [qtpy](https://github.com/goanpeca/qtpy) is the abstraction layer on top of PyQt4 or PyQt5.\n\t- [PyQt4](http://www.riverbankcomputing.com/software/pyqt/download) is the graphics toolkit that is used to for the user interface; or\n\t- [PyQt5](http://www.riverbankcomputing.com/software/pyqt/download) is the graphics toolkit that is used to for the user interface.\n- [QScintilla2](http://www.riverbankcomputing.com/software/pyqt/download) is a basic text-editor component. In some cases, it is bundled with `PyQt4`.\n- [QProgEdit](https://github.com/smathot/QProgEdit) is an advanced text-editor component built on top of `QScintilla2`.\n\t- OpenSesame >= 3.1.0 requires QProgEdit >= 4.0.0\n- [PyYAML](http://pyyaml.org/) is a library used for loading `yaml` files.\n- [WebColors](https://pypi.python.org/pypi/webcolors) is a library used for interpreting color descriptions.\n- [python-datamatrix](https://github.com/smathot/python-datamatrix) is used by the loop item.\n- [python-qdatamatrix](https://github.com/smathot/python-qdatamatrix) is used by the loop item.\n- [python-pseudorandom](https://github.com/smathot/python-pseudorandom) is used by the loop item.\n- [QNotifications](https://github.com/dschreij/QNotifications) is used by the notifications extension.\n\n### Optional\n\nThe following packages are not required, but some functionality will be missing if they are not installed.": {
    "fr": "Cette page décrit comment configurer un environnement Python complet sur votre ordinateur, afin de pouvoir exécuter OpenSesame directement à partir du code source.\n\n<notranslate>[TOC]</notranslate>\n\n## Télécharger le code source\n\nTéléchargez le code source de la dernière version stable depuis GitHub:\n\n- <https://github.com/smathot/OpenSesame/releases>\n\nVous pouvez également télécharger un instantané de développement du code. Pour obtenir un instantané raisonnablement stable, téléchargez à partir de la branche `master`. Pour obtenir le dernier instantané, le meilleur et éventuellement très instable, téléchargez à partir de la branche correspondant à la version majeure d'OpenSesane (par exemple, `heisenberg` pour 2.9, `ising` pour 3.0).\n\n- <https://github.com/smathot/OpenSesame/>\n\n## Dépendances\n\n### Thème d'icônes\n\nSi vous exécutez OpenSesame directement à partir du code source, le thème d'icônes n'est pas inclus. OpenSesame utilise deux thèmes d'icônes: [MokaSesame](https://github.com/smathot/moka-icon-theme/tree/MokaSesame), un fork de Moka, et [Faba](https://github.com/snwh/faba-icon-theme).\n\nIl est possible de compiler ces thèmes d'icônes vous-même, mais vous pouvez également télécharger des thèmes précompilés à partir d'ici:\n\n- http://forum.cogsci.nl/uploads/editor/we/p1y3i4qm70ch.zip\n\nPlacez les dossiers `Faba` et `MokaSesame` sous `opensesame_resources/theme/default/`.\n\n### Requis\n\nLes packages suivants sont requis pour exécuter une version minimale de l'interface graphique OpenSesame, avec prise en charge uniquement pour le backend [legacy], sans prise en charge du son et sans support de plugin.\n\n- [Python](http://www.python.org) est le langage de programmation dans lequel OpenSesame est créé. Les versions suivantes de Python sont prises en charge:\n\t- Python 2.7 (par défaut)\n    - OpenSesame >= 3.0.0 prend en charge Python >= 3.4\n- [PyGame](http://www.pygame.org) est une bibliothèque utilisée pour les graphiques et le son.\n- [qtpy](https://github.com/goanpeca/qtpy) est la couche d'abstraction sur PyQt4 ou PyQt5.\n\t- [PyQt4](http://www.riverbankcomputing.com/software/pyqt/download) est la boîte à outils graphique utilisée pour l'interface utilisateur; ou\n\t- [PyQt5](http://www.riverbankcomputing.com/software/pyqt/download) est la boîte à outils graphique utilisée pour l'interface utilisateur.\n- [QScintilla2](http://www.riverbankcomputing.com/software/pyqt/download) est un composant éditeur de texte de base. Dans certains cas, il est livré avec `PyQt4`.\n- [QProgEdit](https://github.com/smathot/QProgEdit) est un composant éditeur de texte avancé basé sur `QScintilla2`.\n\t- OpenSesame >= 3.1.0 nécessite QProgEdit >= 4.0.0\n- [PyYAML](http://pyyaml.org/) est une bibliothèque utilisée pour charger les fichiers `yaml`.\n- [WebColors](https://pypi.python.org/pypi/webcolors) est une bibliothèque utilisée pour interpréter les descriptions de couleur.\n- [python-datamatrix](https://github.com/smathot/python-datamatrix) est utilisé par l'élément de boucle.\n- [python-qdatamatrix](https://github.com/smathot/python-qdatamatrix) est utilisé par l'élément de boucle.\n- [python-pseudorandom](https://github.com/smathot/python-pseudorandom) est utilisé par l'élément de boucle.\n- [QNotifications](https://github.com/dschreij/QNotifications) est utilisé par l'extension de notifications.\n\n### Optionnel\n\nLes packages suivants ne sont pas requis, mais certaines fonctionnalités seront manquantes s'ils ne sont pas installés."
  },
  "<notranslate>[TOC]</notranslate>\n\n## About\n\nPyGaze is a Python library for eye tracking. A set of plugins allow you to use PyGaze from within OpenSesame. For more information on PyGaze, visit:\n\n- <http://www.pygaze.org/>\n\nPlease cite PyGaze as:\n\nDalmaijer, E., Mathôt, S., & Van der Stigchel, S. (2014). PyGaze: An open-source, cross-platform toolbox for minimal-effort programming of eyetracking experiments. *Behavior Research Methods*. doi:10.3758/s13428-013-0422-2\n{: .reference}\n\n## Supported eye trackers\n\nPyGaze supports the following eye trackers:\n\n- [EyeLink](%link:eyelink%)\n- [EyeTribe](%link:eyetribe%)\n\nFor the following eye trackers, there is experimental support:\n\n- [EyeLogic](%link:eyelogic%)\n- [GazePoint / OpenGaze](%link:gazepoint%)\n- [SMI](%link:smi%)\n- [Tobii](%link:tobii%)\n\nYou can also perform basic eye tracking in online experiments with WebGazer.js:\n\n- [WebGazer.js](%link:webgazer%)\n\nPyGaze also includes two dummy eye trackers for testing purposes:\n\n- __Simple dummy__ — Does nothing.\n- __Advanced dummy__ — Mouse simulation of eye movements.\n\n## Installing PyGaze\n\n### Windows\n\nIf you use the official Windows package of OpenSesame, PyGaze is already installed.\n\n### Ubuntu\n\nIf you use Ubuntu, you can get PyGaze from the Cogsci.nl PPA:\n\n```\nsudo add-apt-repository ppa:smathot/cogscinl\nsudo apt-get update\nsudo apt-get install python-pygaze\n```\n\nOr, if you are using Python 3, change the last comment to:\n\n```\nsudo apt-get install python3-pygaze\n```\n\n## pip install (all platforms)\n\nYou can install PyGaze with `pip`:\n\n```\npip install python-pygaze\n```\n\n### Anaconda (all platforms)\n\n```\nconda install python-pygaze -c cogsci\n```\n\n## PyGaze OpenSesame plugins\n\nThe following PyGaze plugins are available:\n\n- PYGAZE_INIT — Initializes PyGaze. This plugin is generally inserted at the start of the experiment.\n- PYGAZE_DRIFT_CORRECT — Implements a drift correction procedure.\n- PYGAZE_START_RECORDING — Puts PyGaze in recording mode.\n- PYGAZE_STOP_RECORDING — Puts PyGaze out of recording mode.\n- PYGAZE_WAIT — Pauses until an event occurs, such as a saccade start.\n- PYGAZE_LOG — Logs experimental variables and arbitrary text.\n\n## Example\n\nFor an example of how to use the PyGaze plugins, see the PyGaze template that is included with OpenSesame.\n\nBelow is an example of how to use PyGaze in a Python INLINE_SCRIPT:\n\n~~~ .python\n# Create a keyboard and a canvas object\nmy_keyboard = Keyboard(timeout=0)\nmy_canvas = Canvas()\nmy_canvas['dot'] = Circle(x=0, y=0, r=10, fill=True)\n# Loop ...\nwhile True:\n\t# ... until space is pressed\n\tkey, timestamp = my_keyboard.get_key()\n\tif key == 'space':\n\t\tbreak\n\t# Get gaze position from pygaze ...\n\tx, y = eyetracker.sample()\n\t# ... and draw a gaze-contingent fixation dot!\n\tmy_canvas['dot'].x = x + my_canvas.left\n\tmy_canvas['dot'].y = y + my_canvas.top\n\tmy_canvas.show()\n~~~\n\n## Function overview\n\nTo initialize PyGaze in OpenSesame, insert the PYGAZE_INIT plugin into your experiment. Once you have done this, an `eyetracker` object will be available, which offers the following functions:\n\n<notranslate> include: include/api/eyetracker.md --%\n": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos\n\nPyGaze est une bibliothèque Python pour l'eye tracking. Un ensemble de plugins vous permet d'utiliser PyGaze au sein d'OpenSesame. Pour plus d'informations sur PyGaze, visitez :\n\n- <http://www.pygaze.org/>\n\nVeuillez citer PyGaze comme suit :\n\nDalmaijer, E., Mathôt, S., & Van der Stigchel, S. (2014). PyGaze: une boîte à outils open source et multiplateforme pour la programmation d'expériences d'eye tracking avec un effort minimal. *Behavior Research Methods*. doi:10.3758/s13428-013-0422-2\n{: .reference}\n\n## Eye trackers pris en charge\n\nPyGaze prend en charge les eye trackers suivants:\n\n- [EyeLink](%link:eyelink%)\n- [EyeTribe](%link:eyetribe%)\n\nPour les eye trackers suivants, il y a un support expérimental :\n\n- [EyeLogic](%link:eyelogic%)\n- [GazePoint / OpenGaze](%link:gazepoint%)\n- [SMI](%link:smi%)\n- [Tobii](%link:tobii%)\n\nVous pouvez également effectuer un eye tracking basique dans des expériences en ligne avec WebGazer.js :\n\n- [WebGazer.js](%link:webgazer%)\n\nPyGaze inclut également deux eye trackers fictifs pour les tests :\n\n- __Simple dummy__ — Ne fait rien.\n- __Dummy avancé__ — Simulation de mouvements oculaires avec la souris.\n\n## Installation de PyGaze\n\n### Windows\n\nSi vous utilisez le package officiel Windows d'OpenSesame, PyGaze est déjà installé.\n\n### Ubuntu\n\nSi vous utilisez Ubuntu, vous pouvez obtenir PyGaze à partir du PPA Cogsci.nl :\n\n```\nsudo add-apt-repository ppa:smathot/cogscinl\nsudo apt-get update\nsudo apt-get install python-pygaze\n```\n\nOu, si vous utilisez Python 3, changez la dernière commande pour :\n\n```\nsudo apt-get install python3-pygaze\n```\n\n## Installation avec pip (toutes les plates-formes)\n\nVous pouvez installer PyGaze avec `pip` :\n\n```\npip install python-pygaze\n```\n\n### Anaconda (toutes les plates-formes)\n\n```\nconda install python-pygaze -c cogsci\n```\n\n## Plugins PyGaze OpenSesame\n\nLes plugins PyGaze suivants sont disponibles :\n\n- PYGAZE_INIT — Initialise PyGaze. Ce plugin est généralement inséré au début de l'expérience.\n- PYGAZE_DRIFT_CORRECT — Implémente une procédure de correction de dérive.\n- PYGAZE_START_RECORDING — Met PyGaze en mode enregistrement.\n- PYGAZE_STOP_RECORDING — Sort PyGaze du mode enregistrement.\n- PYGAZE_WAIT — Met en pause jusqu'à ce qu'un événement se produise, comme le début d'une saccade.\n- PYGAZE_LOG — Enregistre des variables expérimentales et du texte arbitraire.\n\n## Exemple\n\nPour un exemple d'utilisation des plugins PyGaze, consultez le modèle PyGaze inclus avec OpenSesame.\n\nCi-dessous un exemple d'utilisation de PyGaze dans un INLINE_SCRIPT Python :\n\n~~~ .python\n# Créez un clavier et un objet toile\nmy_keyboard = Keyboard(timeout=0)\nmy_canvas = Canvas()\nmy_canvas['dot'] = Circle(x=0, y=0, r=10, fill=True)\n# Boucle ...\nwhile True:\n\t# ... jusqu'à ce que l'espace soit pressé\n\tkey, timestamp = my_keyboard.get_key()\n\tif key == 'space':\n\t\tbreak\n\t# Obtenez la position du regard à partir de pygaze ...\n\tx, y = eyetracker.sample()\n\t# ... et dessinez un point de fixation dépendant du regard !\n\tmy_canvas['dot'].x = x + my_canvas.left\n\tmy_canvas['dot'].y = y + my_canvas.top\n\tmy_canvas.show()\n~~~\n\n## Aperçu des fonctions\n\nPour initialiser PyGaze dans OpenSesame, insérez le plugin PYGAZE_INIT dans votre expérience. Une fois que vous avez fait cela, un objet `eyetracker` sera disponible, qui offre les fonctions suivantes :\n\n<notranslate> include: include/api/eyetracker.md --%"
  },
  "<notranslate>[TOC]</notranslate>\n\n## Difficulty\n\nThis tutorial assumes a basic knowledge of OpenSesame, experimental design, and Python. An introductory OpenSesame tutorial can be found here:\n\n- [/tutorials/step-by-step-tutorial/](/tutorials/step-by-step-tutorial/)\n\nLinks to introductory Python tutorials can be found here:\n\n- [/python/about/](/python/about/)\n\n## The goal\n\nIn this tutorial, we will implement an attentional-blink paradigm, as introduced by [Raymond, Shapiro, and Arnell (1992)](#references). We will re-create experiment 2 from Raymond et al. almost exactly, with only a few minor modifications. In this experiment, the participant sees a stream of letters, typically called an RSVP stream (for Rapid Serial Visual Presentation). There are two conditions. In the *experimental* condition, the participant's task is twofold:\n\n- Report the identity of the white letter (all other letters were black).\n- Indicate whether an 'X' was present.\n\nIn the control condition, the participant's task is only to ...\n\n- Indicate whether an 'X' was present.\n\nThe white letter is called the *T1* (or 'target'). The 'X' is called the *T2* (or 'probe'). The typical finding is that the T2 is often missed when it is presented 200 - 500 ms after T1, but only when T1 needs to be reported. This phenomenon is called the *attentional blink*, because it is as though your mind's eye briefly blinks after seeing T1. But surprisingly, T2 is usually not missed when it follows T1 immediately. This is called *lag-1 sparing*. The results of Raymond et al. (1992) looked like this:\n\n<notranslate>\nfigure:\n id: FigResults\n source: FigResults.svg\n caption: |\n  T2 accuracy as a function of the serial position of T2 relative to T1 ('lag'). A lag of 0 means that T1 and T2 where identical (i.e. a white 'X'). Adapted from Raymond et al. (1992).\n</notranslate>\n\n## Step 1: Download and start OpenSesame\n\nOpenSesame is available for Windows, Linux, Mac OS (experimental), and Android (runtime only). This tutorial is written for OpenSesame 3.0.X. You can download OpenSesame from here:\n\n- <http://osdoc.cogsci.nl/>\n\nWhen you start OpenSesame, you will be given a choice of template experiments, and a list of recently opened experiments (%FigStartup).\n\n<notranslate>\nfigure:\n id: FigStartup\n source: FigStartup.png\n caption: |\n  The OpenSesame window on start-up.\n</notranslate>\n\n## Step 2: Choose template, font, and colors\n\nThe 'Extended template' provides the basic structure of a typical trial-based experiment with a practice and experimental phase. Because our experiment fits this template very well, we're going to use it. Therefore, double-click on 'Extended template' to open it.\n\nIn the 'General tab' that now appears, you can specify the general properties of your experiment. For this experiment, we want to use black letters on a gray background. Also, the default font size of 18 is a bit small, so change that to 32. Finally, it's good practice to give your experiment an informative name and description. Your 'General tab' now looks as in %FigGeneralTab.\n\n<notranslate>\nfigure:\n id: FigGeneralTab\n source: FigGeneralTab.png\n caption: |\n  The General tab is where you define the general properties of your experiment.\n</notranslate>\n\n## Step 3: Implement counterbalancing\n\nIn Raymond et al. (1992), the experimental and control conditions were mixed between blocks: Participants first did a full block in one condition, and then a full block in the other condition. Condition order was counterbalanced, so that half the participants started with the experimental condition, and the other half started with the control condition.\n\nLet's start with the counterbalancing part, and use the participant number to decide which condition is tested first. We need to do this as the very first thing of the experiment, and we need to use some Python scripting to do it.": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## Difficulté\n\nCe tutoriel suppose une connaissance de base d'OpenSesame, de la conception expérimentale et de Python. Un tutoriel d'introduction à OpenSesame se trouve ici :\n\n- [/tutorials/step-by-step-tutorial/](/tutorials/step-by-step-tutorial/)\n\nDes liens vers des tutoriels Python d'introduction se trouvent ici :\n\n- [/python/about/](/python/about/)\n\n## L'objectif\n\nDans ce tutoriel, nous mettrons en œuvre un paradigme de clignotement attentionnel, tel qu'introduit par [Raymond, Shapiro et Arnell (1992)](#références). Nous recréerons presque exactement l'expérience 2 de Raymond et al., avec seulement quelques modifications mineures. Dans cette expérience, le participant voit un flux de lettres, généralement appelé flux RSVP (pour Rapid Serial Visual Presentation). Il y a deux conditions. Dans la condition *expérimentale*, la tâche du participant est double :\n\n- Signaler l'identité de la lettre blanche (toutes les autres lettres étaient noires).\n- Indiquer si un 'X' était présent.\n\nDans la condition de contrôle, la tâche du participant consiste uniquement à ...\n\n- Indiquer si un 'X' était présent.\n\nLa lettre blanche est appelée *T1* (ou 'cible'). Le 'X' est appelé *T2* (ou 'sonde'). Le résultat typique est que le T2 est souvent manqué lorsqu'il est présenté 200 à 500 ms après T1, mais seulement lorsque T1 doit être signalé. Ce phénomène est appelé *clignotement attentionnel*, car il semble que l'œil de votre esprit cligne brièvement après avoir vu T1. Mais étonnamment, le T2 n'est généralement pas manqué lorsqu'il suit immédiatement T1. Ceci est appelé *préservation au temps d'attente-1*. Les résultats de Raymond et al. (1992) ressemblaient à ceci :\n\n<notranslate>\nfigure:\n id: FigResults\n source: FigResults.svg\n caption: |\n  Précision du T2 en fonction de la position sérielle du T2 par rapport au T1 ('temps d'attente'). Un temps d'attente de 0 signifie que le T1 et le T2 étaient identiques (c'est-à-dire un 'X' blanc). Adapté de Raymond et al. (1992).\n</notranslate>\n\n## Étape 1 : Télécharger et démarrer OpenSesame\n\nOpenSesame est disponible pour Windows, Linux, Mac OS (expérimental) et Android (runtime uniquement). Ce tutoriel est écrit pour OpenSesame 3.0.X. Vous pouvez télécharger OpenSesame à partir d'ici :\n\n- <http://osdoc.cogsci.nl/>\n\nLorsque vous démarrez OpenSesame, on vous proposera des expériences modèles et une liste d'expériences récemment ouvertes (%FigStartup).\n\n<notranslate>\nfigure\n id: FigStartup\n source: FigStartup.png\n caption: |\n  La fenêtre OpenSesame au démarrage.\n</notranslate>\n\n## Étape 2 : Choisir un modèle, une police et des couleurs\n\nLe \"modèle étendu\" fournit la structure de base d'une expérience typique basée sur des essais avec une phase de pratique et une phase expérimentale. Comme notre expérience correspond très bien à ce modèle, nous allons l'utiliser. Par conséquent, double-cliquez sur \"Extended template\" pour l'ouvrir.\n\nDans l'onglet \"General tab\" qui apparaît maintenant, vous pouvez spécifier les propriétés générales de votre expérience. Pour cette expérience, nous voulons utiliser des lettres noires sur un fond gris. De plus, la taille de police par défaut de 18 est un peu petite, alors changez-la pour 32. Enfin, il est recommandé de donner à votre expérience un nom et une description informatifs. Votre onglet \"General tab\" ressemble maintenant à %FigGeneralTab.\n\n<notranslate>\nfigure:\n id: FigGeneralTab\n source: FigGeneralTab.png\n caption: |\n  L'onglet \"General tab\" est l'endroit où vous définissez les propriétés générales de votre expérience.\n</notranslate>\n\n## Étape 3 : Mettre en œuvre la contrebalancement\n\nDans Raymond et al. (1992), les conditions expérimentales et de contrôle étaient mélangées entre les blocs : les participants faisait d'abord un bloc complet dans une condition, puis un bloc complet dans l'autre condition. L'ordre des conditions était contrebalancé, de sorte que la moitié des participants commençaient par la condition expérimentale, et l'autre moitié par la condition de contrôle.\n\nCommençons par la partie contrebalancement, et utilisons le numéro du participant pour décider quelle condition est testée en premier. Nous devons faire cela dès le début de l'expérience, et nous devons utiliser des scripts Python pour le faire."
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this tutorial\n\nThis tutorial assumes a basic knowledge of OpenSesame and, for some parts, Python. Therefore, if you're not familiar with OpenSesame or Python, I recommend that you walk through the beginner and intermediate tutorials before continuing with this tutorial:\n\n- %link:beginner%\n- %link:intermediate%\n\nIn this tutorial, you will learn the following:\n\n- Eye tracking with PyGaze\n- Doing things in parallel with `coroutines`\n- Using advanced `loop` operations\n\n\n## About the experiment\n\nIn this tutorial, we will implement a *visual-world paradigm*, which was introduced by Cooper (1974; for a review see also Huettig, Rommers, and Meyer, 2011). In this paradigm, participants hear a spoken sentence, while they are looking at a display with several objects. We will use four separate objects presented in the four quadrants of the display (%FigParadigm).\n\n\n<notranslate>\nfigure:\n id: FigParadigm\n source: visual-world-paradigm.svg\n caption: >\n  A schematic of our trial sequence. This is an example of a Full Match trial, because the target object (the apple) is directly mentioned in the spoken sentence. Stimuli taken from the [BOSS](https://sites.google.com/site/bosstimuli/) stimuli (Brodier et al., 2010).\n</notranslate>\n\n\nThe spoken sentence refers to one or more of the objects. For example, an apple (the target object) may be shown while the spoken sentence \"at breakfast, the girl ate an apple\" is played back. In this case, the target matches the sentence fully. The sentence may also refer indirectly to a shown object. For example, an apple (again the target object) may be shown while the spoken sentence \"at breakfast, the girl ate a banana\" is played back. In this case, the target matches the sentence semantically, because a banana and an apple are both fruits that a girl may eat at breakfast.\n\nDuring the experiment, eye position is recorded, and the proportion of fixations on target and non-target objects is measured over time. The typical finding is then that the eyes are drawn toward target objects; that is, participants look mostly at objects that are directly or indirectly referred to by the spoken sentence. And the more direct the reference, the stronger this effect.\n\nNow let's make this more formal. Our experiment will have the following design:\n\n- One factor (Target Match) with two levels (Full or Semantic), varied within subjects. In the Full Match condition, the target object is directly mentioned in the sentence. In the Semantic Match condition, the target object is semantically related to an object that is mentioned in the sentence.\n- We have 16 spoken sentences and sixteen target objects. Every sentence and every target object is shown twice: once in the Full Match condition, and once in the Semantic Match condition.\n- We have 16 × 3 = 48 distractor objects, each of which (like the targets) is shown twice.\n- Each trial starts with a fixation dot for 1 s, followed by the presentation of the stimuli, followed 1 s later by the onset of the spoken sentence. The trial ends 5 s later.\n\n\n## The tutorial\n\n\n### Step 1: Download and start OpenSesame\n\nOpenSesame is available for Windows, Linux, Mac OS (experimental), and Android (runtime only). This tutorial is written for OpenSesame 3.2.X *Kafkaesque Koffka*. To be able to use PyGaze, you should download the Python 2.7 version (which is the default). You can download OpenSesame from here:\n\n- %link:download%\n\n(If you start OpenSesame for the first time, you will see a Welcome tab. Dismiss this tab.) When you start OpenSesame, you will be given a choice of template experiments, and (if any) a list of recently opened experiments (see %FigStartUp). Click on 'Default Template' to start with an almost empty experiment.\n\n\n<notranslate>\nfigure:\n id: FigStartUp\n source: start-up.png\n caption: |\n  The OpenSesame window on start-up.\n</notranslate>\n\n\n### Step 2: Build the main structure of the experiment": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de ce tutoriel\n\nCe tutoriel suppose une connaissance de base d'OpenSesame et, pour certaines parties, de Python. Par conséquent, si vous n'êtes pas familier avec OpenSesame ou Python, je vous recommande de suivre les tutoriels débutant et intermédiaire avant de continuer avec ce tutoriel :\n\n- %link:beginner%\n- %link:intermediate%\n\nDans ce tutoriel, vous apprendrez les éléments suivants :\n\n- Suivi oculaire avec PyGaze\n- Faire des choses en parallèle avec `coroutines`\n- Utiliser des opérations `loop` avancées\n\n## À propos de l'expérience\n\nDans ce tutoriel, nous mettrons en œuvre un *paradigme du monde visuel*, qui a été introduit par Cooper (1974; pour un examen, voir aussi Huettig, Rommers, et Meyer, 2011). Dans ce paradigme, les participants entendent une phrase prononcée, pendant qu'ils regardent un écran avec plusieurs objets. Nous utiliserons quatre objets distincts présentés dans les quatre quadrants de l'écran (%FigParadigm).\n\n<notranslate>\nfigure:\n id: FigParadigm\n source: visual-world-paradigm.svg\n caption: >\n  Un schéma de notre séquence d'essai. Il s'agit d'un exemple d'essai de correspondance complète, car l'objet cible (la pomme) est directement mentionné dans la phrase parlée. Stimuli tirés des stimuli [BOSS](https://sites.google.com/site/bosstimuli/) (Brodeur et al., 2010).\n</notranslate>\n\nLa phrase parlée fait référence à un ou plusieurs des objets. Par exemple, une pomme (l'objet cible) peut être montrée pendant que la phrase parlée \"au petit déjeuner, la fille a mangé une pomme\" est jouée. Dans ce cas, la cible correspond à la phrase complète. La phrase peut également faire référence indirectement à un objet montré. Par exemple, une pomme (là encore l'objet cible) peut être montrée pendant que la phrase parlée \"au petit déjeuner, la fille a mangé une banane\" est jouée. Dans ce cas, l'objet cible correspond à la phrase sémantiquement, car une banane et une pomme sont tous les deux des fruits qu'une fille peut manger au petit déjeuner.\n\nPendant l'expérience, la position des yeux est enregistrée et la proportion de fixations sur les objets cibles et les objets non-cibles est mesurée dans le temps. La découverte typique est alors que les yeux sont attirés vers les objets cibles; c'est-à-dire que les participants regardent principalement les objets qui sont directement ou indirectement mentionnés par la phrase parlée. Et plus la référence est directe, plus cet effet est fort.\n\nFormalisons ceci davantage. Notre expérience aura la conception suivante :\n\n- Un facteur (Target Match) avec deux niveaux (Full ou Semantic), varié au sein des sujets. Dans la condition Full Match, l'objet cible est directement mentionné dans la phrase. Dans la condition de correspondance sémantique, l'objet cible est lié de manière sémantique à un objet mentionné dans la phrase.\n- Nous avons 16 phrases parlées et seize objets cibles. Chaque phrase et chaque objet cible est montré deux fois : une fois dans la condition Full Match et une fois dans la condition Semantic Match.\n- Nous avons 16 × 3 = 48 objets distracteurs, dont chacun (comme les cibles) est montré deux fois.\n- Chaque essai commence avec un point de fixation pendant 1 s, suivi de la présentation des stimuli, suivi 1 s plus tard par le début de la phrase parlée. L'essai se termine 5 s plus tard.\n\n## Le tutoriel\n\n### Étape 1 : Téléchargez et démarrez OpenSesame\n\nOpenSesame est disponible pour Windows, Linux, Mac OS (expérimental) et Android (runtime uniquement). Ce tutoriel est écrit pour OpenSesame 3.2.X *Kafkaesque Koffka*. Pour pouvoir utiliser PyGaze, vous devez télécharger la version Python 2.7 (qui est la version par défaut). Vous pouvez télécharger OpenSesame ici :\n\n- %link:download%\n\n(Si vous démarrez OpenSesame pour la première fois, vous verrez un onglet Welcome. Fermez cet onglet.) Lorsque vous démarrez OpenSesame, il vous sera proposé de choisir des expériences de modèles et, le cas échéant, une liste d'expériences récemment ouvertes (voir %FigStartUp). Cliquez sur \"Default Template\" pour commencer avec une expérience presque vide.\n\n<notranslate>\nfigure:\n id: FigStartUp\n source: start-up.png\n caption: |\n  La fenêtre OpenSesame au démarrage.\n</notranslate>\n\n### Étape 2 : Construire la structure principale de l'expérience"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.3.7 *Lentiform Loewenfeld* is the seventh maintenance release in the 3.3 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.3 series.\n\nA notable improvement in this release is the update to the [Rapunzel code editor](https://rapunzel.cogsci.nl/). Rapunzel is now able to capture output, and to show figures right next to the code that generated them. Rapunzel is now also able to import and export from and to various formats, including `.pdf`, `.html`, and `.ipynb` (Jupyter Notebook).\n\nIf you are upgrading from OpenSesame 3.2 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for his work on the Mac OS package\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.3.7\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 741 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 742 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 743 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 744 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 745 } --%\n\nrapunzel:\n\n- Updated to 0.5.10\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 14 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 15 } --%\n\npyqode.python:\n\n- Updated to 3.1.5\n- %-- github: { repo: \"open-cogsci/pyqode.python\", issue: 2 } --%\n\npyqode.core:\n\n- Updated to 3.1.11\n\nosweb:\n\n- Updated to 1.3.12\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 42 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 43 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 49 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 54 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 55 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 56 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 57 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 58 } --%\n\nopensesame-extension-osweb:\n\n- Udated to 1.3.12.1\n\npsychopy:\n\n- Updated to 2020.2.10\n\n\n## Packages\n\n\n### Python 3.7 (standard)": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.3.7 *Lentiform Loewenfeld* est la septième version de maintenance de la série 3.3. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.3.\n\nUne amélioration notable de cette version est la mise à jour de l'[éditeur de code Rapunzel](https://rapunzel.cogsci.nl/). Rapunzel est maintenant capable de capturer la sortie et d'afficher des figures juste à côté du code qui les a générées. Rapunzel est désormais également capable d'importer et d'exporter à partir et vers différents formats, notamment `.pdf`, `.html` et `.ipynb` (Jupyter Notebook).\n\nSi vous passez de OpenSesame 3.2 ou une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour son travail sur le paquet Mac OS\n\n## Corrections de bugs et améliorations\n\nopensesame:\n\n- Mis à jour en 3.3.7\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 741 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 742 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 743 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 744 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 745 } --%\n\nrapunzel:\n\n- Mis à jour en 0.5.10\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 14 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 15 } --%\n\npyqode.python:\n\n- Mis à jour en 3.1.5\n- %-- github: { repo: \"open-cogsci/pyqode.python\", issue: 2 } --%\n\npyqode.core:\n\n- Mis à jour en 3.1.11\n\nosweb:\n\n- Mis à jour en 1.3.12\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 42 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 43 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 49 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 54 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 55 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 56 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 57 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 58 } --%\n\nopensesame-extension-osweb:\n\n- Mis à jour en 1.3.12.1\n\npsychopy:\n\n- Mis à jour en 2020.2.10\n\n## Paquets\n\n### Python 3.7 (standard)"
  },
  "Another important concept is that of 'blocking on the vertical retrace' or the 'blocking flip'. Usually, when you send a command to show a new display, the computer will accept this command right away and put the to-be-shown display in a queue. However, the display may not actually appear on the monitor until some time later, typically until the start of the next refresh cycle (assuming that v-sync is enabled). Therefore, you don't know exactly when the display has appeared, because your timestamp reflects the moment that the display was queued, rather than the moment that it was presented. To get around this issue, you can use a so-called 'blocking flip'. This basically means that when you send a command to show a new display, the computer will freeze until the display actually appears. This allows you to get very accurate display timestamps, at the cost of a significant performance hit due to the computer being frozen for much of the time while it is waiting for a display to be shown. But for the purpose of experiments, a blocking flip is generally considered the optimal strategy.\n\nFinally, LCD monitors may suffer from 'input lag'. This means that there is an additional and sometimes variable delay between the moment that the computer 'thinks' that a display appears, and the moment that the display actually appears. This delay results from various forms of digital processing that are performed by the monitor, such as color correction or image smoothing. As far as I know, input lag is not something that can be resolved programmatically, and you should avoid monitors with significant input lag for time-critical experiments. \n\nFor a related discussion, see:\n\n- <http://docs.expyriment.org/Timing.html#visual>\n\n\n### Making the refresh deadline\n\nImagine that you arrive at a train station at 10:30. Your train leaves at 11:00, which gives you exactly 30 minutes to get a cup of coffee. However, if you have coffee for exactly 30 minutes, then you will arrive back at the platform just in time to see your train depart, and you will have to wait for the next train. Therefore, if you have 30 minutes waiting time, you should have a coffee for slightly less than 30 minutes, such as 25 minutes.\n\nThe situation is analogous when specifying intervals for visual-stimulus presentation. Let's say that you have a 100 Hz monitor (so 1 refresh every 10 ms) and want to present a target stimulus for 100 ms, followed by a mask. Your first inclination might be to specify an interval of 100 ms between the target and the mask, because that's after all what you want. However, specifying an interval of exactly 100 ms will likely cause the mask to 'miss the refresh deadline', and the mask will be presented only on the next refresh cycle, which is 10 ms later (assuming that v-sync is enabled). So if you specify an interval of 100 ms, you will in most cases end up with an interval of 110 ms!\n\nThe solution is simple: You should specify an interval that is slightly shorter than what you are aiming for, such as 95 ms. Don't worry about the interval being too short, because on a 100 Hz monitor the interval between two stimulus displays is necessarily a multiple of 10 ms. Therefore, 95 ms will become 100 ms (10 frames), 1 ms will become 10 ms (1 frame), etc. Phrased differently, intervals will be rounded up (and never rounded down!) to the nearest interval that is consistent with your monitor's refresh rate.\n\n\n### Disabling desktop effects\n\nMany modern operating systems make use of graphical desktop effects. These provide, for example, the transparency effects and the smooth window minimization and maximization effects that you see on most modern operating systems. Although the software that underlies these effects differs from system to system, they generally form an additional layer between your application and the display. This additional layer may prevent OpenSesame from synchronizing to the vertical refresh and/ or from implementing a blocking flip.": {
    "fr": "Un autre concept important est celui du \"blocage sur le rafraîchissement vertical\" ou le \"basculement bloquant\". Habituellement, lorsque vous envoyez une commande pour afficher un nouvel écran, l'ordinateur accepte cette commande immédiatement et place l'écran à afficher dans une file d'attente. Cependant, l'écran peut ne pas apparaître réellement sur le moniteur avant un certain temps, généralement jusqu'au début du prochain cycle de rafraîchissement (en supposant que la synchronisation verticale soit activée). Par conséquent, vous ne savez pas exactement quand l'écran apparaît, car votre horodatage reflète le moment où l'affichage a été mis en file d'attente, plutôt que le moment où il a été présenté. Pour contourner ce problème, vous pouvez utiliser un \"basculement bloquant\". Cela signifie essentiellement que lorsque vous envoyez une commande pour afficher un nouvel écran, l'ordinateur se bloque jusqu'à ce que l'affichage apparaisse réellement. Cela vous permet d'obtenir des horodatages d'affichage très précis, au prix d'une baisse significative des performances due au fait que l'ordinateur est bloqué pendant une grande partie du temps alors qu'il attend qu'un affichage soit montré. Mais pour les expériences, un basculement bloquant est généralement considéré comme la stratégie optimale.\n\nEnfin, les moniteurs LCD peuvent souffrir de \"latence d'entrée\". Cela signifie qu'il y a un délai supplémentaire et parfois variable entre le moment où l'ordinateur \"pense\" qu'un écran apparaît et le moment où l'écran apparaît réellement. Ce délai résulte de diverses formes de traitement numérique effectuées par le moniteur, telles que la correction des couleurs ou le lissage des images. À ma connaissance, la latence d'entrée ne peut pas être résolue de manière programmatique, et vous devez éviter les moniteurs avec une latence d'entrée significative pour des expériences critiques en matière de temps.\n\nPour une discussion connexe, voir :\n\n- <http://docs.expyriment.org/Timing.html#visual>\n\n\n### Respecter la limite de rafraîchissement\n\nImaginez que vous arrivez à une gare à 10h30. Votre train part à 11h00, ce qui vous laisse exactement 30 minutes pour prendre un café. Cependant, si vous prenez un café pendant exactement 30 minutes, vous arriverez de nouveau sur le quai juste à temps pour voir votre train partir, et vous devrez attendre le prochain train. Par conséquent, si vous avez 30 minutes d'attente, vous devriez prendre un café pendant légèrement moins de 30 minutes, comme 25 minutes.\n\nLa situation est analogue lors de la spécification des intervalles pour la présentation de stimuli visuels. Disons que vous avez un moniteur 100 Hz (donc 1 rafraîchissement toutes les 10 ms) et que vous voulez présenter un stimulus cible pendant 100 ms, suivi d'un masque. Votre première inclination pourrait être de spécifier un intervalle de 100 ms entre la cible et le masque, car c'est après tout ce que vous voulez. Cependant, spécifier un intervalle de 100 ms exactement fera probablement en sorte que le masque \"manque la limite de rafraîchissement\", et le masque ne sera présenté que lors du prochain cycle de rafraîchissement, soit 10 ms plus tard (en supposant que la synchronisation verticale soit activée). Donc, si vous spécifiez un intervalle de 100 ms, vous obtiendrez dans la plupart des cas un intervalle de 110 ms !\n\nLa solution est simple : vous devez spécifier un intervalle légèrement plus court que ce que vous visez, comme 95 ms. Ne vous inquiétez pas de l'intervalle étant trop court, car sur un moniteur 100 Hz, l'intervalle entre deux affichages de stimulus est nécessairement un multiple de 10 ms. Par conséquent, 95 ms deviendront 100 ms (10 images), 1 ms deviendra 10 ms (1 image), etc. Autrement dit, les intervalles seront arrondis à la hausse (et jamais arrondis à la baisse!) à l'intervalle le plus proche qui est cohérent avec la fréquence de rafraîchissement de votre moniteur.\n\n### Désactiver les effets du bureau\n\nDe nombreux systèmes d'exploitation modernes utilisent des effets graphiques de bureau. Ceux-ci fournissent, par exemple, les effets de transparence et les effets de minimisation et de maximisation de fenêtre fluides que vous voyez sur la plupart des systèmes d'exploitation modernes. Bien que le logiciel qui sous-tend ces effets diffère d'un système à l'autre, ils forment généralement une couche supplémentaire entre votre application et l'affichage. Cette couche supplémentaire peut empêcher OpenSesame de se synchroniser avec le rafraîchissement vertical et/ou de mettre en œuvre un basculement bloquant."
  },
  "- [Expyriment](http://www.expyriment.org/) is required for the [xpyriment] backend.\n    - OpenSesame >= 3.0.0 requires Expyriment >= 0.8.0.\n- [NumPy](http://www.numpy.org/) is an advanced mathematical library that is used for various things, such as sound support.\n- [PIL](http://www.pythonware.com/products/pil/) is an imaging library that is used for various things.\n    - You can also use `pillow`, an actively maintained fork of the original, and no longer maintained `PIL`.\n- [PsychoPy](http://www.psychopy.org/) is required for the [psycho] backend.\n- [pyflakes](https://pypi.python.org/pypi/pyflakes) is required for automatic validation of your Python scripts.\n- [Pyglet](http://www.pyglet.org/) is required by PsychoPy.\n- [PyOpenGL](http://pyopengl.sourceforge.net/) is required by PsychoPy and Expyriment.\n- [pySerial](http://pyserial.sourceforge.net/) is required for serial-port communication.\n- [python-markdown](https://pypi.python.org/pypi/Markdown) is required for viewing in-program help files.\n- [IPython](http://ipython.org/), when available, is used for the debug window.\n- [python-fileinspector](https://github.com/dschreij/fileinspector) is used to generate file-type-specific icons.\n- [shapely](https://pypi.org/project/Shapely/) is used to check the boundaries of `Canvas` elements\n\n### Extra\n\nThe following packages are not used directly by OpenSesame, but may come in handy while developing your experiments, and are included with the official Windows distribution of OpenSesame.\n\n- [PyAudio](http://people.csail.mit.edu/hubert/pyaudio/) is an alternative library for sound recording and playback.\n- [Matplotlib](http://matplotlib.org/) is a library for plotting graphs.\n- [Scipy](http://www.scipy.org/) is a set of miscellaneous scientific routines.\n- [pyCairo](http://www.lfd.uci.edu/~gohlke/pythonlibs/#pycairo) is a library for vector graphics.\n- [pyParallel](http://sourceforge.net/projects/pyserial/files/pyparallel) allows communication via the parallel port.\n- [OpenCV](http://opencv.org/) (Python bindings) is an extensive computer-vision library.\n- [PyGaze](http://www.pygaze.org/) is a Python library for eye tracking.\n    - OpenSesame >= 3.0.0 requires PyGaze >= 0.6.0.\n\n## Instructions for Mac OS\n\nThere are three ways to prepare the software environment for running OpenSesame from source on Mac OS X. You can either download and install all required packages manually, or compose the required source environment by using the repository-based package managers MacPorts or Homebrew. The easiest and preferred method nowadays to get OpenSesame working is by using Homebrew. This package manager works very fast, handles dependency requirements very well, and is very well maintained. The other package manager, MacPorts, is basically a large repository containing the source code of programs that have been ported from Linux to Mac OS X (which are very related as Mac OS X is also a Unix based system, as you might know). Compared to Homebrew, Macports takes an astoundingly long time to compile all dependencies. Furthermore, even though Macports used to work very well, it nowadays experiences a lot of 'breaks' due to dependency issues. The downside of homebrew is that it is 'less complete' than macports and you have to manually install many python packages (using easy_install or pip).\n\n### Download Xcode\n\nIf you want to install with either Homebrew or Macports, the first thing that you need to do is install Xcode, the Apple developer toolkit. You can get the latest version of Xcode for free from the App Store or from their website (you do need to login with an apple account though).\n\nWebsite: <https://developer.apple.com/xcode/>\n\nUsing the App Store is preferable, as it will keep your version of X Code automatically up to date. You do need to also manually install the Command Line tools for X Code (and do this each time again after it is updated).\n\n### Installing with Homebrew": {
    "fr": "- [Expyriment](http://www.expyriment.org/) est nécessaire pour le backend [xpyriment].\n    - OpenSesame >= 3.0.0 nécessite Expyriment >= 0.8.0.\n- [NumPy](http://www.numpy.org/) est une bibliothèque mathématique avancée utilisée pour diverses choses, telles que la prise en charge du son.\n- [PIL](http://www.pythonware.com/products/pil/) est une bibliothèque d'imagerie utilisée pour diverses choses.\n    - Vous pouvez également utiliser `pillow`, un fork activement maintenu de l'original, et `PIL` qui n'est plus maintenu.\n- [PsychoPy](http://www.psychopy.org/) est nécessaire pour le backend [psycho].\n- [pyflakes](https://pypi.python.org/pypi/pyflakes) est nécessaire pour la validation automatique de vos scripts Python.\n- [Pyglet](http://www.pyglet.org/) est requis par PsychoPy.\n- [PyOpenGL](http://pyopengl.sourceforge.net/) est requis par PsychoPy et Expyriment.\n- [pySerial](http://pyserial.sourceforge.net/) est nécessaire pour la communication par port série.\n- [python-markdown](https://pypi.python.org/pypi/Markdown) est requis pour visualiser les fichiers d'aide intégrés au programme.\n- [IPython](http://ipython.org/), lorsqu'il est disponible, est utilisé pour la fenêtre de débogage.\n- [python-fileinspector](https://github.com/dschreij/fileinspector) est utilisé pour générer des icônes spécifiques au type de fichier.\n- [shapely](https://pypi.org/project/Shapely/) est utilisé pour vérifier les limites des éléments `Canvas`.\n\n### Extra\n\nLes packages suivants ne sont pas utilisés directement par OpenSesame, mais peuvent être utiles pour développer vos expériences et sont inclus dans la distribution officielle d'OpenSesame pour Windows.\n\n- [PyAudio](http://people.csail.mit.edu/hubert/pyaudio/) est une bibliothèque alternative pour l'enregistrement et la lecture de sons.\n- [Matplotlib](http://matplotlib.org/) est une bibliothèque pour tracer des graphiques.\n- [Scipy](http://www.scipy.org/) est un ensemble de routines scientifiques diverses.\n- [pyCairo](http://www.lfd.uci.edu/~gohlke/pythonlibs/#pycairo) est une bibliothèque pour les graphiques vectoriels.\n- [pyParallel](http://sourceforge.net/projects/pyserial/files/pyparallel) permet la communication via le port parallèle.\n- [OpenCV](http://opencv.org/) (liaisons Python) est une bibliothèque étendue de vision par ordinateur.\n- [PyGaze](http://www.pygaze.org/) est une bibliothèque Python pour l'eye tracking.\n    - OpenSesame >= 3.0.0 nécessite PyGaze >= 0.6.0.\n\n## Instructions pour Mac OS\n\nIl y a trois façons de préparer l'environnement logiciel pour exécuter OpenSesame à partir du code source sur Mac OS X. Vous pouvez soit télécharger et installer tous les packages requis manuellement, soit composer l'environnement source requis à l'aide des gestionnaires de packages basés sur les dépôts MacPorts ou Homebrew. La méthode la plus facile et préférée aujourd'hui pour faire fonctionner OpenSesame est d'utiliser Homebrew. Ce gestionnaire de packages fonctionne très rapidement, gère très bien les exigences de dépendance et est très bien entretenu. L'autre gestionnaire de paquets, MacPorts, est essentiellement un grand dépôt contenant le code source de programmes qui ont été portés de Linux à Mac OS X (qui sont très liés car Mac OS X est également un système basé sur Unix, comme vous le savez peut-être). Comparé à Homebrew, Macports prend un temps incroyablement long pour compiler toutes les dépendances. De plus, même si Macports fonctionnait très bien auparavant, il connaît aujourd'hui de nombreux problèmes de dépendance. L'inconvénient de Homebrew est qu'il est \"moins complet\" que Macports et vous devez installer manuellement de nombreux packages Python (en utilisant easy_install ou pip).\n\n### Télécharger Xcode\n\nSi vous souhaitez installer avec Homebrew ou Macports, la première chose que vous devez faire est d'installer Xcode, la boîte à outils développeur d'Apple. Vous pouvez obtenir la dernière version d'Xcode gratuitement depuis l'App Store ou depuis leur site web (vous devez toutefois vous connecter avec un compte Apple).\n\nSite web : <https://developer.apple.com/xcode/>\n\nUtiliser l'App Store est préférable, car il maintiendra votre version de X Code automatiquement à jour. Vous devez également installer manuellement les outils de ligne de commande pour X Code (et le faire à chaque fois qu'il est mis à jour).\n\n### Installation avec Homebrew"
  },
  "Therefore, drag an INLINE_SCRIPT from the item toolbar onto the very top of the experiment. Change the name of the new item to *counterbalance*. In the *Prepare* phase of the *counterbalance* item, enter the following script:\n\n~~~ .python\nif var.subject_parity == 'even':\n\tvar.condition1 = 'experimental'\n\tvar.condition2 = 'control'\nelse:\n\tvar.condition1 = 'control'\n\tvar.condition2 = 'experimental'\n~~~\n\nOk, let's take a moment to understand what's going on here.\n\nThe first thing to know is that experimental variables are properties of the `var` object. Experimental variables are variables that you have defined yourself, for example in a LOOP item, as well as built-in variables. One such built-in experimental variable is `subject_parity`, which is automatically set to 'even' when the experiment is launched with an even subject number (0, 2, 4, etc.), and to 'odd' when the subject number is odd (1, 3, 5, etc.).\n\nWe further create two new experimental variables `condition1` and `condition2`. By setting these as properties of `var`, we make them available elsewhere in OpenSesame, outside of INLINE_SCRIPT items. So this line:\n\n~~~ .python\nvar.condition1 = 'experimental'\n~~~\n\n... creates an experimental variable with the name `condition1`, and gives it the value 'experimental'. In step 4, we will use this variable to determine which condition is tested first.\n\nIn other words, this script says the following:\n\n- All even-numbered subjects start with the experimental condition.\n- All odd-subjects start with the control condition.\n\n<div class='info-box' markdown='1'>\n\n### Links\n\n- [/python/var/](/python/var/)\n- [/usage/variables-and-conditional-statements/](/usage/variables-and-conditional-statements/)\n- [/miscellaneous/counterbalancing/](/miscellaneous/counterbalancing/)\n\n</div>\n\n## Step 4: Define experimental variables that are varied between blocks\n\nAs mentioned above, conditions are varied between blocks. To understand how this works in OpenSesame, it's best to start at the bottom (see %FigStructure), with ...\n\n- the *trial_sequence*, which corresponds (as you might expect) to a single trial. One level above ...\n- the *block_loop* corresponds to a single block of trials. Therefore, this is where you would define experimental variables that are varied within a block. One level above ...\n- the *block_sequence* corresponds to a single block of trials plus the events that happen before and after every block, such as post-block feedback on accuracy, and pre-block instructions. One level above ...\n- the *practice_loop* and *experimental_loop* correspond to multiple blocks of trials during respectively the practice and non-practice (experimental) phase. Therefore, this is where you would define experimental variables that are varied between blocks.\n\nIn other words, we need to define our between-block manipulations near the top of the experimental hierarchy, in the *practice_loop* and *experimental_loop*.\n\n<notranslate>\nfigure:\n id: FigStructure\n source: FigStructure.png\n caption: |\n  A fragment of the experimental structure as shown in the overview area.\n</notranslate>\n\nClick on *practice_loop* to open the item. Right now, there is only one variable, `practice`, which has the value 'yes' during one cycle (i.e. one block).\n\nLet's get to work! Add a variable called `condition`, change the number of cycles to 2, and change the order to 'sequential'.\nNow use the previously created variables `condition1` and `condition2` to determine which condition is executed first, and which second (see %FigPracticeLoop). To indicate that something is the name of a variable, and not a literal value, put square brackets around the variable name: '[my_variable]'\n\n<notranslate>\nfigure:\n id: FigPracticeLoop\n source: FigPracticeLoop.png\n caption: |\n  The *practice_loop* item after Step 4.\n</notranslate>": {
    "fr": "Ainsi, faites glisser un INLINE_SCRIPT de la barre d'outils des éléments vers le haut de l'expérience. Changez le nom du nouvel élément en *counterbalance*. Dans la phase de *Préparation* de l'élément *counterbalance*, entrez le script suivant :\n\n~~~ .python\nif var.subject_parity == 'even':\n\tvar.condition1 = 'experimental'\n\tvar.condition2 = 'control'\nelse:\n\tvar.condition1 = 'control'\n\tvar.condition2 = 'experimental'\n~~~\n\nOk, prenons un moment pour comprendre ce qui se passe ici.\n\nLa première chose à savoir est que les variables expérimentales sont des propriétés de l'objet `var`. Les variables expérimentales sont des variables que vous avez définies vous-même, par exemple dans un élément LOOP, ainsi que des variables intégrées. Une telle variable expérimentale intégrée est `subject_parity`, qui est automatiquement définie sur 'even' lorsque l'expérience est lancée avec un numéro de sujet pair (0, 2, 4, etc.), et sur 'odd' lorsque le numéro de sujet est impair (1, 3, 5, etc.).\n\nNous créons ensuite deux nouvelles variables expérimentales `condition1` et `condition2`. En définissant ces propriétés comme `var`, nous les rendons disponibles ailleurs dans OpenSesame, en dehors des éléments INLINE_SCRIPT. Ainsi, cette ligne :\n\n~~~ .python\nvar.condition1 = 'experimental'\n~~~\n\n... crée une variable expérimentale avec le nom `condition1`, et lui donne la valeur 'experimental'. À l'étape 4, nous utiliserons cette variable pour déterminer quelle condition est testée en premier.\n\nEn d'autres termes, ce script dit ce qui suit :\n\n- Tous les sujets pairs commencent par la condition expérimentale.\n- Tous les sujets impairs commencent par la condition de contrôle.\n\n<div class='info-box' markdown='1'>\n\n### Liens\n\n- [/python/var/](/python/var/)\n- [/usage/variables-and-conditional-statements/](/usage/variables-and-conditional-statements/)\n- [/miscellaneous/counterbalancing/](/miscellaneous/counterbalancing/)\n\n</div>\n\n## Étape 4 : Définir des variables expérimentales qui varient entre les blocs\n\nComme mentionné ci-dessus, les conditions varient entre les blocs. Pour comprendre comment cela fonctionne dans OpenSesame, il est préférable de commencer par le bas (voir %FigStructure), avec ...\n\n- la *trial_sequence*, qui correspond (comme vous vous en doutez) à un essai unique. Un niveau au-dessus ...\n- la *block_loop* correspond à un seul bloc d'essais. C'est donc là que vous définiriez les variables expérimentales qui varient au sein d'un bloc. Un niveau au-dessus ...\n- la *block_sequence* correspond à un seul bloc d'essais plus les événements qui se produisent avant et après chaque bloc, tels que les commentaires sur la précision après chaque bloc et les instructions avant chaque bloc. Un niveau au-dessus ...\n- la *practice_loop* et *experimental_loop* correspondent à plusieurs blocs d'essais pendant respectivement la phase d'entraînement et la phase non-entraînement (expérimentale). C'est donc là que vous définiriez les variables expérimentales qui varient entre les blocs.\n\nEn d'autres termes, nous devons définir nos manipulations entre blocs près du haut de la hiérarchie expérimentale, dans la *practice_loop* et *experimental_loop*.\n\n<notranslate>\nfigure:\n id: FigStructure\n source: FigStructure.png\n caption: |\n  Un fragment de la structure expérimentale tel qu'il est présenté dans la zone d'aperçu.\n</notranslate>\n\nCliquez sur *practice_loop* pour ouvrir l'élément. Pour l'instant, il n'y a qu'une seule variable, `practice`, qui a la valeur 'yes' pendant un cycle (c'est-à-dire un bloc).\n\nAu travail ! Ajoutez une variable appelée `condition`, changez le nombre de cycles en 2 et changez l'ordre en 'sequentiel'.\nUtilisez ensuite les variables précédemment créées `condition1` et `condition2` pour déterminer quelle condition est exécutée en premier et quelle condition est exécutée en deuxième (voir %FigPracticeLoop). Pour indiquer que quelque chose est le nom d'une variable et non une valeur littérale, placez des crochets autour du nom de la variable : '[my_variable]'\n\n<notranslate>\nfigure:\n id: FigPracticeLoop\n source: FigPracticeLoop.png\n caption: |\n  L'élément *practice_loop* après l'étape 4.\n</notranslate>"
  },
  "For now, build the following main structure for your experiment (see also %FigMainStructure):\n\n1. We start with an instructions screen. This will be a `sketchpad`.\n2. Next, we run one block of trials. This will be a single `sequence`, corresponding to a single trial, inside a single `loop`, corresponding to a block of trials. You can leave the trial sequence empty for now!\n3. Finally, we end with a goodbye screen.\n\nWe also need to change the foreground color of the experiment to black, and the background color to white. This is because we will use images that have a white background, and we don't want these images to stand out!\n\nAnd don't forget to give your experiment a sensible name, and to save it!\n\n\n<notranslate>\nfigure:\n id: FigMainStructure\n source: main-structure.png\n caption: |\n  The main structure of the experiment.\n</notranslate>\n\n\n### Step 3: Import files into the file pool\n\nFor this experiment we need stimuli: sound files for the spoken sentences, and image files for the objects. Download these from the link below, extract the `zip` file, and place the stimuli in the file pool of your experiment (see also %FigFilePool).\n\n- %static:attachments/visual-world/stimuli.zip%\n\n<notranslate>\nfigure:\n id: FigFilePool\n source: file-pool.png\n caption: |\n  The file pool of your experiment after all stimuli have been added.\n</notranslate>\n\n\n### Step 4: Define experimental variables in the block_loop\n\nThe *block_loop* is where we define the experimental variables, by entering them into a table, where each row corresponds to a trial, and each column corresponds to an experimental variable.\n\nFor now, we define only the Full Match condition, in which the target object is directly mentioned in the spoken sentence. (We will add the Semantic Match condition as part of the Extra Assignments.)\n\nWe need the following variables. First, simply add columns to the loop table, without giving the rows any content.\n\n- `pic1` — the name of the first picture (e.g. 'apple.jpg')\n- `pic2` — the name of the second picture\n- `pic3` — the name of the third picture\n- `pic4` — the name of the fourth picture\n- `pos1` — the position of the first picture (e.g. 'topleft')\n- `pos2` — the position of the first picture\n- `pos3` — the position of the first picture\n- `pos4` — the position of the first picture\n- `sound` — the name of a sound file that contains a spoken sentence (e.g. 'apple.ogg').\n\nThe target object will always correspond to `pic1`. We have the following target objects; that is, for the following objects, we have sound files that refer to them. Simply copy-paste the following list into the `pic1` column of the table:\n\n~~~\napple.jpg\narmchair.jpg\nbanana.jpg\nbear.jpg\ncard.jpg\ncello.jpg\nchicken.jpg\ncookie.jpg\ncroissant.jpg\ndice.jpg\negg.jpg\nguitar.jpg\nkeyboard.jpg\nmouse.jpg\nsofa.jpg\nwolf.jpg\n~~~\n\nAnd do the same for the sound files:\n\n~~~\napple.ogg\narmchair.ogg\nbanana.ogg\nbear.ogg\ncard.ogg\ncello.ogg\nchicken.ogg\ncookie.ogg\ncroissant.ogg\ndice.ogg\negg.ogg\nguitar.ogg\nkeyboard.ogg\nmouse.ogg\nsofa.ogg\nwolf.ogg\n~~~\n\nThe rest of the pictures are distractors. Copy-paste the following list into the `pic2`, `pic3`, and `pic4` columns, in such a way that each column has exactly 16 rows. (If you accidentally make the table longer than 16 rows, simply select the extraneous rows, right-click and delete them.)": {
    "fr": "Pour l'instant, construisez la structure principale suivante pour votre expérience (voir aussi %FigMainStructure) :\n\n1. Nous commençons par un écran d'instructions. Ce sera un `sketchpad`.\n2. Ensuite, nous exécutons un bloc d'essais. Ce sera une seule `séquence`, correspondant à un seul essai, à l'intérieur d'une seule `boucle`, correspondant à un bloc d'essais. Vous pouvez laisser la séquence d'essai vide pour l'instant !\n3. Enfin, nous terminons avec un écran d'au revoir.\n\nNous devons également changer la couleur de premier plan de l'expérience en noir et la couleur d'arrière-plan en blanc. C'est parce que nous utiliserons des images qui ont un fond blanc, et nous ne voulons pas que ces images ressortent !\n\nEt n'oubliez pas de donner à votre expérience un nom sensé et de la sauvegarder !\n\n<notranslate>\nfigure:\n id: FigMainStructure\n source: main-structure.png\n caption: |\n  La structure principale de l'expérience.\n</notranslate>\n\n### Étape 3 : Importer les fichiers dans le pool de fichiers\n\nPour cette expérience, nous avons besoin de stimuli : des fichiers sonores pour les phrases prononcées et des fichiers d'images pour les objets. Téléchargez-les à partir du lien ci-dessous, extrayez le fichier `zip` et placez les stimuli dans le pool de fichiers de votre expérience (voir aussi %FigFilePool).\n\n- %static:attachments/visual-world/stimuli.zip%\n\n<notranslate>\nfigure:\n id: FigFilePool\n source: file-pool.png\n caption: |\n  Le pool de fichiers de votre expérience après que tous les stimuli ont été ajoutés.\n</notranslate>\n\n### Étape 4 : Définir les variables expérimentales dans la boucle de blocs\n\nLa *boucle de blocs* est l'endroit où nous définissons les variables expérimentales en les entrant dans un tableau, où chaque ligne correspond à un essai et chaque colonne correspond à une variable expérimentale.\n\nPour l'instant, nous définissons uniquement la condition Full Match, dans laquelle l'objet cible est directement mentionné dans la phrase parlée. (Nous ajouterons la condition Semantic Match dans le cadre des travaux supplémentaires.)\n\nNous avons besoin des variables suivantes. Tout d'abord, ajoutez simplement des colonnes au tableau de la boucle, sans donner de contenu aux lignes.\n\n- `pic1` — le nom de la première image (par exemple, 'apple.jpg')\n- `pic2` — le nom de la deuxième image\n- `pic3` — le nom de la troisième image\n- `pic4` — le nom de la quatrième image\n- `pos1` — la position de la première image (par exemple, 'topleft')\n- `pos2` — la position de la première image\n- `pos3` — la position de la première image\n- `pos4` — la position de la première image\n- `sound` — le nom d'un fichier son contenant une phrase parlée (par exemple, 'apple.ogg').\n\nL'objet cible correspondra toujours à `pic1`. Nous avons les objets cibles suivants ; c'est-à-dire que pour les objets suivants, nous avons des fichiers sonores qui s'y réfèrent. Copiez-collez simplement la liste suivante dans la colonne `pic1` du tableau :\n\n~~~\napple.jpg\narmchair.jpg\nbanana.jpg\nbear.jpg\ncard.jpg\ncello.jpg\nchicken.jpg\ncookie.jpg\ncroissant.jpg\ndice.jpg\negg.jpg\nguitar.jpg\nkeyboard.jpg\nmouse.jpg\nsofa.jpg\nwolf.jpg\n~~~\n\nEt faites de même pour les fichiers sonores :\n\n~~~\napple.ogg\narmchair.ogg\nbanana.ogg\nbear.ogg\ncard.ogg\ncello.ogg\nchicken.ogg\ncookie.ogg\ncroissant.ogg\ndice.ogg\negg.ogg\nguitar.ogg\nkeyboard.ogg\nmouse.ogg\nsofa.ogg\nwolf.ogg\n~~~\n\nLe reste des images sont des distracteurs. Copiez-collez la liste suivante dans les colonnes `pic2`, `pic3` et `pic4`, de telle manière que chaque colonne ait exactement 16 lignes. (Si vous faites accidentellement un tableau de plus de 16 lignes, sélectionnez simplement les lignes superflues, faites un clic droit et supprimez-les.)"
  },
  "Homebrew is a newer and easier way to build a source tree on your mac. It has many benefits on top of macports, such as speed, and nowadays seems to have less trouble compiling and updating packages than macports does.\nYou can install homebrew as instructed on <http://brew.sh/>. Then issue the following command to get started:\n\n    brew update\n    brew doctor\n\nSolve any issues that the 'doctor' command comes up with. This should be easy and usually the solutions (in the form of simple commands) are already given together with the problem statement.\n\nNext, add some other required repositories by using homebrew's \"tap\" command:\n\n\tbrew tap homebrew/python\n\tbrew tap homebrew/headonly\n\tbrew tap homebrew/science\n\nNow it's time to start installing homebrew's own python environment. It's not really necessary to install another Python environment next to your system's python, but the Homebrew version is generally newer and better maintained, so it is definitely recommendable to do this.\n\n    brew install python\n\nAfter python has been installed, you have to make it the 'default' python used by OS X. This means that the home-brewed python interpreter will be used whenever you issue the command 'python' in a terminal instead of the default system python. To do this type the command\n\n    echo export PATH=\"/usr/local/bin:$PATH\" >> ~/.bash_profile\n\nThis will position the reference to the folder in which all your homebrew stuff is located (/usr/local/bin) in front of the rest of the PATH variable. From now on, whenever you issue a command in your terminal, OS X will look in this folder first for the script or program to execute and if it doesn't find it there, it will continue to look in the other folders in the PATH variable. Close and reopen your terminal or enter the command\n\n\tsource ~/.bash_profile\n\nto rerun the commands written in your .bash_profile. If you then run the command\n\n    which python\n\nit should output something like '/usr/local/bin/python'. If it still outputs '/usr/bin/python', OSX is still using the default system python, which is not what you want. You can now continue with installing the rest of the required packages by executing\n\n\tbrew install qt pyqt qscintilla2 freetype portaudio numpy scipy portmidi hg pillow\n\nFor pygame, it is preferable to first install the SDL libraries and smpeg (these are all better than the version that came with OS X, which seem to miss some important functionality):\n\n\tbrew install --HEAD smpeg\n\tbrew install sdl sdl_image sdl_mixer sdl_ttf pygame\n\nInstall the necessary python packages\n\n    pip install pyopengl pyflakes markdown python-bidi pyserial billiard\n\nInstall QProgEdit (from OpenSesame 2.8 on)\n\n    git clone https://github.com/smathot/QProgEdit.git\n\tcd QProgEdit\n\tpython setup.py install\n\tcd ..\n\trm -R QProgEdit\n\nInstall expyriment (from OpenSesame 0.27 on)\n\n    git clone https://github.com/expyriment/expyriment.git\n\tcd expyriment\n\tpython setup.py install\n\tcd ..\n\trm -R expyriment\n\nInstall psychopy and its dependency pyglet. For psychopy to work, you (currently) need the latest repository versions from both pyglet and psychopy\n\nFirst install pyglet:\n\n    hg clone https://code.google.com/p/pyglet/\n\tcd pyglet\n\tpython setup.py install\n\tcd ..\n\trm -R pyglet\n\nThen psychopy. Install it and do some cleanup with:\n\n\tgit clone https://github.com/psychopy/psychopy.git\n\tcd psychopy\n\tpython setup.py install\n\tcd ..\n\trm -R psychopy\n\nDuring installing you might receive an error with the message \"Unknown locale UTF8\". You can easily fix this by placing the line \"LC_ALL=en_US.UTF8\" in your ~/.bash_profile and then re-open your terminal.": {
    "fr": "Homebrew est un moyen plus récent et plus simple de construire un arbre source sur votre Mac. Il présente de nombreux avantages par rapport à macports, tels que la vitesse, et semble aujourd'hui avoir moins de problèmes pour compiler et mettre à jour des packages que macports.\nVous pouvez installer homebrew comme indiqué sur <http://brew.sh/>. Ensuite, exécutez la commande suivante pour commencer:\n\n    brew update\n    brew doctor\n\nRésolvez les problèmes que la commande 'doctor' soulève. Cela devrait être facile et généralement les solutions (sous forme de commandes simples) sont déjà données avec l'énoncé du problème.\n\nEnsuite, ajoutez d'autres référentiels requis en utilisant la commande \"tap\" de homebrew:\n\n\tbrew tap homebrew/python\n\tbrew tap homebrew/headonly\n\tbrew tap homebrew/science\n\nIl est maintenant temps de commencer à installer l'environnement python de homebrew. Ce n'est pas vraiment nécessaire d'installer un autre environnement Python à côté du python de votre système, mais la version Homebrew est généralement plus récente et mieux maintenue, il est donc recommandé de le faire.\n\n    brew install python\n\nAprès avoir installé python, vous devez en faire le python 'par défaut' utilisé par OS X. Cela signifie que l'interpréteur python de homebrew sera utilisé lorsque vous exécutez la commande 'python' dans un terminal au lieu du python système par défaut. Pour ce faire, tapez la commande\n\n    echo export PATH=\"/usr/local/bin:$PATH\" >> ~/.bash_profile\n\nCela placera la référence au dossier dans lequel se trouve tout votre matériel homebrew (/usr/local/bin) devant le reste de la variable PATH. Désormais, chaque fois que vous exécutez une commande dans votre terminal, OS X cherchera d'abord dans ce dossier le script ou le programme à exécuter et s'il ne le trouve pas, il continuera à chercher dans les autres dossiers de la variable PATH. Fermez et rouvrez votre terminal ou entrez la commande\n\n\tsource ~/.bash_profile\n\npour réexécuter les commandes écrites dans votre .bash_profile. Si vous exécutez ensuite la commande\n\n    wich python\n\nil devrait afficher quelque chose comme '/usr/local/bin/python'. S'il affiche toujours '/usr/bin/python', OS X utilise toujours le python système par défaut, ce qui n'est pas ce que vous voulez. Vous pouvez maintenant continuer à installer le reste des packages requis en exécutant\n\n\tbrew install qt pyqt qscintilla2 freetype portaudio numpy scipy portmidi hg pillow\n\nPour pygame, il est préférable d'installer d'abord les bibliothèques SDL et smpeg (ces versions sont toutes meilleures que celles fournies avec OS X, qui semblent manquer certaines fonctionnalités importantes):\n\n\tbrew install --HEAD smpeg\n\tbrew install sdl sdl_image sdl_mixer sdl_ttf pygame\n\nInstallez les packages python nécessaires\n\n    pip install pyopengl pyflakes markdown python-bidi pyserial billiard\n\nInstallez QProgEdit (à partir d'OpenSesame 2.8)\n\n    git clone https://github.com/smathot/QProgEdit.git\n\tcd QProgEdit\n\tpython setup.py install\n\tcd ..\n\trm -R QProgEdit\n\nInstallez expyriment (à partir d'OpenSesame 0.27)\n\n    git clone https://github.com/expyriment/expyriment.git\n\tcd expyriment\n\tpython setup.py install\n\tcd ..\n\trm -R expyriment\n\nInstallez psychopy et sa dépendance pyglet. Pour que psychopy fonctionne, vous devez (actuellement) installer les dernières versions des dépôts pyglet et psychopy\n\nTout d'abord, installez pyglet:\n\n    hg clone https://code.google.com/p/pyglet/\n\tcd pyglet\n\tpython setup.py install\n\tcd ..\n\trm -R pyglet\n\nEnsuite, psychopy. Installez-le et effectuez un nettoyage avec:\n\n\tgit clone https://github.com/psychopy/psychopy.git\n\tcd psychopy\n\tpython setup.py install\n\tcd ..\n\trm -R psychopy\n\nLors de l'installation, vous pouvez recevoir une erreur avec le message \"Unknown locale UTF8\". Vous pouvez facilement résoudre ce problème en plaçant la ligne \"LC_ALL=en_US.UTF8\" dans votre ~/.bash_profile puis rouvrez votre terminal."
  },
  "Although desktop effects *may* cause problems, they usually don't. This appears to vary from system to system and from video card to video card. Nevertheless, when the operating systems allows it, it's best to disable desktop effects on systems that are used for experimental testing.\n\nSome tips regarding desktop effects for the various operating systems:\n\n- Under *Windows XP* there are no desktop effects at all.\n- Under *Windows 7* desktop effects can be disabled by selecting any of the themes listed under 'Basic and High Contrast Themes' in the 'Personalization' section.\n- Under *Windows 10* there is no way to completely disable desktop effects.\n- Under *Ubuntu and other Linux distributions using Gnome 3* there is no way to completely disable desktop effects.\n- Under *Linux distributions using KDE* you can disable desktop effects in the 'Desktop Effects' section of the System Settings.\n- Under *Mac OS* there is apparently no way to completely disable desktop effects.\n\n\n### Taking into account stimulus-preparation time/ the prepare-run structure\n\nIf you care about accurate timing during visual-stimulus presentation, you should prepare your stimuli in advance. That way, you will not get any unpredictable delays due to stimulus preparation during the time-critical parts of your experiment.\n\nLet's first consider a script (you can paste this into an INLINE_SCRIPT item) that includes stimulus-preparation time in the interval between `canvas1` and `canvas2` (%LstStimPrepBad). The interval that is specified is 95 ms, so--taking into account the 'rounding up' rule described in [Making the refresh deadline]--you would expect an interval of 100 ms on my 60 Hz monitor. However, on my test system the script below results in an interval of 150 ms, which corresponds to 9 frames on a 60 Hz monitor. This is an unexpected delay of 50 ms, or 3 frames, due to the preparation of `canvas2`.\n\n<notranslate>\ncode:\n id: LstStimPrepBad\n syntax: python\n source: stimulus-preparation-bad.py\n caption: \"In this script, the duration between `canvas1` and `canvas2` is confounded by stimulus-preparation time.\"\n</notranslate>\n\nNow let's consider a simple variation of the script above (%LstStimPrepGood). This time, we first prepare both `canvas1` and `canvas2` and only afterwards present them. On my test system, this results in a consistent 100 ms interval, just as it should!\n\n<notranslate>\ncode:\n id: LstStimPrepGood\n syntax: python\n source: stimulus-preparation-good.py\n caption: \"In this script, the duration between `canvas1` and `canvas2` is not confounded by stimulus-preparation time.\"\n</notranslate>\n\nWhen using the graphical interface, the same considerations apply, but OpenSesame helps you by automatically handling most of the stimulus preparation in advance. However, you have to take into account that this preparation occurs at the level of SEQUENCE items, and not at the level of LOOP items. Practically speaking, this means that the timing *within* a SEQUENCE is not confounded by stimulus-preparation time. But the timing *between* SEQUENCEs is.\n\nTo make this more concrete, let's consider the structure shown below (%FigStimPrepBad). Suppose that the duration of the SKETCHPAD item is set to 95 ms, thus aiming for a 100 ms duration, or 6 frames on a 60 Hz monitor. On my test system the actual duration is 133 ms, or 8 frames, because the timing is confounded by preparation of the SKETCHPAD item, which occurs each time that that the sequence is executed. So this is an example of how you should *not* implement time-critical parts of your experiment.": {
    "fr": "Bien que les effets de bureau *puissent* causer des problèmes, ils ne le font généralement pas. Cela semble varier d'un système à l'autre et d'une carte vidéo à l'autre. Néanmoins, lorsque le système d'exploitation le permet, il est préférable de désactiver les effets de bureau sur les systèmes utilisés pour les tests expérimentaux.\n\nQuelques conseils concernant les effets de bureau pour les différents systèmes d'exploitation :\n\n- Sous *Windows XP*, il n'y a pas du tout d'effets de bureau.\n- Sous *Windows 7*, les effets de bureau peuvent être désactivés en sélectionnant l'un des thèmes répertoriés sous « Thèmes de base et à contraste élevé » dans la section « Personnalisation ».\n- Sous *Windows 10*, il n'y a pas de moyen de désactiver complètement les effets de bureau.\n- Sous *Ubuntu et autres distributions Linux utilisant Gnome 3*, il n'y a pas de moyen de désactiver complètement les effets de bureau.\n- Sous *les distributions Linux utilisant KDE*, vous pouvez désactiver les effets de bureau dans la section « Effets de bureau » des Paramètres du système.\n- Sous *Mac OS*, il n'y a apparemment pas de moyen de désactiver complètement les effets de bureau.\n\n### Prendre en compte le temps de préparation des stimuli / la structure préparer-exécuter\n\nSi vous vous souciez du temps de réponse précis lors de la présentation de stimuli visuels, vous devez préparer vos stimuli à l'avance. De cette façon, vous n'aurez pas de retards imprévisibles dus à la préparation des stimuli pendant les parties critiques de votre expérience.\n\nPrenons d'abord en considération un script (que vous pouvez coller dans un élément INLINE_SCRIPT) qui inclut le temps de préparation des stimuli dans l'intervalle entre `canvas1` et `canvas2` (%LstStimPrepBad). L'intervalle spécifié est de 95 ms, donc - en tenant compte de la règle d'« arrondir à la hausse » décrite dans [Respecter la date limite de rafraîchissement] - vous vous attendriez à un intervalle de 100 ms sur mon moniteur 60 Hz. Cependant, sur mon système de test, le script ci-dessous donne un intervalle de 150 ms, ce qui correspond à 9 images sur un moniteur 60 Hz. Il s'agit d'un retard inattendu de 50 ms, soit 3 images, dû à la préparation de `canvas2`.\n\n<notranslate>\ncode :\n id : LstStimPrepBad\n syntaxe : python\n source : stimulus-preparation-bad.py\n légende : « Dans ce script, la durée entre `canvas1` et `canvas2` est confondue avec le temps de préparation des stimuli. »\n</notranslate>\n\nPrenons maintenant en considération une simple variation du script ci-dessus (%LstStimPrepGood). Cette fois, nous préparons d'abord les deux `canvas1` et `canvas2`, puis nous les présentons ensuite. Sur mon système de test, cela donne un intervalle constant de 100 ms, comme il se doit!\n\n<notranslate>\ncode :\n id : LstStimPrepGood\n syntaxe : python\n source : stimulus-preparation-good.py\n légende : « Dans ce script, la durée entre `canvas1` et `canvas2` n'est pas confondue avec le temps de préparation des stimuli.»\n</notranslate>\n\nLors de l'utilisation de l'interface graphique, les mêmes considérations s'appliquent, mais OpenSesame vous aide en gérant automatiquement la plupart de la préparation des stimuli à l'avance. Cependant, vous devez tenir compte du fait que cette préparation se fait au niveau des éléments SEQUENCE et non pas au niveau des éléments LOOP. En pratique, cela signifie que le temps *à l'intérieur* d'une SEQUENCE n'est pas confondu avec le temps de préparation des stimuli. Mais le temps *entre* les SEQUENCEs l'est.\n\nPour rendre cela plus concret, prenons en considération la structure présentée ci-dessous (%FigStimPrepBad). Supposons que la durée de l'élément SKETCHPAD soit réglée sur 95 ms, visant ainsi une durée de 100 ms, soit 6 images sur un moniteur 60 Hz. Sur mon système de test, la durée réelle est de 133 ms, soit 8 images, car le temps est confondu par la préparation de l'élément SKETCHPAD, qui a lieu chaque fois que la séquence est exécutée. C'est donc un exemple de la manière dont vous NE devez PAS mettre en œuvre les parties critiques de votre expérience en termes de temps."
  },
  "Do the same thing for *experimental_loop*, except that the variable `practice` has the value 'no'. (The `practice` variable doesn't have a real function. It only allows you to easily filter out all practice trials during data analysis.)\n\n<div class='info-box' markdown='1'>\n\n### Links\n\n- [/usage/variables-and-conditional-statements/](/usage/variables-and-conditional-statements/)\n- [/miscellaneous/counterbalancing/](/miscellaneous/counterbalancing/)\n\n</div>\n\n## Step 5: Create instructions\n\nBecause the task differs between blocks, we need to show an instruction screen before each block. The *block_sequence* is the place to do this, because, as explained above, it corresponds to a single block of trials plus the events that occur before and after every block.\n\nThere are various items that we could use for an instruction screen, but we will use the SKETCHPAD. Insert two new SKETCHPADs at the top of *block_sequence* by dragging them from the item toolbar. Rename the SKETCHPADs to *instructions_experimental* and *instructions_control*. Click on both items to add some instructional text, such as shown in %FigInstructions.\n\n<notranslate>\nfigure:\n id: FigInstructions\n source: FigInstructions.png\n caption: |\n  An example of instructional text in the *instructions_experimental* item.\n</notranslate>\n\nRight now both instruction screens are shown before every block, which is not what we want. Instead, we want to show only the *instructions_experimental* item in the experimental condition, and only the *instructions_control* item in the control condition. We can do this with conditional ('run if') statements.\n\nClick on *block_sequence* to open it. You will see a list of item names, just as in the overview area, except that each item has the text 'always' next to it. These are run-if statements, and they determine the conditions under which an item is executed. Double click on the run-if statement next to *instructions_experimental* and add the following text:\n\n~~~\n[condition] = experimental\n~~~\n\nThis means that *instructions_experimental* will only be executed when the variable `condition` has the value 'experimental.' Analogously, change the run-if statement for *instructions_control* to:\n\n~~~\n[condition] = control\n~~~\n\nYour *block_sequence* should now look as in %FigBlockSequence.\n\n<notranslate>\nfigure:\n id: FigBlockSequence\n source: FigBlockSequence.png\n caption: |\n  The *block_sequence* item at the end of Step 5.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n### Links\n\n- [/usage/sequences-and-loops/](/usage/sequences-and-loops/)\n- [/usage/variables-and-conditional-statements/](/usage/variables-and-conditional-statements/)\n- [/usage/text/](/usage/text/)\n\n</div>\n\n## Step 6: Modify feedback\n\nOpen *feedback*. By default, in the Extended Template, the participant receives feedback on speed (`avg_rt`) and accuracy (`acc`) after each experimental block. However, our experiment doesn't require speeded responses, and we should therefore only provide feedback on accuracy. Modify the *feedback* item to look something like %FigFeedback.\n\n<notranslate>\nfigure:\n id: FigFeedback\n source: FigFeedback.png\n caption: |\n  The *block_sequence* item at the end of Step 6.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n### Links\n\n- [/usage/feedback/](/usage/feedback/)\n- [/usage/text/](/usage/text/)\n\n</div>\n\n## Step 7: Define experimental variables that are varied within a block\n\nRaymond et al. (1992) vary the position of T2 relative to T1 from 0 to 8, where 0 means that one letter is both T1 and T2 (i.e. a white 'X'). They also have trials in which there is no T2. This is all varied within a block. There are various ways to code this, but the easiest way is to use two variables:": {
    "fr": "Faites la même chose pour *experimental_loop*, sauf que la variable `practice` a la valeur 'non'. (La variable `practice` n'a pas de réelle fonction. Elle permet simplement de filtrer facilement tous les essais pratiques lors de l'analyse des données.)\n\n<div class='info-box' markdown='1'>\n\n### Liens\n\n- [/usage/variables-and-conditional-statements/](/usage/variables-and-conditional-statements/)\n- [/miscellaneous/counterbalancing/](/miscellaneous/counterbalancing/)\n\n</div>\n\n## Étape 5 : Créer des instructions\n\nComme la tâche diffère entre les blocs, nous devons afficher un écran d'instructions avant chaque bloc. La *block_sequence* est l'endroit pour le faire, car, comme expliqué ci-dessus, elle correspond à un seul bloc d'essais et aux événements qui se produisent avant et après chaque bloc.\n\nIl existe différents éléments que nous pourrions utiliser pour un écran d'instructions, mais nous utiliserons le SKETCHPAD. Insérez deux nouveaux SKETCHPADs en haut de *block_sequence* en les faisant glisser depuis la barre d'outils des éléments. Renommez les SKETCHPADs en *instructions_experimental* et *instructions_control*. Cliquez sur les deux éléments pour ajouter un texte d'instruction, comme indiqué dans %FigInstructions.\n\n<notranslate>\nfigure:\n id: FigInstructions\n source: FigInstructions.png\n caption: |\n  Un exemple de texte d'instruction dans l'élément *instructions_experimental*.\n</notranslate>\n\nPour l'instant, les deux écrans d'instructions sont affichés avant chaque bloc, ce que nous ne voulons pas. Au lieu de cela, nous voulons montrer seulement l'élément *instructions_experimental* dans la condition expérimentale, et seulement l'élément *instructions_control* dans la condition de contrôle. Nous pouvons le faire avec des instructions conditionnelles ('run if').\n\nCliquez sur *block_sequence* pour l'ouvrir. Vous verrez une liste de noms d'éléments, tout comme dans la zone de vue d'ensemble, sauf que chaque élément a le texte « always » à côté. Ce sont des instructions run-if, et elles déterminent les conditions d'exécution d'un élément. Double-cliquez sur l'instruction run-if à côté de *instructions_experimental* et ajoutez le texte suivant :\n\n~~~\n[condition] = experimental\n~~~\n\nCela signifie que *instructions_experimental* ne sera exécuté que lorsque la variable `condition` a la valeur 'experimental'. Analogiquement, changez l'instruction run-if pour *instructions_control* à :\n\n~~~\n[condition] = control\n~~~\n\nVotre *block_sequence* devrait maintenant ressembler à %FigBlockSequence.\n\n<notranslate>\nfigure:\n id: FigBlockSequence\n source: FigBlockSequence.png\n caption: |\n  L'élément *block_sequence* à la fin de l'étape 5.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n### Liens\n\n- [/usage/sequences-and-loops/](/usage/sequences-and-loops/)\n- [/usage/variables-and-conditional-statements/](/usage/variables-and-conditional-statements/)\n- [/usage/text/](/usage/text/)\n\n</div>\n\n## Étape 6 : Modifier les retours\n\nOuvrez *feedback*. Par défaut, dans le modèle étendu, le participant reçoit des commentaires sur la vitesse (`avg_rt`) et la précision (`acc`) après chaque bloc expérimental. Cependant, notre expérience ne nécessite pas de réponses rapides, et nous devrions donc seulement fournir des commentaires sur la précision. Modifiez l'élément *feedback* pour qu'il ressemble à %FigFeedback.\n\n<notranslate>\nfigure:\n id: FigFeedback\n source: FigFeedback.png\n caption: |\n  L'élément *block_sequence* à la fin de l'étape 6.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n### Liens\n\n- [/usage/feedback/](/usage/feedback/)\n- [/usage/text/](/usage/text/)\n\n</div>\n\n## Étape 7 : Définir les variables expérimentales qui varient au sein d'un bloc\n\nRaymond et al. (1992) font varier la position de T2 par rapport à T1 de 0 à 8, où 0 signifie qu'une lettre est à la fois T1 et T2 (c'est-à-dire un 'X' blanc). Ils ont également des essais où il n'y a pas de T2. Tout cela varie au sein d'un bloc. Il y a différentes façons de coder cela, mais la plus simple est d'utiliser deux variables :"
  },
  "In the mixed part of the experiment, we want OpenSesame to determine whether it should show a face or a word. We can do this by using *Show-if statements*. More precisely, we want that the stimulus_sketchpad:\n\n- Shows a word *only* when the stimulus is a word (i.e., when the current cell in the  stimulus column in the block loop is a word)\n- Shows a face *only* when the stimulus is a face\n\nTo achieve this:\n\n- Add a column to the *congruent_block_loop* and call it *stimulus_type*\n- Give the cells the value 'word' or 'face', depending on the stimulus (see %CongrLoop)\n\n<notranslate>\nfigure:\n id: CongrLoop\n source: congruent_block_loop.png\n caption: |\n  Content of the block loop of the congruent part of the experiment.\n</notranslate>\n\nNext, to make the content of the sketchpad *dependent* on the values in the newly created column:\n\n- Select the black arrow in the element tool bar of the sketchpad\n- Click on the question mark (which indicates the `Draw image element` that takes care of the presentation of the JPG files)\n- Click on the `Show if` box belonging to this element, which by default is set to 'always'\n- Use the square-bracket syntax to indicate that this part of the sketchpad should only be drawn if the current trial contains a face image by typing:\n\n~~~ .python\n[stimulus_type] = face\n~~~\n\n<notranslate>\nvideo:\n source: youtube\n id: RunIf\n videoid: jqGFefCmn1k\n width: 640\n height: 360\n caption: |\n  Using a Run-if statement in a `sketchpad` item.\n</notranslate>\n\n\n\n- Do the same for the `Draw text element` that controls the presentation of the written words. This time, the Show-if statement should be\n\n~~~ .python\n[stimulus_type] = word\n~~~\n\nTest whether the first three blocks of your experiment works as desired.\n\n## Incongruent mapping\n\n## Step 16: Create the incongruent block of the experiment\n\n### Assignment\n\nUse what you learned in the previous steps to build the final, incongruent part of the experiment.\n\nSome tips:\n\n- Give new items (e.g. the new `loop` and `sequence` items) meaningful names (e.g. *incongruent_block_loop*, *incongruent_trial_sequence*)\n- Copy the items that are identical for each block (i.e. the fixation point, the keyboard_response and the logger)\n- You can't copy the stimulus sketchpad, because the mapping of the categories (appearing at the upper left and right side) should be swapped, such that:\n    - The left side shows *POSITIVE* and *OLD*\n    - The right side shows *NEGATIVE* and *YOUNG* (see %Task)\n- The values in the *correct_response* column should be changed accordingly\n\n\n<div class='info-box' markdown='1'>\n\n__Tip__ You can use an *unlinked* copy of the *congruent_stimulus* sketchpad in order to create the *incongruent_stimulus* sketchpad (which is almost identical except that the category names *OLD* and *YOUNG* are swapped).\n\nIn contrast to a *linked* copy, an *unlinked* copy will initially look identical (except for its name), but you can edit the original without affecting the unlinked copy, and vice versa.\n\n\n</div>\n\n\n## Extra assignments:\n\n### Easy: add an instruction and goodbye screen\n\n- `sketchpad` and `form_text_display` items can present text\n- Good instructions are short and concrete\n\n### Medium: provide feedback on every trial\n\n- Use the built-in variable *correct* that has\n    - the value 1 if the participant responded correctly\n    - the value 0 if the participant made an error\n- An easy way to provide feedback is by briefly presenting a red dot after an incorrect response, and a green dot after a correct response\n- Use Show-if statements\n": {
    "fr": "Dans la partie mixte de l'expérience, nous voulons qu'OpenSesame détermine s'il doit afficher un visage ou un mot. Nous pouvons le faire en utilisant des *Déclarations Show-if*. Plus précisément, nous voulons que le stimulus_sketchpad :\n\n- Montre un mot *uniquement* lorsque le stimulus est un mot (c'est-à-dire lorsque la cellule actuelle de la colonne stimulus dans la boucle de bloc est un mot)\n- Montre un visage *uniquement* lorsque le stimulus est un visage\n\nPour ce faire :\n\n- Ajoutez une colonne au *congruent_block_loop* et appelez-la *stimulus_type*\n- Donnez aux cellules la valeur 'word' ou 'face', en fonction du stimulus (voir %CongrLoop)\n\n<notranslate>\nfigure:\n id: CongrLoop\n source: congruent_block_loop.png\n caption: |\n  Contenu de la boucle de bloc de la partie congruente de l'expérience.\n</notranslate>\n\nEnsuite, pour que le contenu du sketchpad dépende des valeurs de la colonne nouvellement créée:\n\n- Sélectionnez la flèche noire dans la barre d'outils de l'élément du sketchpad\n- Cliquez sur le point d'interrogation (qui indique l'élément `Draw image` qui s'occupe de la présentation des fichiers JPG)\n- Cliquez sur la case `Show if` appartenant à cet élément, qui par défaut est réglé sur 'always'\n- Utilisez la syntaxe des crochets pour indiquer que cette partie du sketchpad ne doit être dessinée que si l'essai en cours contient une image de visage en tapant:\n\n~~~ .python\n[stimulus_type] = face\n~~~\n\n<notranslate>\nvideo:\n source: youtube\n id: RunIf\n videoid: jqGFefCmn1k\n width: 640\n height: 360\n caption: |\n  Utilisation d'une déclaration Run-if dans un élément `sketchpad`.\n</notranslate>\n\n\n\n- Faites de même pour l'élément `Draw text` qui contrôle la présentation des mots écrits. Cette fois, la déclaration Show-if doit être\n\n~~~ .python\n[stimulus_type] = word\n~~~\n\nTestez si les trois premiers blocs de votre expérience fonctionnent comme vous le souhaitez.\n\n## Cartographie incongruente\n\n## Étape 16 : Créer le bloc incongruent de l'expérience\n\n### Devoir\n\nUtilisez ce que vous avez appris dans les étapes précédentes pour construire la partie finale, incongruente de l'expérience.\n\nQuelques conseils :\n\n- Donnez des noms significatifs aux nouveaux éléments (par exemple, aux nouveaux éléments `loop` et `sequence`) (par exemple *incongruent_block_loop*, *incongruent_trial_sequence*)\n- Copiez les éléments qui sont identiques pour chaque bloc (c'est-à-dire le point de fixation, la réponse_clavier et le logger)\n- Vous ne pouvez pas copier le stimulus_sketchpad, car la correspondance des catégories (apparaissant en haut à gauche et à droite) doit être intervertie, de sorte que:\n    - Le côté gauche montre *POSITIF* et *VIEUX*\n    - Le côté droit montre *NÉGATIF* et *JEUNE* (voir %Task)\n- Les valeurs dans la colonne *correct_response* doivent être modifiées en conséquence\n\n\n<div class='info-box' markdown='1'>\n\n__Astuce__ Vous pouvez utiliser une copie *non liée* du sketchpad *congruent_stimulus* pour créer le sketchpad *incongruent_stimulus* (qui est presque identique, sauf que les noms de catégorie *OLD* et *YOUNG* sont échangés).\n\nContrairement à une copie *liée*, une copie *non liée* aura au départ l'air identique (à l'exception de son nom), mais vous pouvez modifier l'original sans affecter la copie non liée, et vice versa.\n\n\n</div>\n\n\n## Devoirs supplémentaires :\n\n### Facile : ajoutez un écran d'instruction et d'au revoir\n\n- Les éléments `sketchpad` et `form_text_display` peuvent présenter du texte\n- Les bonnes instructions sont courtes et concrètes\n\n### Moyen : fournir un retour d'information à chaque essai\n\n- Utilisez la variable intégrée *correct* qui a\n    - la valeur 1 si le participant a répondu correctement\n    - la valeur 0 si le participant a commis une erreur\n- Un moyen simple de fournir un retour d'information est de présenter brièvement un point rouge après une réponse incorrecte et un point vert après une réponse correcte\n- Utilisez des déclarations Show-if"
  },
  "Wisconsin Card Sorting Test": {
    "fr": "Test de Tri de Cartes du Wisconsin"
  },
  "You should now be able to run OpenSesame, but you'll notice you're missing some icons! You need to download the Faenza icon theme from <http://tiheum.deviantart.com/art/Faenza-Icons-173323228> and place it under resources/theme/default/. Furthermore, there is a quirk in that multiprocessing won't work when the main file is not present as a .py file, which is the case for opensesame. To enable the multiprocessing support, you need to rename the opensesame file to opensesame.py, then if you run an experiment now once, you'll see that opensesame.pyc will have been created. From the moment this file is present, Python will use the .pyc when spawning new processes and you can now rename back opensesame.py to opensesame again. This is a weird fix to get multiprocessing working, but at the moment it is the only one we know.\n\nThe following packages are optional, but might be useful to install nevertheless:\n\n\tbrew install matplotlib opencv\n\tpip install pycairo pyparallel scikit-image\n\n### Installing with MacPorts\n\nAnother way to install the necessary packages on Mac OS is by using MacPorts, a large repository of packages. It takes a long time (and by this I mean many hours!) to install all the packages that are required for running OpenSesame, because MacPorts works by compiling from source. But on the bright side, it's a pretty straightforward process.\n\n#### Download MacPorts\n\nYou can download macports from its website on which you can also find the necessary documentation and a catalogue of all available packages.\n\nWebsite: <http://www.macports.org/install.php>\n\nYou can add +universal to your /opt/local/etc/macports/variants.conf to ask MacPorts to build all ports you install with that variant (thus 32-bit and 64-bit versions packed in the same module), without having to remember to type it at every install command. However, some ports have not yet been tested as universal binaries and may not build properly.\n\n#### Install dependencies\n\nEssentially, you can now install all required packages by running a single command in a terminal:\n\n\tsudo port install py27-game py27-pyqt4 py27-scintilla py27-serial py27-pil py27-opengl py27-pyaudio opencv +python27 py27-pip\n\nThis takes forever and, in my case, crashed a few times with a checksum error. You can simply recover from such errors by executing the following command:\n\n\tsudo port clean --all [package_that_caused_the_error]\n\nThen you repeat the first command and MacPorts should be on its way again.\n\nInstall the remaining necessary python packages by using pip\n\n    sudo pip install pyflakes markdown python-bidi pyserial billiard\n\nInstall QProgEdit (the default code editor from OpenSesame 2.8 on)\n\n    git clone https://github.com/smathot/QProgEdit.git\n\tcd QProgEdit\n\tsudo python setup.py install\n\tcd ..\n\trm -R QProgEdit\n\n#### Expyriment and Psychopy backends\n\nNext to the legacy backend, which is based on pygame, OpenSesame also offers you the option of using expyriment or psychopy. In contrast to the legacy backend, both of these backends are hardware accelerated (OpenGL) and should have increased timing precision.\n\nInstall expyriment (from OpenSesame 0.27 on)\n\n    git clone https://github.com/expyriment/expyriment.git\n    cd expyriment\n    sudo python setup.py install\n    cd ..\n    rm -R expyriment\n\nInstall psychopy and its dependency pyglet:\n\nFirst install pyglet:\n\n    hg clone https://code.google.com/p/pyglet/\n    cd pyglet\n    sudo python setup.py install\n    cd ..\n    rm -R pyglet\n\nThen install psychopy:\n\n    git clone https://github.com/psychopy/psychopy.git\n    cd psychopy\n    python setup.py install\n    cd ..\n    rm -R psychopy\n\nPsychoPy refuses to run without the wxPython library installed (which is weird, because OpenSesame doesn't use any of the wx GUI components of psychopy), so as a final step install wxPython with:\n\n\tsudo port install py27-wxpython-dev\n\n#### Make the MacPorts Python the default Python": {
    "fr": "Vous devriez maintenant être en mesure d'exécuter OpenSesame, mais vous remarquerez qu'il vous manque certaines icônes! Vous devez télécharger le thème d'icônes Faenza à partir de <http://tiheum.deviantart.com/art/Faenza-Icons-173323228> et le placer dans resources/theme/default/. De plus, il y a une particularité selon laquelle le multiprocessing ne fonctionne pas lorsque le fichier principal n'est pas présent en tant que fichier .py, ce qui est le cas pour opensesame. Pour activer la prise en charge du multiprocessing, vous devez renommer le fichier opensesame en opensesame.py, puis si vous exécutez une expérience maintenant, vous verrez que opensesame.pyc aura été créé. Dès que ce fichier est présent, Python utilisera le .pyc lors de la création de nouveaux processus et vous pourrez maintenant renommer à nouveau opensesame.py en opensesame. C'est une solution étrange pour que le multiprocessing fonctionne, mais pour l'instant c'est la seule que nous connaissons.\n\nLes packages suivants sont optionnels, mais il peut être utile de les installer néanmoins :\n\n\tbrew install matplotlib opencv\n\tpip install pycairo pyparallel scikit-image\n\n### Installation avec MacPorts\n\nUne autre manière d'installer les paquets nécessaires sur Mac OS est en utilisant MacPorts, un grand dépôt de paquets. Cela prend beaucoup de temps (et par là, je veux dire plusieurs heures!) pour installer tous les paquets nécessaires à l'exécution d'OpenSesame, car MacPorts fonctionne en compilant à partir des sources. Mais pour être positif, c'est un processus assez simple.\n\n#### Télécharger MacPorts\n\nVous pouvez télécharger macports depuis son site web sur lequel vous pouvez également trouver la documentation nécessaire et un catalogue de tous les paquets disponibles.\n\nSite web : <http://www.macports.org/install.php>\n\nVous pouvez ajouter +universal à votre /opt/local/etc/macports/variants.conf pour demander à MacPorts de construire tous les ports que vous installez avec cette variante (donc les versions 32 bits et 64 bits empaquetées dans le même module), sans avoir à vous souvenir de le taper à chaque commande d'installation. Cependant, certains ports n'ont pas encore été testés en tant que binaires universels et peuvent ne pas se construire correctement.\n\n#### Installer les dépendances\n\nEssentiellement, vous pouvez maintenant installer tous les paquets requis en exécutant une seule commande dans un terminal :\n\n\tsudo port install py27-game py27-pyqt4 py27-scintilla py27-serial py27-pil py27-opengl py27-pyaudio opencv +python27 py27-pip\n\nCela prend énormément de temps et, dans mon cas, a échoué plusieurs fois avec une erreur de somme de contrôle. Vous pouvez simplement récupérer de telles erreurs en exécutant la commande suivante :\n\n\tsudo port clean --all [paquet_qui_a_causé_l'erreur]\n\nEnsuite, vous répétez la première commande et MacPorts devrait être de nouveau en route.\n\nInstallez les autres paquets python nécessaires en utilisant pip\n\n    sudo pip install pyflakes markdown python-bidi pyserial billiard\n\nInstaller QProgEdit (l'éditeur de code par défaut d'OpenSesame 2.8 et suivants)\n\n    git clone https://github.com/smathot/QProgEdit.git\n\tcd QProgEdit\n\tsudo python setup.py install\n\tcd ..\n\trm -R QProgEdit\n\n#### Backend Expyriment et Psychopy\n\nEn plus du backend legacy, qui est basé sur pygame, OpenSesame vous offre également la possibilité d'utiliser expyriment ou psychopy. Contrairement au backend legacy, ces deux backend sont accélérés matériellement (OpenGL) et devraient avoir une meilleure précision de temporisation.\n\nInstallez expyriment (à partir d'OpenSesame 0.27)\n\n    git clone https://github.com/expyriment/expyriment.git\n    cd expyriment\n    sudo python setup.py install\n    cd ..\n    rm -R expyriment\n\nInstaller psychopy et sa dépendance pyglet :\n\nInstallez d'abord pyglet :\n\n    hg clone https://code.google.com/p/pyglet/\n    cd pyglet\n    sudo python setup.py install\n    cd ..\n    rm -R pyglet\n\nEnsuite, installez psychopy :\n\n    git clone https://github.com/psychopy/psychopy.git\n    cd psychopy\n    python setup.py install\n    cd ..\n    rm -R psychopy\n\nPsychoPy refuse de fonctionner sans la bibliothèque wxPython installée (ce qui est étrange, car OpenSesame n'utilise aucun des composants wx GUI de psychopy), installez donc wxPython en dernier avec :\n\n\tsudo port install py27-wxpython-dev\n\n#### Faites de MacPorts Python le Python par défaut"
  },
  "<notranslate>\nfigure:\n id: FigStimPrepBad\n source: stimulus-preparation-incorrect.png\n caption: \"An example of an experimental structure in which the timing between successive presentations of SKETCHPAD is confounded by stimulus-preparation time. The sequence of events in this case is as follows: prepare SKETCHPAD (2 frames), show SKETCHPAD (6 frames), prepare SKETCHPAD (2 frames), show SKETCHPAD (6 frames), etc.\"\n</notranslate>\n\nNow let's consider the structure shown below (%FigStimPrepGood). Suppose that the duration of `sketchpad1` is set to 95 ms, thus aiming for a 100 ms interval between `sketchpad1` and `sketchpad2`. In this case, both items are shown as part of the same SEQUENCE and the timing will not be confounded by stimulus-preparation time. On my test system the actual interval between `sketchpad1` and `sketchpad2` is therefore indeed 100 ms, or 6 frames on a 60 Hz monitor.\n\nNote that this only applies to the interval between `sketchpad1` and `sketchpad2`, because they are executed in that order as part of the same sequence. The interval between `sketchpad2` on run *i* and `sketchpad1` on run *i+1* is again confounded by stimulus-preparation time.\n\n<notranslate>\nfigure:\n id: FigStimPrepGood\n source: stimulus-preparation-correct.png\n caption: \"An example of an experimental structure in which the timing between the presentation of `sketchpad1` and `sketchpad2` is not confounded by stimulus-preparation time. The sequence of events in this case is as follows: prepare `sketchpad1` (2 frames), prepare `sketchpad2` (2 frames), show `sketchpad1` (6 frames), show `sketchpad2` (6 frames), prepare `sketchpad1` (2 frames), prepare `sketchpad2` (2 frames), show `sketchpad1` (6 frames), show `sketchpad2` (6 frames), etc.\"\n</notranslate>\n\nFor more information, see:\n\n- [usage/prepare-run]\n\n### Differences between backends\n\nOpenSesame is not tied to one specific way of controlling the display, system timer, etc. Therefore, OpenSesame *per se* does not have specific timing properties, because these depend on the backend that is used. The performance characteristics of the various backends are not perfectly correlated: It is possible that on some system the [psycho] backend works best, whereas on another system the [xpyriment] backend works best. Therefore, one of the great things about OpenSesame is that you can choose which backend works best for you!\n\nIn general, the [xpyriment] and [psycho] backends are preferable for time-critical experiments, because they use a blocking flip. On the other hand, the [legacy] backend is slightly more stable and also considerably faster when using [forms].\n\nUnder normal circumstances the three current OpenSesame backends have the properties shown in %TblBackendInfo.\n\n<notranslate>\ntable:\n id: TblBackendInfo\n source: backend-info.csv\n caption: backend properties.\n</notranslate>\n\nSee also:\n\n- [backends]\n\n## Benchmark results and tips for testing your own system\n\n### Checking whether v-sync is enabled\n\nAs described in [Understanding your monitor], the presentation of a new display should ideally coincide with the start of a new refresh cycle (i.e. 'v-sync'). You can test whether this is the case by presenting displays of different colors in rapid alternation. If v-sync is not enabled you will clearly observe horizontal lines running across the monitor (i.e. 'tearing'). To perform this test, run an experiment with the following script in an INLINE_SCRIPT item (%LstVSync):\n\n<notranslate>\ncode:\n id: LstVSync\n syntax: python\n source: v-sync-check.py\n caption: A script that presents yellow and blue displays in rapid alternation. A lack of synchronization with the vertical refresh can be observed as horizontal lines running through the monitor.\n</notranslate>\n\n### Testing precision and accuracy of timing": {
    "fr": "<notranslate>\nfigure:\n id: FigStimPrepBad\n source: stimulus-preparation-incorrect.png\n caption: \"Un exemple de structure expérimentale dans laquelle le temps entre les présentations successives de SKETCHPAD est confondu par le temps de préparation des stimuli. La séquence d'événements dans ce cas est la suivante : préparer SKETCHPAD (2 images), afficher SKETCHPAD (6 images), préparer SKETCHPAD (2 images), afficher SKETCHPAD (6 images), etc.\"\n</notranslate>\n\nMaintenant, considérons la structure montrée ci-dessous (%FigStimPrepGood). Supposons que la durée de `sketchpad1` soit réglée à 95 ms, visant ainsi un intervalle de 100 ms entre `sketchpad1` et `sketchpad2`. Dans ce cas, les deux éléments sont affichés dans la même SEQUENCE et le temps ne sera pas confondu par le temps de préparation des stimuli. Sur mon système de test, l'intervalle réel entre `sketchpad1` et `sketchpad2` est donc bien de 100 ms, soit 6 images sur un écran de 60 Hz.\n\nNotez que cela ne s'applique qu'à l'intervalle entre `sketchpad1` et `sketchpad2`, car ils sont exécutés dans cet ordre dans la même séquence. L'intervalle entre `sketchpad2` lors de la répétition *i* et `sketchpad1` lors de la répétition *i+1* est à nouveau confondu par le temps de préparation des stimuli.\n\n<notranslate>\nfigure:\n id: FigStimPrepGood\n source: stimulus-preparation-correct.png\n caption: \"Un exemple de structure expérimentale dans laquelle le temps entre les présentations de `sketchpad1` et `sketchpad2` n'est pas confondu par le temps de préparation des stimuli. La séquence d'événements dans ce cas est la suivante: préparer `sketchpad1` (2 images), préparer `sketchpad2` (2 images), afficher `sketchpad1` (6 images), afficher `sketchpad2` (6 images), préparer `sketchpad1` (2 images), préparer `sketchpad2` (2 images), afficher `sketchpad1` (6 images), afficher `sketchpad2` (6 images), etc.\"\n</notranslate>\n\nPour plus d'informations, voir :\n\n- [usage/prepare-run]\n\n### Différences entre les backends\n\nOpenSesame n'est pas lié à une manière spécifique de contrôler l'affichage, le minuteur système, etc. Par conséquent, OpenSesame *per se* n'a pas de propriétés de minutage spécifiques, car celles-ci dépendent du backend utilisé. Les caractéristiques de performance des différents backends ne sont pas parfaitement corrélées : il est possible que sur un système, le backend [psycho] fonctionne mieux, tandis que sur un autre système, le backend [xpyriment] fonctionne mieux. L'un des grands avantages d'OpenSesame est donc que vous pouvez choisir le backend qui vous convient le mieux !\n\nEn général, les backends [xpyriment] et [psycho] sont préférables pour les expériences critiques en termes de temps, car ils utilisent un flip bloquant. D'un autre côté, le backend [legacy] est légèrement plus stable et également considérablement plus rapide lors de l'utilisation de [forms].\n\nDans des conditions normales, les trois backends actuels d'OpenSesame ont les propriétés présentées dans %TblBackendInfo.\n\n<notranslate>\ntable:\n id: TblBackendInfo\n source: backend-info.csv\n caption: Propriétés des backends.\n</notranslate>\n\nVoir également :\n\n- [backends]\n\n## Résultats des tests et conseils pour tester votre propre système\n\n### Vérifier si le v-sync est activé\n\nComme décrit dans [Understanding your monitor], la présentation d'un nouvel affichage devrait idéalement coïncider avec le début d'un nouveau cycle de rafraîchissement (c'est-à-dire le 'v-sync'). Vous pouvez vérifier si c'est le cas en présentant des affichages de différentes couleurs en alternance rapide. Si le v-sync n'est pas activé, vous observerez clairement des lignes horizontales qui traversent l'écran (c'est-à-dire des 'déchirures'). Pour effectuer ce test, exécutez une expérience avec le script suivant dans un élément INLINE_SCRIPT (%LstVSync) :\n\n<notranslate>\ncode:\n id: LstVSync\n syntax: python\n source: v-sync-check.py\n caption: Un script qui présente des affichages jaunes et bleus en alternance rapide. Un manque de synchronisation avec le rafraîchissement vertical peut être observé sous forme de lignes horizontales traversant l'écran.\n</notranslate>\n\n### Tester la précision et l'exactitude du temps"
  },
  "- `lag` indicates the position of T2 relative to T1. It has a value of 0 - 8, or no value if there is no T2.\n- `T2_present` is 'y' for trials on which there is a T2 and 'n' for trials on which there is no T2. Of course, this is redundant, because `T2_present` is 'y' on all trials on which `lag` has a value. But it's convenient to define `T2_present`, because we can use it later on to specify the correct T2 response.\n\nClick on *block_loop* and create a variable table as shown in %FigBlockLoop.\n\n<notranslate>\nfigure:\n id: FigBlockLoop\n source: FigBlockLoop.png\n caption: |\n  The *block_loop* item after Step 7.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n### Links\n\n- [/usage/sequences-and-loops/](/usage/sequences-and-loops/)\n- [/usage/variables-and-conditional-statements/](/usage/variables-and-conditional-statements/)\n\n</div>\n\n## Step 8: Define trial sequence\n\nWe will use an INLINE_SCRIPT item to do most of the heavy lifting, and therefore our *trial_sequence* is quite simple. It consists of:\n\n1. A SKETCHPAD (called *fixation*) to show a fixation dot.\n2. An INLINE_SCRIPT (called *RSVP*) item that implements the RSVP stream.\n3. A SKETCHPAD (called *ask_T1*) that asks the participant to report T1.\n4. A KEYBOARD_RESPONSE (called *response_T1*) that collects the T1 report.\n5. A SKETCHPAD (called *ask_T2*) that asks the participant to report T2.\n6. A KEYBOARD_RESPONSE (called *response_T2*) that collects the T2 report.\n7. A LOGGER (called *logger*) that writes all the data to a log file.\n\nDrag all the required items from the item toolbar into *trial_sequence*, re-order them if necessary, and give them informative names. Also, use run-if statements to collect a T1 response only in the experimental condition. Your trial sequence should now look like %FigTrialSequence.\n\n<notranslate>\nfigure:\n id: FigTrialSequence\n source: FigTrialSequence.png\n caption: |\n  The *trial_sequence* item after Step 8.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n### Links\n\n- [/usage/sequences-and-loops/](/usage/sequences-and-loops/)\n- [/usage/variables-and-conditional-statements/](/usage/variables-and-conditional-statements/)\n\n</div>\n\n## Step 9: Create RSVP stream (prepare phase)\n\nNow we're getting to the fun-but-tricky part: implementing the RSVP stream. Click on *RSVP* to open the item. You see two tabs: *Prepare* and *Run*. The golden rule is to add all code related to stimulus preparation to the *Prepare* tab, and all code related to stimulus presentation to the *Run* tab. Let's start with the preparatory stuff, so switch to the *Prepare* tab.\n\nFirst, we need to import the Python modules that we plan to use:\n\n~~~ .python\nimport random\nimport string\n~~~\n\nNext, we need to define several variables that determine the details of the RSVP stream. We will make them properties of the `var` object, that is, turn them into experimental variables. This not necessary, but has the advantage that they will be automatically logged.\n\n~~~ .python\n# The color of T1\nvar.T1_color = 'white'\n# The presentation time of each stimulus\n# (rounded up to nearest value compatible with refresh rate)\nvar.letter_dur = 10\n# The inter-stimulus interval\n# (rounded up to nearest value compatible with refresh rate)\nvar.isi = 70\n~~~\n\nNext, we are going to create the letter stream. Raymond et al. have a few rules:\n\n- The number of letters that precede T1 is randomly selected between 7 and 15.\n- The number of letters that follow T1 is always 8.\n- Letters are randomly sampled without replacement from all uppercase letters except 'X' (which is used for T2).\n\nLet's translate these rules to Python:": {
    "fr": "- `lag` indique la position de T2 par rapport à T1. Il a une valeur de 0 à 8, ou aucune valeur s'il n'y a pas de T2.\n- `T2_present` est 'y' pour les essais où il y a un T2 et 'n' pour les essais où il n'y a pas de T2. Bien sûr, ceci est redondant, car `T2_present` est 'y' sur tous les essais où `lag` a une valeur. Mais c'est pratique de définir `T2_present`, car nous pouvons l'utiliser plus tard pour spécifier la réponse T2 correcte.\n\nCliquez sur *block_loop* et créez un tableau de variables comme indiqué dans %FigBlockLoop.\n\n<notranslate>\nfigure:\n id: FigBlockLoop\n source: FigBlockLoop.png\n caption: |\n  L'élément *block_loop* après l'étape 7.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n### Liens\n\n- [/usage/sequences-and-loops/](/usage/sequences-and-loops/)\n- [/usage/variables-and-conditional-statements/](/usage/variables-and-conditional-statements/)\n\n</div>\n\n## Étape 8 : Définir la séquence d'essai\n\nNous allons utiliser un élément INLINE_SCRIPT pour faire la majeure partie du travail, et donc notre *trial_sequence* est assez simple. Il se compose de :\n\n1. Un SKETCHPAD (appelé *fixation*) pour montrer un point de fixation.\n2. Un élément INLINE_SCRIPT (appelé *RSVP*) qui met en œuvre le flux RSVP.\n3. Un SKETCHPAD (appelé *ask_T1*) qui demande au participant de signaler T1.\n4. Une réponse au clavier (appelée *response_T1*) qui recueille le rapport T1.\n5. Un SKETCHPAD (appelé *ask_T2*) qui demande au participant de signaler T2.\n6. Une réponse au clavier (appelée *response_T2*) qui recueille le rapport T2.\n7. Un LOGGER (appelé *logger*) qui écrit toutes les données dans un fichier journal.\n\nFaites glisser tous les éléments nécessaires de la barre d'outils des éléments dans *trial_sequence*, réorganisez-les si nécessaire et donnez-leur des noms informatifs. Utilisez également des instructions run-if pour collecter une réponse T1 uniquement dans la condition expérimentale. Votre séquence d'essai devrait maintenant ressembler à %FigTrialSequence.\n\n<notranslate>\nfigure:\n id: FigTrialSequence\n source: FigTrialSequence.png\n caption: |\n  L'élément *trial_sequence* après l'étape 8.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n### Liens\n\n- [/usage/sequences-and-loops/](/usage/sequences-and-loops/)\n- [/usage/variables-and-conditional-statements/](/usage/variables-and-conditional-statements/)\n\n</div>\n\n## Étape 9 : Créer le flux RSVP (phase de préparation)\n\nMaintenant, nous arrivons à la partie amusante mais délicate : la mise en œuvre du flux RSVP. Cliquez sur *RSVP* pour ouvrir l'élément. Vous voyez deux onglets : *Prepare* et *Run*. La règle d'or est d'ajouter tout le code lié à la préparation des stimuli à l'onglet *Prepare*, et tout le code lié à la présentation des stimuli à l'onglet *Run*. Commençons par les choses préparatoires, donc passez à l'onglet *Prepare*.\n\nTout d'abord, nous devons importer les modules Python que nous prévoyons d'utiliser :\n\n~~~ .python\nimport random\nimport string\n~~~\n\nEnsuite, nous devons définir plusieurs variables qui déterminent les détails du flux RSVP. Nous les ferons propriétés de l'objet `var`, c'est-à-dire les transformer en variables expérimentales. Ce n'est pas nécessaire, mais cela a l'avantage qu'ils seront automatiquement enregistrés.\n\n~~~ .python\n# La couleur de T1\nvar.T1_color = 'blanc'\n# Le temps de présentation de chaque stimulus\n# (arrondi à la valeur supérieure compatible avec le taux de rafraîchissement)\nvar.letter_dur = 10\n# L'intervalle entre les stimuli\n# (arrondi à la valeur supérieure compatible avec le taux de rafraîchissement)\nvar.isi = 70\n~~~\n\nEnsuite, nous allons créer le flux de lettres. Raymond et al. ont quelques règles :\n\n- Le nombre de lettres qui précèdent T1 est sélectionné aléatoirement entre 7 et 15.\n- Le nombre de lettres qui suivent T1 est toujours 8.\n- Les lettres sont échantillonnées aléatoirement et sans remplacement à partir de toutes les lettres majuscules sauf 'X' (qui est utilisé pour T2).\n\nTraduisons ces règles en Python:"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## The basic steps\n\n\n<notranslate>\nfigure:\n id: FigWCST\n source: wcst.png\n caption: |\n  The Wisconsin Card Sorting Test (WCST) is a neuropsychological test of executive functions.\n</notranslate>\n\n\nIn this tutorial, you will implement the Wisconsin Card Sorting Test (WCST) and learn how you can run this test online with OSWeb.\n\nIn the WCST, participants see four stimulus cards, which differ on three dimensions: color (red, green, blue, yellow), shape (circle, star, triangle, cross), and number of shapes (one, two, three, or four). Participants also see a single response card, which also has a color, shape, and number.\n\nThe participant's task is to match the response card to the correct stimulus card, based on a specific dimension (e.g. color), or *matching rule*. The participant initially doesn't know on which dimension to match, and his or her task is to figure out the matching rule through trial and error.\n\nTo make things more difficult, the matching rule changes after every five correct responses. Therefore, the participant needs to flexibly update their matching rule.\n\n\n### Step 1: Download and start OpenSesame\n\nOpenSesame is available for Windows, Linux, and Mac OS. This tutorial is written for OpenSesame 3.2 or higher.\n\nWhen you start OpenSesame, you will be given a choice of template experiments, and (if any) a list of recently opened experiments (see %FigStartUp).\n\n<notranslate>\nfigure:\n id: FigStartUp\n source: start-up.png\n caption: |\n  The OpenSesame window on start-up.\n</notranslate>\n\nThe *Extended template* provides a good starting point for creating many experiments that use a block-trial structure. However, in this tutorial we will create the entire experiment from scratch, and we will use the 'default template', which is already loaded when OpenSesame is launched (%FigDefaultTemplate). Therefore, simply close the 'Get started!' and (if shown) 'Welcome!' tabs.\n\n<notranslate>\nfigure:\n id: FigDefaultTemplate\n source: default-template.png\n caption: |\n  The structure of the 'Default template' as seen in the overview area.\n</notranslate>\n\n\n### Step 2: Add a block_loop and trial_sequence\n\nThe default template starts with three items: A NOTEPAD called *getting_started*, a SKETCHPAD called *welcome*, and a SEQUENCE called *experiment*. We don't need *getting_started* and *welcome*, so let's remove these right away. To do so, right-click on these items and select 'Delete'. Don't remove *experiment*, because it is the entry for the experiment (i.e. the first item that is called when the experiment is started).\n\nOur experiment will have a very simple structure. At the top of the hierarchy is a LOOP, which we will call *block_loop*. The *block_loop* is the place where we will define our independent variables. To add a LOOP to your experiment, drag the LOOP icon from the item toolbar onto the *experiment* item in the overview area.\n\nA LOOP item needs another item to run; usually, and in this case as well, this is a SEQUENCE. Drag the SEQUENCE item from the item toolbar onto the *new_loop* item in the overview area. OpenSesame will ask whether you want to insert the SEQUENCE into or after the LOOP. Select 'Insert into new_loop'.\n\nBy default, items have names such as *new_sequence*, *new_loop*, *new_sequence_2*, etc. These names are not very informative, and it is good practice to rename them. Item names must consist of alphanumeric characters and/ or underscores. To rename an item, double-click on the item in the overview area. Rename *new_sequence* to *trial_sequence* to indicate that it will correspond to a single trial. Rename *new_loop* to *block_loop* to indicate that will correspond to a block of trials.\n\nFinally, click on 'New experiment'to open the General Properties tab. Click on the title of the experiment, and rename it to 'Wisconsin Card Sorting Test'.\n\nThe overview area of our experiment now looks as in %FigBasicStructure.": {
    "fr": "[TOC]\n\n## Les étapes de base\n\nfigure :\n id : FigWCST\n source : wcst.png\n légende : |\n  Le Wisconsin Card Sorting Test (WCST) est un test neuropsychologique des fonctions exécutives.\n\nDans ce tutoriel, vous allez mettre en œuvre le Wisconsin Card Sorting Test (WCST) et apprendre comment vous pouvez réaliser ce test en ligne avec OSWeb.\n\nDans le WCST, les participants voient quatre cartes stimulus, qui diffèrent selon trois dimensions : la couleur (rouge, vert, bleu, jaune), la forme (cercle, étoile, triangle, croix) et le nombre de formes (un, deux, trois ou quatre). Les participants voient également une seule carte réponse, qui a également une couleur, une forme et un nombre.\n\nLa tâche du participant est d'associer la carte réponse à la carte stimulus correcte, en fonction d'une dimension spécifique (par exemple la couleur) ou *règle d'appariement*. Le participant ne sait initialement pas sur quelle dimension appairer, et sa tâche est de déterminer la règle d'appariement par essais et erreurs.\n\nPour compliquer les choses, la règle d'appariement change après chaque série de cinq bonnes réponses. Le participant doit donc mettre à jour de manière flexible sa règle d'appariement.\n\n### Étape 1 : Téléchargez et démarrez OpenSesame\n\nOpenSesame est disponible pour Windows, Linux et Mac OS. Ce tutoriel est rédigé pour OpenSesame 3.2 ou supérieur.\n\nLorsque vous démarrez OpenSesame, on vous proposera de choisir parmi des modèles d'expériences, et (le cas échéant) une liste d'expériences récemment ouvertes (voir %FigStartUp).\n\nfigure :\n id : FigStartUp\n source : start-up.png\n légende : |\n  La fenêtre OpenSesame au démarrage.\n\nLe modèle *Extended template* offre un bon point de départ pour créer de nombreuses expériences qui utilisent une structure de blocs-essais. Cependant, dans ce tutoriel, nous créerons l'ensemble de l'expérience à partir de zéro et nous utiliserons le modèle 'default template', qui est déjà chargé lors du lancement d'OpenSesame (%FigDefaultTemplate). Fermez simplement les onglets 'Get started!' et (s'il est affiché) 'Welcome!'.\n\nfigure :\n id : FigDefaultTemplate\n source : default-template.png\n légende : |\n  La structure du 'Default template' vue dans la zone d'aperçu.\n\n### Étape 2 : Ajoutez un block_loop et un trial_sequence\n\nLe modèle par défaut démarre avec trois éléments : un NOTEPAD appelé *getting_started*, un SKETCHPAD appelé *welcome* et une SEQUENCE appelée *experiment*. Nous n'avons pas besoin de *getting_started* et *welcome*, alors supprimons-les tout de suite. Pour ce faire, faites un clic droit sur ces éléments et sélectionnez 'Supprimer'. Ne supprimez pas *experiment*, car il s'agit de l'entrée de l'expérience (c'est-à-dire le premier élément qui est appelé lorsque l'expérience commence).\n\nNotre expérience aura une structure très simple. Au sommet de la hiérarchie se trouve une LOOP, que nous appellerons *block_loop*. Le *block_loop* est l'endroit où nous définirons nos variables indépendantes. Pour ajouter une LOOP à votre expérience, faites glisser l'icône LOOP depuis la barre d'outils d'éléments sur l'élément *experiment* dans la zone d'aperçu.\n\nUn élément LOOP a besoin d'un autre élément pour fonctionner ; habituellement, et dans ce cas également, il s'agit d'une SEQUENCE. Faites glisser l'élément SEQUENCE depuis la barre d'outils d'éléments sur l'élément *new_loop* dans la zone d'aperçu. OpenSesame vous demandera si vous voulez insérer la SEQUENCE dans ou après la LOOP. Sélectionnez 'Insérer dans new_loop'.\n\nPar défaut, les éléments ont des noms tels que *new_sequence*, *new_loop*, *new_sequence_2*, etc. Ces noms ne sont pas très informatifs, et il est recommandé de les renommer. Les noms d'éléments doivent être composés de caractères alphanumériques et/ou de soulignements. Pour renommer un élément, double-cliquez sur l'élément dans la zone d'aperçu. Renommez *new_sequence* en *trial_sequence* pour indiquer qu'il correspondra à un essai unique. Renommez *new_loop* en *block_loop* pour indiquer qu'il correspondra à un bloc d'essais.\n\nEnfin, cliquez sur 'New experiment' pour ouvrir l'onglet des propriétés générales. Cliquez sur le titre de l'expérience et renommez-le en 'Wisconsin Card Sorting Test'.\n\nLa zone d'aperçu de notre expérience ressemble maintenant à %FigBasicStructure."
  },
  "Timing is precise or consistent when you can present visual stimuli over and over again with the same timing. Timestamps are accurate when they accurately reflect when visual stimuli appear on the monitor. The script below shows how you can check precision and accuracy of timing. This test can be performed both with and without an external photodiode, although the use of a photodiode provides extra verification.\n\nTo keep things simple, let's assume that your monitor is running at 100 Hz, which means that a single frame takes 10 ms. The script then presents a white canvas for 1 frame (10 ms). Next, the script presents a black canvas for 9 frames (90 ms). Note that we have specified a duration of 85, which is rounded up as explained under [Making the refresh deadline]. Therefore, we expect that the interval between the onsets of two consecutive white displays will be 10 frames or 100 ms (= 10 ms + 90 ms).\n\nWe can use two ways to verify whether the interval between two white displays is indeed 100 ms:\n\n1. Using the timestamps reported by OpenSesame. This is the easiest way and is generally accurate when the backend uses a blocking flip.\n2. Using a photodiode that responds to the onsets of the white displays and logs the timestamps of these onsets to an external computer. This is the best way to verify the timing, because it does not rely on introspection of the software. Certain issues, such as TFT input lag, discussed above, will come out only using external photodiode measurement.\n\n<notranslate>\ncode:\n id: LstIntervalBenchmark\n syntax: python\n source: interval-benchmark.py\n caption: A Python script to test the timing consistency and accuracy of display timestamps. You can paste this code into an INLINE_SCRIPT item.\n</notranslate>\n\nI ran %LstIntervalBenchmark on Windows XP, using all three backends. I also recorded the onsets of the white displays using a photodiode connected to a second computer. The results are summarized in %TblBenchmarkResults.\n\n<notranslate>\ntable:\n id: TblBenchmarkResults\n source: benchmark-results.csv\n caption: Benchmark results for %LstIntervalBenchmark. Tested with Windows XP, HP Compaq dc7900, Intel Core 2 Quad Q9400 @ 2.66Ghz, 3GB, 21\" ViewSonic P227f CRT. Each test was conducted twice (i.e. two sessions). The column `Session` corresponds to different test runs. The column `Source` indicates whether the measurements are from an external photiodiode, or based on OpenSesame's internal timestamps.\n</notranslate>\n\nAs you can see, the [xpyriment] and [psycho] backends consistently show a 100 ms interval. This is good and just as we would expect. However, the [legacy] backend shows a 90 ms interval. This discrepancy is due to the fact that the [legacy] backend does not use a blocking flip (see [Understanding your monitor]), which leads to some unpredictability in display timing. Note also that there is close agreement between the timestamps as recorded by the external photodiode and the timestamps reported by OpenSesame. This agreement demonstrates that OpenSesame's timestamps are reliable, although, again, they are slightly less reliable for the [legacy] backend due to the lack of a blocking-flip.\n\n\n## Expyriment benchmarks and test suite\n\nA very nice set of benchmarks is available on the Expyriment website. This information is applicable to OpenSesame experiments using the [xpyriment] backend.\n\n- <http://docs.expyriment.org/Timing.html>\n\nExpyriment includes a very useful test suite. You can launch this test suite by running the `test_suite.opensesame` example experiment, or by adding a simple INLINE_SCRIPT to your experiment with the following lines of code (%LstExpyrimentTestSuite):\n\n<notranslate>\ncode:\n id: LstExpyrimentTestSuite\n syntax: python\n source: expyriment-test-suite.py\n caption: A script to start the Expyriment test suite.\n</notranslate>\n\nFor more information, please visit:\n\n- <http://docs.expyriment.org/Testsuite.html>\n\n## PsychoPy benchmarks and timing-related information": {
    "fr": "La synchronisation est précise ou cohérente lorsque vous pouvez présenter des stimuli visuels encore et encore avec la même synchronisation. Les horodatages sont exacts lorsqu'ils reflètent avec précision l'apparition des stimuli visuels sur le moniteur. Le script ci-dessous montre comment vous pouvez vérifier la précision et l'exactitude de la synchronisation. Ce test peut être effectué avec ou sans photodiode externe, bien que l'utilisation d'une photodiode fournisse une vérification supplémentaire.\n\nPour simplifier, supposons que votre moniteur fonctionne à 100 Hz, ce qui signifie qu'une seule image dure 10 ms. Le script présente ensuite un canevas blanc pendant 1 image (10 ms). Ensuite, le script présente un canevas noir pendant 9 images (90 ms). Notez que nous avons spécifié une durée de 85, qui est arrondie comme expliqué sous [Respecter la date limite de rafraîchissement]. Par conséquent, nous nous attendons à ce que l'intervalle entre les débuts de deux affichages blancs consécutifs soit de 10 images ou 100 ms (= 10 ms + 90 ms).\n\nNous pouvons utiliser deux méthodes pour vérifier si l'intervalle entre deux affichages blancs est bien de 100 ms :\n\n1. En utilisant les horodatages rapportés par OpenSesame. C'est la méthode la plus simple et généralement précise lorsque le backend utilise un flip bloquant.\n2. En utilisant une photodiode qui réagit aux débuts des affichages blancs et enregistre les horodatages de ces débuts sur un ordinateur externe. C'est la meilleure façon de vérifier le timing, car elle ne repose pas sur l'introspection du logiciel. Certains problèmes, tels que le décalage d'entrée TFT, discuté ci-dessus, ne sortiront qu'en utilisant une mesure de photodiode externe.\n\n<notranslate>\ncode :\n id: LstIntervalBenchmark\n syntax: python\n source: interval-benchmark.py\n légende: Un script Python pour tester la cohérence et l'exactitude des horodatages d'affichage. Vous pouvez coller ce code dans un élément INLINE_SCRIPT.\n</notranslate>\n\nJ'ai exécuté %LstIntervalBenchmark sur Windows XP, en utilisant les trois backends. J'ai également enregistré les débuts des affichages blancs en utilisant une photodiode connectée à un deuxième ordinateur. Les résultats sont résumés dans %TblBenchmarkResults.\n\n<notranslate>\ntable :\n id: TblBenchmarkResults\n source: benchmark-results.csv\n légende: Résultats de référence pour %LstIntervalBenchmark. Testé avec Windows XP, HP Compaq dc7900, Intel Core 2 Quad Q9400 @ 2.66Ghz, 3GB, 21\" ViewSonic P227f CRT. Chaque test a été effectué deux fois (c'est-à-dire deux sessions). La colonne `Session` correspond à différentes séquences de test. La colonne `Source` indique si les mesures proviennent d'une photiodiode externe ou des horodatages internes d'OpenSesame.\n</notranslate>\n\nComme vous pouvez le voir, les backends [xpyriment] et [psycho] montrent constamment un intervalle de 100 ms. C'est bien, et c'est juste comme nous le prévoyions. Cependant, le backend [legacy] montre un intervalle de 90 ms. Cette différence est due au fait que le backend [legacy] n'utilise pas de flip bloquant (voir [Comprendre votre moniteur]), ce qui entraîne une certaine imprévisibilité dans la synchronisation de l'affichage. Notez également qu'il y a un accord étroit entre les horodatages enregistrés par la photodiode externe et les horodatages rapportés par OpenSesame. Cet accord démontre que les horodatages d'OpenSesame sont fiables, bien que, encore une fois, ils le soient légèrement moins pour le backend [legacy] en raison de l'absence de flip bloquant.\n\n## Benchmarks et suite de tests Expyriment\n\nUn ensemble très intéressant de benchmarks est disponible sur le site web d'Expyriment. Ces informations sont applicables aux expériences OpenSesame utilisant le backend [xpyriment].\n\n- <http://docs.expyriment.org/Timing.html>\n\nExpyriment inclut une suite de tests très utile. Vous pouvez lancer cette suite de tests en exécutant l'expérience exemple `test_suite.opensesame` ou en ajoutant un INLINE_SCRIPT simple à votre expérience avec les lignes de code suivantes (%LstExpyrimentTestSuite) :\n\n<notranslate>\ncode :\n id: LstExpyrimentTestSuite\n syntax: python\n source: expyriment-test-suite.py\n légende: Un script pour démarrer la suite de tests Expyriment.\n</notranslate>\n\nPour plus d'informations, veuillez visiter :\n\n- <http://docs.expyriment.org/Testsuite.html>\n\n## Benchmarks PsychoPy et informations relatives au timing"
  },
  "Mac OS comes with a custom version of Python but, for our purpose (and many purposes), you need the official Python. This has already been installed by MacPorts, but you still need to make it the default. You can do this with the following command:\n\n\tsudo port select --set python python27\n\n### Installing packages manually\n\nIf you want to install all Opensesame dependecies yourself you need to download and install the following package distributions:\n\n#### Install Python\n\nThe python installation that comes with OS X is usually of an older version. Therefore it is better to install the newest version from python.org:\n\nWebsite: <http://www.python.org/>\n\nDirect download: http://www.python.org/ftp/python/2.7.3/python-2.7.3-macosx10.6.dmg\n\nAnother option is to install the [Enthought Python Distribution (EPD)][EPD_Download] instead. This distribution includes Python and many of the modules OpenSesame depends on ([view][EPD_Packages] a complete list).\n\n#### Install PyGame\n\nWebsite: <http://www.pygame.org/>\n\nDirect download (Snow Leopard): <http://www.pygame.org/ftp/pygame-1.9.2pre-py2.6-macosx10.6.mpkg.zip><br/>\nDirect download ((Mountain) Lion): <http://www.pygame.org/ftp/pygame-1.9.2pre-py2.7-macosx10.7.mpkg.zip>\n\n#### Install PyQt4\n\nThere is no official distribution (from Riverbank) available of PyQt4 for Mac OS X. However there are some well maintained unofficial distributions:\n\nOfficial website: <http://www.riverbankcomputing.co.uk/software/pyqt/intro>\n\nMac OS X distribution (PyQtX) website: <http://sourceforge.net/projects/pyqtx/> (Direct download: <http://sourceforge.net/projects/pyqtx/files/latest/download>)\n\n\nAfter PyQt4 is installed, download and install the QScintilla module, which is used for the inline script editor in OpenSesame:\n\nPyQScintillaX: <http://sourceforge.net/projects/pyqtx/files/PyQScintillaX/>\n\n#### Install NumPy and SciPy\n\nGetting the latest versions of NumPy or SciPy can be done in two ways:\n\nYou can use the installation script which can be found at <http://fonnesbeck.github.com/ScipySuperpack/>  (Direct download: <https://raw.github.com/fonnesbeck/ScipySuperpack/master/install_superpack.sh>)\nalong with the instructions of how to use it. This script will automatically find the latest versions of numpy and scipy and install them for you. Basically you just have to run\n\n\tsudo sh ./install_superpack.sh\n\nin the console in the folder which you downloaded the script.\n\nAlternatively, you can download and install the packages from the projects' own websites:\n\nNumpy: <http://sourceforge.net/projects/numpy/files/NumPy/> (Direct download version 1.7.0: <http://sourceforge.net/projects/numpy/files/NumPy/1.7.0/numpy-1.7.0-py2.7-python.org-macosx10.6.dmg/download>)\nScipy: <http://sourceforge.net/projects/scipy/files/scipy/> (Direct download version 0.11.0: <http://sourceforge.net/projects/scipy/files/scipy/0.11.0/scipy-0.11.0-py2.7-python.org-macosx10.6.dmg/download>)\n\n#### Install PsychoPy and Expyriment(optional)\n\nPsychoPy requires the installation of a number of dependencies. Most of these can be installed fairly easily using setuptools.\n\nWebsite: <http://pypi.python.org/pypi/setuptools>\n\nDirect download: <http://pypi.python.org/packages/2.7/s/setuptools/setuptools-0.6c11-py2.7.egg#md5=fe1f997bc722265116870bc7919059ea>\n\nAs described on the website, installation should proceed through the following steps:\n\nDownload the appropriate egg for your version of Python (e.g. setuptools-0.6c9-py2.7.egg). Do NOT rename it.\n\nRun it as if it were a shell script, e.g.\n\n\tsh setuptools-0.6c9-py2.7.egg\n\nSetuptools will install itself using the matching version of Python (e.g. python2.7), and will place the easy_install executable in the default location for installing Python scripts (as determined by the standard distutils configuration files, or by the Python installation).\nAfterwards, install most dependencies with the command:\n\n\tsudo easy_install psychopy pyglet pyopengl pil expyriment": {
    "fr": "Mac OS est livré avec une version personnalisée de Python, mais pour notre objectif (et de nombreux objectifs), vous avez besoin de la version officielle de Python. Cela a déjà été installé par MacPorts, mais vous devez toujours en faire la version par défaut. Vous pouvez le faire avec la commande suivante :\n\n\tsudo port select --set python python27\n\n### Installation des packages manuellement\n\nSi vous souhaitez installer toutes les dépendances d'Opensesame vous-même, vous devez télécharger et installer les distributions des packages suivants :\n\n#### Installer Python\n\nL'installation de python qui vient avec OS X est généralement d'une version plus ancienne. Il est donc préférable d'installer la dernière version à partir de python.org :\n\nSite web : <http://www.python.org/>\n\nTéléchargement direct : http://www.python.org/ftp/python/2.7.3/python-2.7.3-macosx10.6.dmg\n\nUne autre option est d'installer la [Enthought Python Distribution (EPD)][EPD_Download] à la place. Cette distribution inclut Python et plusieurs modules dont OpenSesame dépend ([voir][EPD_Packages] la liste complète).\n\n#### Installer PyGame\n\nSite web : <http://www.pygame.org/>\n\nTéléchargement direct (Snow Leopard) : <http://www.pygame.org/ftp/pygame-1.9.2pre-py2.6-macosx10.6.mpkg.zip><br/>\nTéléchargement direct ((Mountain) Lion) : <http://www.pygame.org/ftp/pygame-1.9.2pre-py2.7-macosx10.7.mpkg.zip>\n\n#### Installer PyQt4\n\nIl n'y a pas de distribution officielle (de Riverbank) disponible de PyQt4 pour Mac OS X. Cependant, il existe quelques distributions non officielles bien entretenues :\n\nSite officiel : <http://www.riverbankcomputing.co.uk/software/pyqt/intro>\n\nSite web de la distribution Mac OS X (PyQtX) : <http://sourceforge.net/projects/pyqtx/> (Téléchargement direct : <http://sourceforge.net/projects/pyqtx/files/latest/download>)\n\nAprès avoir installé PyQt4, téléchargez et installez le module QScintilla, qui est utilisé pour l'éditeur de script en ligne dans OpenSesame :\n\nPyQScintillaX : <http://sourceforge.net/projects/pyqtx/files/PyQScintillaX/>\n\n#### Installer NumPy et SciPy\n\nPour obtenir les dernières versions de NumPy ou SciPy, vous pouvez procéder de deux manières :\n\nVous pouvez utiliser le script d'installation qui se trouve à l'adresse <http://fonnesbeck.github.com/ScipySuperpack/> (Téléchargement direct : <https://raw.github.com/fonnesbeck/ScipySuperpack/master/install_superpack.sh>)\nainsi que les instructions sur la façon de l'utiliser. Ce script trouvera automatiquement les dernières versions de numpy et scipy et les installera pour vous. Fondamentalement, il suffit de lancer\n\n\tsudo sh ./install_superpack.sh\n\ndans la console du dossier où vous avez téléchargé le script.\n\nAlternativement, vous pouvez télécharger et installer les packages depuis les sites web des projets eux-mêmes :\n\nNumpy : <http://sourceforge.net/projects/numpy/files/NumPy/> (Téléchargement direct version 1.7.0 : <http://sourceforge.net/projects/numpy/files/NumPy/1.7.0/numpy-1.7.0-py2.7-python.org-macosx10.6.dmg/download>)\nScipy : <http://sourceforge.net/projects/scipy/files/scipy/> (Téléchargement direct version 0.11.0 : <http://sourceforge.net/projects/scipy/files/scipy/0.11.0/scipy-0.11.0-py2.7-python.org-macosx10.6.dmg/download>)\n\n#### Installer PsychoPy et Expyriment (optionnel)\n\nPsychoPy nécessite l'installation d'un certain nombre de dépendances. La plupart d'entre elles peuvent être installées assez facilement à l'aide de setuptools.\n\nSite web : <http://pypi.python.org/pypi/setuptools>\n\nTéléchargement direct : <http://pypi.python.org/packages/2.7/s/setuptools/setuptools-0.6c11-py2.7.egg#md5=fe1f997bc722265116870bc7919059ea>\n\nComme décrit sur le site web, l'installation doit se dérouler selon les étapes suivantes :\n\nTéléchargez l'œuf approprié pour votre version de Python (par exemple setuptools-0.6c9-py2.7.egg). Ne le renommez PAS.\n\nExécutez-le comme s'il s'agissait d'un script shell, par exemple\n\n\tsh setuptools-0.6c9-py2.7.egg\n\nSetuptools s'installera en utilisant la version correspondante de Python (par exemple python2.7) et placera l'exécutable easy_install à l'emplacement par défaut pour l'installation des scripts Python (tel que déterminé par les fichiers de configuration distutils standard, ou par l'installation de Python).\nEnsuite, installez la plupart des dépendances avec la commande :\n\n\tsudo easy_install psychopy pyglet pyopengl pil expyriment"
  },
  "Some information about timing is available on the PsychoPy documentation site. This information is applicable to OpenSesame experiments using the [psycho] backend.\n\n- <http://www.psychopy.org/general/timing/timing.html>\n\n[psycho]: /backends/xpyriment/\n[xpyriment]: /backends/xpyriment/\n[legacy]: /backends/legacy/\n[miscellaneous/clock-drift]: /miscellaneous/clock-drift\n[usage/prepare-run]: /usage/prepare-run\n[backends]: /backends\n[forms]: /forms\n": {
    "fr": "Certaines informations sur la synchronisation sont disponibles sur le site de documentation PsychoPy. Ces informations sont applicables aux expériences OpenSesame utilisant le backend [psycho].\n\n- <http://www.psychopy.org/general/timing/timing.html>\n\n[psycho]: /backends/xpyriment/\n[xpyriment]: /backends/xpyriment/\n[legacy]: /backends/legacy/\n[miscellaneous/clock-drift]: /miscellaneous/clock-drift\n[usage/prepare-run]: /usage/prepare-run\n[backends]: /backends\n[forms]: /forms"
  },
  "Running experiments online": {
    "fr": "Réaliser des expériences en ligne"
  },
  "\nThis page has been moved to:\n\n- %link:manual/osweb/workflow%\n": {
    "fr": "Cette page a été déplacée vers :\n\n- %link:manual/osweb/workflow%"
  },
  "Counterbalancing": {
    "fr": "Contrebalancement"
  },
  "~~~ .python\n# The position of T1 is random between 7 and 15. Note that the first position is\n# 0, so the position indicates the number of preceding stimuli.\nvar.T1_pos = random.randint(7, 15)\n# The maximum lag, i.e. the number of letters that follow T1.\nvar.max_lag = 8\n# The length of the stream is the position of T1 + the maximum lag + 1. We need\n# to add 1, because we count starting at 0, so the length of a list is always\n# 1 larger than its maximum index.\nvar.stream_len = var.T1_pos + var.max_lag + 1\n# We take all uppercase letters, which have been predefined in the `string`\n# module. Converting to a `list` creates a list of characters.\nletters = list(string.ascii_uppercase)\n# We remove 'X' from this list.\nletters.remove('X')\n# Randomly sample a `stream_len` number of letters\nstim_list = random.sample(letters, var.stream_len)\n~~~\n\nOk, `stim_list` now contains all letters that make up our RSVP stream on a given trial, except for the T2 (if present). Therefore, on T2-present trials, we need to replace the letter at the T2 position by an 'X'.\n\n~~~ .python\nif var.T2_present == 'y':\n    var.T2_pos = var.T1_pos + var.lag\n    stim_list[var.T2_pos] = 'X'\n~~~\n\nWe now have a variable called `stim_list` that specifies the letters in our RSVP stream. This is a `list` that might contain something like: `['M', 'F', 'O', 'P', 'S', 'R', 'Y', 'C', 'U', 'Z', 'G', 'A', 'T', 'E', 'H', 'J', 'V', 'N', 'B', 'K', 'X', 'Q']`. Note that `stim_list` is not an experimental variable, i.e. it is not a property of the `var` object. This is because experimental variables cannot be lists: The `var` object would turn the list into a character string, and that's not what we want!\n\nThe next step is to create a `list` of `canvas` objects, each of which contains a single letter from `stim_list`. A `canvas` object corresponds to a static visual stimulus display, i.e. to one frame in our RSVP stream. You can create a canvas object using the `canvas()` function, which is one of OpenSesame's common\nfunctions that you can call without needing to import anything.\n\n~~~ .python\n# Create an empty list for the canvas objects.\nletter_canvas_list = []\n# Loop through all letters in `stim_list`. `enumerate()` is a convenient\n# function that automatically returns (index, item) tuples. In our case, the\n# index (`i`) reflects the position in the RSVP stream. This Python trick, in\n# which you assign a single value to two variables, is called tuple unpacking.\nfor i, stim in enumerate(stim_list):\n    # Create a `canvas` object.\n    letter_canvas = canvas()\n    # If we are at the position of T1, we change the foreground color, because\n    # T1 is white, while the default color (specified in the General tab) is\n    # black.\n    if i == var.T1_pos:\n        letter_canvas.set_fgcolor(var.T1_color)\n    # Draw the letter!\n    letter_canvas.text(stim)\n    # And add the canvas to the list.\n    letter_canvas_list.append(letter_canvas)\n~~~\n\nWe also need to create a blank `canvas` to show during the inter-stimulus interval:\n\n~~~ .python\nblank_canvas = canvas()\n~~~\n\nFinally, we set the identity of T1 as an experimental variable, because it has been randomly determined in the script:\n\n~~~ .python\n# Extract T1 from the list\nvar.T1 = stim_list[var.T1_pos]\n~~~\n\nPreparation done!\n\n<div class='info-box' markdown='1'>\n\n### Links\n\n- [/python/about/](/python/about/)\n- [/python/canvas/](/python/canvas/)\n- <https://docs.python.org/2/library/random.html>\n- <https://docs.python.org/2/library/string.html>\n- <https://docs.python.org/2/tutorial/datastructures.html#tuples-and-sequences>\n\n</div>\n\n## Step 10: Execute RSVP stream (run phase)\n\nNow, let's switch to the *Run* tab of the `RSVP` item. Here we add the code that is necessary to show all the `canvas` objects that we have created during the *Prepare* phase. And that's not so hard! All we need to do is:": {
    "fr": "~~~ .python\n# La position de T1 est aléatoire entre 7 et 15. Notez que la première position est\n# 0, donc la position indique le nombre de stimuli précédents.\nvar.T1_pos = random.randint(7, 15)\n# Le décalage maximum, c'est-à-dire le nombre de lettres qui suivent T1.\nvar.max_lag = 8\n# La longueur du flux est la position de T1 + le décalage maximum + 1. Nous avons besoin\n# d'ajouter 1, car nous comptons à partir de 0, donc la longueur d'une liste est toujours\n# 1 de plus que son index maximum.\nvar.stream_len = var.T1_pos + var.max_lag + 1\n# Nous prenons toutes les lettres majuscules, qui ont été prédéfinies dans le module `string`.\n# La conversion en `list` crée une liste de caractères.\nlettres = list(string.ascii_uppercase)\n# Nous supprimons 'X' de cette liste.\nlettres.remove('X')\n# Choisissez au hasard un nombre `stream_len` de lettres\nstim_list = random.sample(lettres, var.stream_len)\n~~~\n\nOk, `stim_list` contient maintenant toutes les lettres qui composent notre flux RSVP lors d'un essai donné, sauf le T2 (s'il est présent). Par conséquent, lors des essais où T2 est présent, nous devons remplacer la lettre à la position T2 par un 'X'.\n\n~~~ .python\nif var.T2_present == 'y':\n    var.T2_pos = var.T1_pos + var.lag\n    stim_list[var.T2_pos] = 'X'\n~~~\n\nNous avons maintenant une variable appelée `stim_list` qui spécifie les lettres de notre flux RSVP. Il s'agit d'une `liste` qui pourrait contenir quelque chose comme : `['M', 'F', 'O', 'P', 'S', 'R', 'Y', 'C', 'U', 'Z', 'G', 'A', 'T', 'E', 'H', 'J', 'V', 'N', 'B', 'K', 'X', 'Q']`. Notez que `stim_list` n'est pas une variable expérimentale, c'est-à-dire qu'elle n'est pas une propriété de l'objet `var`. C'est parce que les variables expérimentales ne peuvent pas être des listes : L'objet `var` transformerait la liste en une chaîne de caractères, et ce n'est pas ce que nous voulons !\n\nLa prochaine étape consiste à créer une `liste` d'objets `canvas`, chacun contenant une seule lettre de `stim_list`. Un objet `canvas` correspond à un affichage de stimulus visuel statique, c'est-à-dire à une image de notre flux RSVP. Vous pouvez créer un objet canvas en utilisant la fonction `canvas()`, qui est l'une des fonctions communes d'OpenSesame que vous pouvez appeler sans avoir besoin d'importer quoi que ce soit.\n\n~~~ .python\n# Créez une liste vide pour les objets canvas.\nliste_canvas_lettre = []\n# Parcourez toutes les lettres de `stim_list`. `enumerate()` est une fonction pratique\n# qui retourne automatiquement des tuples (index, élément). Dans notre cas, l'index (`i`)\n# reflète la position dans le flux RSVP. Cette astuce Python, dans laquelle vous attribuez\n# une seule valeur à deux variables, est appelée déballage de tuple.\nfor i, stim in enumerate(stim_list):\n    # Créez un objet `canvas`.\n    lettre_canvas = canvas()\n    # Si nous sommes à la position de T1, nous changeons la couleur de l'avant-plan, parce que\n    # T1 est blanc, alors que la couleur par défaut (spécifiée dans l'onglet Général) est\n    # noire.\n    if i == var.T1_pos:\n        lettre_canvas.set_fgcolor(var.T1_color)\n    # Dessinez la lettre !\n    lettre_canvas.text(stim)\n    # Et ajoutez le canvas à la liste.\n    liste_canvas_lettre.append(lettre_canvas)\n~~~\n\nNous devons également créer un `canvas` vierge à afficher pendant l'intervalle inter-stimuli :\n\n~~~ .python\ncanvas_vide = canvas()\n~~~\n\nEnfin, nous définissons l'identité de T1 en tant que variable expérimentale, car elle a été déterminée de manière aléatoire dans le script :\n\n~~~ .python\n# Extrait T1 de la liste\nvar.T1 = stim_list[var.T1_pos]\n~~~\n\nPréparation terminée !\n\n<div class='info-box' markdown='1'>\n\n### Liens\n\n- [/python/about/](/python/about/)\n- [/python/canvas/](/python/canvas/)\n- <https://docs.python.org/2/library/random.html>\n- <https://docs.python.org/2/library/string.html>\n- <https://docs.python.org/2/tutorial/datastructures.html#tuples-and-sequences>\n\n</div>\n\n## Étape 10 : Exécuter le flux RSVP (phase d'exécution)\n\nMaintenant, passons à l'onglet *Exécuter* de l'élément `RSVP`. Ici, nous ajoutons le code nécessaire pour afficher tous les objets `canvas` que nous avons créés lors de la phase *Préparer*. Et ce n'est pas si difficile ! Tout ce que nous avons à faire est de :"
  },
  "You may need to manually install Matplotlib, wxPython because (at the time of testing) these didn't install using easy_install. Make sure you install the versions that match your Python version.\n\n*NOTE:* The psychopy backend does not seem to work yet and crashes. The reason is that PsychoPy (or rather its underlying library pyglet) can't cope with the 64-bit cocoa environment of the newer Mac OS X versions yet. In newer versions of psychopy this problem is hopefully solved.\n\n#### Install wxPython (Optional, required for the PsychoPy backend)\n\nYou can download wxPython yourself or install it using easy_install (see \"install PsychoPy\").\n\nWebsite: <http://wxpython.org/>\n\nDirect download: <http://downloads.sourceforge.net/wxpython/wxPython2.9-osx-2.9.4.0-cocoa-py2.7.dmg>\n\n#### Install PyOpenGL (Optional, required for opengl or expyriment backend)\n\nYou can download PyOpenGL yourself or install it using easy_install (see \"install PsychoPy\").\n\nWebsite: <http://pyopengl.sourceforge.net/>\n\nDirect download: <https://pypi.python.org/packages/source/P/PyOpenGL/PyOpenGL-3.0.2.tar.gz#md5=77becc24ffc0a6b28030aa109ad7ff8b>\n\n### Run OpenSesame\n\nDownload the source code of the latest OpenSesame release here. Extract the .tar.gz to your home folder (any other location works analogously). Open a terminal and switch to the location of OpenSesame (this example assumes that the version is 0.26):\n\n\tcd /Users/[your username]/opensesame-0.26\n\nRun OpenSesame using one of the following commands:\n\n\tpython opensesame\n\tpython opensesame --debug\n\n[winpython-based package]: /getting-opensesame/running-with-python-portable/\n[EPD_Download]: http://www.enthought.com/products/epd.php\n[EPD_Packages]: http://www.enthought.com/products/epdlibraries.php\n[xpyriment]: /backends/xpyriment\n[legacy]: /backends/legacy\n[psycho]: /backends/psycho\n[cogsci.nl ppa]: https://launchpad.net/~smathot/+archive/cogscinl\n": {
    "fr": "Vous devrez peut-être installer manuellement Matplotlib, wxPython car (au moment des tests) ceux-ci ne se sont pas installés en utilisant easy_install. Assurez-vous d'installer les versions correspondant à votre version de Python.\n\n*NOTE :* Le backend psychopy ne semble pas encore fonctionner et plante. La raison est que PsychoPy (ou plutôt sa bibliothèque sous-jacente pyglet) ne peut pas gérer l'environnement 64 bits cocoa des nouvelles versions de Mac OS X. Dans les nouvelles versions de psychopy, ce problème est, espérons-le, résolu.\n\n#### Installer wxPython (facultatif, requis pour le backend PsychoPy)\n\nVous pouvez télécharger wxPython vous-même ou l'installer en utilisant easy_install (voir \"installer PsychoPy\").\n\nSite Web : <http://wxpython.org/>\n\nTéléchargement direct : <http://downloads.sourceforge.net/wxpython/wxPython2.9-osx-2.9.4.0-cocoa-py2.7.dmg>\n\n#### Installer PyOpenGL (facultatif, requis pour le backend opengl ou expyriment)\n\nVous pouvez télécharger PyOpenGL vous-même ou l'installer en utilisant easy_install (voir \"installer PsychoPy\").\n\nSite Web : <http://pyopengl.sourceforge.net/>\n\nTéléchargement direct : <https://pypi.python.org/packages/source/P/PyOpenGL/PyOpenGL-3.0.2.tar.gz#md5=77becc24ffc0a6b28030aa109ad7ff8b>\n\n### Exécuter OpenSesame\n\nTéléchargez le code source de la dernière version d'OpenSesame ici. Extrayez le .tar.gz dans votre dossier personnel (toute autre localisation fonctionne de manière analogue). Ouvrez un terminal et passez à l'emplacement d'OpenSesame (cet exemple suppose que la version est 0.26) :\n\n\tcd /Users/[votre nom d'utilisateur]/opensesame-0.26\n\nExécutez OpenSesame avec l'une des commandes suivantes :\n\n\tpython opensesame\n\tpython opensesame --debug\n\n[winpython-based package] : /getting-opensesame/running-with-python-portable/\n[EPD_Download] : http://www.enthought.com/products/epd.php\n[EPD_Packages] : http://www.enthought.com/products/epdlibraries.php\n[xpyriment] : /backends/xpyriment\n[legacy] : /backends/legacy\n[psycho] : /backends/psycho\n[cogsci.nl ppa] : https://launchpad.net/~smathot/+archive/cogscinl"
  },
  "Backends": {
    "fr": "Moteurs"
  },
  "<notranslate>\nfigure:\n id: FigBasicStructure\n source: basic-structure.png\n caption: |\n  The overview area at the end of Step 2.\n</notranslate>\n\n\n### Step 3: Import images and sound files\n\nFor this experiment, we will use images for the playing cards. You can download these from here:\n\n- %static:attachments/wisconsin-card-sorting-test/stimuli.zip%\n\nDownload `stimuli.zip` and extract it somewhere (to your desktop, for example). Next, in OpenSesame, click on the 'Show file pool' button in the main toolbar (or: Menu →View → Show file pool). This will show the file pool, by default on the right side of the window. The easiest way to add the stimuli to the file pool is by dragging them from the desktop (or wherever you have extracted the files to) into the file pool. Alternatively, you can click on the '+' button in the file pool and add files using the file-selection dialog that appears. The file pool will automatically be saved with your experiment.\n\nAfter you have added all stimuli, your file pool looks as in %FigFilePool.\n\n<notranslate>\nfigure:\n id: FigFilePool\n source: file-pool.png\n caption: |\n  The file pool containing the stimuli.\n</notranslate>\n\n\n### Step 4: Create a static card display\n\nTo start with, we'll create a display with four stimulus cards and one response card. However, which cards are shown will not, for now, depend on variables; that is, we will create a *static* display.\n\nDrag a a SKETCHPAD into *trial_sequence*, and rename it to *card_display*. Use the image tool to draw four cards in a horizontal row somewhere near the top of the display; these will be the stimulus cards. Draw a single card near the bottom of the display; this will be the response card. Also add some text to indicate to the participant what he or she has to do, namely press `a`, `b`, `c`, or `d` to indicate which of the stimulus cards matches the response card. The exact text, layout, and cards are up to you! Tips: you can use the *scale* option to adjust the size of the cards; you can change the background color in the General Properties tab, which you can open by clicking on the top-level item of the experiment.\n\nFor me, the result looks like this:\n\n\n<notranslate>\nfigure:\n id: FigStaticCards\n source: static-cards.png\n caption: |\n  A SKETCHPAD with statically defined cards.\n</notranslate>\n\n\n### Step 5: Make the response card variable\n\nRight now we're always showing the same response card (in the example above a single blue triangle). But of course we want to show a different response card on every trial. To do so, we first need to define the variables that determine which response card we will show. We will do this in the *block_loop*.\n\nOpen the *block_loop*. The LOOP table is now empty. To determine the color, shape, and number of the response card, we could manually create three columns (`response_color`, `response_shape`, and `response_number`) and 64 rows for all possible combinations of colors, shapes, and numbers. But that would be a lot of work. Instead, we will use the full-factorial-design wizard, which you can open by clicking on the 'Full-factorial design' button. (A full-factorial design is a design in which all possible combinations of variable levels occur.) In this wizard, you create one column for each of the three variables, and in the cells below enter the possible values for that variable (see %FigDesignWizard).\n\n\n<notranslate>\nfigure:\n id: FigDesignWizard\n source: design-wizard.png\n caption: |\n  The full-factorial-design wizard allows you to easily generate large LOOP tables that correspond to full-factorial designs.\n</notranslate>\n\n\nNext, click the OK button. The *block_loop* now contains all 64 combinations of colors, numbers, and shapes (see %FigLoopTable1).\n\n\n<notranslate>\nfigure:\n id: FigLoopTable1\n source: loop-table-1.png\n caption: |\n  The *block_loop* at the end of step 5.\n</notranslate>": {
    "fr": "<notranslate>\nfigure:\n id: FigBasicStructure\n source: basic-structure.png\n caption: |\n  La zone d'aperçu à la fin de l'étape 2.\n</notranslate>\n\n### Étape 3 : Importer des images et des fichiers sonores\n\nPour cette expérience, nous utiliserons des images pour les cartes à jouer. Vous pouvez les télécharger à partir d'ici :\n\n- %static:attachments/wisconsin-card-sorting-test/stimuli.zip%\n\nTéléchargez `stimuli.zip` et extrayez-le quelque part (sur votre bureau, par exemple). Ensuite, dans OpenSesame, cliquez sur le bouton \"Afficher le pool de fichiers\" dans la barre d'outils principale (ou : Menu → Vue → Afficher le pool de fichiers). Le pool de fichiers apparaîtra, par défaut, sur le côté droit de la fenêtre. La manière la plus simple d'ajouter des stimuli dans le pool de fichiers consiste à les faire glisser depuis le bureau (ou l'endroit où vous avez extrait les fichiers) vers ce dernier. Vous pouvez également cliquer sur le bouton '+' dans le pool de fichiers et ajouter des fichiers en utilisant la boîte de dialogue de sélection qui s'affiche. Le pool de fichiers sera automatiquement enregistré avec votre expérience.\n\nAprès avoir ajouté tous les stimuli, votre pool de fichiers ressemblera à celui présenté en %FigFilePool.\n\n<notranslate>\nfigure:\n id: FigFilePool\n source: file-pool.png\n caption: |\n  Le pool de fichiers contenant les stimuli.\n</notranslate>\n\n### Étape 4 : Créer un affichage statique de cartes\n\nPour commencer, nous allons créer un affichage avec quatre cartes de stimulus et une carte de réponse. Toutefois, pour l'instant, les cartes affichées ne dépendront pas des variables ; c'est-à-dire que nous créerons un affichage *statique*.\n\nFaites glisser un SKETCHPAD dans *trial_sequence* et renommez-le *card_display*. Utilisez l'outil image pour dessiner quatre cartes dans une rangée horizontale près du haut de l'écran ; ce seront les cartes de stimulus. Dessinez une seule carte près du bas de l'écran ; ce sera la carte de réponse. Ajoutez également du texte pour indiquer au participant ce qu'il doit faire, à savoir appuyer sur `a`, `b`, `c`, ou `d` pour indiquer laquelle des cartes de stimulus correspond à la carte de réponse. Le texte exact, la mise en page et les cartes dépendent de vous ! Conseils : vous pouvez utiliser l'option *scale* pour ajuster la taille des cartes ; vous pouvez modifier la couleur d'arrière-plan dans l'onglet Propriétés générales, que vous pouvez ouvrir en cliquant sur l'élément de niveau supérieur de l'expérience.\n\nPour moi, le résultat ressemble à ceci :\n\n<notranslate>\nfigure:\n id: FigStaticCards\n source: static-cards.png\n caption: |\n  Un SKETCHPAD avec des cartes définies de manière statique.\n</notranslate>\n\n### Étape 5 : Rendre la carte de réponse variable\n\nPour l'instant, nous montrons toujours la même carte de réponse (dans l'exemple ci-dessus, un seul triangle bleu). Mais bien sûr, nous voulons montrer une carte de réponse différente à chaque essai. Pour ce faire, nous devons d'abord définir les variables qui déterminent quelle carte de réponse nous montrerons. Nous ferons cela dans le *block_loop*.\n\nOuvrez le *block_loop*. La table LOOP est maintenant vide. Pour déterminer la couleur, la forme et le nombre de la carte de réponse, nous pourrions créer manuellement trois colonnes (`response_color`, `response_shape` et `response_number`) et 64 lignées pour toutes les combinaisons possibles de couleurs, formes et nombres. Mais cela demanderait beaucoup de travail. Au lieu de cela, nous utiliserons l'assistant de conception à facteurs complets, que vous pouvez ouvrir en cliquant sur le bouton \"Conception à facteurs complets\" (Une conception à facteurs complets est une conception dans laquelle toutes les combinaisons possibles de niveaux de variable se produisent.) Dans cet assistant, vous créez une colonne pour chacune des trois variables, et dans les cellules en dessous, entrez les valeurs possibles pour cette variable (voir %FigDesignWizard).\n\n<notranslate>\nfigure:\n id: FigDesignWizard\n source: design-wizard.png\n caption: |\n  L'assistant de conception à facteurs complets vous permet de générer facilement de grandes tables LOOP qui correspondent à des conceptions à facteurs complets.\n</notranslate>\n\nEnsuite, cliquez sur le bouton OK. Le *block_loop* contient maintenant les 64 combinaisons de couleurs, nombres et formes (voir %FigLoopTable1).\n\n<notranslate>\nfigure:\n id: FigLoopTable1\n source: loop-table-1.png\n caption: |\n  Le *block_loop* à la fin de l'étape 5.\n</notranslate>"
  },
  "Counterbalancing is a way to remove confounding factors from an experiment by having slightly different tasks for different groups of participants. This sounds abstract, so let's consider two examples.\n\n<notranslate>[TOC]</notranslate>\n\n### Example 1: Counterbalancing response rule\n\nConsider a lexical-decision experiment in which participants classify words as verbs by pressing 'z' with their left hand, or as nouns by pressing 'm' with their right hand. This design has a problem: If you find that participants respond faster to nouns than to verbs, this could be because nouns are processed faster than verbs, or because participants respond faster with their right hand than with their left hand. You can fix this problem by counterbalancing the response rule.\n\nFor even participant numbers:\n\n- verb → z\n- noun → m\n\nFor uneven participant numbers:\n\n- verb → m\n- noun → z\n\n### Example 2: Rotating stimulus conditions\n\nConsider a masked-priming experiment in which participants read target words aloud. On each trial, the target word is preceded by one of three types of priming words:\n\n- An unrelated prime, e.g. priming with 'berry' for target 'house'.\n- An ortoghraphically related prime, e.g. priming with 'mouse' for target 'house'\n- A semantically related prime, e.g. priming with 'garden' for target 'house'\n\nTo avoid repetition effects, you only want to show target words only once per participant. Therefore, you create three different sets of target words, one for each prime type. This is a between-word design, which has less statistical power than a within-word design, in which each target word occurs in each condition. (For the same reason that between-subject designs are less powerful than within-subject designs.)\n\nYou can use counterbalancing to change this experiment into a within-word design by 'rotating' the condition in which each word occurs between participants. We have three conditions, and we therefore have three groups of participants:\n\n- Participants 1, 4, 7, etc.\n    - Word A in condition 1\n    - Word B in condition 2\n    - Word C in condition 3\n- Participants 2, 5, 8, etc.\n    - Word A in condition 2\n    - Word B in condition 3\n    - Word C in condition 1\n- Participants 3, 6, 9, etc.\n    - Word A in condition 3\n    - Word B in condition 1\n    - Word C in condition 2\n\n\n## Implementing counterbalancing\n\n\n### Using the subject number\n\nWhen you run an experiment in OpenSesame on the desktop, you are asked for a subject number. When you run an experiment online, a subject number is randomly selected from the list of possible subject numbers that you have specified in the [OSWeb extension](%url:osweb). (This means that for online experiments you cannot ensure that the number of participants is exactly equal for the different conditions that you want to counterbalance, at least not if you rely on the subject number.)\n\nThis subject number is available as the experimental variable `subject_nr`. In  addition, the experimental variable `subject_parity` has the value 'odd' or 'even', depending on whether the subject number is odd or even. Now say that you want to counterbalance the response rule as in Example 1, you could add the following INLINE_SCRIPT to the start of the experiment.\n\n```python\nif subject_parity == 'odd':\n    verb_response = 'z'\n    noun_response = 'm'\nelse:\n    verb_response = 'm'\n    noun_response = 'z'\n```\n\nOr, when creating an OSWeb experiment, add the following INLINE_JAVASCRIPT to the start of the experiment:\n\n```javascript\nif (subject_parity === 'odd') {\n    verb_response = 'z'\n    noun_response = 'm'\n} else {\n    verb_response = 'm'\n    noun_response = 'z'\n}\n```\n\nNow, in your *block_loop*, instead of setting `correct_response` to a fixed value, you set it to a variable: `{verb_response}` or `{noun_response}`. You can take a look at the *lexical-decision task* example to see how this works (Menu -> Tools -> Example experiments).\n\n\n### Using Batch Session Data (JATOS and OSWeb only)": {
    "fr": "La contrebalancement est une méthode pour éliminer les facteurs de confusion d'une expérience en proposant des tâches légèrement différentes pour différents groupes de participants. Cela semble abstrait, alors examinons deux exemples.\n\n<notranslate>[TOC]</notranslate>\n\n### Exemple 1 : Contrebalancement de la règle de réponse\n\nPrenons une expérience de décision lexicale dans laquelle les participants classent les mots en verbes en appuyant sur 'z' avec leur main gauche, ou en noms en appuyant sur 'm' avec leur main droite. Ce plan a un problème : si vous constatez que les participants répondent plus rapidement aux noms qu'aux verbes, cela pourrait être parce que les noms sont traités plus rapidement que les verbes, ou parce que les participants répondent plus rapidement avec leur main droite qu'avec leur main gauche. Vous pouvez résoudre ce problème en contrebalançant la règle de réponse.\n\nPour un nombre pair de participants :\n\n- verbe → z\n- nom → m\n\nPour un nombre impair de participants :\n\n- verbe → m\n- nom → z\n\n### Exemple 2 : Rotation des conditions de stimulus\n\nPrenons une expérience d'amorçage masqué dans laquelle les participants lisent à haute voix des mots cibles. À chaque essai, le mot cible est précédé par l'un des trois types de mots d'amorçage :\n\n- Un amorce non liée, par exemple amorcer avec 'baie' pour la cible 'maison'.\n- Une amorce orthographiquement liée, par exemple amorcer avec 'souris' pour la cible 'maison'.\n- Une amorce sémantiquement liée, par exemple amorcer avec 'jardin' pour la cible 'maison'.\n\nPour éviter les effets de répétition, vous ne voulez montrer les mots cibles qu'une seule fois par participant. Par conséquent, vous créez trois ensembles différents de mots cibles, un pour chaque type d'amorce. Il s'agit d'un plan entre mots, qui a moins de puissance statistique qu'un plan intra-mots, dans lequel chaque mot cible se produit dans chaque condition. (Pour la même raison que les plans entre-sujets sont moins puissants que les plans intra-sujets.)\n\nVous pouvez utiliser le contrebalancement pour transformer cette expérience en un plan intra-mots en faisant « tourner » la condition dans laquelle chaque mot apparaît entre les participants. Nous avons trois conditions et donc trois groupes de participants :\n\n- Participants 1, 4, 7, etc.\n    - Mot A en condition 1\n    - Mot B en condition 2\n    - Mot C en condition 3\n- Participants 2, 5, 8, etc.\n    - Mot A en condition 2\n    - Mot B en condition 3\n    - Mot C en condition 1\n- Participants 3, 6, 9, etc.\n    - Mot A en condition 3\n    - Mot B en condition 1\n    - Mot C en condition 2\n\n## Mise en œuvre du contrebalancement\n\n### En utilisant le numéro de sujet\n\nLorsque vous exécutez une expérience dans OpenSesame sur le bureau, on vous demande un numéro de sujet. Lorsque vous exécutez une expérience en ligne, un numéro de sujet est sélectionné au hasard dans la liste des numéros de sujet possibles que vous avez spécifiés dans l'[extension OSWeb](%url:osweb). (Cela signifie que pour les expériences en ligne, vous ne pouvez pas garantir que le nombre de participants est exactement égal pour les différentes conditions que vous souhaitez contrebalancer, du moins pas si vous comptez sur le numéro de sujet.)\n\nCe numéro de sujet est disponible sous la forme de la variable expérimentale `subject_nr`. De plus, la variable expérimentale `subject_parity` a la valeur \"impair\" ou \"pair\", selon que le numéro de sujet est impair ou pair. Maintenant, disons que vous voulez contrebalancer la règle de réponse comme dans l'exemple 1, vous pouvez ajouter le SCRIPT_EN_LIGNE suivant au début de l'expérience.\n\n```python\nif subject_parity == 'odd':\n    verb_response = 'z'\n    noun_response = 'm'\nelse:\n    verb_response = 'm'\n    noun_response = 'z'\n```\n\nOu, lors de la création d'une expérience OSWeb, ajoutez le INLINE_JAVASCRIPT suivant au début de l'expérience :\n\n```javascript\nif (subject_parity === 'odd') {\n    verb_response = 'z'\n    noun_response = 'm'\n} else {\n    verb_response = 'm'\n    noun_response = 'z'\n}\n```\n\nMaintenant, dans votre *block_loop*, au lieu de définir `correct_response` sur une valeur fixe, vous le définissez sur une variable : `{verb_response}` ou `{noun_response}`. Vous pouvez jeter un coup d'œil à l'exemple de *tâche de décision lexicale* pour voir comment cela fonctionne (Menu -> Outils -> Expériences d'exemple).\n\n\n### En utilisant les données de session Batch (JATOS et OSWeb uniquement)"
  },
  "- For each letter canvas in the letter-canvas list\n    - Show the letter canvas\n    - Wait for `letter_dur` milliseconds\n    - Show the blank canvas\n    - Wait for `isi` milliseconds\n\nThis translates almost directly into Python:\n\n~~~ .python\nfor letter_canvas in letter_canvas_list:\n    letter_canvas.show()\n    clock.sleep(var.letter_dur)\n    blank_canvas.show()\n    clock.sleep(var.isi)\n~~~\n\nDone!\n\n<div class='info-box' markdown='1'>\n\n### Links\n\n- [/python/about/](/python/about/)\n- [/python/canvas/](/python/canvas/)\n- [/python/clock/](/python/clock/)\n\n</div>\n\n## Step 11: Create fixation point\n\nAfter all this coding, it's time to get back to something simpler: Defining the fixation point. Click on *fixation* in to open the item. Change the duration to 995. This value will be rounded up to the nearest value compatible with your monitors refresh rate, which is 1000 ms for most common refresh rates. Draw a fixation dot in the center, using the fixation-dot tool (the dot with the little hole in it).\n\n<notranslate>\nfigure:\n id: FigFixation\n source: FigFixation.png\n caption: |\n  The *fixation* SKETCHPAD after Step 11.\n</notranslate>\n\n## Step 12: Define response collection\n\nWe will collect responses as follows:\n\n- Ask for T1\n- Collect a response, which is a single key press that corresponds to T1. So if T1 was 'A', the participant should press the 'a' key.\n- Ask for T2\n- Collect a response, which is 'y' when T2 was present and 'n' when T2 was absent.\n\nWe will use the *ask_T1* SKETCHPAD to ask the participant for T1. Click on *ask_T1* to open the item, and add a line of text, such as 'Please type the white letter'. Change the duration to 0. This 0 ms duration does not mean that the text is only shown for 0 ms, but that the experiment moves immediately to the next item, which is *response_T1*.\n\nOpen *response_T1*. The only thing that we have to do is define the correct response. To do this, we can use the `T1` experimental variable that we have set while preparing the RSVP stream. Therefore, enter '[T1]' in the 'Correct response' field.\n\nOpen *ask_T2*, and add a line of text, such as 'Did you see an X? (y/n)'. Again, set the duration to 0, so that the experiment moves immediately to the next item, which is *response_T2*.\n\nOpen *response_T2*. Again, we need to define the correct response, this time using the variable `T2_present`, which we had defined in the *block_loop*. Therefore, add '[T2_present]' to the 'Correct response' field. It's also useful to restrict the allowed responses to 'y' and 'n', so that participants don't accidentally press the wrong key. You can do this by entering a semicolon-separated list of keys in the 'Allowed responses' field (i.e. 'y;n').\n\nSo how will the responses be logged? Each response item sets `response`, `correct`, and `response_time` variables. In addition, to distinguish responses set by different items, each response item sets these same variables followed by `_[item name]`. In other words, in this experiment the response variables of interests would be `correct_T1_response` and `correct_T2_response`.\n\n<div class='info-box' markdown='1'>\n\n### Links\n\n- [/usage/collecting-responses/](/usage/collecting-responses/)\n- [/usage/text/](/usage/text/)\n\n</div>\n\n## Step 13: Specify number and length of blocks\n\nYou now have a fully working experiment, but one thing still needs to be done: Setting the length and number of blocks. We will use the following structure:\n\n- 1 practice block of 9 trials in each conditon.\n- 5 experimental blocks of 36 trials in each condition.": {
    "fr": "- Pour chaque canvas de lettre dans la liste letter-canvas\n    - Afficher le canvas de lettre\n    - Attendre `letter_dur` millisecondes\n    - Afficher le canvas vide\n    - Attendre `isi` millisecondes\n\nCela se traduit presque directement en Python :\n\n~~~ .python\nfor letter_canvas in letter_canvas_list:\n    letter_canvas.show()\n    clock.sleep(var.letter_dur)\n    blank_canvas.show()\n    clock.sleep(var.isi)\n~~~\n\nFait !\n\n<div class='info-box' markdown='1'>\n\n### Liens\n\n- [/python/about/](/python/about/)\n- [/python/canvas/](/python/canvas/)\n- [/python/clock/](/python/clock/)\n\n</div>\n\n## Étape 11 : Créer un point de fixation\n\nAprès tout ce codage, il est temps de revenir à quelque chose de plus simple : définir le point de fixation. Cliquez sur *fixation* pour ouvrir l'élément. Changez la durée à 995. Cette valeur sera arrondie à la valeur la plus proche compatible avec le taux de rafraîchissement de votre moniteur, qui est de 1000 ms pour la plupart des taux de rafraîchissement courants. Dessinez un point de fixation au centre, en utilisant l'outil fixation-dot (le point avec le petit trou dedans).\n\n<notranslate>\nfigure:\n id: FigFixation\n source: FigFixation.png\n caption: |\n  Le SKETCHPAD *fixation* après l'étape 11.\n</notranslate>\n\n## Étape 12 : Définir la collecte des réponses\n\nNous allons collecter les réponses comme suit :\n\n- Demander T1\n- Collecter une réponse, qui est une seule pression de touche correspondant à T1. Donc si T1 était 'A', le participant devrait appuyer sur la touche 'a'.\n- Demander T2\n- Collecter une réponse, qui est 'y' lorsque T2 était présent et 'n' lorsque T2 était absent.\n\nNous utiliserons le SKETCHPAD *ask_T1* pour demander T1 au participant. Cliquez sur *ask_T1* pour ouvrir l'élément, et ajoutez une ligne de texte, comme \"Veuillez taper la lettre blanche\". Changez la durée à 0. Cette durée de 0 ms ne signifie pas que le texte est montré seulement pendant 0 ms, mais que l'expérience passe immédiatement à l'élément suivant, qui est *response_T1*.\n\nOuvrez *response_T1*. La seule chose que nous avons à faire est de définir la réponse correcte. Pour ce faire, nous pouvons utiliser la variable expérimentale `T1` que nous avons définie lors de la préparation du flux RSVP. Par conséquent, entrez '[T1]' dans le champ 'Réponse correcte'.\n\nOuvrez *ask_T2*, et ajoutez une ligne de texte, comme \"Avez-vous vu un X ? (y/n)\". Là encore, réglez la durée sur 0, afin que l'expérience passe immédiatement à l'élément suivant, qui est *response_T2*.\n\nOuvrez *response_T2*. Là encore, nous devons définir la réponse correcte, cette fois en utilisant la variable `T2_present`, que nous avions définie dans le *block_loop*. Par conséquent, ajoutez '[T2_present]' dans le champ 'Réponse correcte'. Il est également utile de limiter les réponses autorisées à 'y' et 'n', afin que les participants n'appuient pas accidentellement sur la mauvaise touche. Vous pouvez le faire en entrant une liste de touches séparées par des points-virgules dans le champ 'Réponses autorisées' (c'est-à-dire 'y;n').\n\nComment les réponses seront-elles enregistrées ? Chaque élément de réponse définit des variables `response`, `correct` et `response_time`. De plus, pour distinguer les réponses définies par différents éléments, chaque élément de réponse définit ces mêmes variables suivies de `_[item name]`. En d'autres termes, dans cette expérience, les variables de réponse intéressantes seraient `correct_T1_response` et `correct_T2_response`.\n\n<div class='info-box' markdown='1'>\n\n### Liens\n\n- [/usage/collecting-responses/](/usage/collecting-responses/)\n- [/usage/text/](/usage/text/)\n\n</div>\n\n## Étape 13 : Spécifier le nombre et la longueur des blocs\n\nVous avez maintenant une expérience entièrement fonctionnelle, mais une chose doit encore être faite : définir la longueur et le nombre de blocs. Nous utiliserons la structure suivante :\n\n- 1 bloc de pratique de 9 essais dans chaque condition.\n- 5 blocs expérimentaux de 36 essais dans chaque condition."
  },
  "The *backend* is the software layer that deals with input (keyboard input, mouse input, etc.) and output (display presentation, sound playback, etc.). There are many libraries that offer this type of functionality and OpenSesame could, in principle, use any one of them. For this reason, OpenSesame is backend-independent, in the sense that you can choose which backend should be used. Currently there are four backends: *legacy*, *psycho*, *xpyriment*, and *osweb*.\n\n<notranslate>[TOC]</notranslate>\n\n## Differences and some tips\n\nUsually, you won't notice which backend is used. The differences between backends are largely technical, and, as long as you use the graphical user interface, all backends work more ore less the same way. However, there are a few reasons to prefer one backend over another:\n\n- If you want to run the experiment in a browser, you need to select the *osweb* backend.\n- Backend differs in [temporal precision](%link:timing%).\n\t- Tip: If you care about millisecond temporal precision, use *xpyriment* or *psycho*.\n- Backends differ in how long stimulus preparation takes.\n\t- Tip: If [forms](%link:manual/forms/about%) are slow, use *legacy*.\n\t- Tip: If the intertrial interval is long (due to stimulus preparation), use *legacy*.\n- You can use backend-specific functionality when writing Python code.\n\t- Tip: If you want to use PsychoPy functionality, use *psycho*.\n\t- Tip: If you want to use Expyriment functionality, use *xpyriment*.\n\t- Tip: If you want to use PyGame functionality, use *legacy*.\n- Some backends are not available on all platforms.\n\n## Selecting a backend\n\nYou can select a backend in the general properties of the experiment (%FigSelect).\n\n<notranslate>\nfigure:\n id: FigSelect\n source: fig-select.png\n caption: \"Selecting a backend\"\n</notranslate>\n\nIf you view the general script (select \"Show script editor\"), you will see that there are actually six distinct backends: canvas, keyboard, mouse, sampler, color, and clock. The combobox-method automatically selects an appropriate, predefined combination of backends, but you could, in theory, mix and match.\n\nFor example, if you select the *xpyriment* backend, the following code will be generated:\n\n\tset sampler_backend legacy\n\tset mouse_backend xpyriment\n\tset keyboard_backend legacy\n\tset color_backend legacy\n\tset clock_backend legacy\n\tset canvas_backend xpyriment\n\n## xpyriment\n\nThe *xpyriment* backend is built on top of [Expyriment][], a library designed for creating psychology experiments. It is a light-weight hardware-accelerated backend with excellent timing properties. If you care about temporal precision, but do not plan on generating complex stimuli (i.e. Gabor patches, random-dot gratings, etc.) *xpyriment* is a good choice.\n\n### Using Expyriment directly\n\nYou can find extensive documentation on Expyriment at <http://www.expyriment.org/doc>. The following code snippet shows a line of text:\n\n~~~ .python\nfrom expyriment import stimuli\ntext = stimuli.TextLine('This is expyriment!')\ntext.present()\n~~~\n\n### Citation\n\nAlthough Expyriment is bundled with the binary distributions of OpenSesame, it is a separate project. When appropriate, please provide the following citation in addition to citing OpenSesame:\n\nKrause, F., & Lindemann, O. (in press). Expyriment: A Python library for cognitive and neuroscientific experiments. *Behavior Research Methods*.\n{: .reference}\n\n## psycho\n\nThe psycho backend is built on top of [PsychoPy][], a library designed for creating psychology experiments. It is hardware accelerated and provides high-level routines for creating complex visual stimuli (drifting gratings, etc.). If you care about timing and plan on creating complex stimuli, Psycho is a good choice.\n\n### Using PsychoPy directly": {
    "fr": "Le *backend* est la couche logicielle qui traite les entrées (entrée clavier, entrée souris, etc.) et les sorties (présentation de l'affichage, lecture du son, etc.). Il existe de nombreuses bibliothèques offrant ce type de fonctionnalité et OpenSesame pourrait, en principe, utiliser n'importe laquelle d'entre elles. Pour cette raison, OpenSesame est indépendant du backend, en ce sens que vous pouvez choisir quel backend doit être utilisé. Actuellement, il existe quatre backends : *legacy*, *psycho*, *xpyriment* et *osweb*.\n\n<notranslate>[TOC]</notranslate>\n\n## Différences et quelques conseils\n\nHabituellement, vous ne remarquerez pas quel backend est utilisé. Les différences entre les backends sont en grande partie techniques et, tant que vous utilisez l'interface utilisateur graphique, tous les backends fonctionnent plus ou moins de la même manière. Cependant, il y a quelques raisons de préférer un backend à un autre :\n\n- Si vous souhaitez exécuter l'expérience dans un navigateur, vous devez sélectionner le backend *osweb*.\n- Les backends diffèrent en [précision temporelle](%link:timing%).\n\t- Conseil : Si vous vous souciez de la précision temporelle en millisecondes, utilisez *xpyriment* ou *psycho*.\n- Les backends diffèrent dans la durée de préparation des stimuli.\n\t- Conseil : Si les [formulaires](%link:manual/forms/about%) sont lents, utilisez *legacy*.\n\t- Conseil : Si l'intervalle inter-essais est long (en raison de la préparation des stimuli), utilisez *legacy*.\n- Vous pouvez utiliser des fonctionnalités spécifiques au backend en écrivant du code Python.\n\t- Conseil : Si vous souhaitez utiliser les fonctionnalités de PsychoPy, utilisez *psycho*.\n\t- Conseil : Si vous souhaitez utiliser les fonctionnalités d'Expyriment, utilisez *xpyriment*.\n\t- Conseil : Si vous souhaitez utiliser les fonctionnalités de PyGame, utilisez *legacy*.\n- Certains backends ne sont pas disponibles sur toutes les plateformes.\n\n## Sélection d'un backend\n\nVous pouvez sélectionner un backend dans les propriétés générales de l'expérience (%FigSelect).\n\n<notranslate>\nfigure:\n id: FigSelect\n source: fig-select.png\n caption: \"Sélection d'un backend\"\n</notranslate>\n\nSi vous affichez le script général (sélectionnez \"Afficher l'éditeur de script\"), vous verrez qu'il y a en réalité six backends distincts : canvas, keyboard, mouse, sampler, color et clock. La méthode combobox sélectionne automatiquement une combinaison appropriée et prédéfinie de backends, mais vous pourriez, en théorie, les mélanger et les assortir.\n\nPar exemple, si vous sélectionnez le backend *xpyriment*, le code suivant sera généré :\n\n\tset sampler_backend legacy\n\tset mouse_backend xpyriment\n\tset keyboard_backend legacy\n\tset color_backend legacy\n\tset clock_backend legacy\n\tset canvas_backend xpyriment\n\n## xpyriment\n\nLe backend *xpyriment* est basé sur [Expyriment][], une bibliothèque conçue pour créer des expériences de psychologie. C'est un backend léger et accéléré par le matériel avec d'excellentes propriétés de synchronisation. Si vous vous souciez de la précision temporelle, mais ne prévoyez pas de générer des stimuli complexes (c'est-à-dire des patchs Gabor, des grilles de points aléatoires, etc.), *xpyriment* est un bon choix.\n\n### Utilisation d'Expyriment directement\n\nVous pouvez trouver une documentation détaillée sur Expyriment à l'adresse <http://www.expyriment.org/doc>. L'extrait de code suivant montre une ligne de texte :\n\n~~~ .python\nfrom expyriment import stimuli\ntext = stimuli.TextLine('Ceci est expyriment !')\ntext.present()\n~~~\n\n### Citation\n\nBien qu'Expyriment soit inclus avec les distributions binaires d'OpenSesame, il s'agit d'un projet distinct. Lorsque cela est approprié, veuillez fournir la citation suivante en plus de citer OpenSesame :\n\nKrause, F., & Lindemann, O. (sous presse). Expyriment: A Python library for cognitive and neuroscientific experiments. *Behavior Research Methods*.\n{: .reference}\n\n## psycho\n\nLe backend psycho est construit sur [PsychoPy][], une bibliothèque conçue pour créer des expériences de psychologie. Il est accéléré par le matériel et fournit des routines de haut niveau pour créer des stimuli visuels complexes (gratings en mouvement, etc.). Si vous vous souciez de la synchronisation et prévoyez de créer des stimuli complexes, Psycho est un bon choix.\n\n### Utilisation de PsychoPy directement"
  },
  "\nNow return to the *card_display*. Every item in OpenSesame is defined through a script. This script is generated automatically by the user interface. Sometimes it can be convenient (or even necessary) to edit this script directly. The most common reason for editing an item's script is to add variables to the script, which is also what we will do now!\n\nTo view the script, click on the 'View' button and select 'View script'. (The view button is the middle button at the top right of the item controls.) This will open a script editor.\n\nThe script for *card_display* mostly consists of `draw` commands, which define each of the five cards, and also the various text elements. Locate the line that corresponds to the response card. You can find it by looking at the Y coordinate, which should be positive (i.e. at the lower part of the display), or by looking at the name of the image file.\n\n```\ndraw image center=1 file=\"1-blue-triangle.png\" scale=0.5 show_if=always x=0 y=192 z_index=0\n```\n\nRight now, in my example, the image file for the response card is always `\"1-blue-triangle.png\"`. But of course we don't always want to show a single blue triangle. Instead, we want to have the image file depend on the variables that we have defined in the *block_loop*. To do so, replace the number by `[response_number]`, the color by `[response_color]`, and the shape by `[response_shape]`: (The square brackets indicate that these refer to names of variables.)\n\n\n```\ndraw image center=1 file=\"[response_number]-[response_color]-[response_shape].png\" scale=0.5 show_if=always x=0 y=192 z_index=0\n```\n\nClick on Apply to accept the changes to the script. The response card has now been replaced by a question-mark icon. This is because OpenSesame doesn't know how to show a preview of an image that has been defined using variables. But don't worry: the image will be shown when you run the experiment!\n\n\n### Step 6: Make the stimulus cards variable\n\nThe stimulus cards should be more-or-less randomly selected, but each color, shape, and number should occur only once; that is, there should never be two red cards or two cards with triangles. (If there were, the matching procedure would become ambiguous.) To accomplish this, we can use *horizontal shuffling*, which is a powerful but unusual feature of the LOOP item.\n\n- %link:loop%\n\nFirst, open the *block_loop* and create 12 (!) new columns to define the stimulus cards: `color1`, for the color of the first card, `color2`, `color3`, `color4`, and `shape1` … `shape4`, and `number1` … `number4`. Each column has the same value on every row (see %FigLoopTable2).\n\n\n<notranslate>\nfigure:\n id: FigLoopTable2\n source: loop-table-2.png\n caption: |\n  The *block_loop* during step 6.\n</notranslate>\n\n\nBut we're not done yet! Right now, the first stimulus card is always a single red circle, the second two blue triangles, etc. To randomize this we tell OpenSesame to randomly swap (horizontally shuffle) the values of the four color variables, the four shape variables, and the four number variables. To do so, open the script for the *block_loop*. At the semi-last line (right before `run trial_sequence`) add the following commands:\n\n```\nshuffle_horiz color1 color2 color3 color4\nshuffle_horiz shape1 shape2 shape3 shape4\nshuffle_horiz number1 number2 number3 number4\n```\n\nClick on Apply to accept the script. To see if this has worked, click on the Preview button. This will show a preview of how the LOOP table will be randomized during the experiment. Does it look good?\n\nNow return to the *card_display* and have the image of the first stimulus card depend on the variable `color1`, `shape1`, and `number1`, and analogously for the other stimulus cards. (If you're unsure how to do this, revisit step 5.)\n\n\n### Step 7: Determine the correct response (for one matching rule)\n\n\nFor now, we're going to assume that participants always match by shape. (One of the Extra Assignments is to improve this.)": {
    "fr": "Revenez maintenant au *card_display*. Chaque élément d'OpenSesame est défini par un script. Ce script est généré automatiquement par l'interface utilisateur. Parfois, il peut être pratique (ou même nécessaire) de modifier ce script directement. La raison la plus courante de modifier le script d'un élément est d'ajouter des variables au script, ce que nous ferons maintenant !\n\nPour afficher le script, cliquez sur le bouton \"View\" et sélectionnez \"View script\". (Le bouton \"View\" est le bouton du milieu en haut à droite des contrôles de l'élément.) Cela ouvrira un éditeur de script.\n\nLe script pour *card_display* se compose principalement de commandes `draw`, qui définissent chacune des cinq cartes, ainsi que des divers éléments textuels. Repérez la ligne correspondant à la carte de réponse. Vous pouvez la trouver en regardant la coordonnée Y, qui devrait être positive (c'est-à-dire dans la partie inférieure de l'affichage), ou en regardant le nom du fichier image.\n\n```\ndraw image center=1 file=\"1-blue-triangle.png\" scale=0.5 show_if=always x=0 y=192 z_index=0\n```\n\nActuellement, dans mon exemple, le fichier image de la carte de réponse est toujours `\"1-blue-triangle.png\"`. Mais bien sûr, nous ne voulons pas toujours montrer un seul triangle bleu. Au lieu de cela, nous voulons que le fichier image dépende des variables que nous avons définies dans le *block_loop*. Pour ce faire, remplacez le nombre par `[response_number]`, la couleur par `[response_color]`, et la forme par `[response_shape]`: (Les crochets indiquent que ceux-ci font référence à des noms de variables.)\n\n```\ndraw image center=1 file=\"[response_number]-[response_color]-[response_shape].png\" scale=0.5 show_if=always x=0 y=192 z_index=0\n```\n\nCliquez sur \"Apply\" pour accepter les modifications apportées au script. La carte de réponse a maintenant été remplacée par une icône en forme de point d'interrogation. C'est parce qu'OpenSesame ne sait pas comment montrer un aperçu d'une image qui a été définie en utilisant des variables. Mais ne vous inquiétez pas : l'image sera affichée lorsque vous exécuterez l'expérience!\n\n### Étape 6 : Rendre les cartes stimulus variables\n\nLes cartes stimulus doivent être sélectionnées plus ou moins au hasard, mais chaque couleur, forme et nombre doit apparaître une seule fois ; c'est-à-dire qu'il ne devrait jamais y avoir deux cartes rouges ou deux cartes avec des triangles. (S'il y en avait, la procédure de correspondance deviendrait ambiguë.) Pour ce faire, nous pouvons utiliser la *mélange horizontal*, qui est une fonctionnalité puissante mais inhabituelle de l'élément LOOP.\n\n- %link:loop%\n\nTout d'abord, ouvrez le *block_loop* et créez 12 (!) nouvelles colonnes pour définir les cartes stimulus : `color1`, pour la couleur de la première carte, `color2`, `color3`, `color4`, et `shape1` ... `shape4`, et `number1` ... `number4`. Chaque colonne a la même valeur sur chaque ligne (voir %FigLoopTable2).\n\n<notranslate>\nfigure:\n id: FigLoopTable2\n source: loop-table-2.png\n caption: |\n  Le *block_loop* lors de l'étape 6.\n</notranslate>\n\nMais nous n'avons pas encore terminé ! Actuellement, la première carte stimulus est toujours un cercle rouge unique, la deuxième deux triangles bleus, etc. Pour mélanger cela, nous disons à OpenSesame d'échanger aléatoirement (mélanger horizontalement) les valeurs des quatre variables de couleur, des quatre variables de forme et des quatre variables de nombre. Pour ce faire, ouvrez le script pour le *block_loop*. À l'avant-dernière ligne (juste avant `run trial_sequence`) ajoutez les commandes suivantes:\n\n```\nshuffle_horiz color1 color2 color3 color4\nshuffle_horiz shape1 shape2 shape3 shape4\nshuffle_horiz number1 number2 number3 number4\n```\n\nCliquez sur \"Apply\" pour accepter le script. Pour voir si cela a fonctionné, cliquez sur le bouton Preview (Aperçu). Cela montrera un aperçu de comment la table LOOP sera mélangée au hasard pendant l'expérience. Est-ce que ça a l'air bien ?\n\nRevenez maintenant au *card_display* et faites en sorte que l'image de la première carte stimulus dépende de la variable `color1`, `shape1`, et `number1`, et analogiquement pour les autres cartes stimulus. (Si vous ne savez pas comment faire, reprenez l'étape 5.)\n\n### Étape 7 : Déterminer la réponse correcte (pour une règle de correspondance)\n\nPour l'instant, nous allons supposer que les participants font toujours correspondre la forme. (L'une des missions supplémentaires consiste à améliorer cela.)"
  },
  "When running an OSWeb experiment that is hosted on JATOS, you can make use of [Batch Session Data](https://www.jatos.org/jatos.js-Reference.html#functions-to-access-the-batch-session). This is data that is shared between all experimental sessions that are part of the same worker batch. Therefore, you can use this data to define a list of conditions that should be distributed across participants. At the start of each experimental session, one condition is removed from this list and used for the current session. This is the most sophisticated way to implement counterbalancing for OSWeb experiments that are hosted on JATOS.\n\nYou can download a template experiment here:\n\n- %static:attachments/counterbalancing-osweb-jatos.osexp%\n\nWhen running from JATOS, the experiment retrieves a single condition from the Batch Session Data (see below) and registers this as the experimental variable `condition`. When doing a test run, `condition` is set to a default value specified at the end of *init_condition*.\n\nThe experiment itself should be implemented in the *experiment* SEQUENCE, which in the template contains only the *show_condition* SKETCHPAD (see %FigCounterbalancingOSWebJATOS).\n\n<notranslate>\nfigure:\n    source: counterbalancing-osweb-jatos.png\n    id: FigCounterbalancingOSWebJATOS\n    caption: |\n        The overview area of the template experiment for implementing counterbalancing with JATOS Batch Session Data.\n</notranslate>\n\nWhen importing the experiment into JATOS, all conditions should be specified in the Batch Session Data as the `pending` list (under Worker & Batch Manager; see %FigBatchSessionData). Each condition from `pending` corresponds to a single experimental session; therefore, if condition `a` should be used for two experimental sessions, then `a` needs to occur twice in the `pending` list. The conditions are used in the order in which they are defined.\n\n<notranslate>\nfigure:\n    source: batch-session-data.png\n    id: FigBatchSessionData\n    caption: |\n        The conditions should be specified in the Batch Session Data in JATOS.\n</notranslate>\n\nAt the start of an experimental session, a single condition is moved from `pending` to `started`. (When the `pending` list is empty, the participant is informed that he or she can no longer participate in the experiment.) At the end of the experimental session, the condition is appended to the `finished` list.\n\nTo make this more concrete, let's say that you've defined the Batch Session Data as shown in %FigBatchSessionData. Then, four experimental sessions are started, but the second experimental session, with condition `a`, never finishes, for example because the participant closes the browser halfway the experiment. The Batch Session Data will then look as in %FigBatchSessionAfter:\n\n<notranslate>\nfigure:\n    source: batch-session-data-after.png\n    id: FigBatchSessionAfter\n    caption: |\n        The Batch Session Data after all conditions have been consumed. One session, with condition `a`, never finished.\n</notranslate>\n\nYou can tell from the Batch Session Data that one experimental session started with condition `a` but never finished. To nevertheless collect an experimental session with this condition, you have to manually add a new `a` to the `pending` list and collect a new session.\n": {
    "fr": "Lors de l'exécution d'une expérience OSWeb hébergée sur JATOS, vous pouvez utiliser les [Données de Session de Lot](https://www.jatos.org/jatos.js-Reference.html#functions-to-access-the-batch-session). Il s'agit de données partagées entre toutes les sessions expérimentales faisant partie du même lot de travailleurs. Vous pouvez donc utiliser ces données pour définir une liste de conditions à répartir entre les participants. Au début de chaque session expérimentale, une condition est retirée de cette liste et utilisée pour la session en cours. Il s'agit de la manière la plus sophistiquée de mettre en œuvre le contrebalancement pour les expériences OSWeb hébergées sur JATOS.\n\nVous pouvez télécharger un modèle d'expérience ici :\n\n- %static:attachments/counterbalancing-osweb-jatos.osexp%\n\nLors de l'exécution sur JATOS, l'expérience récupère une seule condition à partir des Données de Session de Lot (voir ci-dessous) et l'enregistre en tant que variable expérimentale `condition`. Lors d'un test, `condition` est définie sur une valeur par défaut spécifiée à la fin de *init_condition*.\n\nL'expérience elle-même doit être mise en œuvre dans la SEQUENCE *experiment*, qui dans le modèle ne contient que l'élément SKETCHPAD *show_condition* (voir %FigCounterbalancingOSWebJATOS).\n\n<notranslate>\nfigure:\n    source: counterbalancing-osweb-jatos.png\n    id: FigCounterbalancingOSWebJATOS\n    caption: |\n        La zone d'aperçu du modèle d'expérience pour mettre en œuvre le contrebalancement avec JATOS Batch Session Data.\n</notranslate>\n\nLors de l'importation de l'expérience dans JATOS, toutes les conditions doivent être spécifiées dans les Données de Session de Lot sous forme de liste `pending` (sous Worker & Batch Manager; voir %FigBatchSessionData). Chaque condition de `pending` correspond à une seule session expérimentale ; ainsi, si la condition `a` doit être utilisée pour deux sessions expérimentales, alors `a` doit apparaître deux fois dans la liste `pending`. Les conditions sont utilisées dans l'ordre dans lequel elles sont définies.\n\n<notranslate>\nfigure:\n    source: batch-session-data.png\n    id: FigBatchSessionData\n    caption: |\n        Les conditions doivent être spécifiées dans les Données de Session de Lot dans JATOS.\n</notranslate>\n\nAu début d'une session expérimentale, une seule condition est déplacée de `pending` à `started`. (Lorsque la liste `pending` est vide, le participant est informé qu'il ne peut plus participer à l'expérience.) À la fin de la session expérimentale, la condition est ajoutée à la liste `finished`.\n\nPour rendre cela plus concret, disons que vous avez défini les Données de Session de Lot comme indiqué dans %FigBatchSessionData. Ensuite, quatre sessions expérimentales sont lancées, mais la deuxième session expérimentale, avec la condition `a`, ne se termine jamais, par exemple parce que le participant ferme le navigateur à mi-parcours de l'expérience. Les Données de Session de Lot ressembleront alors à celles de %FigBatchSessionAfter :\n\n<notranslate>\nfigure:\n    source: batch-session-data-after.png\n    id: FigBatchSessionAfter\n    caption: |\n        Les Données de Session de Lot après que toutes les conditions ont été consommées. Une session, avec la condition `a`, n'a jamais été terminée.\n</notranslate>\n\nVous pouvez constater à partir des Données de Session de Lot qu'une session expérimentale a commencé avec la condition `a` mais ne s'est jamais terminée. Pour néanmoins recueillir une session expérimentale avec cette condition, vous devez ajouter manuellement un nouveau `a` à la liste `pending` et collecter une nouvelle session."
  },
  "First, open *block_loop*. The 'Repeat' value is currently set to 1, which means that each trial is executed once, giving a block length of 18 trials. We want to specify the 'Repeat' value with a variable, so that we can have a different value for the practice and experimental blocks. To do this, we need to make a small modification to the script of *block_loop*. Click on the 'View' button in top-right of the tab (the middle of the three buttons), and select 'View script'. This will hide the graphical controls, and show the underlying OpenSesame script. Now change this line ...\n\n~~~\nset repeat \"1\"\n~~~\n\n... to ...\n\n~~~\nset repeat \"[block_repeat]\"\n~~~\n\n... and click 'Apply and close'. This means that the variable `repeat` is now defined in terms of another variable, `block_repeat`. OpenSesame will tell you that it doesn't know the length of the block anymore (see %FigVariableLoop), but that's ok: As long as the variable `block_repeat` is defined, things will work fine.\n\n<notranslate>\nfigure:\n id: FigVariableLoop\n source: FigVariableLoop.png\n caption: |\n  If the length of a LOOP is variably defined, OpenSesame notifies you of this.\n</notranslate>\n\nNow open *practice_loop*. Add a variable `block_repeat` and give it the value 0.5. This means that 0.5 x 18 = 9 cycles of *block_loop* will be executed, just as we want.\n\nNow open *experimental_loop*. Again, add a variable `block_repeat` and give it the value 2. This means that each block has a length of 2 x 18 = 36 trials. Also, change the number of cycles to 10, and arrange the loop table so that you first have five blocks of `condition1`, followed by five blocks of `condition2` (see %FigExperimentalLoop).\n\n<notranslate>\nfigure:\n id: FigExperimentalLoop\n source: FigExperimentalLoop.png\n caption: |\n  If the length of a LOOP is variably defined, OpenSesame notifies you of this.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n### Links\n\n- [/usage/opensesame-script/](/usage/opensesame-script/)\n\n</div>\n\n## Step 14: Run experiment!\n\nThat's it. You can now run the experiment!\n\n<notranslate>\nfigure:\n id: FigDone\n source: FigDone.svg\n caption: Yes, you did!\n</notranslate>\n\n## Extra 1: Check timing (and learn some NumPy)\n\nIn time-critical experiments, you should always verify whether the timing is as intended. When using `canvas` objects, you can make use of the fact that the `canvas.show()` method returns the timestamp of the display onset. Therefore, as a first step, we maintain two lists: one to keep track of the letter-canvas onsets, and one to keep track of the blank-canvas onsets.\n\nTo do this, we need a small modification to the script in the *Run* tab of the *RSVP* item:\n\n~~~ .python\nl_letter_time = []\nl_blank_time = []\nfor letter_canvas in letter_canvas_list:\n    t1 = letter_canvas.show()\n    l_letter_time.append(t1)\n    clock.sleep(var.letter_dur)\n    t2 = blank_canvas.show()\n    l_blank_time.append(t2)\n    clock.sleep(var.isi)\n~~~\n\nWe now have two `list`s with timestamps: `l_letter_time` and `l_blank_time` From these, we want to determine the average presentation duration of a letter, the average duration of a blank, and the standard deviation for both averages. But because `list`s are not great for these kinds of numerical computations, we are going to convert them to another kind of object: a `numpy.array`.\n\n~~~ .python\nimport numpy\na_letter_time = numpy.array(l_letter_time)\na_blank_time = numpy.array(l_blank_time)\n~~~\n\nNow we can easily create an array that contains the presentation duration for each letter:\n\n~~~ .python\na_letter_dur = a_blank_time - a_letter_time\n~~~\n\nThis creates a new array, `a_letter_dur`, in which each item is the result of subtracting the corresponding item in `a_letter_time` from the corresponding item in `a_blank_time`. Schematically:\n\n    a_letter_dur    ->  [  1,  1,  1 ]\n    =\n    a_blank_time    ->  [ 11, 21, 31 ]\n    -\n    a_letter_time   ->  [ 10, 20, 30 ]": {
    "fr": "Tout d'abord, ouvrez *block_loop*. La valeur de \"Répéter\" est actuellement définie sur 1, ce qui signifie que chaque essai est exécuté une fois, donnant une longueur de bloc de 18 essais. Nous voulons spécifier la valeur \"Répéter\" avec une variable, afin que nous puissions avoir une valeur différente pour les blocs de pratique et expérimentaux. Pour ce faire, nous devons apporter une petite modification au script de *block_loop*. Cliquez sur le bouton \"Afficher\" en haut à droite de l'onglet (le milieu des trois boutons), et sélectionnez \"Afficher le script\". Cela masquera les commandes graphiques et montrera le script OpenSesame sous-jacent. Modifier maintenant cette ligne...\n\n~~~\nset repeat \"1\"\n~~~\n\n... en ...\n\n~~~\nset repeat \"[block_repeat]\"\n~~~\n\n... et cliquez sur \"Appliquer et fermer\". Cela signifie que la variable `repeat` est maintenant définie en fonction d'une autre variable, `block_repeat`. OpenSesame vous dira qu'il ne connaît plus la longueur du bloc (voir %FigVariableLoop), mais c'est bon : Tant que la variable `block_repeat` est définie, tout fonctionnera bien.\n\n<notranslate>\nfigure:\n id: FigVariableLoop\n source: FigVariableLoop.png\n caption: |\n  Si la longueur d'une LOOP est définie de manière variable, OpenSesame vous en informe.\n</notranslate>\n\nMaintenant, ouvrez *practice_loop*. Ajoutez une variable `block_repeat` et donnez-lui la valeur 0,5. Cela signifie que 0,5 x 18 = 9 cycles de *block_loop* seront exécutés, comme nous le souhaitons.\n\nMaintenant, ouvrez *experimental_loop*. Ajoutez à nouveau une variable `block_repeat` et donnez-lui la valeur 2. Cela signifie que chaque bloc a une longueur de 2 x 18 = 36 essais. Modifiez également le nombre de cycles à 10 et disposez la table de boucle de manière à avoir d'abord cinq blocs de `condition1`, suivis de cinq blocs de `condition2` (voir %FigExperimentalLoop).\n\n<notranslate>\nfigure:\n id: FigExperimentalLoop\n source: FigExperimentalLoop.png\n caption: |\n  Si la longueur d'une LOOP est définie de manière variable, OpenSesame vous en informe.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n### Liens\n\n- [/usage/opensesame-script/](/usage/opensesame-script/)\n\n</div>\n\n## Étape 14 : Exécutez l'expérience !\n\nC'est tout. Vous pouvez maintenant lancer l'expérience !\n\n<notranslate>\nfigure:\n id: FigDone\n source: FigDone.svg\n caption: Oui, vous l'avez fait !\n</notranslate>\n\n## Extra 1 : Vérifiez le minutage (et apprenez un peu de NumPy)\n\nDans les expériences critiques en termes de temps, vous devez toujours vérifier si le minutage est conforme à vos intentions. Lors de l'utilisation d'objets `canvas`, vous pouvez profiter du fait que la méthode `canvas.show()` renvoie le timestamp du début de l'affichage. Par conséquent, en premier lieu, nous maintenons deux listes : une pour suivre les débuts des lettres-canvas et une autre pour suivre les débuts des canvas vierges.\n\nPour ce faire, nous avons besoin d'une petite modification du script dans l'onglet *Run* de l'élément *RSVP* :\n\n~~~ .python\nl_letter_time = []\nl_blank_time = []\nfor letter_canvas in letter_canvas_list:\n    t1 = letter_canvas.show()\n    l_letter_time.append(t1)\n    clock.sleep(var.letter_dur)\n    t2 = blank_canvas.show()\n    l_blank_time.append(t2)\n    clock.sleep(var.isi)\n~~~\n\nNous avons maintenant deux `list` avec des timestamps: `l_letter_time` et `l_blank_time` À partir de celles-ci, nous voulons déterminer la durée de présentation moyenne d'une lettre, la durée moyenne d'un espace vierge et l'écart-type pour les deux moyennes. Mais comme les `list` ne sont pas idéales pour ce genre de calculs numériques, nous allons les convertir en un autre type d'objet: un `numpy.array`.\n\n~~~ .python\nimport numpy\na_letter_time = numpy.array(l_letter_time)\na_blank_time = numpy.array(l_blank_time)\n~~~\n\nMaintenant, nous pouvons facilement créer un tableau qui contient la durée de présentation de chaque lettre:\n\n~~~ .python\na_letter_dur = a_blank_time - a_letter_time\n~~~\n\nCela crée un nouveau tableau, `a_letter_dur`, dans lequel chaque élément est le résultat de la soustraction de l'élément correspondant dans `a_letter_time` de l'élément correspondant dans `a_blank_time`. Schématiquement :\n\n    a_letter_dur    ->  [  1,  1,  1 ]\n    =\n    a_blank_time    ->  [ 11, 21, 31 ]\n    -\n    a_letter_time   ->  [ 10, 20, 30 ]"
  },
  "You can find extensive documentation on PsychoPy at <http://www.psychopy.org/>. When using PsychoPy in OpenSesame, it is important to know that the main window can be accessed as `self.experiment.window` or simply `win`. So the following code snippet draws a Gabor patch:\n\n~~~ .python\nfrom psychopy import visual\ngabor = visual.PatchStim(win, tex=\"sin\", size=256, mask=\"gauss\", sf=0.05, ori=45)\ngabor.draw()\nwin.flip()\n~~~\n\n### Tutorials\n\nA tutorial specifically for using PsychoPy from within OpenSesame:\n\n- <http://www.cogsci.nl/blog/tutorials/211-a-bit-about-patches-textures-and-masks-in-psychopy>\n\nAnd a more general PsychoPy tutorial:\n\n- <http://gestaltrevision.be/wiki/coding>\n\n### Citation\n\nAlthough PsychoPy is bundled with the binary distributions of OpenSesame, it is a separate project. When appropriate, please cite the following papers in addition to citing OpenSesame:\n\nPeirce, J. W. (2007). PsychoPy: Psychophysics software in Python. *Journal of Neuroscience Methods*, *162*(1-2), 8-13. doi:10.1016/j.jneumeth.2006.11.017\n{: .reference}\n\nPeirce, J. W. (2009). Generating stimuli for neuroscience using PsychoPy. *Frontiers in Neuroinformatics*, *2*(10). doi:10.3389/neuro.11.010.2008\n{: .reference}\n\n## legacy\n\nThe legacy backend is built on top of [PyGame][] in non-OpenGL mode. The downside of this is that there is no hardware acceleration, and the timing properties are not as good as that of the psycho or xpyriment backends. The upside is that PyGame is very easy to use, very reliable, and well supported on a wide range of platforms.\n\n### Mouse-cursor visibility\n\nOn some systems, the mouse cursor is not visible when using the *legacy* backend in fullscreen mode. You can work around this is the following ways:\n\n1. Open the *legacy* backend settings and set \"Double buffering\" to \"no\".\n\t- *Note:* This may disable v-sync, which can be important for time critical experiments, as discussed [here](%link:timing%).\n2. Open the *legacy* backend settings and set \"Custom cursor\" to \"yes\".\n3. Switch to another backend.\n\n### Using PyGame directly\n\nPyGame is well documented and you can find everything you need to know about using PyGame on <http://www.pygame.org/docs/>. Specific to OpenSesame is the fact that the display surface is stored as `self.experiment.window` or simply `win`. So the following code snippet, which you could paste into an INLINE_SCRIPT item, draws a red rectangle to the display:\n\n~~~ .python\nimport pygame # Import the PyGame module\npygame.draw.rect(self.experiment.window, pygame.Color(\"red\"),\n\t[20, 20, 100, 100]) # Draw a red rectangle. Not shown yet...\npygame.display.flip() # Update the display to show the red rectangle.\n~~~\n\n\n## osweb\n\nThe *osweb* backend is built on top of OSWeb and allows you run experiments in a browser. For more information, see:\n\n- %link:manual/osweb/workflow%\n": {
    "fr": "Vous pouvez trouver une documentation complète sur PsychoPy à l'adresse <http://www.psychopy.org/>. Lors de l'utilisation de PsychoPy dans OpenSesame, il est important de savoir que la fenêtre principale peut être accessible via `self.experiment.window` ou simplement `win`. Ainsi, le fragment de code suivant dessine un patch de Gabor :\n\n~~~ .python\nfrom psychopy import visual\ngabor = visual.PatchStim(win, tex=\"sin\", size=256, mask=\"gauss\", sf=0.05, ori=45)\ngabor.draw()\nwin.flip()\n~~~\n\n### Tutoriels\n\nUn tutoriel spécifique pour l'utilisation de PsychoPy depuis OpenSesame :\n\n- <http://www.cogsci.nl/blog/tutorials/211-a-bit-about-patches-textures-and-masks-in-psychopy>\n\nEt un tutoriel PsychoPy plus général :\n\n- <http://gestaltrevision.be/wiki/coding>\n\n### Citation\n\nBien que PsychoPy soit intégré aux distributions binaires d'OpenSesame, il s'agit d'un projet distinct. Le cas échéant, veuillez citer les articles suivants en plus de citer OpenSesame :\n\nPeirce, J. W. (2007). PsychoPy: Psychophysics software in Python. *Journal of Neuroscience Methods*, *162*(1-2), 8-13. doi:10.1016/j.jneumeth.2006.11.017\n{: .reference}\n\nPeirce, J. W. (2009). Generating stimuli for neuroscience using PsychoPy. *Frontiers in Neuroinformatics*, *2*(10). doi:10.3389/neuro.11.010.2008\n{: .reference}\n\n## legacy\n\nLe backend legacy est construit sur [PyGame][] en mode non-OpenGL. L'inconvénient est qu'il n'y a pas d'accélération matérielle et que les propriétés de synchronisation ne sont pas aussi bonnes que celles des backend psycho ou xpyriment. L'avantage est que PyGame est très facile à utiliser, très fiable et bien pris en charge sur un large éventail de plateformes.\n\n### Visibilité du curseur de souris\n\nSur certains systèmes, le curseur de la souris n'est pas visible lors de l'utilisation du backend *legacy* en mode plein écran. Vous pouvez contourner ce problème de plusieurs manières :\n\n1. Ouvrez les paramètres du backend *legacy* et réglez \"Double buffering\" sur \"non\".\n    - *Remarque :* Cela peut désactiver la synchronisation verticale, qui peut être importante pour les expériences critiques en termes de temps, comme discuté [ici](%link:timing%).\n2. Ouvrez les paramètres du backend *legacy* et réglez \"Custom cursor\" sur \"oui\".\n3. Passez à un autre backend.\n\n### Utilisation de PyGame directement\n\nPyGame est bien documenté et vous pouvez trouver tout ce que vous devez savoir sur l'utilisation de PyGame sur <http://www.pygame.org/docs/>. Particulier à OpenSesame, le fait que la surface d'affichage est stockée en tant que `self.experiment.window` ou simplement `win`. Ainsi, le fragment de code suivant, que vous pourriez coller dans un élément INLINE_SCRIPT, dessine un rectangle rouge sur l'affichage :\n\n~~~ .python\nimport pygame # Import du module PyGame\npygame.draw.rect(self.experiment.window, pygame.Color(\"red\"),\n\t[20, 20, 100, 100]) # Dessine un rectangle rouge. Pas encore affiché...\npygame.display.flip() # Met à jour l'affichage pour montrer le rectangle rouge.\n~~~\n\n## osweb\n\nLe backend *osweb* est construit sur OSWeb et permet d'exécuter des expériences dans un navigateur. Pour plus d'informations, consultez :\n\n- %link:manual/osweb/workflow%"
  },
  "Variables": {
    "fr": "Variables"
  },
  "Right now, the duration of *card_display* is set to 'keypress'. This means that the *card_display* is shown until a key is pressed, but it provides no control over how this key press is handled. Therefore, change the duration to 0, and insert a KEYBOARD_RESPONSE directly after the *card_display*. Rename the KEYBOARD_RESPONSE to *press_a*, and specify that the correct response is 'a' and that the allowed responses are 'a;b;c;d'.\n\n\n<notranslate>\nfigure:\n id: FigPressA\n source: press-a.png\n caption: |\n  One of the KEYBOARD_RESPONSE items defined in step 7.\n</notranslate>\n\n\nBut this is not enough! Right now there's a single response item that assumes that the correct response is always 'a'. We have not yet specified *when* the correct response is 'a', nor have we considered trials on which the correct response is 'b', 'c', or 'd'.\n\nTo accomplish this, first create three more KEYBOARD_RESPONSE items: *press_b*, *press_c*, and *press_d*. These are all the same, except for the correct response, which is defined for each of them separately and should be respectively 'b', 'c', and 'd'.\n\nFinally, in the *trial_sequence*, use Run If statements to decide under which condition each of the four KEYBOARD_RESPONSE items should be executed (thus deciding what the correct response is). For *press_a*, the condition is that `shape1` should be equal to `response_shape`. Why? Well, because that means that the shape of the first stimulus card is equal to the shape of the response card, and in that case the correct response is 'a'. This condition corresponds to the following run-if statement: `[shape1] = [response_shape]`. The run-if statements for the other KEYBOARD_RESPONSE items are analogous (see %FigTrialSequence1).\n\n\n<notranslate>\nfigure:\n id: FigTrialSequence1\n source: trial-sequence-1.png\n caption: |\n  The *trial_sequence* at the end of step 7.\n</notranslate>\n\n\n### Step 8: Give feedback to the participant\n\nOpenSesame automatically keeps track of whether a response was correct or not, by setting the variable `correct` to respectively 1 or 0. (Provided, of course, that you have specified the correct response, as we've done in step 7.) We can use this to give feedback to the participant about whether they responded correctly or not.\n\nTo do this, add two new SKETCHPADs to the *trial_sequence* and call them *correct_feedback* and *incorrect_feedback*. Then, specify which of the two should be executed using a run-if statement (see %FigTrialSequence2).\n\n\n<notranslate>\nfigure:\n id: FigTrialSequence2\n source: trial-sequence-2.png\n caption: |\n  The *trial_sequence* at the end of step 8.\n</notranslate>\n\n\nFinally, add some useful content to both SKETCHPADs. For example, for *correct_feedback* you could use a green fixation dot, and for *incorrect_feedback* you could use a red fixation dot, in both cases shown for 500 ms (i.e. setting the SKETCHPAD duration to 500). Colored dots are a nice, unobtrusive way to provide feedback.\n\n\n### Step 9: Test the experiment\n\nYou have now created a basic (but incomplete!) implementation of the Wisconsin Card Sorting Test. (You will complete the implementation as part of the Extra Assignments below.)\n\n\n<notranslate>\nfigure:\n id: FigRunButtons\n source: run-buttons.png\n caption: |\n  The main toolbar contains buttons to (from left to right): run fullscreen, run in a window, quick-run (run in a window without asking for log file or participant numebr ), abort the experiment, and run in a browser.\n</notranslate>\n\n\nTo test the experiment, click on the quick-run button (the blue double arrows) to test the experiment on the desktop (see %FigRunButtons). If the experiment runs as expected on the desktop, click on the run-in-browser button (the arrow inside a green circle) to test the experiment in a browser.\n\n\n## Extra assignments\n\n\n### Extra 1 (easy): Add a logger": {
    "fr": "Actuellement, la durée de *card_display* est définie sur 'keypress'. Cela signifie que le *card_display* est affiché jusqu'à ce qu'une touche soit pressée, mais cela ne permet pas de contrôler comment cette pression de touche est gérée. Par conséquent, changez la durée à 0 et insérez un KEYBOARD_RESPONSE directement après le *card_display*. Renommez le KEYBOARD_RESPONSE en *press_a* et spécifiez que la réponse correcte est 'a' et que les réponses autorisées sont 'a; b; c; d'.\n\nMais ce n'est pas suffisant ! En ce moment, il y a un seul élément de réponse qui suppose que la réponse correcte est toujours 'a'. Nous n'avons pas encore précisé *quand* la réponse correcte est 'a', ni examiné les essais pour lesquels la réponse correcte est 'b', 'c' ou 'd'.\n\nPour ce faire, créez d'abord trois autres éléments KEYBOARD_RESPONSE : *press_b*, *press_c* et *press_d*. Ils sont tous les mêmes, sauf pour la réponse correcte, qui est définie pour chacun d'eux séparément et doit être respectivement 'b', 'c' et 'd'.\n\nEnfin, dans la *trial_sequence*, utilisez des instructions Run If pour décider dans quelle condition chacun des quatre éléments KEYBOARD_RESPONSE doit être exécuté (déterminant ainsi quelle est la réponse correcte). Pour *press_a*, la condition est que `shape1` doit être égale à `response_shape`. Pourquoi ? Eh bien, parce que cela signifie que la forme de la première carte stimulus est égale à la forme de la carte de réponse, et dans ce cas, la réponse correcte est 'a'. Cette condition correspond à l'instruction run-if suivante : `[shape1] = [response_shape]`. Les instructions run-if pour les autres éléments KEYBOARD_RESPONSE sont analogues (voir %FigTrialSequence1).\n\n### Étape 8 : Donner un retour d'information au participant\n\nOpenSesame suit automatiquement si une réponse était correcte ou non, en définissant la variable `correct` à respectivement 1 ou 0. (À condition, bien sûr, que vous ayez spécifié la réponse correcte, ce que nous avons fait à l'étape 7.) Nous pouvons utiliser cela pour donner un retour d'information au participant sur le fait qu'il a répondu correctement ou non.\n\nPour ce faire, ajoutez deux nouveaux SKETCHPADs à la *trial_sequence* et appelez-les *correct_feedback* et *incorrect_feedback*. Ensuite, spécifiez lequel des deux doit être exécuté en utilisant une instruction run-if (voir %FigTrialSequence2).\n\nEnfin, ajoutez des contenus utiles aux deux SKETCHPADs. Par exemple, pour *correct_feedback*, vous pouvez utiliser un point de fixation vert, et pour *incorrect_feedback*, vous pouvez utiliser un point de fixation rouge, dans les deux cas affiché pendant 500 ms (c'est-à-dire en réglant la durée du SKETCHPAD à 500). Les points colorés sont un moyen discret de fournir des commentaires.\n\n### Étape 9 : Tester l'expérience\n\nVous avez maintenant créé une implémentation de base (mais incomplète !) du test de tri de cartes du Wisconsin. (Vous compléterez l'implémentation dans le cadre des exercices supplémentaires ci-dessous.)\n\nPour tester l'expérience, cliquez sur le bouton de lancement rapide (les doubles flèches bleues) pour tester l'expérience sur le bureau (voir %FigRunButtons). Si l'expérience fonctionne comme prévu sur le bureau, cliquez sur le bouton de lancement dans un navigateur (la flèche à l'intérieur d'un cercle vert) pour tester l'expérience dans un navigateur.\n\n## Affectations supplémentaires\n\n### Extra 1 (facile) : Ajouter un logger"
  },
  "<notranslate>[TOC]</notranslate>\n\n## What is an experimental variable in OpenSesame?\n\nExperimental variables in OpenSesame are those variables that:\n\n- You can refer to in the user interface with the '{variable_name}' syntax.\n- Are available as global variables in a Python INLINE_SCRIPT.\n- Are available as global variables in a JavaScript INLINE_JAVASCRIPT.\n- Contain things like:\n\t- The variables that you have defined in a LOOP item.\n\t- The responses that you have collected.\n\t- Various properties of the experiment.\n\t- Etc.\n\n## The variable inspector\n\nThe variable inspector (`Ctrl+I`) provides an overview of available variables (%FigVariableInspector). When the experiment is not running, this overview is based on a best guess of which variables will become available during the experiment. However, when the experiment is running, the variable inspector shows a live overview of variables and their values. This is useful for debugging your experiment.\n\n<notranslate>\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: The variable inspector provides an overview of all variables that OpenSesame knows about.\n</notranslate>\n\n## Defining variables\n\nThe simplest way to define a variable is through the LOOP item. For example, %FigLoop shows how to define a variable named `gaze_cue`. In this example, *trial_sequence* item is called four times while `gaze_cue` is 'left' and another four times while 'gaze_cue' is 'right'.\n\n<notranslate>\nfigure:\n id: FigLoop\n source: defining-variables-in-a-loop.png\n caption: The most common way to define independent variables is using the LOOP table.\n</notranslate>\n\n## Built-in variables\n\nThe following variables are always available:\n\n### Experiment variables\n\n|Variable name\t\t\t|Description|\n|-----------------------|-----------|\n|`title`\t\t\t\t|The title of the experiment|\n|`description`\t\t\t|The description of the experiment|\n|`foreground`\t\t\t|The default foreground color. E.g., 'white' or '#FFFFFF'.|\n|`background`\t\t\t|The default background color. E.g., 'black' or '#000000'.|\n|`height`\t\t\t\t|The height-part of the display resolution. E.g., '768'|\n|`width`\t\t\t\t|The width-part of the display resolution. E.g., '1024'|\n|`subject_nr`\t\t\t|The subject number, which is asked when the experiment is started.|\n|`subject_parity`\t\t|Is 'odd' if `subject_nr` is odd and 'even' if `subject_nr` is even. Useful for counterbalancing.|\n|`experiment_path`\t\t|The folder of the current experiment, without the experiment filename itself. If the experiment is unsaved, it has the value `None`.|\n|`pool_folder`\t\t\t|The folder where the contents of the file pool have been extracted to. This is generally a temporary folder.|\n|`logfile`\t\t\t\t|The path to the logfile.|\n\n### Item variables\n\nThere are also variables that keep track of all the items in the experiment.\n\n|Variable name\t\t\t|Description|\n|-----------------------|-----------|\n|`time_[item_name]`\t\t|Contains a timestamp of when the item was last executed. For SKETCHPAD items, this can be used to verify the timing of display presentation.|\n|`count_[item_name]`\t|Is equal the number of times minus one (starting at 0, in other words) that an item has been called. This can, for example, be used as a trial or block counter.|\n\n### Response variables\n\nWhen you use the standard response items, such as the KEYBOARD_RESPONSE and MOUSE_RESPONSE, a number of variables are set based on the participant's response.": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## Qu'est-ce qu'une variable expérimentale dans OpenSesame ?\n\nLes variables expérimentales dans OpenSesame sont celles qui :\n\n- Peuvent être mentionnées dans l'interface utilisateur avec la syntaxe '{variable_name}'.\n- Sont disponibles en tant que variables globales dans un INLINE_SCRIPT Python.\n- Sont disponibles en tant que variables globales dans un INLINE_JAVASCRIPT JavaScript.\n- Contiennent des éléments tels que :\n\t- Les variables que vous avez définies dans un élément LOOP.\n\t- Les réponses que vous avez collectées.\n\t- Diverses propriétés de l'expérience.\n\t- Etc.\n\n## L'inspecteur de variables\n\nL'inspecteur de variables (`Ctrl+I`) fournit un aperçu des variables disponibles (%FigVariableInspector). Lorsque l'expérience n'est pas en cours, cet aperçu est basé sur une meilleure estimation des variables qui deviendront disponibles au cours de l'expérience. Cependant, lorsque l'expérience est en cours, l'inspecteur de variables montre un aperçu en direct des variables et de leurs valeurs. Ceci est utile pour déboguer votre expérience.\n\n<notranslate>\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: L'inspecteur de variables fournit un aperçu de toutes les variables qu'OpenSesame connaît.\n</notranslate>\n\n## Définition des variables\n\nLa façon la plus simple de définir une variable est via l'élément LOOP. Par exemple, %FigLoop montre comment définir une variable nommée `gaze_cue`. Dans cet exemple, l'élément *trial_sequence* est appelé quatre fois alors que `gaze_cue` est 'left' et quatre autres fois alors que 'gaze_cue' est 'right'.\n\n<notranslate>\nfigure:\n id: FigLoop\n source: defining-variables-in-a-loop.png\n caption: La façon la plus courante de définir des variables indépendantes est en utilisant la table LOOP.\n</notranslate>\n\n## Variables intégrées\n\nLes variables suivantes sont toujours disponibles :\n\n### Variables d'expérience\n\n|Nom de la variable\t\t\t|Description|\n|-----------------------|-----------|\n|`title`\t\t\t\t|Le titre de l'expérience|\n|`description`\t\t\t|La description de l'expérience|\n|`foreground`\t\t\t|La couleur d'avant-plan par défaut. Ex. : 'white' ou '#FFFFFF'.|\n|`background`\t\t\t|La couleur d'arrière-plan par défaut. Ex. : 'black' ou '#000000'.|\n|`height`\t\t\t\t|La hauteur de la résolution d'affichage. Ex. : '768'|\n|`width`\t\t\t\t|La largeur de la résolution d'affichage. Ex. : '1024'|\n|`subject_nr`\t\t\t|Le numéro du sujet, qui est demandé lors du démarrage de l'expérience.|\n|`subject_parity`\t\t|Est 'odd' si `subject_nr` est impair et 'even' si `subject_nr` est pair. Utile pour la contrebalancement.|\n|`experiment_path`\t\t|Le dossier de l'expérience en cours, sans le nom de fichier de l'expérience elle-même. Si l'expérience n'a pas été enregistrée, sa valeur est `None`.|\n|`pool_folder`\t\t\t|Le dossier où les éléments du fichier \"pool\" ont été extraits. Il s'agit généralement d'un dossier temporaire.|\n|`logfile`\t\t\t\t|Le chemin d'accès au fichier de journal.|\n\n### Variables des éléments\n\nIl existe également des variables qui suivent tous les éléments de l'expérience.\n\n|Nom de la variable\t\t\t|Description|\n|-----------------------|-----------|\n|`time_[item_name]`\t\t|Contient un horodatage du dernier moment où l'élément a été exécuté. Pour les éléments SKETCHPAD, cela peut être utilisé pour vérifier le moment de présentation de l'affichage.|\n|`count_[item_name]`\t|Est égal au nombre de fois moins un (commençant par 0, en d'autres termes) qu'un élément a été appelé. Ceci peut être utilisé, par exemple, comme un compteur d'essais ou de blocs.|\n\n### Variables de réponse\n\nLorsque vous utilisez les éléments de réponse standard, tels que KEYBOARD_RESPONSE et MOUSE_RESPONSE, un certain nombre de variables sont définies en fonction de la réponse du participant."
  },
  "Similarly, but slightly more complicated, we can create a new array, `a_blank_dur`, in which each item is the result of subtracting item *i* in `a_blank_time` from item *i+1* in `a_letter_time`.\n\n~~~ .python\na_blank_dur = a_letter_time[1:] - a_blank_time[:-1]\n~~~\n\nSchematically:\n\n    a_blank_dur         ->  [  9,  9 ]\n    =\n    a_letter_time[1:]   ->  [ 20, 30 ] # The leading 10 is stripped off\n    -\n    a_blank_time[:-1]   ->  [ 11, 21 ] # The trailing 31 is stripped off\n\nThe next step is to use the `array.mean()` and `array.std()` methods to get the averages and standard deviations of the durations in one go. To inspect these\nvalues, we set them as experimental variables (i.e. as properties of the `var` object). That way they will be logged and visible in the variable inspector.\n\n~~~ .python\nvar.mean_letter_dur = a_letter_dur.mean()\nvar.std_letter_dur = a_letter_dur.std()\nvar.mean_blank_dur = a_blank_dur.mean()\nvar.std_blank_dur = a_blank_dur.std()\n~~~\n\nDone!\n\n<div class='info-box' markdown='1'>\n\n### Links\n\n- [/miscellaneous/timing/](/miscellaneous/timing/)\n- <http://wiki.scipy.org/Tentative_NumPy_Tutorial>\n\n</div>\n\n## Extra 2: Add assertions to check your experiment\n\nA Dutch proverb states that a mistake is in a small corner. (I suspect that according to the original proverb the mistake, rather than the corner, was small, but no matter.) Developing experiments, or any kind of software, without bugs is almost impossible. However, you can protect yourself from many bugs by building safeguards into your experiment.\n\nFor example, our experiment has two conditions, defined as 'experimental' and 'control'. But what if I accidentally misspelled 'experimental' as 'experimentel' in the *experimental_loop*? The experiment would still run, but it would no longer work as expected. Therefore, we want to make sure that `condition` is either 'experimental' or 'control', but nothing else. In computer-speak, we want to *assert* that this is the case. Let's take a look at how we can do this.\n\nFirst, drag a new INLINE_SCRIPT item to the start of the *trial_sequence* and rename it to *assertions*. Add the following line to the *Run* tab:\n\n~~~ .python\nassert(var.condition in ['experimental', 'control'])\n~~~\n\nLet's dissect this line:\n\n- `var.condition` refers to the experimental `condition` variable.\n- `in ['experimental', 'control']` checks whether this variable matches any of the items in the list, i.e. whether it is 'experimental' or 'control'.\n- `assert()` states that there *has* to be a match. If not, the experiment will crash (an `AssertionError` will be raised).\n\nIn other words, whatever you pass to `assert()` has to be `True`, otherwise your experiment will crash. This useful for sanity checks.\n\nSome more assertions:\n\n~~~ .python\nassert(var.T2_present in ['y', 'n'])\nassert(var.lag in ['']+range(0,9))\n~~~\n\nAnd a final one that is a bit more complicated. Can you figure out what it does?\n\n~~~ .python\nassert((var.lag == '') != (var.T2_present == 'y'))\n~~~\n\n<div class='info-box' markdown='1'>\n\n### Links\n\n- <https://wiki.python.org/moin/UsingAssertionsEffectively>\n- Advice on protective programming in Axelrod (2014, doi:10.3389/fpsyg.2014.01435)\n\n</div>\n\n## Extra 3: Use PsychoPy directly\n\nOpenSesame is backend independent. This means that different libraries can be used for controlling the display, sound, response collection, etc. You can select the backend in the General tab.\n\nSo far, we have used OpenSesame's own `canvas` object, which automatically maps onto the correct functions of the selected backend. Therefore, you don't have to bother with or know about the details of each backend. However, you can also directly use the functions offered by a specific backend, such as PsychoPy. This is especially useful if you want to use functionality that is not available in OpenSesame's own modules.": {
    "fr": "De même, mais légèrement plus compliqué, nous pouvons créer un nouveau tableau, `a_blank_dur`, dans lequel chaque élément est le résultat de la soustraction de l'élément *i* dans `a_blank_time` de l'élément *i+1* dans `a_letter_time`.\n\n~~~ .python\na_blank_dur = a_letter_time[1:] - a_blank_time[:-1]\n~~~\n\nSchématiquement :\n\n    a_blank_dur         ->  [  9,  9 ]\n    =\n    a_letter_time[1:]   ->  [ 20, 30 ] # Les 10 premiers sont supprimés\n    -\n    a_blank_time[:-1]   ->  [ 11, 21 ] # Les 31 derniers sont supprimés\n\nLa prochaine étape consiste à utiliser les méthodes `array.mean()` et `array.std()` pour obtenir les moyennes et les écarts-types des durées en une seule fois. Pour inspecter ces valeurs, nous les définissons comme des variables expérimentales (c'est-à-dire comme des propriétés de l'objet `var`). De cette façon, elles seront enregistrées et visibles dans l'inspecteur de variables.\n\n~~~ .python\nvar.mean_letter_dur = a_letter_dur.mean()\nvar.std_letter_dur = a_letter_dur.std()\nvar.mean_blank_dur = a_blank_dur.mean()\nvar.std_blank_dur = a_blank_dur.std()\n~~~\n\nFait!\n\n<div class='info-box' markdown='1'>\n\n### Liens\n\n- [/miscellaneous/timing/](/miscellaneous/timing/)\n- <http://wiki.scipy.org/Tentative_NumPy_Tutorial>\n\n</div>\n\n## Supplément 2 : Ajouter des assertions pour vérifier votre expérience\n\nUn proverbe néerlandais dit qu'une erreur est dans un petit coin. (Je soupçonne que selon le proverbe original, l'erreur, plutôt que le coin, était petite, mais peu importe.) Développer des expériences, ou tout type de logiciel, sans bogues est presque impossible. Cependant, vous pouvez vous protéger de nombreux bogues en intégrant des protections dans votre expérience.\n\nPar exemple, notre expérience a deux conditions, définies comme «expérimental» et «contrôle». Mais que se passe-t-il si je fais une faute de frappe avec «experimental» comme «experimentel» dans la boucle expérimentale? L'expérience fonctionnerait toujours, mais elle ne fonctionnerait plus comme prévu. Par conséquent, nous voulons nous assurer que `condition` est soit \"expérimental\", soit \"contrôle\", mais rien d'autre. En termes informatiques, nous voulons *affirmer* que c'est le cas. Jetons un coup d'œil à comment nous pouvons le faire.\n\nTout d'abord, faites glisser un nouvel élément de script en ligne au début de la *séquence d'essai* et renommez-le *assertions*. Ajoutez la ligne suivante à l'onglet *Exécution* :\n\n~~~ .python\nassert(var.condition in ['experimental', 'control'])\n~~~\n\nDécortiquons cette ligne :\n\n- `var.condition` fait référence à la variable expérimentale `condition`.\n- `in ['experimental', 'control']` vérifie si cette variable correspond à l'un des éléments de la liste, c'est-à-dire si elle est \"expérimental\" ou \"contrôle\".\n- `assert()` déclare qu'il *doit* y avoir une correspondance. Sinon, l'expérience se bloquera (une `AssertionError` sera levée).\n\nEn d'autres termes, ce que vous passez à `assert()` doit être `True`, sinon votre expérience se bloquera. Ceci est utile pour les vérifications de bon sens.\n\nQuelques assertions supplémentaires :\n\n~~~ .python\nassert(var.T2_present in ['y', 'n'])\nassert(var.lag in ['']+list(range(0,9)))\n~~~\n\nEt enfin une assertion un peu plus compliquée. Pouvez-vous comprendre ce qu'elle fait ?\n\n~~~ .python\nassert((var.lag == '') != (var.T2_present == 'y'))\n~~~\n\n<div class='info-box' markdown='1'>\n\n### Liens\n\n- <https://wiki.python.org/moin/UsingAssertionsEffectively>\n- Conseils sur la programmation de protection dans Axelrod (2014, doi:10.3389/fpsyg.2014.01435)\n\n</div>\n\n## Supplément 3 : Utiliser directement PsychoPy\n\nOpenSesame est indépendant du backend. Cela signifie que différentes bibliothèques peuvent être utilisées pour contrôler l'affichage, le son, la collecte des réponses, etc. Vous pouvez sélectionner le backend dans l'onglet Général.\n\nJusqu'à présent, nous avons utilisé l'objet `canvas` de OpenSesame, qui se mappe automatiquement sur les fonctions correctes du backend sélectionné. Par conséquent, vous n'avez pas à vous soucier des détails de chaque backend. Cependant, vous pouvez également utiliser directement les fonctions offertes par un backend spécifique, tel que PsychoPy. Ceci est particulièrement utile si vous souhaitez utiliser des fonctionnalités qui ne sont pas disponibles dans les propres modules d'OpenSesame."
  },
  "OpenSesame doesn't automatically log data. Instead, you need to explicitly add a `logger` item to your experiment. In a trial-based experiment, a `logger` is generally the last item of the *trial_sequence*, so that it logs all the data that was collected during the trial.\n\nRight now, our WCST doesn't log any data. Time to fix that!\n\n\n### Extra 2 (easy): Inspect the data file\n\n*Requires that you have completed Extra 1*.\n\nGive the experiment a short test run. Now inspect the log file in a program like Excel, LibreOffice Calc, or JASP. Identify the relevant variables, and think of how you could analyze the results.\n\n__Pro-tip:__ Set the repeat value of the *block_loop* to 0.1 to reduce the number of trials during testing.\n\n\n### Extra 3 (easy): Add instructions and goodbye screen\n\nA good experiment comes with clear instructions. And a polite experiment says goodbye to the participants when they are done. You can use a SKETCHPAD to do this.\n\n__Pro-tip:__ A FORM_TEXT_DISPLAY is not compatible with OSWeb, so you should not use it for instructions if you want to run your experiment online.\n\n\n### Extra 4 (medium): Set the correct response and matching rule through JavaScript\n\nTo include scripting in OSWeb, you can use the INLINE_JAVASCRIPT item, which supports JavaScript. (But it does not currently provide all the functionality that is offered by the regular Python INLINE_SCRIPT!)\n\nSo far, the matching rule is always to match by shape. To change this, add an INLINE_JAVASCRIPT item to the start of the experiment, and use the following script (in the *prepare* phase) to randomly set the variable `matching_rule` to 'shape', 'number', or 'color'.\n\n```javascript\nfunction choice(choices) {\n    // JavaScript does not have a built-in choice function, so we define it\n    // here.\n    let index = Math.floor(Math.random() * choices.length)\n    return choices[index]\n}\n\n\n// The vars object contains all experimental variables, like the var object\n// in Python inline script\nvars.matching_rule = choice(['shape', 'number', 'color'])\n```\n\nNow add another INLINE_JAVASCRIPT item to the start of the *trial_sequence*. In the *prepare* phase, add a script to set the `correct_response` variable to 'a', 'b', 'c', or 'd'. To do so, you need a series of `if` statements, that first look at the matching rule, and then look at which shape corresponds to the response shape (for the shape-matching rule) or which color corresponds to the response color (for the color-matching rule) etc.\n\nTo get started, here's part of the solution (but it needs to be completed!):\n\n```javascript\nif (vars.matching_rule === 'shape') {\n    if (vars.shape1 === vars.response_shape) vars.correct_response = 'a'\n    // Not done yet\n} // Not done yet\n\n// Let's print some info to the debug window\nconsole.log('matching_rule = ' + vars.matching_rule)\nconsole.log('correct_response = ' + vars.correct_response)\n```\n\n\n### Extra 5 (difficult): Periodically change the matching rule\n\nSo far, the matching rule is randomly determined at the start of the experiment, but then remains constant throughout the experiment. In a real WCST, the matching rule changes periodically, typically after the participant has made a fixed number of correct responses.\n\nTo implement this, you need another INLINE_JAVASCRIPT. Here are some pointers to get started:\n\n- Use a counter variable that increments by 1 after a correct response, and is reset to 0 after an incorrect response.\n- When changing the matching rule, make sure that it is not (by coincidence) set to the same matching rule again.\n\n\n### Extra 6 (really difficult): Constrain the response card\n\nRight now, the response card can overlap with a stimulus card on multiple dimensions. For example, if one of the stimulus cards is a single blue circle, the response card might be two blue circles, thus overlapping on both color and shape. In a real WCST, the response card should overlap with each stimulus card on no more than a dimension.": {
    "fr": "OpenSesame ne consigne pas automatiquement les données. Vous devez plutôt ajouter explicitement un élément `logger` à votre expérience. Dans une expérience basée sur des essais, un `logger` est généralement le dernier élément de la *trial_sequence*, afin qu'il consigne toutes les données collectées au cours de l'essai.\n\nPour le moment, notre WCST ne consigne aucune donnée. Il est temps de remédier à cela !\n\n### Supplément 2 (facile) : Inspecter le fichier de données\n\n*Nécessite d'avoir effectué le Supplément 1*.\n\nFaites un court test de l'expérience. Inspectez maintenant le fichier journal à l'aide d'un programme tel qu'Excel, LibreOffice Calc ou JASP. Identifiez les variables pertinentes et réfléchissez à la manière dont vous pourriez analyser les résultats.\n\n__Astuce:__ Réglez la valeur de répétition du *block_loop* sur 0.1 pour réduire le nombre d'essais lors des tests.\n\n### Supplément 3 (facile) : Ajouter des instructions et un écran d'au revoir\n\nUne bonne expérience est accompagnée d'instructions claires. Et une expérience polie dit au revoir aux participants lorsqu'ils ont terminé. Vous pouvez utiliser un SKETCHPAD pour ce faire.\n\n__Astuce:__ Un FORM_TEXT_DISPLAY n'est pas compatible avec OSWeb, vous ne devez donc pas l'utiliser pour les instructions si vous souhaitez exécuter votre expérience en ligne.\n\n### Supplément 4 (moyen) : Définir la réponse correcte et la règle de correspondance à l'aide de JavaScript\n\nPour inclure des scripts dans OSWeb, vous pouvez utiliser l'élément INLINE_JAVASCRIPT, qui prend en charge JavaScript. (Mais il n'offre pas actuellement toutes les fonctionnalités proposées par le INLINE_SCRIPT Python habituel !)\n\nJusqu'à présent, la règle de correspondance est toujours de correspondre par forme. Pour la modifier, ajoutez un élément INLINE_JAVASCRIPT au début de l'expérience et utilisez le script suivant (dans la phase *prepare*) pour définir aléatoirement la variable `matching_rule` sur 'shape' (forme), 'number' (nombre) ou 'color' (couleur).\n\n```javascript\nfunction choice(choices) {\n    // JavaScript n'a pas de fonction de choix intégrée, alors nous la définissons\n    // ici.\n    let index = Math.floor(Math.random() * choices.length)\n    return choices[index]\n}\n\n\n// L'objet vars contient toutes les variables expérimentales, comme l'objet var\n// dans le script inline Python\nvars.matching_rule = choice(['shape', 'number', 'color'])\n```\n\nAjoutez maintenant un autre élément INLINE_JAVASCRIPT au début de la *trial_sequence*. Dans la phase *prepare*, ajoutez un script pour définir la variable `correct_response` sur 'a', 'b', 'c' ou 'd'. Pour ce faire, vous devez utiliser une série d'instructions `if` qui examinent d'abord la règle de correspondance, puis la forme correspondant à la réponse de la forme (pour la règle de correspondance des formes) ou la couleur correspondant à la couleur de réponse (pour la règle de correspondance des couleurs) etc.\n\nPour commencer, voici une partie de la solution (mais elle doit être complétée !) :\n\n```javascript\nif (vars.matching_rule === 'shape') {\n    if (vars.shape1 === vars.response_shape) vars.correct_response = 'a'\n    // Pas encore terminé\n} // Pas encore terminé\n\n// Imprimons quelques informations dans la fenêtre de débogage\nconsole.log('matching_rule = ' + vars.matching_rule)\nconsole.log('correct_response = ' + vars.correct_response)\n```\n\n### Supplément 5 (difficile) : Changer périodiquement la règle de correspondance\n\nJusqu'à présent, la règle de correspondance est déterminée de manière aléatoire au début de l'expérience, mais elle reste constante tout au long de l'expérience. Dans un vrai WCST, la règle de correspondance change périodiquement, généralement après que le participant a fait un nombre fixe de réponses correctes.\n\nPour cela, vous avez besoin d'un autre INLINE_JAVASCRIPT. Voici quelques conseils pour commencer :\n\n- Utiliser une variable compteur qui augmente de 1 après une réponse correcte et qui est réinitialisée à 0 après une réponse incorrecte.\n- Lors de la modification de la règle de correspondance, assurez-vous qu'elle n'est pas (par hasard) réglée à nouveau sur la même règle de correspondance.\n\n\n### Supplément 6 (très difficile) : Limiter la carte de réponse\n\nActuellement, la carte de réponse peut chevaucher une carte stimulus sur plusieurs dimensions. Par exemple, si l'une des cartes stimulus est un seul cercle bleu, la carte de réponse pourrait être deux cercles bleus, chevauchant ainsi la couleur et la forme. Dans un vrai WCST, la carte de réponse ne doit chevaucher chaque carte stimulus que sur une seule dimension au maximum."
  },
  "This one is up to you. No pointers this time!\n\n\n### Extra 7 (easy): Running the experiment online with JATOS\n\nOur WCST is compatible with OSWeb, which means that you can run it in a browser. To test if this still works, you can click on the run-in-browser button in OpenSesame.\n\nHowever, to collect actual data with the experiment in a browser, you need to import the experiment into JATOS, and use JATOS to generate a link that you can distribute to your participants. This is much easier than it sounds! For more information, see:\n\n- %link:manual/osweb/workflow%\n\n\n## Solutions\n\nYou can download the full experiment, including the solutions to the extra assignments, here:\n\n- <https://osf.io/f5er2/>\n": {
    "fr": "Cela dépend de vous. Pas d'indications cette fois !\n\n### Extra 7 (facile) : Exécuter l'expérience en ligne avec JATOS\n\nNotre WCST est compatible avec OSWeb, ce qui signifie que vous pouvez l'exécuter dans un navigateur. Pour vérifier si cela fonctionne toujours, vous pouvez cliquer sur le bouton \"run-in-browser\" dans OpenSesame.\n\nCependant, pour collecter des données réelles avec l'expérience dans un navigateur, vous devez importer l'expérience dans JATOS, et utiliser JATOS pour générer un lien que vous pouvez distribuer à vos participants. C'est beaucoup plus facile qu'il n'y paraît ! Pour plus d'informations, consultez :\n\n- %link:manual/osweb/workflow%\n\n## Solutions\n\nVous pouvez télécharger l'expérience complète, y compris les solutions des exercices supplémentaires, ici :\n\n- <https://osf.io/f5er2/>"
  },
  "|Variable name\t\t\t\t\t|Description|\n|-------------------------------|-----------|\n|`response`\t\t\t\t\t\t|Contains the last response that has been given.|\n|`response_[item_name]`\t\t\t|Contains the last response for a specific response item. This is useful in case there are multiple response items.|\n|`response_time`\t\t\t\t|Contains the interval in milliseconds between the start of the response interval and the last response.|\n|`response_time_[item_name]`\t|Contains the response time for a specific response item.|\n|`correct`\t\t\t\t\t\t|Is set to '1' if the last `response` matches the variable `correct_response`, '0' if not, and 'undefined' if the variable `correct_response` has not been set.|\n|`correct_[item_name]`\t\t\t|As `correct` but for a specifc response item.|\n\n### Feedback variables\n\nFeedback variables maintain a running average of accuracy and response times.\n\n|Variable name\t\t\t\t\t|Description|\n|-------------------------------|-----------|\n|`average_response_time`\t\t|The average response time. This is variable is useful for presenting feedback to the participant.|\n|`avg_rt`\t\t\t\t\t\t|Synonym for `average_response_time`|\n|`accuracy`\t\t\t\t\t\t|The average percentage of correct responses. This is variable is useful for presenting feedback to the participant.|\n|`acc`\t\t\t\t\t\t\t|Synonym for `accuracy`|\n\n\n## Using variables in the user interface\n\nWherever you see a value in the user interface, you can replace that value by a variable using the '{variable name}' notation. For example, if you have defined a variable `soa` in a LOOP item, you can use this variable for the duration of a sketchpad as shown in %FigSketchpad.\n\n<notranslate>\nfigure:\n id: FigSketchpad\n source: variable-duration.png\n caption: The duration '{soa}' indicates that the duration of the SKETCHPAD depends on the variable `soa`.\n</notranslate>\n\nThis works throughout the user interface. For example, if you have the defined a variable `my_freq`, you can use this variable as the frequency in a SYNTH item, as shown in %FigSynth.\n\n<notranslate>\nfigure:\n id: FigSynth\n source: variable-frequency.png\n caption: The frequency '{my_freq}' indicates that the frequency of the SYNTH depends on the variable `my_freq`.\n</notranslate>\n\nSometimes, the user interface doesn't let you type in arbitrary text. For example, the elements of a SKETCHPAD are shown visually, and you cannot directly change an X coordinate to a variable. However, you can click on the *Select view → View script* button on the top right, and edit the script directly.\n\nFor example, you can change the position of a fixation dot from the center:\n\n```text\ndraw fixdot x=0 y=0\n```\n\n… to a position defined by the variables `xpos` and `ypos`:\n\n```text\ndraw fixdot x={xpos} y={ypos}\n```\n\n\n## Using Python expressions in the user interface\n\nWhen referring to variables using the `{my_var}` notation, you are in fact using a so-called [f-string](https://peps.python.org/pep-0498/), which is a way to embed Python code in strings of text. You can also use f-strings to evaluate arbitrary Python code. For example, you can multiply the variables `width` and `height` and include the result in a SKETCHPAD, like so:\n\n<notranslate>\nfigure:\n id: FigFString\n source: fstrings.png\n caption: You can embed Python expressions using f-strings.\n</notranslate>\n\nf-strings are Python code, and are therefore only supported on the desktop, but see below for a JavaScript alternative for browser experiments.\n\n\n## Using JavaScript expressions in the user interface\n\nWhen using OSWeb, expressions included between curly braces are interpreted as [template literals](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals). This is very similar to f-strings in Python, with the important difference that it uses JavaScript.": {
    "fr": "|Nom de la variable\t\t\t\t\t|Description|\n|-------------------------------|-----------|\n|`response`\t\t\t\t\t\t|Contient la dernière réponse donnée.|\n|`response_[item_name]`\t\t\t|Contient la dernière réponse pour un élément de réponse spécifique. Ceci est utile s'il y a plusieurs éléments de réponse.|\n|`response_time`\t\t\t\t|Contient l'intervalle en millisecondes entre le début de l'intervalle de réponse et la dernière réponse.|\n|`response_time_[item_name]`\t|Contient le temps de réponse pour un élément de réponse spécifique.|\n|`correct`\t\t\t\t\t\t|Est défini sur '1' si la dernière `response` correspond à la variable `correct_response`, '0' sinon, et 'undefined' si la variable `correct_response` n'a pas été définie.|\n|`correct_[item_name]`\t\t\t|Comme `correct`, mais pour un élément de réponse spécifique.|\n\n### Variables de feedback\n\nLes variables de feedback maintiennent une moyenne mobile de la précision et des temps de réponse.\n\n|Nom de la variable\t\t\t\t\t|Description|\n|-------------------------------|-----------|\n|`average_response_time`\t\t|Le temps de réponse moyen. Cette variable est utile pour présenter un feedback au participant.|\n|`avg_rt`\t\t\t\t\t\t|Synonyme de `average_response_time`|\n|`accuracy`\t\t\t\t\t\t|Le pourcentage moyen de réponses correctes. Cette variable est utile pour présenter un feedback au participant.|\n|`acc`\t\t\t\t\t\t\t|Synonyme de `accuracy`|\n\n## Utilisation des variables dans l'interface utilisateur\n\nPartout où vous voyez une valeur dans l'interface utilisateur, vous pouvez remplacer cette valeur par une variable en utilisant la notation '{variable name}'. Par exemple, si vous avez défini une variable `soa` dans un élément LOOP, vous pouvez utiliser cette variable pour la durée d'un sketchpad comme indiqué dans %FigSketchpad.\n\n<notranslate>\nfigure :\n id: FigSketchpad\n source: variable-duration.png\n légende: La durée '{soa}' indique que la durée du SKETCHPAD dépend de la variable `soa`.\n</notranslate>\n\nCela fonctionne dans toute l'interface utilisateur. Par exemple, si vous avez défini une variable `my_freq`, vous pouvez utiliser cette variable comme fréquence dans un élément SYNTH, comme le montre %FigSynth.\n\n<notranslate>\nfigure :\n id: FigSynth\n source: variable-frequency.png\n légende : La fréquence '{my_freq}' indique que la fréquence du SYNTH dépend de la variable `my_freq`.\n</notranslate>\n\nParfois, l'interface utilisateur ne vous permet pas de taper du texte arbitraire. Par exemple, les éléments d'un SKETCHPAD sont affichés visuellement et vous ne pouvez pas changer directement une coordonnée X en une variable. Cependant, vous pouvez cliquer sur le bouton *Select view → View script* en haut à droite et modifier directement le script.\n\nPar exemple, vous pouvez changer la position d'un point de fixation du centre :\n\n```text\ndraw fixdot x=0 y=0\n```\n\n... vers une position définie par les variables `xpos` et `ypos` :\n\n```text\ndraw fixdot x={xpos} y={ypos}\n```\n\n## Utilisation des expressions Python dans l'interface utilisateur\n\nLorsque vous faites référence aux variables en utilisant la notation `{my_var}`, vous utilisez en fait ce qu'on appelle une [f-string](https://peps.python.org/pep-0498/), qui est un moyen d'intégrer du code Python dans des chaînes de texte. Vous pouvez également utiliser des f-strings pour évaluer du code Python arbitraire. Par exemple, vous pouvez multiplier les variables `width` et `height` et inclure le résultat dans un SKETCHPAD, comme suit :\n\n<notranslate>\nfigure :\n id: FigFString\n source: fstrings.png\n légende: Vous pouvez intégrer des expressions Python en utilisant des f-strings.\n</notranslate>\n\nLes f-strings sont du code Python et ne sont donc pris en charge que sur le bureau, mais voir ci-dessous pour une alternative JavaScript pour les expériences sur navigateur.\n\n## Utilisation des expressions JavaScript dans l'interface utilisateur\n\nLors de l'utilisation d'OSWeb, les expressions incluses entre accolades sont interprétées comme des [modèles littéraux](https://developer.mozilla.org/fr/docs/Web/JavaScript/Reference/Litt%C3%A9raux_gabarits). Cela ressemble beaucoup aux f-strings en Python, avec la différence importante qu'il utilise JavaScript."
  },
  "First, to use PsychoPy, you need to switch to the *psycho* backend, which you can do in the 'General properties' tab of your experiment . Now, when you start the experiment, OpenSesame will automatically initialize PsychoPy, and the `psychopy.visual.Window` object will be available as `win` in INLINE_SCRIPTs.\n\nNow let's see how we can implement our RSVP stream in PsychoPy. (The script below replaces the part in the *Prepare* phase of *RSVP* in which we created `letter_canvas_list`.)\n\n~~~ .python\nfrom psychopy import visual\ntextstim_list = []\nfor i, stim in enumerate(stim_list):\n    if i == var.T1_pos:\n        color = 'white'\n    else:\n        color = 'black'\n    # All stimuli require an psychopy.visual.Window object to be passed as first\n    # argument. In OpenSesame, this object is available as `win`.\n    textstim = visual.TextStim(win, text=stim, color=color)\n    textstim_list.append(textstim)\n~~~\n\nThe main difference with our previous script is that we don't draw text on a `canvas` object. Instead, the text is an object by itself (a `TextStim`), and it has its own `draw()` method to draw it to the screen.\n\nOf course, we also need to update the *Run* phase of the *RSVP* stream, which now looks like this:\n\n~~~ .python\nfor textstim in textstim_list:\n    textstim.draw()\n    win.flip()\n    clock.sleep(var.letter_dur)\n    win.flip()\n    clock.sleep(var.isi)\n~~~\n\nThe main difference here is that we need to call several methods to show our stimuli, instead of only `canvas.show()`. First, we need to call the `draw()` method on all stimuli that we want to show: `textstim.draw()` Next, we need to call `win.flip()` to refresh the display so that the stimuli actually become visible. If we call `win.flip()` without any preceding calls to `draw()`, as we do before the inter-stimulus-interval, it has the effect of clearing the display.\n\nThat's it!\n\n<div class='info-box' markdown='1'>\n\n### Links\n\n- [/backends/psycho/](/backends/psycho/)\n- <http://www.psychopy.org/api/visual.html>\n\n</div>\n\n## References\n\nAxelrod, V. (2014). Minimizing bugs in cognitive neuroscience programming. *Frontiers in Psychology: Perception Science*, *5*, 1435. doi:10.3389/fpsyg.2014.01435\n{: .reference}\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314–324. doi:10.3758/s13428-011-0168-7\n{: .reference}\n\nPeirce, J. W. (2007). PsychoPy: Psychophysics software in Python. Journal of Neuroscience Methods, 162(1-2), 8–13. doi:10.1016/j.jneumeth.2006.11.017\n{: .reference}\n\nRaymond, J. E., Shapiro, K. L., & Arnell, K. M. (1992). Temporary suppression of visual processing in an RSVP task: An attentional blink? *Journal of Experimental Psychology: Human Perception and Performance*, *18*(3), 849–860. doi:10.1037/0096-1523.18.3.849\n{: .reference}\n\n[OpenSesame runtime for Android]: /getting-opensesame/android\n[slides]: /attachments/neurospin2015-workshop-slides.pdf\n[pdf]: /neurospin2015/index.pdf\n[step-by-step tutorial]: /tutorials/step-by-step-tutorial/\n": {
    "fr": "Tout d'abord, pour utiliser PsychoPy, vous devez passer au moteur *psycho*, que vous pouvez faire dans l'onglet 'Propriétés générales' de votre expérience. Maintenant, lorsque vous démarrez l'expérience, OpenSesame initialisera automatiquement PsychoPy, et l'objet `psychopy.visual.Window` sera disponible sous le nom `win` dans les scripts INLINE.\n\nVoyons maintenant comment nous pouvons mettre en œuvre notre flux RSVP dans PsychoPy. (Le script ci-dessous remplace la partie de la phase *Préparer* de *RSVP* dans laquelle nous avons créé `letter_canvas_list`.)\n\n~~~ .python\nfrom psychopy import visual\ntextstim_list = []\nfor i, stim in enumerate(stim_list):\n    if i == var.T1_pos:\n        color = 'white'\n    else:\n        color = 'black'\n    # Tous les stimuli nécessitent un objet psychopy.visual.Window à passer en premier\n    # argument. Dans OpenSesame, cet objet est disponible sous le nom `win`.\n    textstim = visual.TextStim(win, text=stim, color=color)\n    textstim_list.append(textstim)\n~~~\n\nLa principale différence avec notre script précédent est que nous ne plaçons pas de texte sur un objet `canvas`. Au lieu de cela, le texte est un objet en soi (un `TextStim`), et il a sa propre méthode `draw()` pour le dessiner à l'écran.\n\nBien sûr, nous devons également mettre à jour la phase *Exécuter* du flux *RSVP*, qui ressemble maintenant à ceci :\n\n~~~ .python\nfor textstim in textstim_list:\n    textstim.draw()\n    win.flip()\n    clock.sleep(var.letter_dur)\n    win.flip()\n    clock.sleep(var.isi)\n~~~\n\nLa principale différence ici est que nous devons appeler plusieurs méthodes pour afficher nos stimuli, au lieu de simplement `canvas.show()`. Tout d'abord, nous devons appeler la méthode `draw()` sur tous les stimuli que nous voulons montrer : `textstim.draw()` Ensuite, nous devons appeler `win.flip()` pour actualiser l'affichage afin que les stimuli deviennent réellement visibles. Si nous appelons `win.flip()` sans appeler la méthode `draw()` au préalable, comme nous le faisons avant l'intervalle inter-stimulus, cela a pour effet d'effacer l'affichage.\n\nC'est tout !\n\n<div class='info-box' markdown='1'>\n\n### Liens\n\n- [/backends/psycho/](/backends/psycho/)\n- <http://www.psychopy.org/api/visual.html>\n\n</div>\n\n## Références\n\nAxelrod, V. (2014). Minimiser les erreurs de programmation en neurosciences cognitives. *Frontiers in Psychology: Perception Science*, *5*, 1435. doi:10.3389/fpsyg.2014.01435\n{: .reference}\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: Un générateur d'expériences graphiques open-source pour les sciences sociales. *Behavior Research Methods*, *44*(2), 314–324. doi:10.3758/s13428-011-0168-7\n{: .reference}\n\nPeirce, J. W. (2007). PsychoPy : Logiciel de psychophysique en Python. Journal of Neuroscience Methods, 162(1-2), 8–13. doi:10.1016/j.jneumeth.2006.11.017\n{: .reference}\n\nRaymond, J. E., Shapiro, K. L., & Arnell, K. M. (1992). Suppression temporaire du traitement visuel dans une tâche RSVP: un clignotement attentionnel? *Journal of Experimental Psychology: Human Perception and Performance*, *18*(3), 849–860. doi:10.1037/0096-1523.18.3.849\n{: .reference}\n\n[OpenSesame runtime pour Android]: /getting-opensesame/android\n[diapositives]: /attachments/neurospin2015-workshop-slides.pdf\n[pdf]: /neurospin2015/index.pdf\n[tutoriel étape par étape]: /tutorials/step-by-step-tutorial/"
  },
  "Intermediate tutorial (JavaScript): visual search": {
    "fr": "Tutoriel intermédiaire (JavaScript) : recherche visuelle"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## The basic steps\n\n\n<notranslate>\nfigure:\n id: FigWCST\n source: wcst.png\n caption: |\n  The Wisconsin Card Sorting Test (WCST) is a neuropsychological test of executive functions.\n</notranslate>\n\n\nIn this tutorial, you will implement the Wisconsin Card Sorting Test (WCST). You will also learn how to embed Python code in the experiment. (For the OSWeb implementation of this task, see [this tutorial](%url:wcst%)).\n\nIn the WCST, participants see four stimulus cards, which differ on three dimensions: color (red, green, blue, yellow), shape (circle, star, triangle, cross), and number of shapes (one, two, three, or four). Participants also see a single response card, which also has a color, shape, and number.\n\nThe participant's task is to match the response card to the correct stimulus card, based on a specific dimension (e.g. color), or *matching rule*. The participant initially doesn't know on which dimension to match, and his or her task is to figure out the matching rule through trial and error.\n\nTo make things more difficult, the matching rule changes after every five correct responses. Therefore, the participant needs to flexibly update their matching rule.\n\n\n### Step 1: Download and start OpenSesame\n\nOpenSesame is available for Windows, Linux, and Mac OS. This tutorial is written for OpenSesame 3.2 or higher.\n\nWhen you start OpenSesame, you will be given a choice of template experiments, and (if any) a list of recently opened experiments (see %FigStartUp).\n\n<notranslate>\nfigure:\n id: FigStartUp\n source: start-up.png\n caption: |\n  The OpenSesame window on start-up.\n</notranslate>\n\nThe *Extended template* provides a good starting point for creating many experiments that use a block-trial structure. However, in this tutorial we will create the entire experiment from scratch, and we will use the 'default template', which is already loaded when OpenSesame is launched (%FigDefaultTemplate). Therefore, simply close the 'Get started!' and (if shown) 'Welcome!' tabs.\n\n<notranslate>\nfigure:\n id: FigDefaultTemplate\n source: default-template.png\n caption: |\n  The structure of the 'Default template' as seen in the overview area.\n</notranslate>\n\n\n### Step 2: Add a block_loop and trial_sequence\n\nThe default template starts with three items: A NOTEPAD called *getting_started*, a SKETCHPAD called *welcome*, and a SEQUENCE called *experiment*. We don't need *getting_started* and *welcome*, so let's remove these right away. To do so, right-click on these items and select 'Delete'. Don't remove *experiment*, because it is the entry for the experiment (i.e. the first item that is called when the experiment is started).\n\nOur experiment will have a very simple structure. At the top of the hierarchy is a LOOP, which we will call *block_loop*. The *block_loop* is the place where we will define our independent variables. To add a LOOP to your experiment, drag the LOOP icon from the item toolbar onto the *experiment* item in the overview area.\n\nA LOOP item needs another item to run; usually, and in this case as well, this is a SEQUENCE. Drag the SEQUENCE item from the item toolbar onto the *new_loop* item in the overview area. OpenSesame will ask whether you want to insert the SEQUENCE into or after the LOOP. Select 'Insert into new_loop'.\n\nBy default, items have names such as *new_sequence*, *new_loop*, *new_sequence_2*, etc. These names are not very informative, and it is good practice to rename them. Item names must consist of alphanumeric characters and/ or underscores. To rename an item, double-click on the item in the overview area. Rename *new_sequence* to *trial_sequence* to indicate that it will correspond to a single trial. Rename *new_loop* to *block_loop* to indicate that will correspond to a block of trials.\n\nFinally, click on 'New experiment'to open the General Properties tab. Click on the title of the experiment, and rename it to 'Wisconsin Card Sorting Test'.": {
    "fr": "\n<notranslate>[TOC]</notranslate>\n\n## Les étapes de base\n\n<notranslate>\nfigure:\n id: FigWCST\n source: wcst.png\n caption: |\n  Le Wisconsin Card Sorting Test (WCST) est un test neuropsychologique des fonctions exécutives.\n</notranslate>\n\nDans ce tutoriel, vous allez mettre en œuvre le Wisconsin Card Sorting Test (WCST). Vous apprendrez également comment intégrer du code Python dans l'expérience. (Pour la mise en œuvre de cette tâche dans OSWeb, consultez [ce tutoriel](%url:wcst%)).\n\nDans le WCST, les participants voient quatre cartes stimulus, qui diffèrent selon trois dimensions : couleur (rouge, vert, bleu, jaune), forme (cercle, étoile, triangle, croix) et nombre de formes (une, deux, trois ou quatre). Les participants voient également une seule carte réponse, qui a aussi une couleur, une forme et un nombre.\n\nLa tâche du participant consiste à faire correspondre la carte réponse à la bonne carte stimulus, en fonction d'une dimension spécifique (par exemple la couleur), ou *règle de correspondance*. Le participant ne sait pas initialement sur quelle dimension faire correspondre, et sa tâche est de découvrir la règle de correspondance par essais et erreurs.\n\nPour compliquer les choses, la règle de correspondance change après chaque cinq réponses correctes. Le participant doit donc mettre à jour de manière flexible leur règle de correspondance.\n\n### Étape 1 : Télécharger et démarrer OpenSesame\n\nOpenSesame est disponible pour Windows, Linux et Mac OS. Ce tutoriel est rédigé pour OpenSesame 3.2 ou supérieur.\n\nLorsque vous démarrez OpenSesame, on vous propose un choix d'expériences modèle, et (le cas échéant) une liste d'expériences récemment ouvertes (voir %FigStartUp).\n\n<notranslate>\nfigure:\n id: FigStartUp\n source: start-up.png\n caption: |\n  La fenêtre OpenSesame au démarrage.\n</notranslate>\n\nLe *modèle étendu* offre un bon point de départ pour créer de nombreuses expériences qui utilisent une structure de bloc-essai. Cependant, dans ce tutoriel, nous créerons l'ensemble de l'expérience à partir de zéro, et nous utiliserons le 'modèle par défaut', qui est déjà chargé lorsque OpenSesame est lancé (%FigDefaultTemplate). Fermez simplement les onglets 'Commencer !' et (si affiché) 'Bienvenue !'.\n\n<notranslate>\nfigure:\n id: FigDefaultTemplate\n source: default-template.png\n caption: |\n  La structure du 'Modèle par défaut' vue dans la zone d'aperçu.\n</notranslate>\n\n### Étape 2 : Ajouter un block_loop et un trial_sequence\n\nLe modèle par défaut commence avec trois éléments : un NOTEPAD appelé *getting_started*, un SKETCHPAD appelé *welcome* et une SEQUENCE appelée *experiment*. Nous n'avons pas besoin de *getting_started* et *welcome*, alors supprimons-les tout de suite. Pour ce faire, faites un clic droit sur ces éléments et sélectionnez 'Supprimer'. Ne supprimez pas *experiment*, car c'est l'entrée de l'expérience (c'est-à-dire le premier élément appelé lorsque l'expérience est lancée).\n\nNotre expérience aura une structure très simple. Au sommet de la hiérarchie se trouve une LOOP, que nous appellerons *block_loop*. Le *block_loop* est l'endroit où nous définirons nos variables indépendantes. Pour ajouter une LOOP à votre expérience, faites glisser l'icône LOOP depuis la barre d'outils des éléments sur l'élément *experiment* dans la zone d'aperçu.\n\nUn élément LOOP a besoin d'un autre élément pour être exécuté ; généralement, et dans ce cas également, il s'agit d'une SEQUENCE. Faites glisser l'élément SEQUENCE depuis la barre d'outils des éléments sur l'élément *new_loop* dans la zone d'aperçu. OpenSesame vous demandera si vous voulez insérer la SEQUENCE dans ou après la LOOP. Sélectionnez 'Insérer dans new_loop'.\n\nPar défaut, les éléments ont des noms tels que *new_sequence*, *new_loop*, *new_sequence_2*, etc. Ces noms ne sont pas très informatifs et il est recommandé de les renommer. Les noms des éléments doivent être constitués de caractères alphanumériques et/ou de tirets bas. Pour renommer un élément, double-cliquez sur l'élément dans la zone d'aperçu. Renommez *new_sequence* en *trial_sequence* pour indiquer qu'il correspondra à un seul essai. Renommez *new_loop* en *block_loop* pour indiquer qu'il correspondra à un bloc d'essais.\n\nEnfin, cliquez sur 'Nouvelle expérience' pour ouvrir l'onglet Propriétés générales. Cliquez sur le titre de l'expérience et renommez-le 'Wisconsin Card Sorting Test'."
  },
  "In normal JavaScript, expressions inside template literals are prefixed with a `$`, like so: `${expression}`. This is allowed in OpenSesame but not necessary: the prefix is automatically added to improve compatibility between browser and desktop experiments. In most cases, as in the figure below, the exact same expression is valid as a Python f-string on the desktop and a JavaScript template literal in the browser.\n\n\n<notranslate>\nfigure:\n id: FigTempalteLiteral\n source: template-literals.png\n caption: You can embed JavaScript expressions using template literals.\n</notranslate>\n\n\n## Using variables in Python\n\nIn an INLINE_SCRIPT, experimental variables are available as global variables. For example, if you have defined `example_variable` in a LOOP, then the following will print the value `example_variable` to the debug window:\n\n~~~ .python\nprint(example_variable)\n~~~\n\nYou can set the experimental variable `example_variable` to the value 'some value' as follows:\n\n~~~ .python\nexample_variable = 'some value'\n~~~\n\n\n## Using variables in JavaScript\n\nIn an INLINE_JAVASCRIPT, experimental variables are available as global variables. For example, if you have defined `example_variable` in a LOOP, then the following will print the value `example_variable` to the browser console:\n\n```js\nconsole.log(example_variable)\n```\n\nYou can set the experimental variable `example_variable` to the value 'some value' as follows:\n\n```js\nexample_variable = 'some value'\n```\n\n\n## Using conditional (\"if\") statements\n\nConditional statements, or 'if statements', provide a way to indicate that something should happen only under specific circumstances, such when some variable has a specific value. Conditional statements are regular Python expressions.\n\nThe most commonly used if-statement in OpenSesame is the run-if statement of the SEQUENCE, which allows you to specify the conditions under which a particular element is executed. If you open a SEQUENCE item, you see that every item from the sequence has a 'Run if …'' option. The default value is 'always', which means that the item is always run; but you can also enter a condition here. For example, if you want to show a green fixation dot after a correct response, and a red fixation dot after an incorrect response, you can create a SEQUENCE like the following (this makes use of the fact that a KEYBOARD_RESPONSE item automatically sets the `correct` variable, as discussed above) as shown in %FigRunIf.\n\n*Important:* Run-if statements only apply to the Run phase of items. The Prepare phase is always executed. See also [this page](%link:prepare-run%).\n\n<notranslate>\nfigure:\n id: FigRunIf\n source: run-if.png\n caption: |\n  'Run if' statements can be used to indicate that certain items from a SEQUENCE should only be executed under specific circumstances.\n</notranslate>\n\nYou can use more complex conditions as well. Let's take a look at a few examples:\n\n```python\ncorrect == 1 and response_time > 2000\ncorrect != 1 or response_time > max_response_time or response_time < min_response_time\n```\n\nThe same principle applies to 'Show if' fields in SKETCHPAD items. For example, if you want to draw a right-upwards-pointing arrow only if the variable `quadrant` has been set to 'upper right', simply type the proper condition in the 'Show if ...' field and draw the arrow, as in %FigShowIf. Make sure that you draw the arrow after you have set the condition.\n\n<notranslate>\nfigure:\n id: FigShowIf\n source: show-if.png\n caption: \"'Show if' statements can be used to indicate that certain elements from a SKETCHPAD or FEEDBACK item should only be shown under specific circumstances.\"\n</notranslate>\n\nImportant: The moment at which a conditional statement is evaluated may affect how your experiment works. This is related to the prepare-run strategy employed by OpenSesame, which is explained here:\n\n- %link:prepare-run%\n": {
    "fr": "Dans le JavaScript normal, les expressions à l'intérieur des littéraux de modèle sont précédées d'un `$`, comme ceci : `${expression}`. Ceci est autorisé dans OpenSesame, mais pas nécessaire : le préfixe est ajouté automatiquement pour améliorer la compatibilité entre les expériences de bureau et de navigateur. Dans la plupart des cas, comme sur la figure ci-dessous, la même expression exacte est valable sous forme de chaîne f en Python sur le bureau et de littéral de modèle en JavaScript dans le navigateur.\n\n<notranslate>\nfigure:\n id: FigTempalteLiteral\n source: template-literals.png\n caption: Vous pouvez intégrer des expressions JavaScript en utilisant des littéraux de modèle.\n</notranslate>\n\n## Utilisation de variables en Python\n\nDans un INLINE_SCRIPT, les variables expérimentales sont disponibles en tant que variables globales. Par exemple, si vous avez défini `exemple_variable` dans une LOOP, alors le code suivant affichera la valeur `exemple_variable` dans la fenêtre de débogage :\n\n~~~ .python\nprint(example_variable)\n~~~\n\nVous pouvez définir la variable expérimentale `exemple_variable` à la valeur 'some value' comme suit :\n\n~~~ .python\nexemple_variable = 'some value'\n~~~\n\n## Utilisation de variables en JavaScript\n\nDans un INLINE_JAVASCRIPT, les variables expérimentales sont disponibles en tant que variables globales. Par exemple, si vous avez défini `exemple_variable` dans une LOOP, alors le code suivant affichera la valeur `exemple_variable` dans la console du navigateur :\n\n```js\nconsole.log(example_variable)\n```\n\nVous pouvez définir la variable expérimentale `exemple_variable` à la valeur 'some value' comme suit :\n\n```js\nexemple_variable = 'some value'\n```\n\n## Utilisation des instructions conditionnelles (\"if\")\n\nLes instructions conditionnelles, ou 'instructions if', permettent d'indiquer que quelque chose doit se produire uniquement dans des circonstances spécifiques, par exemple lorsqu'une variable a une valeur spécifique. Les instructions conditionnelles sont des expressions Python régulières.\n\nL'instruction if la plus couramment utilisée dans OpenSesame est l'instruction run-if de la SEQUENCE, qui vous permet de spécifier les conditions dans lesquelles un élément particulier est exécuté. Si vous ouvrez un élément de SEQUENCE, vous pouvez voir que chaque élément de la séquence a une option 'Run if …'. La valeur par défaut est 'always', ce qui signifie que l'élément est toujours exécuté ; mais vous pouvez également entrer une condition ici. Par exemple, si vous voulez montrer un point de fixation vert après une réponse correcte et un point de fixation rouge après une réponse incorrecte, vous pouvez créer une SEQUENCE comme suit (cela suppose qu'un élément KEYBOARD_RESPONSE ajuste automatiquement la variable `correct`, comme discuté précédemment) comme indiqué dans %FigRunIf.\n\n*Important :* Les instructions Run-if ne s'appliquent qu'à la phase Run des éléments. La phase Prepare est toujours exécutée. Voir également [cette page](%link:prepare-run%).\n\n<notranslate>\nfigure:\n id: FigRunIf\n source: run-if.png\n caption: |\n  'Run if' peut être utilisé pour indiquer que certains éléments d'une SEQUENCE ne doivent être exécutés que dans des circonstances spécifiques.\n</notranslate>\n\nVous pouvez utiliser des conditions plus complexes. Voyons quelques exemples :\n\n```python\ncorrect == 1 and response_time > 2000\ncorrect != 1 or response_time > max_response_time or response_time < min_response_time\n```\n\nLe même principe s'applique aux champs 'Show if' dans les items SKETCHPAD. Par exemple, si vous souhaitez dessiner une flèche pointant vers le haut à droite uniquement si la variable `quadrant` a été définie sur \"upper right\", il suffit de saisir la condition appropriée dans le champ 'Show if ...' et de dessiner la flèche, comme dans %FigShowIf. Assurez-vous de dessiner la flèche après avoir défini la condition.\n\n<notranslate>\nfigure:\n id: FigShowIf\n source: show-if.png\n caption: \"'Show if' peut être utilisé pour indiquer que certains éléments d'un item SKETCHPAD ou FEEDBACK ne doivent être montrés que dans des circonstances spécifiques.\"\n</notranslate>\n\nImportant : Le moment auquel une instruction conditionnelle est évaluée peut affecter le fonctionnement de votre expérience. Ceci est lié à la stratégie prepare-run utilisée par OpenSesame, qui est expliquée ici :\n\n- %link:prepare-run%"
  },
  "Using the interface": {
    "fr": "En utilisant l'interface"
  },
  "<notranslate>[TOC]</notranslate>\n\n## About OpenSesame\n\nOpenSesame is a user-friendly program for the development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface. For advanced users, OpenSesame supports Python (desktop only) and JavaScript (desktop and browser).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a basic visual-search experiment using OpenSesame [(Mathôt, Schreij, & Theeuwes, 2012)][references]. We will use both the graphical interface and JavaScript. Some experience with OpenSesame and JavaScript is recommended. This tutorial takes approximately one hour.\n\nA Python-based version of this tutorial is also available. If you don't need to run your experiments online, then the Python tutorial is likely what you need:\n\n- %link:tutorials/intermediate%\n\n\n## Resources\n\n- __Download__ — This tutorial assumes that you are running OpenSesame version 3.3.10 or later and OSWeb 1.4 or later. You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ — A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ — A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n\n\n## The experiment\n\nIn this tutorial, you will create a basic visual-search experiment. The experiment resembles the classic visual-search studies of [Treisman and Gelade (1980)][references], but it is not identical.\n\nBefore starting to *build* the experiment for yourself, you can already *participate* in it. This will give you a good idea of what you're working towards in this tutorial.\n\n<a role=\"button\" class=\"btn btn-success btn-align-left\" href=\"https://jatos.mindprobe.eu/publix/1938/start?batchId=2191&generalMultiple\">Participate in the experiment!</a>\n\nIn this experiment, participants search for a target object, which can be a yellow square, a yellow circle, a blue square, or a blue circle; the identity of the target is varied between blocks of trials. Participants indicate whether the target is present or not by pressing the right (present) or left (absent) arrow key.\n\nIn addition to the target, zero or more distractor objects are shown. There are three conditions, and the condition determines what kind of distractors there are:\n\n- In the *Conjunction* condition, distractors can have any shape and color, with the only restriction that distractors cannot be identical to the target. So, for example, if the target is a yellow square, then distractors are yellow circles, blue circles, and blue squares.\n- In the *Shape Feature* condition, distractors have a different shape from the target, but can have any color. So, for example, if the target is a yellow square, then distractors are yellow circles and blue circles.\n- In the *Color Feature* condition, distractors can have any shape, but have a different color from the target. So, for example, if the target is a yellow square, then distractors are blue squares and blue circles.\n\nImmediate feedback is shown after each trial: a green dot after a correct response, and a red dot after an incorrect response. Detailed feedback on average response times and accuracy is shown after each block of trials.\n\n<notranslate>\nfigure:\n id: FigVisualSearch\n source: visual-search.svg\n caption: |\n  The visual-search experiment that you will implement in this tutorial.\n</notranslate>\n\nExperiments like this show two typical findings:": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos d'OpenSesame\n\nOpenSesame est un programme convivial pour le développement d'expériences comportementales en psychologie, neurosciences et économie expérimentale. Pour les débutants, OpenSesame propose une interface graphique complète en mode point-and-click. Pour les utilisateurs avancés, OpenSesame prend en charge Python (seulement sur ordinateur) et JavaScript (pour ordinateur et navigateur).\n\nOpenSesame est disponible gratuitement sous la [General Public License v3][gpl].\n\n## À propos de ce tutoriel\n\nCe tutoriel montre comment créer une expérience de recherche visuelle de base à l'aide d'OpenSesame [(Mathôt, Schreij, & Theeuwes, 2012)][references]. Nous utiliserons à la fois l'interface graphique et JavaScript. Une certaine expérience avec OpenSesame et JavaScript est recommandée. Ce tutoriel dure environ une heure.\n\nUne version Python de ce tutoriel est également disponible. Si vous n'avez pas besoin d'exécuter vos expériences en ligne, le tutoriel Python est probablement ce dont vous avez besoin :\n\n- %link:tutorials/intermediate%\n\n\n## Ressources\n\n- __Téléchargement__ — Ce tutoriel suppose que vous utilisez la version 3.3.10 d'OpenSesame ou ultérieure et OSWeb 1.4 ou ultérieure. Vous pouvez télécharger la version la plus récente d'OpenSesame à partir de :\n\t- %link:download%\n- __Documentation__ — Un site web dédié à la documentation se trouve à :\n\t- < http://osdoc.cogsci.nl/ >\n- __Forum__ — Un forum d'assistance se trouve à :\n\t- < http://forum.cogsci.nl/ >\n\n\n## L'expérience\n\nDans ce tutoriel, vous créerez une expérience de recherche visuelle de base. L'expérience ressemble aux études classiques de recherche visuelle de [Treisman et Gelade (1980)][references], mais elle n'est pas identique.\n\nAvant de commencer à *construire* l'expérience par vous-même, vous pouvez déjà *participer* à celle-ci. Cela vous donnera une bonne idée de ce que vous allez réaliser dans ce tutoriel.\n\n<a role=\"button\" class=\"btn btn-success btn-align-left\" href=\"https://jatos.mindprobe.eu/publix/1938/start?batchId=2191&generalMultiple\">Participez à l'expérience !</a>\n\nDans cette expérience, les participants recherchent un objet cible, qui peut être un carré jaune, un cercle jaune, un carré bleu ou un cercle bleu ; l'identité de la cible varie entre les blocs d'essais. Les participants indiquent si la cible est présente ou non en appuyant sur la flèche droite (présente) ou gauche (absente) du clavier.\n\nEn plus de la cible, zéro ou plusieurs objets distracteurs sont affichés. Il y a trois conditions, et la condition détermine le type de distracteurs :\n\n- Dans la condition *Conjonction*, les distracteurs peuvent avoir n'importe quelle forme et couleur, à condition qu'ils ne soient pas identiques à la cible. Par exemple, si la cible est un carré jaune, les distracteurs sont des cercles jaunes, des cercles bleus et des carrés bleus.\n- Dans la condition *Caractéristique de forme*, les distracteurs ont une forme différente de la cible, mais peuvent avoir n'importe quelle couleur. Par exemple, si la cible est un carré jaune, les distracteurs sont des cercles jaunes et des cercles bleus.\n- Dans la condition *Caractéristique de couleur*, les distracteurs peuvent avoir n'importe quelle forme, mais ont une couleur différente de la cible. Par exemple, si la cible est un carré jaune, les distracteurs sont des carrés bleus et des cercles bleus.\n\nUn retour d'information immédiat est affiché après chaque essai : un point vert après une réponse correcte et un point rouge après une réponse incorrecte. Un retour d'information détaillé sur les temps de réponse moyens et la précision est affiché après chaque bloc d'essais.\n\n<notranslate>\nfigure:\n id: FigVisualSearch\n source: visual-search.svg\n caption: | \n  L'expérience de recherche visuelle que vous allez implémenter dans ce tutoriel.\n</notranslate>\n\nDes expériences comme celle-ci montrent deux résultats typiques :"
  },
  "The overview area of our experiment now looks as in %FigBasicStructure.\n\n<notranslate>\nfigure:\n id: FigBasicStructure\n source: basic-structure.png\n caption: |\n  The overview area at the end of Step 2.\n</notranslate>\n\n\n### Step 3: Import images and sound files\n\nFor this experiment, we will use images for the playing cards. You can download these from here:\n\n- %static:attachments/wisconsin-card-sorting-test/stimuli.zip%\n\nDownload `stimuli.zip` and extract it somewhere (to your desktop, for example). Next, in OpenSesame, click on the 'Show file pool' button in the main toolbar (or: Menu →View → Show file pool). This will show the file pool, by default on the right side of the window. The easiest way to add the stimuli to the file pool is by dragging them from the desktop (or wherever you have extracted the files to) into the file pool. Alternatively, you can click on the '+' button in the file pool and add files using the file-selection dialog that appears. The file pool will automatically be saved with your experiment.\n\nAfter you have added all stimuli, your file pool looks as in %FigFilePool.\n\n<notranslate>\nfigure:\n id: FigFilePool\n source: file-pool.png\n caption: |\n  The file pool containing the stimuli.\n</notranslate>\n\n\n### Step 4: Create a static card display\n\nTo start with, we'll create a display with four stimulus cards and one response card. However, which cards are shown will not, for now, depend on variables; that is, we will create a *static* display.\n\nDrag a a SKETCHPAD into *trial_sequence*, and rename it to *card_display*. Use the image tool to draw four cards in a horizontal row somewhere near the top of the display; these will be the stimulus cards. Draw a single card near the bottom of the display; this will be the response card. Also add some text to indicate to the participant what he or she has to do, namely press `a`, `b`, `c`, or `d` to indicate which of the stimulus cards matches the response card. The exact text, layout, and cards are up to you! Tips: you can use the *scale* option to adjust the size of the cards; you can change the background color in the General Properties tab, which you can open by clicking on the top-level item of the experiment.\n\nFor me, the result looks like this:\n\n\n<notranslate>\nfigure:\n id: FigStaticCards\n source: static-cards.png\n caption: |\n  A SKETCHPAD with statically defined cards.\n</notranslate>\n\n\n### Step 5: Make the response card variable\n\nRight now we're always showing the same response card (in the example above a single blue triangle). But of course we want to show a different response card on every trial. To do so, we first need to define the variables that determine which response card we will show. We will do this in the *block_loop*.\n\nOpen the *block_loop*. The LOOP table is now empty. To determine the color, shape, and number of the response card, we could manually create three columns (`response_color`, `response_shape`, and `response_number`) and 64 rows for all possible combinations of colors, shapes, and numbers. But that would be a lot of work. Instead, we will use the full-factorial-design wizard, which you can open by clicking on the 'Full-factorial design' button. (A full-factorial design is a design in which all possible combinations of variable levels occur.) In this wizard, you create one column for each of the three variables, and in the cells below enter the possible values for that variable (see %FigDesignWizard).\n\n\n<notranslate>\nfigure:\n id: FigDesignWizard\n source: design-wizard.png\n caption: |\n  The full-factorial-design wizard allows you to easily generate large LOOP tables that correspond to full-factorial designs.\n</notranslate>\n\n\nNext, click the OK button. The *block_loop* now contains all 64 combinations of colors, numbers, and shapes (see %FigLoopTable1).\n\n\n<notranslate>\nfigure:\n id: FigLoopTable1\n source: loop-table-1.png\n caption: |\n  The *block_loop* at the end of step 5.\n</notranslate>": {
    "fr": "La zone d'aperçu de notre expérience ressemble maintenant à celle de %FigBasicStructure.\n\n<notranslate>\nfigure:\n id: FigBasicStructure\n source: basic-structure.png\n caption: |\n  La zone d'aperçu à la fin de l'étape 2.\n</notranslate>\n\n\n### Étape 3: Importer des images et des fichiers sonores\n\nPour cette expérience, nous utiliserons des images pour les cartes à jouer. Vous pouvez les télécharger ici :\n\n- %static:attachments/wisconsin-card-sorting-test/stimuli.zip%\n\nTéléchargez `stimuli.zip` et extrayez-le quelque part (sur votre bureau, par exemple). Ensuite, dans OpenSesame, cliquez sur le bouton \"Afficher le pool de fichiers\" dans la barre d'outils principale (ou: Menu → Affichage → Afficher le pool de fichiers). Cela affichera le pool de fichiers, par défaut sur le côté droit de la fenêtre. La façon la plus simple d'ajouter les stimuli au pool de fichiers est de les faire glisser à partir du bureau (ou de l'endroit où vous avez extrait les fichiers) vers le pool de fichiers. Vous pouvez également cliquer sur le bouton '+' dans le pool de fichiers et ajouter des fichiers à l'aide de la boîte de dialogue de sélection de fichiers qui apparaît. Le pool de fichiers sera automatiquement sauvegardé avec votre expérience.\n\nAprès avoir ajouté tous les stimuli, votre pool de fichiers ressemblera à celui de %FigFilePool.\n\n<notranslate>\nfigure:\n id: FigFilePool\n source: file-pool.png\n caption: |\n  Le pool de fichiers contenant les stimuli.\n</notranslate>\n\n\n### Étape 4: Créer un affichage de cartes statique\n\nPour commencer, nous créerons un affichage avec quatre cartes stimulis et une carte réponse. Cependant, pour l'instant, les cartes affichées ne dépendront pas des variables ; autrement dit, nous allons créer un affichage *statique*.\n\nFaites glisser un SKETCHPAD dans *trial_sequence* et renommez-le *card_display*. Utilisez l'outil image pour dessiner quatre cartes dans une rangée horizontale près du haut de l'affichage ; il s'agira des cartes stimulis. Dessinez une seule carte près du bas de l'affichage ; ce sera la carte réponse. Ajoutez également du texte pour indiquer au participant ce qu'il doit faire, à savoir appuyer sur `a`, `b`, `c` ou `d` pour indiquer laquelle des cartes stimulis correspond à la carte réponse. Le texte exact, la disposition et les cartes sont à vous de choisir ! Astuces : vous pouvez utiliser l'option *scale* pour ajuster la taille des cartes ; vous pouvez changer la couleur d'arrière-plan dans l'onglet Propriétés Générales, que vous pouvez ouvrir en cliquant sur l'élément de niveau supérieur de l'expérience.\n\nPour moi, le résultat ressemble à ceci :\n\n<notranslate>\nfigure:\n id: FigStaticCards\n source: static-cards.png\n caption: |\n  Un SKETCHPAD avec des cartes définies de manière statique.\n</notranslate>\n\n\n### Étape 5: Rendre la carte réponse variable\n\nPour l'instant, nous montrons toujours la même carte réponse (dans l'exemple ci-dessus, un seul triangle bleu). Mais bien sûr, nous voulons afficher une carte réponse différente à chaque essai. Pour cela, nous devons d'abord définir les variables qui déterminent quelle carte réponse nous allons montrer. Nous le ferons dans le *block_loop*.\n\nOuvrez le *block_loop*. La table LOOP est maintenant vide. Pour déterminer la couleur, la forme et le nombre de la carte réponse, nous pourrions créer manuellement trois colonnes (`response_color`, `response_shape` et `response_number`) et 64 lignées pour toutes les combinaisons possibles de couleurs, formes et nombres. Mais cela représenterait beaucoup de travail. À la place, nous utiliserons l'assistant de conception à facteurs complets, que vous pouvez ouvrir en cliquant sur le bouton \"full-factorial design\". (Une conception à facteurs complets est une conception dans laquelle toutes les combinaisons possibles de niveaux de variables se produisent.) Dans cet assistant, vous créez une colonne pour chacune des trois variables, et dans les cellules ci-dessous, vous entrez les valeurs possibles pour cette variable (voir %FigDesignWizard).\n\n<notranslate>\nfigure:\n id: FigDesignWizard\n source: design-wizard.png\n caption: |\n  L'assistant de conception à facteurs complets vous permet de générer facilement de grandes tables LOOP correspondant à des conceptions à facteurs complets.\n</notranslate>\n\n\nEnsuite, cliquez sur le bouton OK. Le *block_loop* contient maintenant toutes les 64 combinaisons de couleurs, nombres et formes (voir %FigLoopTable1).\n\n<notranslate>\nfigure:\n id: FigLoopTable1\n source: loop-table-1.png\n caption: |\n  Le *block_loop* à la fin de l'étape 5.\n</notranslate>"
  },
  "- It takes more time to find the target in the Conjunction condition than in the two Feature conditions.\n- In the Conjunction condition, response times increase as the number of distractors increases. This suggests that people search for the target one item at a time; this is called *serial search*.\n- In the Feature conditions (both shape and color), response times do not, or hardly, increase as the the number of distractors increases. This suggests that people process the entire display at once; this is called *parallel search*.\n\nAccording to Treisman and Gelade's feature-integration theory, these results reflect that the Conjunction condition requires that you combine, or *bind*, the color and shape of each object. This binding requires attention, and you therefore need to shift your attention from one object to the next; this is slow, and explains why response times depend on how many objects there are. In contrast, in the Feature conditions, color and shape do not need to be bound, and therefore the whole display can be processed in a single sweep without attention being directed at each and every object.\n\n## Experimental design\n\nThis design:\n\n- Is *within-subject*, because all participants do all conditions\n- Is *fully-crossed* (or full factorial), because all combinations of conditions occur\n- Has three conditions (or factors):\n\t- Varied within blocks:\n\t\t- `set_size` with three levels (1, 5, 15), or SS<sub>3</sub>\n\t\t- `condition` with three levels (conjunction, feature_shape, feature_color), or CN<sub>3</sub>\n\t\t- `target_present` with two levels (present, absent), or TP<sub>2</sub>\n\t- Varied between blocks:\n\t\t- `target_shape` with two levels (square, circle), or TS<sub>2</sub>\n\t\t- `target_color` with two levels (yellow, blue), or TC<sub>2</sub>\n- Has N subjects, or <u>S</u><sub>N</sub>\n\nYou can write this design as <u>S</u><sub>N</sub>×SS<sub>3</sub>×CN<sub>3</sub>×TP<sub>2</sub>×TS<sub>2</sub>×TC<sub>2</sub>\n\nFor more information about this notation for experimental design, see:\n\n- %link:experimentaldesign%\n\n## Step 1: Create the basic structure of the experiment\n\nStart OpenSesame and, in the 'Get started!' tab, select the Extended template. This template provides the basic structure that is common to many cognitive-psychology experiments, such as the one that we will create here.\n\nThe Extended template contains a few items that we don't need. Delete the following items:\n\n- *about_this_template*\n- *practice_loop*\n- *end_of_practice*\n\nWhen you have deleted these items, they are still visible in the 'Unused items' bin. To permanently delete these items, click on the 'Unused items' bin, and then click on the 'Permanently delete unused items' button.\n\nFinally, give the experiment a good title, such as 'Visual search'. To do this, open the general-properties tab (by clicking on 'Extended template' in the overview area) and click on the experiment name to edit it.\n\nThe overview area should now look like %FigStep1:\n\n<notranslate>\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of step 1.\n</notranslate>\n\n## Step 2: Define experimental variables that are varied between blocks\n\nAs described above, two variables are varied between blocks in our experiment: `target_shape` and `target_color`. We therefore need to define these variables in the *experimental_loop*. To understand why, consider the structure shown in %FigStep1, starting from the bottom (i.e. the most indented level).": {
    "fr": "- Il faut plus de temps pour trouver la cible dans la condition de Conjonction que dans les deux conditions de Caractéristique.\n- Dans la condition de Conjonction, les temps de réponse augmentent à mesure que le nombre de distracteurs augmente. Cela suggère que les personnes recherchent la cible un élément à la fois ; cela s'appelle une *recherche sérielle*.\n- Dans les conditions de Caractéristique (forme et couleur), les temps de réponse n'augmentent pas, ou très peu, à mesure que le nombre de distracteurs augmente. Cela suggère que les personnes traitent l'ensemble de l'affichage en une seule fois ; cela s'appelle une *recherche parallèle*.\n\nSelon la théorie de l'intégration des caractéristiques de Treisman et Gelade, ces résultats reflètent que la condition de Conjonction nécessite de combiner, ou *lier*, la couleur et la forme de chaque objet. Cette liaison nécessite de l'attention, et vous devez donc déplacer votre attention d'un objet à l'autre ; cela est lent, et explique pourquoi les temps de réponse dépendent du nombre d'objets présents. En revanche, dans les conditions de Caractéristique, la couleur et la forme n'ont pas besoin d'être liées, et donc l'ensemble de l'affichage peut être traité en un seul balayage sans que l'attention ne soit dirigée vers chaque objet individuellement.\n\n## Conception expérimentale\n\nCette conception :\n\n- Est *intrasujet*, car tous les participants effectuent toutes les conditions\n- Est *entièrement croisée* (ou factorielle complète), car toutes les combinaisons de conditions se produisent\n- Comporte trois conditions (ou facteurs) :\n\t- Variées au sein des blocs :\n\t\t- `set_size` avec trois niveaux (1, 5, 15), soit SS<sub>3</sub>\n\t\t- `condition` avec trois niveaux (conjonction, caractéristique_forme, caractéristique_couleur), soit CN<sub>3</sub>\n\t\t- `target_present` avec deux niveaux (présent, absent), soit TP<sub>2</sub>\n\t- Variées entre les blocs :\n\t\t- `target_shape` avec deux niveaux (carré, cercle), soit TS<sub>2</sub>\n\t\t- `target_color` avec deux niveaux (jaune, bleu), soit TC<sub>2</sub>\n- Comporte N sujets, soit <u>S</u><sub>N</sub>\n\nVous pouvez écrire cette conception sous la forme <u>S</u><sub>N</sub>×SS<sub>3</sub>×CN<sub>3</sub>×TP<sub>2</sub>×TS<sub>2</sub>×TC<sub>2</sub>\n\nPour plus d'informations sur cette notation pour la conception expérimentale, consultez :\n\n- %link:experimentaldesign%\n\n## Étape 1 : Créer la structure de base de l'expérience\n\nLancez OpenSesame et, dans l'onglet 'Commencer !', sélectionnez le modèle Extended. Ce modèle fournit la structure de base commune à de nombreuses expériences de psychologie cognitive, comme celle que nous allons créer ici.\n\nLe modèle Extended contient quelques éléments dont nous n'avons pas besoin. Supprimez les éléments suivants :\n\n- *about_this_template*\n- *practice_loop*\n- *end_of_practice*\n\nLorsque vous avez supprimé ces éléments, ils sont toujours visibles dans la corbeille \"Unused items\". Pour supprimer définitivement ces éléments, cliquez sur la corbeille \"Unused items\", puis sur le bouton \"Supprimer définitivement les éléments inutilisés\".\n\nEnfin, donnez à l'expérience un bon titre, comme \"Recherche visuelle\". Pour ce faire, ouvrez l'onglet des propriétés générales (en cliquant sur \"Extended template\" dans la zone de vue d'ensemble) et cliquez sur le nom de l'expérience pour le modifier.\n\nLa zone de vue d'ensemble devrait maintenant ressembler à %FigStep1 :\n\n<notranslate>\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  La zone de vue d'ensemble à la fin de l'étape 1.\n</notranslate>\n\n## Étape 2 : Définir les variables expérimentales qui varient entre les blocs\n\nComme décrit ci-dessus, deux variables varient entre les blocs dans notre expérience : `target_shape` et `target_color`. Nous devons donc définir ces variables dans la *experimental_loop*. Pour comprendre pourquoi, considérez la structure montrée dans %FigStep1, en commençant par le bas (c.-à-d. le niveau le plus indenté)."
  },
  "OpenSesame has a powerful graphical interface that consists of several components (%FigInterface).\n\n<notranslate>\nfigure:\n id: FigInterface\n source: interface.png\n caption: The OpenSesame user interface.\n</notranslate>\n\n\n<notranslate>[TOC]</notranslate>\n\n## Toolbars and menubar\n\n### The menubar\n\nThe menubar (%FigMenubar) is shown at the top of the window, or, on some operating systems, is integrated into the border around the window. The menubar contains general functionality, such as saving and opening experiments, running experiments, etc.\n\n<notranslate>\nfigure:\n id: FigMenubar\n source: menubar.png\n caption: The menubar.\n</notranslate>\n\n### The main toolbar\n\nThe main toolbar (%FigMainToolbar) is (by default) shown at the top of the window, just below the menubar. The main toolbar contains a selection of the most relevant functionality from the menubar.\n\n<notranslate>\nfigure:\n id: FigMainToolbar\n source: main-toolbar.png\n caption: The main toolbar.\n</notranslate>\n\n### The item toolbar\n\nThe item toolbar (%FigItemToolbar) is (by default) shown at the left of the window. The item toolbar contains all items, that is, all building blocks of an experiment. You can add items to your experiment by dragging them from the item toolbar into the overview area.\n\n<notranslate>\nfigure:\n id: FigItemToolbar\n source: item-toolbar.png\n caption: The item toolbar.\n</notranslate>\n\n## The tab area\n\nThe tab area is the central part of the window (%FigTabArea). The tab area is where item controls, documentation, important messages, etc. are shown. The tab area can contain multiple tabs, and functions much like a tabbed web browser.\n\n<notranslate>\nfigure:\n id: FigTabArea\n source: tab-area.png\n caption: The tab area.\n</notranslate>\n\n## The overview area\n\nThe overview area (%FigOverviewArea) is (by default) shown at the left of the window, to the right of the item toolbar. The overview area shows the structure of your experiment as a tree. You can re-order the items in your experiment by dragging them from one position to another in the overview area.\n\n- Shortcut to hide/ show: `Ctrl+\\`\n\n<notranslate>\nfigure:\n id: FigOverviewArea\n source: overview-area.png\n caption: The overview area.\n</notranslate>\n\n## The file pool\n\nThe file pool (%FigFilePool) is (by default) shown at the right of the window. It provides an overview of all files that are bundled with the experiment.\n\n- Shortcut to hide/ show: `Ctrl+P`\n\n<notranslate>\nfigure:\n id: FigFilePool\n source: file-pool.png\n caption: The file pool.\n</notranslate>\n\n## The debug window\n\nThe debug window (%FigDebugWindow) is (by default) shown at the bottom of the window. It provides an [IPython interpreter](https://ipython.org/), and is used as the standard output while an experiment is running. That is, if you use the Python `print()` function, the result will be printed to the debug window.\n\n- Shortcut to hide/ show: `Ctrl+D`\n\n<notranslate>\nfigure:\n id: FigDebugWindow\n source: debug-window.png\n caption: The debug window.\n</notranslate>\n\n## The variable inspector\n\nThe variable inspector (%FigVariableInspector) is (by default) shown at the right of the window. It provides a list of all variables that are detected in your experiment. When you are running an experiment, the variable inspector also provides a real-time overview of variables and their values.\n\n- Shortcut to hide/ show: `Ctrl+I`\n\n<notranslate>\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: The variable inspector.\n</notranslate>\n\n## Keyboard shortcuts\n\nThe keyboard shortcuts listed below are default values. Many of them can be changed through *Menu → Tools → Preferences*.\n\n### General shortcuts\n\nThe following keyboard shortcuts are available everywhere:": {
    "fr": "OpenSesame possède une interface graphique puissante composée de plusieurs composants (%FigInterface).\n\n<notranslate>\nfigure:\n id: FigInterface\n source: interface.png\n caption: L'interface utilisateur d'OpenSesame.\n</notranslate>\n\n\n<notranslate>[TOC]</notranslate>\n\n## Barre d'outils et barre de menu\n\n### La barre de menu\n\nLa barre de menu (%FigMenubar) est affichée en haut de la fenêtre ou, sur certains systèmes d'exploitation, est intégrée à la bordure autour de la fenêtre. La barre de menu contient des fonctionnalités générales, telles que l'enregistrement et l'ouverture d'expériences, l'exécution d'expériences, etc.\n\n<notranslate>\nfigure:\n id: FigMenubar\n source: menubar.png\n caption: La barre de menu.\n</notranslate>\n\n### La barre d'outils principale\n\nLa barre d'outils principale (%FigMainToolbar) est (par défaut) affichée en haut de la fenêtre, juste en dessous de la barre de menu. La barre d'outils principale contient une sélection des fonctionnalités les plus pertinentes de la barre de menu.\n\n<notranslate>\nfigure:\n id: FigMainToolbar\n source: main-toolbar.png\n caption: La barre d'outils principale.\n</notranslate>\n\n### La barre d'outils des éléments\n\nLa barre d'outils des éléments (%FigItemToolbar) est (par défaut) affichée à gauche de la fenêtre. La barre d'outils des éléments contient tous les éléments, c'est-à-dire tous les blocs de construction d'une expérience. Vous pouvez ajouter des éléments à votre expérience en les faisant glisser depuis la barre d'outils des éléments dans la zone de présentation générale.\n\n<notranslate>\nfigure:\n id: FigItemToolbar\n source: item-toolbar.png\n caption: La barre d'outils des éléments.\n</notranslate>\n\n## La zone des onglets\n\nLa zone des onglets est la partie centrale de la fenêtre (%FigTabArea). La zone des onglets affiche les contrôles des éléments, la documentation, les messages importants, etc. La zone des onglets peut contenir plusieurs onglets et fonctionne de manière similaire à un navigateur Web à onglets.\n\n<notranslate>\nfigure:\n id: FigTabArea\n source: tab-area.png\n caption: La zone des onglets.\n</notranslate>\n\n## La zone de présentation générale\n\nLa zone de présentation générale (%FigOverviewArea) est (par défaut) affichée à gauche de la fenêtre, à droite de la barre d'outils des éléments. La zone de présentation générale montre la structure de votre expérience sous forme d'arbre. Vous pouvez réorganiser les éléments de votre expérience en les faisant glisser d'une position à une autre dans la zone de présentation générale.\n\n- Raccourci pour masquer/afficher : `Ctrl+\\`\n\n<notranslate>\nfigure:\n id: FigOverviewArea\n source: overview-area.png\n caption: La zone de présentation générale.\n</notranslate>\n\n## La réserve de fichiers\n\nLa réserve de fichiers (%FigFilePool) est (par défaut) affichée à droite de la fenêtre. Elle offre un aperçu de tous les fichiers associés à l'expérience.\n\n- Raccourci pour masquer/afficher : `Ctrl+P`\n\n<notranslate>\nfigure:\n id: FigFilePool\n source: file-pool.png\n caption: La réserve de fichiers.\n</notranslate>\n\n## La fenêtre de débogage\n\nLa fenêtre de débogage (%FigDebugWindow) est (par défaut) affichée en bas de la fenêtre. Elle fournit un [interpréteur IPython](https://ipython.org/) et est utilisée comme sortie standard lorsqu'une expérience est en cours d'exécution. Autrement dit, si vous utilisez la fonction Python `print()`, le résultat sera affiché dans la fenêtre de débogage.\n\n- Raccourci pour masquer/afficher : `Ctrl+D`\n\n<notranslate>\nfigure:\n id: FigDebugWindow\n source: debug-window.png\n caption: La fenêtre de débogage.\n</notranslate>\n\n## L'inspecteur de variables\n\nL'inspecteur de variables (%FigVariableInspector) est (par défaut) affiché à droite de la fenêtre. Il fournit une liste de toutes les variables détectées dans votre expérience. Lorsque vous exécutez une expérience, l'inspecteur de variables offre également un aperçu en temps réel des variables et de leurs valeurs.\n\n- Raccourci pour masquer/afficher : `Ctrl+I`\n\n<notranslate>\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: L'inspecteur de variables.\n</notranslate>\n\n## Raccourcis clavier\n\nLes raccourcis clavier listés ci-dessous sont des valeurs par défaut. Beaucoup d'entre eux peuvent être modifiés via *Menu → Outils → Préférences*.\n\n### Raccourcis généraux\n\nLes raccourcis clavier suivants sont disponibles partout :"
  },
  "OpenSesame doesn't automatically log data. Instead, you need to explicitly add a `logger` item to your experiment. In a trial-based experiment, a `logger` is generally the last item of the *trial_sequence*, so that it logs all the data that was collected during the trial.\n\nRight now, our WCST doesn't log any data. Time to fix that!\n\n\n### Extra 2 (easy): Inspect the data file\n\n*Requires that you have completed Extra 1*.\n\nGive the experiment a short test run. Now inspect the log file in a program like Excel, LibreOffice Calc, or JASP. Identify the relevant variables, and think of how you could analyze the results.\n\n__Pro-tip:__ Set the repeat value of the *block_loop* to 0.1 to reduce the number of trials during testing.\n\n\n### Extra 3 (easy): Add instructions and goodbye screen\n\nA good experiment comes with clear instructions. And a polite experiment says goodbye to the participants when they are done. You can use a SKETCHPAD to do this.\n\n\n### Extra 4 (medium): Set the correct response and matching rule through Python inline script\n\nTo include Python scripting in OpenSesame, you can use the INLINE_SCRIPT item.\n\nSo far, the matching rule is always to match by shape. To change this, add an INLINE_SCRIPT item to the start of the experiment, and use the following script (in the *prepare* phase) to randomly set the variable `matching_rule` to 'shape', 'number', or 'color'.\n\n```python\nimport random\n\nvar.matching_rule = random.choice(['shape', 'number', 'color'])\n```\n\nNow add another INLINE_SCRIPT item to the start of the *trial_sequence*. In the *prepare* phase, add a script to set the `correct_response` variable to 'a', 'b', 'c', or 'd'. To do so, you need a series of `if` statements, that first look at the matching rule, and then look at which shape corresponds to the response shape (for the shape-matching rule) or which color corresponds to the response color (for the color-matching rule) etc.\n\nTo get started, here's part of the solution (but it needs to be completed!):\n\n```python\nif var.matching_rule == 'shape':\n    if var.shape1 == var.response_shape:\n        var.correct_response = 'a'\n    # Not done yet\n# Not done yet\n\n# Let's print some info to the debug window\nprint('matching_rule = {}'.format(var.matching_rule))\nprint('correct_response = {}'.format(var.correct_response))\n```\n\n\n### Extra 5 (difficult): Periodically change the matching rule\n\nSo far, the matching rule is randomly determined at the start of the experiment, but then remains constant throughout the experiment. In a real WCST, the matching rule changes periodically, typically after the participant has made a fixed number of correct responses.\n\nTo implement this, you need another INLINE_SCRIPT. Here are some pointers to get started:\n\n- Use a counter variable that increments by 1 after a correct response, and is reset to 0 after an incorrect response.\n- When changing the matching rule, make sure that it is not (by coincidence) set to the same matching rule again.\n\n\n### Extra 6 (really difficult): Constrain the response card\n\nRight now, the response card can overlap with a stimulus card on multiple dimensions. For example, if one of the stimulus cards is a single blue circle, the response card might be two blue circles, thus overlapping on both color and shape. In a real WCST, the response card should overlap with each stimulus card on no more than a dimension.\n\nThis one is up to you. No pointers this time!\n\n\n## Solutions\n\nYou can download the full experiment, including the solutions to the extra assignments, here:\n\n- <https://osf.io/f5er2/>\n": {
    "fr": "OpenSesame ne consigne pas automatiquement les données. Au lieu de cela, vous devez ajouter explicitement un élément `logger` à votre expérience. Dans une expérience basée sur des essais, un `logger` est généralement le dernier élément de la *trial_sequence*, afin qu'il consigne toutes les données collectées pendant l'essai.\n\nEn ce moment, notre WCST ne consigne aucune donnée. Il est temps de régler cela !\n\n### Supplément 2 (facile) : Inspecter le fichier de données\n\n*Nécessite d'avoir terminé le Supplément 1*.\n\nFaites un court essai de l'expérience. Inspectez maintenant le fichier de journalisation dans un programme comme Excel, LibreOffice Calc ou JASP. Identifiez les variables pertinentes et réfléchissez à la manière dont vous pourriez analyser les résultats.\n\n__Astuce :__ Réglez la valeur de répétition de la *block_loop* sur 0,1 pour réduire le nombre d'essais lors des tests.\n\n### Supplément 3 (facile) : Ajouter des instructions et un écran d'au revoir\n\nUne bonne expérience est accompagnée d'instructions claires. Et une expérience polie dit au revoir aux participants lorsqu'ils ont terminé. Vous pouvez utiliser un SKETCHPAD pour cela.\n\n### Supplément 4 (moyen): Définir la réponse correcte et la règle de correspondance via du script Python en ligne\n\nPour inclure des scripts Python dans OpenSesame, vous pouvez utiliser l'élément INLINE_SCRIPT.\n\nJusqu'à présent, la règle de correspondance est toujours de correspondre par forme. Pour changer cela, ajoutez un élément INLINE_SCRIPT au début de l'expérience et utilisez le script suivant (dans la phase *prepare*) pour définir aléatoirement la variable `matching_rule` sur 'shape', 'number' ou 'color'.\n\n```python\nimport random\n\nvar.matching_rule = random.choice(['shape', 'number', 'color'])\n```\n\nAjoutez maintenant un autre élément INLINE_SCRIPT au début de la *trial_sequence*. Dans la phase *prepare*, ajoutez un script pour définir la variable `correct_response` sur 'a', 'b', 'c' ou 'd'. Pour ce faire, vous avez besoin d'une série d'instructions `if`, qui examinent d'abord la règle de correspondance, puis la forme qui correspond à la forme de la réponse (pour la règle de correspondance par forme) ou la couleur qui correspond à la couleur de la réponse (pour la règle de correspondance par couleur) etc.\n\nPour commencer, voici une partie de la solution (mais elle doit être complétée !) :\n\n```python\nif var.matching_rule == 'shape':\n    if var.shape1 == var.response_shape:\n        var.correct_response = 'a'\n    # Pas encore terminé\n# Pas encore terminé\n\n# Imprimons quelques informations dans la fenêtre de débogage\nprint('matching_rule = {}'.format(var.matching_rule))\nprint('correct_response = {}'.format(var.correct_response))\n```\n\n### Supplément 5 (difficile) : Modifier périodiquement la règle de correspondance\n\nJusqu'à présent, la règle de correspondance est déterminée aléatoirement au début de l'expérience, mais reste constante tout au long de l'expérience. Dans un véritable WCST, la règle de correspondance change périodiquement, généralement après que le participant a obtenu un nombre fixe de réponses correctes.\n\nPour cela, vous avez besoin d'un autre INLINE_SCRIPT. Voici quelques conseils pour commencer :\n\n- Utilisez une variable compteur qui s'incrémente de 1 après une réponse correcte et est réinitialisée à 0 après une réponse incorrecte.\n- Lors de la modification de la règle de correspondance, assurez-vous qu'elle n'est pas (par coïncidence) réglée à nouveau sur la même règle de correspondance.\n\n### Supplément 6 (vraiment difficile) : Contraindre la carte de réponse\n\nEn ce moment, la carte de réponse peut chevaucher une carte de stimulus sur plusieurs dimensions. Par exemple, si l'une des cartes de stimulus est un cercle bleu unique, la carte de réponse peut être deux cercles bleus, chevauchant ainsi à la fois la couleur et la forme. Dans un véritable WCST, la carte de réponse ne doit chevaucher chaque carte de stimulus sur pas plus d'une dimension.\n\nCelle-ci vous appartient. Pas de conseils cette fois !\n\n## Solutions\n\nVous pouvez télécharger l'expérience complète, y compris les solutions des tâches supplémentaires, ici :\n\n- <https://osf.io/f5er2/>"
  },
  "Intermediate tutorial (Python) visual search": {
    "fr": "Tutoriel intermédiaire (Python) recherche visuelle"
  },
  "- Quick switcher: `Ctrl+Space`\n- Command palette: `Ctrl+Shift+P`\n- New experiment: `Ctrl+N`\n- Open experiment: `Ctrl+O`\n- Save experiment: `Ctrl+S`\n- Save experiment as: `Ctrl+Shift+S`\n- Undo: `Ctrl+Alt+Z`\n- Redo: `Ctrl+Alt+Shift+Z`\n- Run experiment fullscreen: `Ctrl+R`\n- Run experiment in window: `Ctrl+W`\n- Quick-run experiment: `Ctrl+Shift+W`\n- Test experiment in browser: `Alt+Ctrl+W`\n- Show/ hide overview area: `Ctrl+\\`\n- Show/ hide debug window: `Ctrl+D`\n- Show/ hide file pool: `Ctrl+P`\n- Show/ hide variable inspector: `Ctrl+I`\n- Focus overview area: `Ctrl+1`\n- Focus tab area: `Ctrl+2`\n- Focus debug window: `Ctrl+3`\n- Focus file pool: `Ctrl+4`\n- Focus variable inspector: `Ctrl+5`\n\n### Editor shortcuts\n\nThe following keyboard shortcuts are available in editor components, such as the INLINE_SCRIPT:\n\n- (Un)comment selected line(s): `Ctrl+/`\n- Find text: `Ctrl+F`\n- Replace text: `Ctrl+H`\n- Hide find/ replace dialog: `Escape`\n- Duplicate line: `Ctrl+Shift+D`\n- Undo: `Ctrl+Z`\n- Redo: `Ctrl+Shift+Z`\n- Copy: `Ctrl+C`\n- Cut: `Ctrl+X`\n- Paste: `Ctrl+V`\n\n### Tab-area shortcuts\n\nThe following keyboard shortcuts are available in the tab area:\n\n- Next tab: `Ctrl+Tab`\n- Previous tab: `Ctrl+Shift+Tab`\n- Close other tabs: `Ctrl+T`\n- Close all tabs: `Ctrl+Alt+T`\n- Close current tab: `Alt+T`\n\n### Overview-area and sequence shortcuts\n\nThe following keyboard shortcuts are available in the overview area and the SEQUENCE item:\n\n- Context menu: `+`\n- Copy item (unlinked): `Ctrl+C`\n- Copy item (linked): `Ctrl+Shift+C`\n- Paste item: `Ctrl+V`\n- Delete item: `Del`\n- Permanently delete item: `Shift+Del`\n- Rename: `F2`\n- Change run-if statement (if applicable): `F3`\n": {
    "fr": "- Sélecteur rapide : `Ctrl+Espace`\n- Palette de commandes : `Ctrl+Maj+P`\n- Nouvelle expérience : `Ctrl+N`\n- Ouvrir une expérience : `Ctrl+O`\n- Sauvegarder une expérience : `Ctrl+S`\n- Sauvegarder une expérience sous : `Ctrl+Maj+S`\n- Annuler : `Ctrl+Alt+Z`\n- Rétablir : `Ctrl+Alt+Maj+Z`\n- Lancer l'expérience en plein écran : `Ctrl+R`\n- Lancer l'expérience dans une fenêtre : `Ctrl+W`\n- Lancer l'expérience rapidement : `Ctrl+Maj+W`\n- Tester l'expérience dans un navigateur : `Alt+Ctrl+W`\n- Afficher/ masquer la zone d'aperçu : `Ctrl+\\`\n- Afficher/ masquer la fenêtre de débogage : `Ctrl+D`\n- Afficher/ masquer la liste de fichiers : `Ctrl+P`\n- Afficher/ masquer l'inspecteur de variables : `Ctrl+I`\n- Mettre l'accent sur la zone d'aperçu : `Ctrl+1`\n- Mettre l'accent sur la zone des onglets : `Ctrl+2`\n- Mettre l'accent sur la fenêtre de débogage : `Ctrl+3`\n- Mettre l'accent sur la liste de fichiers : `Ctrl+4`\n- Mettre l'accent sur l'inspecteur de variables : `Ctrl+5`\n\n### Raccourcis de l'éditeur\n\nLes raccourcis clavier suivants sont disponibles dans les composants de l'éditeur, tels que le INLINE_SCRIPT :\n\n- (Dé)commenter la ou les lignes sélectionnées : `Ctrl+/`\n- Rechercher du texte : `Ctrl+F`\n- Remplacer du texte : `Ctrl+H`\n- Masquer la boîte de dialogue rechercher/remplacer : `Échap`\n- Dupliquer la ligne : `Ctrl+Maj+D`\n- Annuler : `Ctrl+Z`\n- Rétablir : `Ctrl+Maj+Z`\n- Copier : `Ctrl+C`\n- Couper : `Ctrl+X`\n- Coller : `Ctrl+V`\n\n### Raccourcis de la zone des onglets\n\nLes raccourcis clavier suivants sont disponibles dans la zone des onglets :\n\n- Onglet suivant : `Ctrl+Tab`\n- Onglet précédent : `Ctrl+Maj+Tab`\n- Fermer les autres onglets : `Ctrl+T`\n- Fermer tous les onglets : `Ctrl+Alt+T`\n- Fermer l'onglet actuel : `Alt+T`\n\n### Raccourcis de la zone d'aperçu et des séquences\n\nLes raccourcis clavier suivants sont disponibles dans la zone d'aperçu et l'élément SEQUENCE :\n\n- Menu contextuel : `+`\n- Copier l'élément (non lié) : `Ctrl+C`\n- Copier l'élément (lié) : `Ctrl+Maj+C`\n- Coller l'élément : `Ctrl+V`\n- Supprimer l'élément : `Suppr`\n- Supprimer définitivement l'élément : `Maj+Suppr`\n- Renommer : `F2`\n- Modifier la déclaration run-if (si applicable) : `F3`"
  },
  "- *trial_sequence* corresponds to a single trial\n- *block_loop* corresponds to a block of a trials\n\t- Therefore, variables defined here vary for each run of *trial_sequence*; in other words, variables defined in *block_loop* are varied __within blocks__.\n- *block_sequence* corresponds to a block of trials, preceded by resetting of the feedback variables, and followed by participant feedback\n- *experimental_loop* corresponds to multiple blocks of trials\n\t- Therefore, variables defined here vary for each run of *block_sequence*; in other words, variables defined in *experimental_loop* are varied __between blocks__.\n- *experiment* corresponds to the entire experimental, which is an instruction screen, followed by multiple blocks of trials, followed by an end-of-experiment screen\n\nClick on experimental loop, and define:\n\n- `target_shape`, which can be 'square' or 'circle'; and\n- `target_color`, which can be 'yellow' or 'blue'.\n\nWe have a full-factorial design, which means that all 2 × 2 = 4 combinations must occur. The table of *experimental_loop* should now look like %FigStep2:\n\n<notranslate>\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The table of *experimental_loop* at the end of step 2.\n</notranslate>\n\n## Step 3: Give instructions at the start of each block\n\nRight now, the experiment starts with a single *instructions* screen. In our case, we want to give instructions before each block of trials, to tell the participant what target to look for (because the identity of the target varies between blocks).\n\n__Move the instructions into block_sequence__\n\nTherefore, pick up the *instructions* item and drag it onto *block_sequence*. A pop-up will appear, asking you if you want to:\n\n- Insert the item into *block_sequence*, in which case *instructions* would become the first item of *block_sequence*; or\n- Insert the item after *block_sequence*, in which case *instructions* would move to a position after *block_sequence*.\n\nSelect the first option ('Insert into'). Now *block_sequence* starts with an instructions screen, which is what we want.\n\n__Add instructional text__\n\nClick on *instructions* to open it, and add a good instructional text, such as:\n\n```text\nINSTRUCTIONS\n\nSearch for the [target_color] [target_shape]\n\nPress the right-arrow key if you find it\nPress the left-arrow key if you don't\n\nPress any key to begin\n```\n\nThe square brackets around '[target_color]' and '[target_shape]' indicate that these are not literal text, but refer to the variables that we have defined in *experimental_loop*. When the experiment runs, the values of these variables will appear here, and the participant will see (for example), 'Search for the yellow circle'.\n\n__Give a visual preview of the target__\n\nIt also good to show the participant the actual stimulus that she needs to find. To do this:\n\n- Draw a filled circle at the center of the display (make sure it doesn't overlap with the text);\n- Change the color of the circle to '[target_color]'. This means that the color of the circle depends on the value of the variable `target_color`; and\n- Change the show-if statement to '[target_shape] = circle'.\n\nIn other words, we have drawn a circle of which the color is determined by `target_color`; furthermore, this circle is only shown when the variable `target_shape` has the value 'circle'. For more information about variables and show-if statements, see:\n\n- %link:manual/variables%\n\nWe use the same trick to draw a square:\n\n- Draw a filled square at the center of the display;\n- Change the color of the square to '[target_color]'; and\n- Change the show-if statement to '[target_shape] = square'\n\nThe *instructions*  screen should now look like %FigStep3:\n\n<notranslate>\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  The *instructions* screen at the end of step 3.\n</notranslate>\n\n## Step 4: Define experimental variables that are varied within blocks": {
    "fr": "- *trial_sequence* correspond à un essai unique\n- *block_loop* correspond à un bloc d'essais\n\t- Par conséquent, les variables définies ici varient pour chaque exécution de *trial_sequence* ; en d'autres termes, les variables définies dans *block_loop* varient __au sein des blocs__.\n- *block_sequence* correspond à un bloc d'essais, précédé par la réinitialisation des variables de feedback, et suivi par un feedback du participant\n- *experimental_loop* correspond à plusieurs blocs d'essais\n\t- Par conséquent, les variables définies ici varient pour chaque exécution de *block_sequence* ; en d'autres termes, les variables définies dans *experimental_loop* varient __entre les blocs__.\n- *experiment* correspond à l'ensemble de l'expérience, qui est un écran d'instruction, suivi de plusieurs blocs d'essais, suivi d'un écran de fin d'expérience\n\nCliquez sur experimental loop, et définissez :\n\n- `target_shape`, qui peut être 'carré' ou 'cercle' ; et\n- `target_color`, qui peut être 'jaune' ou 'bleu'.\n\nNous avons un plan factoriel complet, ce qui signifie que les 4 combinaisons 2 × 2 doivent se produire. La table de *experimental_loop* doit maintenant ressembler à %FigStep2:\n\n<notranslate>\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  La table de *experimental_loop* à la fin de l'étape 2.\n</notranslate>\n\n## Étape 3 : Donner des instructions au début de chaque bloc\n\nPour l'instant, l'expérience commence par un écran unique d'*instructions*. Dans notre cas, nous voulons donner des instructions avant chaque bloc d'essais, pour indiquer au participant quelle cible rechercher (car l'identité de la cible varie entre les blocs).\n\n__Déplacer les instructions dans block_sequence__\n\nPour cela, prenez l'élément *instructions* et faites-le glisser sur *block_sequence*. Une fenêtre contextuelle apparaîtra, vous demandant si vous souhaitez :\n\n- Insérer l'élément dans *block_sequence*, auquel cas *instructions* deviendrait le premier élément de *block_sequence* ; ou\n- Insérer l'élément après *block_sequence*, auquel cas *instructions* passerait à une position après *block_sequence*.\n\nSélectionnez la première option ('Insérer dans'). *block_sequence* commence maintenant par un écran d'instructions, ce que nous voulons.\n\n__Ajouter du texte d'instruction__\n\nCliquez sur *instructions* pour l'ouvrir et ajoutez un bon texte d'instruction, tel que :\n\n```text\nINSTRUCTIONS\n\nRecherchez le [target_shape] [target_color]\n\nAppuyez sur la touche flèche droite si vous le trouvez\nAppuyez sur la touche flèche gauche si vous ne le trouvez pas\n\nAppuyez sur n'importe quelle touche pour commencer\n```\n\nLes crochets autour de '[target_color]' et '[target_shape]' indiquent qu'il ne s'agit pas de texte littéral, mais qu'ils font référence aux variables que nous avons définies dans *experimental_loop*. Lorsque l'expérience se déroule, les valeurs de ces variables apparaîtront ici et le participant verra (par exemple) 'Recherchez le cercle jaune'.\n\n__Donner un aperçu visuel de la cible__\n\nIl est également bon de montrer au participant le stimulus qu'elle doit trouver. Pour ce faire :\n\n- Dessinez un cercle rempli au centre de l'affichage (assurez-vous qu'il ne chevauche pas le texte) ;\n- Changez la couleur du cercle en '[target_color]'. Cela signifie que la couleur du cercle dépend de la valeur de la variable `target_color` ; et\n- Changez la déclaration show-if en '[target_shape] = cercle'.\n\nEn d'autres termes, nous avons dessiné un cercle dont la couleur est déterminée par `target_color` ; en outre, ce cercle n'est affiché que lorsque la variable `target_shape` a la valeur 'cercle'. Pour plus d'informations sur les variables et les déclarations show-if, voir :\n\n- %link:manuel/variables%\n\nNous utilisons la même astuce pour dessiner un carré :\n\n- Dessinez un carré rempli au centre de l'affichage ;\n- Changez la couleur du carré en '[target_color]'; et\n- Changez la déclaration show-if en '[target_shape] = carré'\n\nL'écran *instructions* doit maintenant ressembler à %FigStep3:\n\n<notranslate>\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  L'écran *instructions* à la fin de l'étape 3.\n</notranslate>\n\n## Étape 4 : Définir les variables expérimentales qui varient au sein des blocs"
  },
  "<notranslate>[TOC]</notranslate>\n\n## About OpenSesame\n\nOpenSesame is a user-friendly program for the development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface.  For advanced users, OpenSesame supports Python (desktop only) and JavaScript (desktop and browser).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a basic visual-search experiment using OpenSesame [(Mathôt, Schreij, & Theeuwes, 2012)][references]. We will use both the graphical interface and Python scripting. Some experience with OpenSesame and Python is recommended. This tutorial takes approximately one hour.\n\nA JavaScript-based version of this tutorial is also available. If you want to run your experiments online (with OSWeb), then the JavaScript tutorial is what you need:\n\n- %link:tutorials/intermediate-javascript%\n\n## Resources\n\n- __Download__ — This tutorial assumes that you are running OpenSesame version 3.2.0 or later. You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ — A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ — A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n\n## The experiment\n\nIn this tutorial, you will create a basic visual-search experiment. The experiment resembles the classic visual-search studies of [Treisman and Gelade (1980)][references], but it is not identical.\n\nIn this experiment, participants search for a target object, which can be a yellow square, a yellow circle, a blue square, or a blue circle; the identity of the target is varied between blocks of trials. Participants indicate whether the target is present or not by pressing the right (present) or left (absent) arrow key.\n\nIn addition to the target, zero or more distractor objects are shown. There are three conditions, and the condition determines what kind of distractors there are:\n\n- In the *Conjunction* condition, distractors can have any shape and color, with the only restriction that distractors cannot be identical to the target. So, for example, if the target is a yellow square, then distractors are yellow circles, blue circles, and blue squares.\n- In the *Shape Feature* condition, distractors have a different shape from the target, but can have any color. So, for example, if the target is a yellow square, then distractors are yellow circles and blue circles.\n- In the *Color Feature* condition, distractors can have any shape, but have a different color from the target. So, for example, if the target is a yellow square, then distractors are blue squares and blue circles.\n\nImmediate feedback is shown after each trial: a green dot after a correct response, and a red dot after an incorrect response. Detailed feedback on average response times and accuracy is shown after each block of trials.\n\n<notranslate>\nfigure:\n id: FigVisualSearch\n source: visual-search.svg\n caption: |\n  The visual-search experiment that you will implement in this tutorial.\n</notranslate>\n\nExperiments like this show two typical findings:\n\n- It takes more time to find the target in the Conjunction condition than in the two Feature conditions.\n- In the Conjunction condition, response times increase as the number of distractors increases. This suggests that people search for the target one item at a time; this is called *serial search*.\n- In the Feature conditions (both shape and color), response times do not, or hardly, increase as the the number of distractors increases. This suggests that people process the entire display at once; this is called *parallel search*.": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos d'OpenSesame\n\nOpenSesame est un programme convivial pour le développement d'expériences comportementales en psychologie, neurosciences et économie expérimentale. Pour les débutants, OpenSesame dispose d'une interface graphique complète, basée sur des actions point et clic. Pour les utilisateurs avancés, OpenSesame prend en charge Python (bureau uniquement) et JavaScript (bureau et navigateur).\n\nOpenSesame est disponible gratuitement sous la [Licence publique générale v3][gpl].\n\n## À propos de ce tutoriel\n\nCe tutoriel montre comment créer une expérience de recherche visuelle de base en utilisant OpenSesame [(Mathôt, Schreij, & Theeuwes, 2012)][references]. Nous utiliserons à la fois l'interface graphique et les scripts Python. Une certaine expérience avec OpenSesame et Python est recommandée. Ce tutoriel dure environ une heure.\n\nUne version JavaScript de ce tutoriel est également disponible. Si vous souhaitez exécuter vos expériences en ligne (avec OSWeb), alors le tutoriel JavaScript est ce dont vous avez besoin :\n\n- %link:tutorials/intermediate-javascript%\n\n## Ressources\n\n- __Téléchargement__ — Ce tutoriel suppose que vous utilisez la version 3.2.0 d'OpenSesame ou ultérieure. Vous pouvez télécharger la version la plus récente d'OpenSesame à partir de :\n\t- %link:download%\n- __Documentation__ — Un site web de documentation dédié se trouve à l'adresse :\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ — Un forum de support est disponible à l'adresse :\n\t- <http://forum.cogsci.nl/>\n\n## L'expérience\n\nDans ce tutoriel, vous créerez une expérience de recherche visuelle de base. L'expérience ressemble aux études classiques de recherche visuelle de [Treisman et Gelade (1980)][references], mais elle n'est pas identique.\n\nDans cette expérience, les participants recherchent un objet cible, qui peut être un carré jaune, un cercle jaune, un carré bleu ou un cercle bleu ; l'identité de la cible varie entre les blocs d'essais. Les participants indiquent si la cible est présente ou non en appuyant sur la flèche droite (présente) ou gauche (absente).\n\nEn plus de la cible, zéro ou plusieurs objets distracteurs sont montrés. Il y a trois conditions, et la condition détermine quel type de distracteurs il y a :\n\n- Dans la condition *Conjonction*, les distracteurs peuvent avoir n'importe quelle forme et couleur, avec pour seule restriction que les distracteurs ne peuvent pas être identiques à la cible. Ainsi, par exemple, si la cible est un carré jaune, les distracteurs sont des cercles jaunes, des cercles bleus et des carrés bleus.\n- Dans la condition *Attribut de forme*, les distracteurs ont une forme différente de la cible, mais peuvent avoir n'importe quelle couleur. Ainsi, par exemple, si la cible est un carré jaune, les distracteurs sont des cercles jaunes et des cercles bleus.\n- Dans la condition *Attribut de couleur*, les distracteurs peuvent avoir n'importe quelle forme, mais ont une couleur différente de la cible. Ainsi, par exemple, si la cible est un carré jaune, les distracteurs sont des carrés bleus et des cercles bleus.\n\nUn retour d'information immédiat est présenté après chaque essai : un point vert après une réponse correcte et un point rouge après une réponse incorrecte. Des informations détaillées sur les temps de réponse moyens et la précision sont présentées après chaque bloc d'essais.\n\n<notranslate>\nfigure :\n id: FigVisualSearch\n source: visual-search.svg\n caption: |\n  L'expérience de recherche visuelle que vous allez mettre en œuvre dans ce tutoriel.\n</notranslate>\n\nLes expériences comme celle-ci montrent deux résultats typiques :\n\n- Il faut plus de temps pour trouver la cible dans la condition Conjonction que dans les deux conditions Attribut.\n- Dans la condition Conjonction, les temps de réponse augmentent à mesure que le nombre de distracteurs augmente. Cela suggère que les gens recherchent la cible un élément à la fois ; c'est ce qu'on appelle la *recherche série*.\n- Dans les conditions Attribut (forme et couleur), les temps de réponse n'augmentent pas, ou très peu, à mesure que le nombre de distracteurs augmente. Cela suggère que les gens traitent l'ensemble de l'affichage en même temps ; c'est ce qu'on appelle la *recherche parallèle*."
  },
  "Three variables are varied within blocks in our experiment: `condition`, `set_size`, and `target_present`. As described under Step 2, we need to define these variables in the *block_loop* so that they vary for each run of *trial_sequence*.\n\nThe three variables make a total of 3 × 3 × 2 = 18 different combinations. We can type these into the table manually, but, because we have full-factorial design, we can also use the full-factorial-design wizard. To do this, first open *block_loop* and click on the 'Full-factorial design' button.\n\nIn the table that appears, put the variable names on the first row, and the values on the rows below, as shown in %FigFullFactorial.\n\n<notranslate>\nfigure:\n id: FigFullFactorial\n source: fullfactorial.png\n caption: |\n  The *instructions* screen at the end of step 3.\n</notranslate>\n\nNow click on 'Ok' to generate the full design. The table of *block_loop* should now look like %FigStep4.\n\n<notranslate>\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  The table of *block_loop* at the end of step 4.\n</notranslate>\n\n## Step 5: Create the trial sequence\n\nWe want our trial sequence to look as follows:\n\n- A fixation dot, for which we will use a SKETCHPAD.\n- A search display, which we will create in JavaScript with a custom INLINE_JAVASCRIPT.\n- Response collection, for which we will use a KEYBOARD_RESPONSE.\n- Data logging, for which we will use a LOGGER.\n- (We also want immediate feedback after each trial, but we will get back to this later.)\n\nSo the only thing that is missing is an INLINE_JAVASCRIPT.\n\n- Insert a new INLINE_JAVASCRIPT after *sketchpad* and rename it to *search_display_script*.\n- Rename *sketchpad* to *fixation_dot*, so that its function is clear; and\n- Change the duration of *fixation_dot* to 500, so that the fixation dot is shown for 500 ms. (There should already be a fixation dot drawn; if not, draw one in the center of *fixation_dot*.)\n\nThe overview area should now look like %FigStep5.\n\n<notranslate>\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  The overview area at the end of step 5.\n</notranslate>\n\n## Step 6: Generate the search display\n\n__Top-down and defensive programming__\n\nNow things will get interesting: We will start programming in JavaScript. We will use two guiding principles: *top-down* and *defensive* programming.\n\n- *Top-down programming* means that we start with the most abstract logic, without bothering with how this logic is implemented. Once the most abstract logic is in place, we will move down to a slightly less abstract logic, and so on, until we arrive at the details of the implementation. This technique helps to keep the code structured.\n- *Defensive programming* means that we assume that we make mistakes. Therefore, to protect us from ourselves, we build sanity checks into the code.\n\n*Note:* The explanation below assumes that you're somewhat familiar with JavaScript. If concepts like `Array`, `for` loop, and functions don't mean anything to you, then it's best to first walk through an introductory JavaScript tutorial. You can find links to JavaScript tutorials here:\n\n- %link:manual/javascript/about%\n\nThe logic of the code is shown in %FigHierarchy. The numbers indicate the order in which we will implement the functionality, starting at the abstract level.\n\n<notranslate>\nfigure:\n id: FigHierarchy\n source: hierarchy.svg\n caption: |\n  The logic of the code to draw a visual-search display.\n</notranslate>\n\n__The Prepare and Run phases__\n\nOpen *search_display_script* and switch to the Prepare tab. OpenSesame distinguishes two phases of execution:": {
    "fr": "Trois variables varient à l'intérieur des blocs de notre expérience : `condition`, `set_size` et `target_present`. Comme décrit à l'étape 2, nous devons définir ces variables dans la *block_loop* afin qu'elles varient à chaque exécution de *trial_sequence*.\n\nLes trois variables représentent un total de 3 × 3 × 2 = 18 combinaisons différentes. Nous pouvons les saisir manuellement dans le tableau, mais, comme nous avons un plan factoriel complet, nous pouvons également utiliser l'assistant de plan factoriel complet. Pour ce faire, ouvrez d'abord *block_loop* et cliquez sur le bouton «Full-factorial design».\n\nDans le tableau qui apparaît, mettez les noms des variables sur la première ligne et les valeurs sur les lignes ci-dessous, comme indiqué dans %FigFullFactorial.\n\n<notranslate>\nfigure:\n id: FigFullFactorial\n source: fullfactorial.png\n caption: |\n  L'écran *instructions* à la fin de l'étape 3.\n</notranslate>\n\nCliquez maintenant sur «Ok» pour générer le plan complet. Le tableau de *block_loop* devrait maintenant ressembler à %FigStep4.\n\n<notranslate>\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  Le tableau de *block_loop* à la fin de l'étape 4.\n</notranslate>\n\n## Étape 5: Créer la séquence de test\n\nNous voulons que notre séquence de test soit:\n\n- Un point de fixation, pour lequel nous utiliserons un SKETCHPAD.\n- Un écran de recherche, que nous créerons en JavaScript avec un custom INLINE_JAVASCRIPT.\n- La collecte des réponses, pour laquelle nous utiliserons un KEYBOARD_RESPONSE.\n- L'enregistrement des données, pour lequel nous utiliserons un LOGGER.\n- (Nous souhaitons également avoir des commentaires immédiats après chaque essai, mais nous y reviendrons plus tard.)\n\nLa seule chose qui manque est un INLINE_JAVASCRIPT.\n\n- Insérez un nouvel INLINE_JAVASCRIPT après *sketchpad* et renommez-le en *search_display_script*.\n- Renommez *sketchpad* en *fixation_dot*, afin que sa fonction soit claire;\n- Changez la durée de *fixation_dot* à 500, pour que le point de fixation soit affiché pendant 500 ms. (Un point de fixation devrait déjà être dessiné ; sinon, en dessinez un au centre de *fixation_dot*.)\n\nLa zone d'aperçu devrait maintenant ressembler à %FigStep5.\n\n<notranslate>\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  La zone d'aperçu à la fin de l'étape 5.\n</notranslate>\n\n## Étape 6: Générer l'affichage de recherche\n\n__Programmation ascendante et défensive__\n\nLes choses vont devenir intéressantes : Nous allons commencer à programmer en JavaScript. Nous utiliserons deux principes directeurs : la programmation *ascendante* et *défensive*.\n\n- La *programmation ascendante* signifie que nous commençons par la logique la plus abstraite, sans nous soucier de la manière dont cette logique est mise en œuvre. Une fois que la logique la plus abstraite est en place, nous passons à un niveau de logique légèrement moins abstrait et ainsi de suite, jusqu'à ce que nous arrivions aux détails de la mise en œuvre. Cette technique contribue à garder le code structuré.\n- La *programmation défensive* signifie que nous supposons que nous faisons des erreurs. Par conséquent, pour nous protéger de nous-mêmes, nous intégrons des vérifications de cohérence dans le code.\n\n*Remarque:* L'explication ci-dessous suppose que vous êtes un peu familiarisé avec JavaScript. Si des concepts tels que `Array`, `for` loop et les fonctions ne signifient rien pour vous, il est préférable de suivre d'abord un tutoriel JavaScript d'introduction. Vous pouvez trouver des liens vers des tutoriels JavaScript ici:\n\n- %link:manual/javascript/about%\n\nLa logique du code est illustrée dans %FigHierarchy. Les chiffres indiquent dans quel ordre nous mettrons en œuvre les fonctionnalités, en commençant par le niveau abstrait.\n\n<notranslate>\nfigure:\n id: FigHierarchy\n source: hierarchy.svg\n caption: |\n  La logique du code pour dessiner un affichage de recherche visuelle.\n</notranslate>\n\n__Les phases de préparation et d'exécution__\n\nOuvrez *search_display_script* et passez à l'onglet Préparer. OpenSesame distingue deux phases d'exécution:"
  },
  "According to Treisman and Gelade's feature-integration theory, these results reflect that the Conjunction condition requires that you combine, or *bind*, the color and shape of each object. This binding requires attention, and you therefore need to shift your attention from one object to the next; this is slow, and explains why response times depend on how many objects there are. In contrast, in the Feature conditions, color and shape do not need to be bound, and therefore the whole display can be processed in a single sweep without attention being directed at each and every object.\n\n## Experimental design\n\nThis design:\n\n- Is *within-subject*, because all participants do all conditions\n- Is *fully-crossed* (or full factorial), because all combinations of conditions occur\n- Has three conditions (or factors):\n\t- Varied within blocks:\n\t\t- `set_size` with three levels (1, 5, 15), or SS<sub>3</sub>\n\t\t- `condition` with three levels (conjunction, feature_shape, feature_color), or CN<sub>3</sub>\n\t\t- `target_present` with two levels (present, absent), or TP<sub>2</sub>\n\t- Varied between blocks:\n\t\t- `target_shape` with two levels (square, circle), or TS<sub>2</sub>\n\t\t- `target_color` with two levels (yellow, blue), or TC<sub>2</sub>\n- Has N subjects, or <u>S</u><sub>N</sub>\n\nYou can write this design as <u>S</u><sub>N</sub>×SS<sub>3</sub>×CN<sub>3</sub>×TP<sub>2</sub>×TS<sub>2</sub>×TC<sub>2</sub>\n\nFor more information about this notation for experimental design, see:\n\n- %link:experimentaldesign%\n\n## Step 1: Create the basic structure of the experiment\n\nStart OpenSesame and, in the 'Get started!' tab, select the Extended template. This template provides the basic structure that is common to many cognitive-psychology experiments, such as the one that we will create here.\n\nThe Extended template contains a few items that we don't need. Delete the following items:\n\n- *about_this_template*\n- *practice_loop*\n- *end_of_practice*\n\nWhen you have deleted these items, they are still visible in the 'Unused items' bin. To permanently delete these items, click on the 'Unused items' bin, and then click on the 'Permanently delete unused items' button.\n\nFinally, give the experiment a good title, such as 'Visual search'. To do this, open the general-properties tab (by clicking on 'Extended template' in the overview area) and click on the experiment name to edit it.\n\nThe overview area should now look like %FigStep1:\n\n<notranslate>\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of step 1.\n</notranslate>\n\n## Step 2: Define experimental variables that are varied between blocks\n\nAs described above, two variables are varied between blocks in our experiment: `target_shape` and `target_color`. We therefore need to define these variables in the *experimental_loop*. To understand why, consider the structure shown in %FigStep1, starting from the bottom (i.e. the most indented level).\n\n- *trial_sequence* corresponds to a single trial\n- *block_loop* corresponds to a block of a trials\n\t- Therefore, variables defined here vary for each run of *trial_sequence*; in other words, variables defined in *block_loop* are varied __within blocks__.\n- *block_sequence* corresponds to a block of trials, preceded by resetting of the feedback variables, and followed by participant feedback\n- *experimental_loop* corresponds to multiple blocks of trials\n\t- Therefore, variables defined here vary for each run of *block_sequence*; in other words, variables defined in *experimental_loop* are varied __between blocks__.\n- *experiment* corresponds to the entire experimental, which is an instruction screen, followed by multiple blocks of trials, followed by an end-of-experiment screen\n\nClick on experimental loop, and define:\n\n- `target_shape`, which can be 'square' or 'circle'; and\n- `target_color`, which can be 'yellow' or 'blue'.": {
    "fr": "Selon la théorie de l'intégration des caractéristiques de Treisman et Gelade, ces résultats montrent que la condition Conjonction exige que vous combiniez, ou *liez*, la couleur et la forme de chaque objet. Cette liaison nécessite de l'attention, et vous devez donc déplacer votre attention d'un objet à l'autre ; cela est lent et explique pourquoi les temps de réponse dépendent du nombre d'objets présents. En revanche, dans les conditions des caractéristiques, la couleur et la forme n'ont pas besoin d'être liées, et l'ensemble du dispositif peut donc être traité en une seule fois sans que l'attention soit dirigée vers chaque objet.\n\n## Plan expérimental\n\nCe plan :\n\n- Est *intra-sujet*, car tous les participants font toutes les conditions\n- Est *entièrement croisé* (ou factoriel complet), car toutes les combinaisons de conditions se produisent\n- A trois conditions (ou facteurs) :\n\t- Variées au sein des blocs :\n\t\t- `set_size` avec trois niveaux (1, 5, 15), ou SS<sub>3</sub>\n\t\t- `condition` avec trois niveaux (conjonction, feature_shape, feature_color), ou CN<sub>3</sub>\n\t\t- `target_present` avec deux niveaux (présent, absent), ou TP<sub>2</sub>\n\t- Variées entre les blocs :\n\t\t- `target_shape` avec deux niveaux (carré, cercle), ou TS<sub>2</sub>\n\t\t- `target_color` avec deux niveaux (jaune, bleu), ou TC<sub>2</sub>\n- A N sujets, ou <u>S</u><sub>N</sub>\n\nVous pouvez écrire ce plan comme <u>S</u><sub>N</sub>×SS<sub>3</sub>×CN<sub>3</sub>×TP<sub>2</sub>×TS<sub>2</sub>×TC<sub>2</sub>\n\nPour plus d'informations sur cette notation pour la conception expérimentale, consultez :\n\n- %link:experimentaldesign%\n\n## Étape 1 : Créez la structure de base de l'expérience\n\nOuvrez OpenSesame et, dans l'onglet 'Démarrer !', sélectionnez le modèle étendu. Ce modèle fournit la structure de base qui est commune à de nombreuses expériences de psychologie cognitive, comme celle que nous allons créer ici.\n\nLe modèle étendu contient quelques éléments dont nous n'avons pas besoin. Supprimez les éléments suivants :\n\n- *about_this_template*\n- *practice_loop*\n- *end_of_practice*\n\nLorsque vous avez supprimé ces éléments, ils sont encore visibles dans la corbeille 'Unused items'. Pour supprimer définitivement ces éléments, cliquez sur la corbeille 'Unused items' puis sur le bouton 'Supprimer définitivement les éléments inutilisés'.\n\nEnfin, donnez un bon titre à l'expérience, comme 'Recherche visuelle'. Pour ce faire, ouvrez l'onglet des propriétés générales (en cliquant sur 'Extended template' dans la zone de vue d'ensemble) et cliquez sur le nom de l'expérience pour le modifier.\n\nLa zone de vue d'ensemble doit maintenant ressembler à %FigStep1 :\n\n<notranslate>\nfigure :\n id: FigStep1\n source: step1.png\n caption: |\n  La zone de vue d'ensemble à la fin de l'étape 1.\n</notranslate>\n\n## Étape 2 : Définir les variables expérimentales qui varient entre les blocs\n\nComme décrit ci-dessus, deux variables varient entre les blocs dans notre expérience : `target_shape` et `target_color`. Nous devons donc définir ces variables dans la *experimental_loop*. Pour comprendre pourquoi, considérez la structure montrée dans %FigStep1, en commençant par le bas (c'est-à-dire le niveau le plus indenté).\n\n- *trial_sequence* correspond à un essai unique\n- *block_loop* correspond à un bloc d'essais\n\t- Par conséquent, les variables définies ici varient pour chaque exécution de *trial_sequence* ; en d'autres termes, les variables définies dans *block_loop* varient __au sein des blocs__.\n- *block_sequence* correspond à un bloc d'essais, précédé par la réinitialisation des variables de feedback et suivi par des commentaires aux participants\n- *experimental_loop* correspond à plusieurs blocs d'essais\n\t- Par conséquent, les variables définies ici varient pour chaque exécution de *block_sequence* ; en d'autres termes, les variables définies dans *experimental_loop* varient __entre les blocs__.\n- *experiment* correspond à l'ensemble de l'expérience, qui est un écran d'instruction, suivi de plusieurs blocs d'essais, puis d'un écran de fin d'expérience\n\nCliquez sur experimental loop et définissez :\n\n- `target_shape`, qui peut être 'square' ou 'circle'; et\n- `target_color`, qui peut être 'yellow' ou 'blue'."
  },
  "- During the Prepare phase, each item is given the opportunity to prepare itself; what this means depends on the item: For a SKETCHPAD, it means drawing a canvas (but not showing it); for a SAMPLER, it means loading a sound file (but not playing it); etc.\n- During the Run phase, each item is actually executed; again, what this means depends on the item: For a SKETCHPAD, it means showing the previously prepared canvas; for a SAMPLER, it means playing a previously loaded sound file.\n\nFor an INLINE_JAVASCRIPT, you have to decide yourself what to put in the Prepare phase, and what to put in the Run phase. The distinction is usually quite clear: In our case, we put the code for drawing the canvas in the Prepare phase, and the code for showing the canvas (which is small) in the Run phase.\n\nSee also:\n\n- %link:prepare-run%\n\n\n__Choosing your version of JavaScript: ECMA 5.1 or 6__\n\nThe formal name of JavaScript is ECMASCRIPT, which exists in different versions. The latest version, ECMA 6 (or: ECMA 2015), has a number of useful features. ECMA 6 is supported by most modern browsers, which means that you can use these features when running an experiment in a browser. However, due to a limitation of the `js2py` library, which is used by OpenSesame to run JavaScript on the desktop, you can only use ECMA 5.1 when running the experiment on the desktop.\n\nIn many cases, you don't really care about being able to run your online experiment also on the desktop, in which case it makes sense to make use of ECMA 6. This is also the approach that we will take for this tutorial.\n\nIn other words: we will use ECMA 6 syntax, and therefore we will only be able to run the experiment in a browser, and not on the desktop.\n\n\n__Implement the abstract level__\n\nWe start at the most abstract level: defining a function that draws a visual-search display. We don't specify *how* this is done; we simply assume that there is a function that does this, and we will worry about the details later—that's top-down programming.\n\nIn the Prepare tab, enter the following code:\n\n```js\npersistent.c = draw_canvas()\n```\n\nWhat happens here? We …\n\n- Call `draw_canvas()`, which returns a `Canvas` object that we store as `c`; in other words, `c` is a `Canvas` object that corresponds the search display. This assumes that there is a function `draw_canvas()`, even though we haven't defined it yet.\n\nA `Canvas` object is a single display; it is, in a sense, the JavaScript counterpart of a SKETCHPAD. See also:\n\n- %link:manual/javascript/canvas%\n\nWe assign `c` as a property of the `persistent` object. This ensures that we are able to access `c` in the *Run* phase as well. This is necessary, because (unlike for Python INLINE_SCRIPT items) variables are not automatically shared between different INLINE_JAVASCRIPT items, nor between the Run and Prepare phase of the same INLINE_JAVASCRIPT item. See also:\n\nWe now go one step down by defining `draw_canvas()` (above the rest of the script so far):\n\n```js\n/**\n * Draws the search canvas.\n * @return A Canvas\n **/\nfunction draw_canvas() {\n    let c = Canvas()\n    let xy_list = xy_random(vars.set_size, 500, 500, 75)\n    if (vars.target_present === 'present') {\n        let [x, y] = xy_list.pop()\n        draw_target(c, x, y)\n    } else if (vars.target_present !== 'absent') {\n        throw 'Invalid value for target_present ' + vars.target_present\n    }\n    for (let [x, y] of xy_list) {\n        draw_distractor(c, x, y)\n    }\n    return c\n}\n```\n\n\nWhat happens here? We …": {
    "fr": "- Pendant la phase de préparation, chaque élément a l'occasion de se préparer ; ce que cela signifie dépend de l'élément : pour un SKETCHPAD, cela signifie dessiner un canevas (mais ne pas le montrer) ; pour un SAMPLER, cela signifie charger un fichier son (mais ne pas le jouer) ; etc.\n- Pendant la phase d'exécution, chaque élément est effectivement exécuté ; là encore, ce que cela signifie dépend de l'élément : pour un SKETCHPAD, cela signifie montrer le canevas préparé précédemment ; pour un SAMPLER, cela signifie jouer un fichier son précédemment chargé.\n\nPour un INLINE_JAVASCRIPT, vous devez décider vous-même quoi mettre dans la phase de préparation et quoi mettre dans la phase d'exécution. La distinction est généralement assez claire : dans notre cas, nous mettons le code pour dessiner le canevas dans la phase de préparation et le code pour montrer le canevas (qui est petit) dans la phase d'exécution.\n\nVoir aussi :\n\n- %link:prepare-run%\n\n__Choisir votre version de JavaScript : ECMA 5.1 ou 6__\n\nLe nom formel de JavaScript est ECMASCRIPT, qui existe en différentes versions. La dernière version, ECMA 6 (ou ECMA 2015), a un certain nombre de fonctionnalités utiles. ECMA 6 est pris en charge par la plupart des navigateurs modernes, ce qui signifie que vous pouvez utiliser ces fonctionnalités lorsque vous exécutez une expérience dans un navigateur. Cependant, en raison d'une limitation de la bibliothèque `js2py`, qui est utilisée par OpenSesame pour exécuter du JavaScript sur le bureau, vous ne pouvez utiliser que ECMA 5.1 lors de l'exécution de l'expérience sur le bureau.\n\nDans de nombreux cas, vous ne vous souciez pas vraiment de pouvoir exécuter votre expérience en ligne également sur le bureau, auquel cas il est logique d'utiliser ECMA 6. C'est également l'approche que nous adopterons pour ce tutoriel.\n\nEn d'autres termes : nous utiliserons la syntaxe ECMA 6, et donc nous ne pourrons exécuter l'expérience que dans un navigateur et non sur le bureau.\n\n__Mettre en œuvre le niveau abstrait__\n\nNous commençons au niveau le plus abstrait : définir une fonction qui dessine un affichage de recherche visuelle. Nous ne précisons pas *comment* cela est fait ; nous supposons simplement qu'il y a une fonction qui fait cela, et nous nous soucierons des détails plus tard - c'est de la programmation descendante.\n\nDans l'onglet Préparer, entrez le code suivant :\n\n```js\npersistent.c = draw_canvas()\n```\n\nQue se passe-t-il ici ? Nous ...\n\n- Appelons `draw_canvas()`, qui renvoie un objet `Canvas` que nous stockons en tant que `c` ; en d'autres termes, `c` est un objet `Canvas` qui correspond à l'affichage de recherche. Cela suppose qu'il y a une fonction `draw_canvas()`, même si nous ne l'avons pas encore définie.\n\nUn objet `Canvas` est un seul affichage ; il est, en un sens, l'équivalent JavaScript d'un SKETCHPAD. Voir aussi :\n\n- %link:manual/javascript/canvas%\n\nNous attribuons `c` comme propriété de l'objet `persistent`. Cela garantit que nous sommes en mesure d'accéder à `c` également dans la phase *Run*. Cela est nécessaire, car (contrairement aux éléments INLINE_SCRIPT Python) les variables ne sont pas automatiquement partagées entre différents éléments INLINE_JAVASCRIPT, ni entre les phases Run et Prepare du même élément INLINE_JAVASCRIPT. Voir aussi :\n\nNous passons maintenant à un niveau inférieur en définissant `draw_canvas()` (au-dessus du reste du script jusqu'à présent) :\n\n```js\n/**\n * Dessine le canevas de recherche.\n * @return Un Canvas\n **/\nfunction draw_canvas() {\n    let c = Canvas()\n    let xy_list = xy_random(vars.set_size, 500, 500, 75)\n    if (vars.target_present === 'present') {\n        let [x, y] = xy_list.pop()\n        draw_target(c, x, y)\n    } else if (vars.target_present !== 'absent') {\n        throw 'Valeur invalide pour target_present ' + vars.target_present\n    }\n    for (let [x, y] of xy_list) {\n        draw_distractor(c, x, y)\n    }\n    return c\n}\n```\n\nQue se passe-t-il ici ? Nous …"
  },
  "We have a full-factorial design, which means that all 2 × 2 = 4 combinations must occur. The table of *experimental_loop* should now look like %FigStep2:\n\n<notranslate>\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The table of *experimental_loop* at the end of step 2.\n</notranslate>\n\n## Step 3: Give instructions at the start of each block\n\nRight now, the experiment starts with a single *instructions* screen. In our case, we want to give instructions before each block of trials, to tell the participant what target to look for (because the identity of the target varies between blocks).\n\n__Move the instructions into block_sequence__\n\nTherefore, pick up the *instructions* item and drag it onto *block_sequence*. A pop-up will appear, asking you if you want to:\n\n- Insert the item into *block_sequence*, in which case *instructions* would become the first item of *block_sequence*; or\n- Insert the item after *block_sequence*, in which case *instructions* would move to a position after *block_sequence*.\n\nSelect the first option ('Insert into'). Now *block_sequence* starts with an instructions screen, which is what we want.\n\n__Add instructional text__\n\nClick on *instructions* to open it, and add a good instructional text, such as:\n\n```text\nINSTRUCTIONS\n\nSearch for the [target_color] [target_shape]\n\nPress the right-arrow key if you find it\nPress the left-arrow key if you don't\n\nPress any key to begin\n```\n\nThe square brackets around '[target_color]' and '[target_shape]' indicate that these are not literal text, but refer to the variables that we have defined in *experimental_loop*. When the experiment runs, the values of these variables will appear here, and the participant will see (for example), 'Search for the yellow circle'.\n\n__Give a visual preview of the target__\n\nIt also good to show the participant the actual stimulus that she needs to find. To do this:\n\n- Draw a filled circle at the center of the display (make sure it doesn't overlap with the text);\n- Change the color of the circle to '[target_color]'. This means that the color of the circle depends on the value of the variable `target_color`; and\n- Change the show-if statement to '[target_shape] = circle'.\n\nIn other words, we have drawn a circle of which the color is determined by `target_color`; furthermore, this circle is only shown when the variable `target_shape` has the value 'circle'. For more information about variables and show-if statements, see:\n\n- %link:manual/variables%\n\nWe use the same trick to draw a square:\n\n- Draw a filled square at the center of the display;\n- Change the color of the square to '[target_color]'; and\n- Change the show-if statement to '[target_shape] = square'\n\nThe *instructions*  screen should now look like %FigStep3:\n\n<notranslate>\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  The *instructions* screen at the end of step 3.\n</notranslate>\n\n## Step 4: Define experimental variables that are varied within blocks\n\nThree variables are varied within blocks in our experiment: `condition`, `set_size`, and `target_present`. As described under Step 2, we need to define these variables in the *block_loop* so that they vary for each run of *trial_sequence*.\n\nThe three variables make a total of 3 × 3 × 2 = 18 different combinations. We can type these into the table manually, but, because we have full-factorial design, we can also use the full-factorial-design wizard. To do this, first open *block_loop* and click on the 'Full-factorial design' button.\n\nIn the table that appears, put the variable names on the first row, and the values on the rows below, as shown in %FigFullFactorial.\n\n<notranslate>\nfigure:\n id: FigFullFactorial\n source: fullfactorial.png\n caption: |\n  The *instructions* screen at the end of step 3.\n</notranslate>\n\nNow click on 'Ok' to generate the full design. The table of *block_loop* should now look like %FigStep4.": {
    "fr": "Nous avons un plan factoriel complet, ce qui signifie que toutes les combinaisons 2 × 2 = 4 doivent se produire. Le tableau de *experimental_loop* devrait maintenant ressembler à %FigStep2 :\n\n<notranslate>\nfigure :\n id: FigStep2\n source: step2.png\n caption: |\n  Le tableau de *experimental_loop* à la fin de l'étape 2.\n</notranslate>\n\n## Étape 3 : Donner des instructions au début de chaque bloc\n\nPour l'instant, l'expérience commence par un seul écran d'instructions. Dans notre cas, nous voulons donner des instructions avant chaque bloc d'essais, pour indiquer au participant quelle cible rechercher (car l'identité de la cible varie entre les blocs).\n\n__Déplacez les instructions dans block_sequence__\n\nPour cela, saisissez l'élément *instructions* et faites-le glisser sur *block_sequence*. Une fenêtre contextuelle apparaîtra, vous demandant si vous voulez :\n\n- Insérer l'élément dans *block_sequence*, auquel cas *instructions* deviendrait le premier élément de *block_sequence* ; ou\n- Insérer l'élément après *block_sequence*, auquel cas *instructions* serait déplacé à une position après *block_sequence*.\n\nSélectionnez la première option ('Insérer dans'). Maintenant, *block_sequence* commence par un écran d'instructions, ce que nous voulons.\n\n__Ajoutez un texte d'instruction__\n\nCliquez sur *instructions* pour l'ouvrir et ajoutez un bon texte d'instruction, tel que :\n\n```text\nINSTRUCTIONS\n\nCherchez le [target_color] [target_shape]\n\nAppuyez sur la touche flèche droite si vous le trouvez\nAppuyez sur la touche flèche gauche si vous ne le trouvez pas\n\nAppuyez sur n'importe quelle touche pour commencer\n```\n\nLes crochets autour de '[target_color]' et '[target_shape]' indiquent qu'il ne s'agit pas de textes littéraux, mais qu'ils se réfèrent aux variables que nous avons définies dans *experimental_loop*. Lorsque l'expérience est en cours, les valeurs de ces variables apparaîtront ici, et le participant verra (par exemple) \"Cherchez le cercle jaune\".\n\n__Donnez un aperçu visuel de la cible__\n\nIl est également bon de montrer au participant le stimulus réel qu'il doit trouver. Pour ce faire :\n\n- Dessinez un cercle rempli au centre de l'affichage (assurez-vous qu'il ne se superpose pas au texte) ;\n- Changez la couleur du cercle en '[target_color]'. Cela signifie que la couleur du cercle dépend de la valeur de la variable `target_color` ; et\n- Changez l'instruction show-if en '[target_shape] = circle'.\n\nEn d'autres termes, nous avons dessiné un cercle dont la couleur est déterminée par `target_color` ; de plus, ce cercle n'est montré que lorsque la variable `target_shape` a la valeur 'circle'. Pour plus d'informations sur les variables et les instructions show-if, voir :\n\n- %link:manual/variables%\n\nNous utilisons la même astuce pour dessiner un carré :\n\n- Dessinez un carré rempli au centre de l'affichage ;\n- Changez la couleur du carré en '[target_color]' ; et\n- Changez l'instruction show-if en '[target_shape] = square'\n\nL'écran *instructions* devrait maintenant ressembler à %FigStep3 :\n\n<notranslate>\nfigure :\n id: FigStep3\n source: step3.png\n caption: |\n  L'écran *instructions* à la fin de l'étape 3.\n</notranslate>\n\n## Étape 4 : Définir les variables expérimentales qui varient à l'intérieur des blocs\n\nTrois variables varient à l'intérieur des blocs dans notre expérience : `condition`, `set_size` et `target_present`. Comme décrit à l'étape 2, nous devons définir ces variables dans le *block_loop* afin qu'elles varient pour chaque exécution de *trial_sequence*.\n\nLes trois variables font un total de 3 × 3 × 2 = 18 combinaisons différentes. Nous pouvons les saisir manuellement dans le tableau, mais, comme nous avons un plan factoriel complet, nous pouvons également utiliser l'assistant de plan factoriel complet. Pour ce faire, ouvrez d'abord *block_loop* et cliquez sur le bouton 'Plan factoriel complet'.\n\nDans le tableau qui apparaît, mettez les noms de variables sur la première ligne et les valeurs sur les lignes ci-dessous, comme indiqué dans %FigFullFactorial.\n\n<notranslate>\nfigure :\n id: FigFullFactorial\n source: fullfactorial.png\n caption: |\n  L'écran *instructions* à la fin de l'étape 3.\n</notranslate>\n\nCliquez maintenant sur 'Ok' pour générer la conception complète. Le tableau de *block_loop* devrait maintenant ressembler à %FigStep4."
  },
  "- Create an empty canvas, `c`, using the factory function `Canvas()`.\n- Generate an array of random `x, y` coordinates, called `xy_list`, using another common function, `xy_random()`. This array determines where the stimuli are shown. Locations are sampled from a 500 × 500 px area with a minimum spacing of 75 px.\n- Check if the experimental variable `target_present` has the value 'present'; if so, `pop()` one `x, y` tuple from `xy_list`, and draw the target at this location. This assumes that there is a function `draw_target()`, even though we haven't defined it yet.\n- If `target_present` is neither 'present' nor 'absent', we `throw` an error; this is defensive programming, and protects us from typos (e.g. if we had accidentally entered 'presenr' instead of 'present').\n- Loop through all remaining `x, y` values and draw a distractor at each position. This assumes that there is a function `draw_distractor()`, even though we haven't defined it yet.\n- Return `c`, which now has the search display drawn onto it.\n\nThere are several common functions, such as `Canvas()` and `xy_random()`, which are always available in an INLINE_JAVASCRIPT item. See:\n\n- %link:manual/javascript/common%\n\nIn JavaScript, experimental variables are stored as properties of the `vars` object. That's why you write `vars.set_size` and not directly `set_size`.\n\n__Implement the intermediate level__\n\nWe now go one more step down by defining `draw_target` (above the rest of the script so far):\n\n```js\n/**\n * Draws the target.\n * @param c A Canvas\n * @param x An x coordinate\n * @param y A y coordinate\n **/\nfunction draw_target(c, x, y) {\n    draw_shape(c, x, y, vars.target_color, vars.target_shape)\n}\n```\n\nWhat happens here? We …\n\n- Call another function, `draw_shape()`, and specify the color and shape that needs to be drawn. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nWe also define `draw_distractor` (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor.\n * @param c A Canvas\n * @param x An x coordinate\n * @param y A y coordinate\n **/\nfunction draw_distractor(c, x, y) {\n    if (vars.condition === 'conjunction') {\n        draw_conjunction_distractor(c, x, y)\n    } else if (vars.condition === 'feature_shape') {\n        draw_feature_shape_distractor(c, x, y)\n    } else if (vars.condition === 'feature_color') {\n        draw_feature_color_distractor(c, x, y)\n    } else {\n        throw 'Invalid condition: ' + vars.condition\n    }\n}\n```\n\nWhat happens here? We …\n\n- Call another function to draw a more specific distractor depending on the Condition.\n- Check whether `vars.condition` has any of the expected values. If not, we `throw` an error. This is defensive programming! Without this check, if we made a typo somewhere, the distractor might simply not be shown without causing an error message.\n\nNow we define the function that draws distractors in the Conjunction condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the conjunction condition: an object that\n * can have any shape and color, but cannot be identical to the target.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_conjunction_distractor(c, x, y) {\n    let conjunctions = [\n        ['yellow', 'circle'],\n        ['blue', 'circle'],\n        ['yellow', 'square'],\n        ['blue', 'square'],\n    ]\n    let [color, shape] = random.pick(conjunctions)\n    while (color === vars.target_color && shape === vars.target_shape) {\n        [color, shape] = random.pick(conjunctions)\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We …": {
    "fr": "- Créez un canvas vide, `c`, en utilisant la fonction usine `Canvas()`.\n- Générez un tableau de coordonnées `x, y` aléatoires, appelé `xy_list`, en utilisant une autre fonction courante, `xy_random()`. Ce tableau détermine où les stimuli sont affichés. Les emplacements sont échantillonnés à partir d'une zone de 500 × 500 px avec un espacement minimum de 75 px.\n- Vérifiez si la variable expérimentale `target_present` a la valeur 'present' ; si c'est le cas, `pop()` une paire `x, y` de `xy_list` et dessinez la cible à cet emplacement. Cela suppose qu'il y a une fonction `draw_target()`, même si nous ne l'avons pas encore définie.\n- Si `target_present` n'est ni 'present' ni 'absent', nous lançons une erreur ; c'est de la programmation défensive et cela nous protège des erreurs de frappe (par exemple, si nous avions accidentellement entré 'presenr' au lieu de 'present').\n- Bouclez toutes les valeurs restantes de `x, y` et dessinez un distracteur à chaque position. Cela suppose qu'il y a une fonction `draw_distractor()`, même si nous ne l'avons pas encore définie.\n- Retournez `c`, qui a maintenant l'affichage de recherche dessiné dessus.\n\nIl y a plusieurs fonctions courantes, telles que `Canvas()` et `xy_random()`, qui sont toujours disponibles dans un élément INLINE_JAVASCRIPT. Voir :\n\n- %link:manual/javascript/common%\n\nEn JavaScript, les variables expérimentales sont stockées en tant que propriétés de l'objet `vars`. C'est pourquoi vous écrivez `vars.set_size` et non directement `set_size`.\n\n__Mettre en œuvre le niveau intermédiaire__\n\nNous passons maintenant à une étape supplémentaire en définissant `draw_target` (au-dessus du reste du script jusqu'à présent) :\n\n```js\n/**\n * Dessine la cible.\n * @param c Un Canvas\n * @param x Une coordonnée x\n * @param y Une coordonnée y\n **/\nfunction draw_target(c, x, y) {\n    draw_shape(c, x, y, vars.target_color, vars.target_shape)\n}\n```\n\nQue se passe-t-il ici ? Nous...\n\n- Appelons une autre fonction, `draw_shape()`, et spécifions la couleur et la forme à dessiner. Cela suppose qu'il y a une fonction `draw_shape()`, même si nous ne l'avons pas encore définie.\n\nNous définissons également `draw_distractor` (au-dessus du reste du script jusqu'à présent) :\n\n```js\n/**\n * Dessine un seul distracteur.\n * @param c Un Canvas\n * @param x Une coordonnée x\n * @param y Une coordonnée y\n **/\nfunction draw_distractor(c, x, y) {\n    if (vars.condition === 'conjunction') {\n        draw_conjunction_distractor(c, x, y)\n    } else if (vars.condition === 'feature_shape') {\n        draw_feature_shape_distractor(c, x, y)\n    } else if (vars.condition === 'feature_color') {\n        draw_feature_color_distractor(c, x, y)\n    } else {\n        throw 'Condition non valide : ' + vars.condition\n    }\n}\n```\n\nQue se passe-t-il ici ? Nous...\n\n- Appelons une autre fonction pour dessiner un distracteur plus spécifique en fonction de la condition.\n- Vérifions si `vars.condition` a l'une des valeurs attendues. Sinon, nous lançons une erreur. C'est de la programmation défensive ! Sans cette vérification, si nous faisions une erreur de frappe quelque part, le distracteur pourrait simplement ne pas être affiché sans provoquer de message d'erreur.\n\nMaintenant, nous définissons la fonction qui dessine les distracteurs dans la condition Conjonction (au-dessus du reste du script jusqu'à présent) :\n\n```js\n/**\n * Dessine un seul distracteur dans la condition de conjonction : un objet qui\n * peut avoir n'importe quelle forme et couleur, mais ne peut pas être identique à la cible.\n * @param c Un Canvas.\n * @param x Une coordonnée x.\n * @param y Une coordonnée y.\n **/\nfunction draw_conjunction_distractor(c, x, y) {\n    let conjunctions = [\n        ['jaune', 'cercle'],\n        ['bleu', 'cercle'],\n        ['jaune', 'carré'],\n        ['bleu', 'carré'],\n    ]\n    let [couleur, forme] = random.pick(conjunctions)\n    while (couleur === vars.target_color && forme === vars.target_shape) {\n        [couleur, forme] = random.pick(conjunctions)\n    }\n    draw_shape(c, x, y, couleur, forme)\n}\n```\n\nQue se passe-t-il ici ? Nous …"
  },
  "<notranslate>\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  The table of *block_loop* at the end of step 4.\n</notranslate>\n\n## Step 5: Create the trial sequence\n\nWe want our trial sequence to look as follows:\n\n- A fixation dot, for which we will use a SKETCHPAD.\n- A search display, which we will create in Python with a custom INLINE_SCRIPT.\n- Response collection, for which we will use a KEYBOARD_RESPONSE.\n- Data logging, for which we will use a LOGGER.\n- (We also want immediate feedback after each trial, but we will get back to this later.)\n\nSo the only thing that is missing is an INLINE_SCRIPT.\n\n- Insert a new INLINE_SCRIPT after *sketchpad* and rename it to *search_display_script*.\n- Rename *sketchpad* to *fixation_dot*, so that its function is clear; and\n- Change the duration of *fixation_dot* to 500, so that the fixation dot is shown for 500 ms. (There should already be a fixation dot drawn; if not, draw one in the center of *fixation_dot*.)\n\nThe overview area should now look like %FigStep5.\n\n<notranslate>\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  The overview area at the end of step 5.\n</notranslate>\n\n## Step 6: Generate the search display\n\n__Top-down and defensive programming__\n\nNow things will get interesting: We will start programming in Python. We will use two guiding principles: *top-down* and *defensive* programming.\n\n- *Top-down programming* means that we start with the most abstract logic, without bothering with how this logic is implemented. Once the most abstract logic is in place, we will move down to a slightly less abstract logic, and so on, until we arrive at the details of the implementation. This technique helps to keep the code structured.\n- *Defensive programming* means that we assume that we make mistakes. Therefore, to protect us from ourselves, we build sanity checks into the code.\n\n*Note:* The explanation below assumes that you're somewhat familiar with Python code. If concepts like `list`, `tuple`, and functions don't mean anything to you, then it's best to first walk through an introductory Python tutorial. You can find links to Python tutorials here:\n\n- %link:manual/python/about%\n\nThe logic of the code is shown in %FigHierarchy. The numbers indicate the order in which we will implement the functionality, starting at the abstract level.\n\n<notranslate>\nfigure:\n id: FigHierarchy\n source: hierarchy.svg\n caption: |\n  The logic of the code to draw a visual-search display.\n</notranslate>\n\n__The Prepare and Run phases__\n\nOpen *search_display_script* and switch to the Prepare tab. OpenSesame distinguishes two phases of execution:\n\n- During the Prepare phase, each item is given the opportunity to prepare itself; what this means depends on the item: For a SKETCHPAD, it means drawing a canvas (but not showing it); for a SAMPLER, it means loading a sound file (but not playing it); etc.\n- During the Run phase, each item is actually executed; again, what this means depends on the item: For a SKETCHPAD, it means showing the previously prepared canvas; for a SAMPLER, it means playing a previously loaded sound file.\n\nFor an INLINE_SCRIPT, you have to decide yourself what to put in the Prepare phase, and what to put in the Run phase. The distinction is usually quite clear: In our case, we put the code for drawing the canvas in the Prepare phase, and the code for showing the canvas (which is small) in the Run phase.\n\nSee also:\n\n- %link:prepare-run%\n\n__Implement the abstract level__\n\nWe start at the most abstract level: defining a function that draws a visual-search display. We don't specify *how* this is done; we simply assume that there is a function that does this, and we will worry about the details later—that's top-down programming.\n\nIn the Prepare tab, enter the following code:\n\n~~~ .python\nc = draw_canvas()\n~~~\n\nWhat happens here? We …": {
    "fr": "<notranslate>\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  Le tableau de *block_loop* à la fin de l'étape 4.\n</notranslate>\n\n## Étape 5 : Créer la séquence d'essai\n\nNous voulons que notre séquence d'essai ressemble à ceci :\n\n- Un point de fixation, pour lequel nous utiliserons un SKETCHPAD.\n- Un affichage de recherche, que nous créerons en Python avec un INLINE_SCRIPT personnalisé.\n- La collecte des réponses, pour laquelle nous utiliserons un KEYBOARD_RESPONSE.\n- L'enregistrement des données, pour lequel nous utiliserons un LOGGER.\n- (Nous voulons également avoir un retour d'information immédiat après chaque essai, mais nous y reviendrons plus tard.)\n\nIl ne manque donc qu'un INLINE_SCRIPT.\n\n- Insérez un nouveau INLINE_SCRIPT après *sketchpad* et renommez-le en *search_display_script*.\n- Renommez *sketchpad* en *fixation_dot*, afin que sa fonction soit claire ; et\n- Changez la durée de *fixation_dot* en 500, de sorte que le point de fixation soit affiché pendant 500 ms. (Il devrait déjà y avoir un point de fixation dessiné ; sinon, dessinez-en un au centre de *fixation_dot*.)\n\nLa zone d'aperçu devrait maintenant ressembler à %FigStep5.\n\n<notranslate>\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  La zone d'aperçu à la fin de l'étape 5.\n</notranslate>\n\n## Étape 6 : Générer l'affichage de recherche\n\n__Programmation descendante et défensive__\n\nMaintenant, les choses vont devenir intéressantes : nous commencerons à programmer en Python. Nous utiliserons deux principes directeurs : la programmation *descendante* et *défensive*.\n\n- La *programmation descendante* signifie que nous commençons par la logique la plus abstraite, sans nous soucier de la façon dont cette logique est mise en œuvre. Une fois la logique la plus abstraite en place, nous passerons à une logique légèrement moins abstraite, et ainsi de suite, jusqu'à ce que nous arrivions aux détails de l'implémentation. Cette technique aide à garder le code structuré.\n- La *programmation défensive* signifie que nous supposons que nous faisons des erreurs. Par conséquent, pour nous protéger de nous-mêmes, nous intégrons des vérifications de cohérence dans le code.\n\n*Note :* L'explication ci-dessous suppose que vous êtes un peu familiarisé avec le code Python. Si des concepts comme `list`, `tuple`, et les fonctions ne vous disent rien, il est préférable de suivre d'abord un didacticiel Python d'introduction. Vous pouvez trouver des liens vers des tutoriels Python ici :\n\n- %link:manual/python/about%\n\nLa logique du code est présentée dans %FigHierarchy. Les chiffres indiquent l'ordre dans lequel nous mettrons en œuvre la fonctionnalité, en commençant par le niveau abstrait.\n\n<notranslate>\nfigure:\n id: FigHierarchy\n source: hierarchy.svg\n caption: |\n  La logique du code pour dessiner un affichage de recherche visuelle.\n</notranslate>\n\n__Les phases de préparation et d'exécution__\n\nOuvrez *search_display_script* et passez à l'onglet Prepare (Préparer). OpenSesame distingue deux phases d'exécution :\n\n- Pendant la phase de préparation, chaque élément a la possibilité de se préparer ; ce que cela signifie dépend de l'élément : Pour un SKETCHPAD, cela signifie dessiner un canevas (mais ne pas l'afficher) ; pour un SAMPLER, cela signifie charger un fichier son (mais ne pas le lire) ; etc.\n- Pendant la phase d'exécution, chaque élément est effectivement exécuté ; là encore, cela dépend de l'élément : Pour un SKETCHPAD, cela signifie afficher le canevas préparé précédemment ; pour un SAMPLER, cela signifie lire un fichier son précédemment chargé.\n\nPour un INLINE_SCRIPT, vous devez décider vous-même ce qu'il faut mettre dans la phase de préparation et ce qu'il faut mettre dans la phase d'exécution. La distinction est généralement assez claire : dans notre cas, nous mettons le code pour dessiner le canevas dans la phase de préparation et le code pour afficher le canevas (qui est petit) dans la phase d'exécution.\n\nVoir aussi :\n\n- %link:prepare-run%\n\n__Mettre en œuvre le niveau abstrait__\n\nNous commençons par le niveau le plus abstrait : définir une fonction qui dessine un affichage de recherche visuelle. Nous ne précisons pas *comment* cela est fait ; nous supposons simplement qu'il existe une fonction qui le fait, et nous nous occuperons des détails plus tard - c'est de la programmation descendante.\n\nDans l'onglet Prepare, saisissez le code suivant :\n\n~~~ .python\nc = draw_canvas()\n~~~\n\nQue se passe-t-il ici ? Nous …"
  },
  "- Define a list, `conjunctions`, of all possible color and shape combinations.\n- Randomly select one of the color and shape combinations from `conjunctions`.\n- Check if the selected color and shape are both equal to the color and shape of the target. If so, keep selecting a new color and shape until this is no longer the case. After all, the distractor cannot be identical to the target!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nIn addition, we …\n\n- Use the `random` library, which is corresponds to the `random-ext` package. This library contains useful randomization functions (such as `random.pick()`) and is one of the non-standard JavaScript libraries that is included with OSWeb.\n\nNow we define the function that draws distractors in the Shape Feature condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the feature-shape condition: an object that\n * has a different shape from the target, but can have any color.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_feature_shape_distractor(c, x, y) {\n    let colors = ['yellow', 'blue']\n    let color = random.pick(colors)\n    let shape\n    if (vars.target_shape === 'circle') {\n        shape = 'square'\n    } else if (vars.target_shape === 'square') {\n        shape = 'circle'\n    } else {\n        throw 'Invalid target_shape: ' + vars.target_shape\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We …\n\n- Randomly select a color.\n- Choose a square shape if the target is a circle, and a circle shape if the target is square.\n- If `target_shape` is neither 'circle' nor 'square', `throw` an error—more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nNow we define the function that draws distractors in the Color Feature condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the feature-color condition: an object that\n * has a different color from the target, but can have any shape.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_feature_color_distractor(c, x, y) {\n    let shapes = ['circle', 'square']\n    let shape = random.pick(shapes)\n    let color\n    if (vars.target_color === 'yellow') {\n        color = 'blue'\n    } else if (vars.target_color === 'blue') {\n        color = 'yellow'\n    } else {\n        throw 'Invalid target_color: ' + vars.target_color\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We …\n\n- Randomly select a shape.\n- Choose a blue color if the target is yellow, and a yellow color if the target is blue.\n- If `target_color` is neither 'yellow' nor 'blue', `throw` and error—more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\n__Implement the detailed level__\n\nNow we go all the way down to the details by defining the function that actually draws a shape to the canvas (above the rest of the script so far):": {
    "fr": "- Définir une liste, `conjonctions`, de toutes les combinaisons possibles de couleurs et de formes.\n- Sélectionnez au hasard l'une des combinaisons de couleurs et de formes dans `conjonctions`.\n- Vérifiez si la couleur et la forme sélectionnées sont toutes deux égales à la couleur et à la forme de la cible. Si c'est le cas, continuez à sélectionner une nouvelle couleur et une nouvelle forme jusqu'à ce que ce ne soit plus le cas. Après tout, le distracteur ne peut pas être identique à la cible !\n- Appelez une autre fonction, `draw_shape()`, et spécifiez la couleur et la forme du distracteur à dessiner. Cela suppose qu'il existe une fonction `draw_shape()`, même si nous ne l'avons pas encore définie.\n\nDe plus, nous ...\n\n- Utilisons la bibliothèque `random`, qui correspond au paquet `random-ext`. Cette bibliothèque contient des fonctions de randomisation utiles (telles que `random.pick()`) et fait partie des bibliothèques JavaScript non standard incluses avec OSWeb.\n\nMaintenant, nous définissons la fonction qui dessine les distracteurs dans la condition Shape Feature (au-dessus du reste du script jusqu'à présent) :\n\n```js\n/**\n * Dessine un seul distracteur dans la condition feature-shape : un objet qui\n * a une forme différente de la cible, mais peut avoir n'importe quelle couleur.\n * @param c Un Canvas.\n * @param x Une coordonnée x.\n * @param y Une coordonnée y.\n **/\nfunction draw_feature_shape_distractor(c, x, y) {\n    let colors = ['jaune', 'bleu']\n    let color = random.pick(colors)\n    let shape\n    if (vars.target_shape === 'cercle') {\n        shape = 'carré'\n    } else if (vars.target_shape === 'carré') {\n        shape = 'cercle'\n    } else {\n        throw 'Invalid target_shape: ' + vars.target_shape\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nQue se passe-t-il ici ? Nous ...\n\n- Sélectionnez au hasard une couleur.\n- Choisissez une forme carrée si la cible est un cercle, et une forme circulaire si la cible est un carré.\n- Si `target_shape` n'est ni 'cercle' ni 'carré', `throw` une erreur - plus de programmation défensive !\n- Appelez une autre fonction, `draw_shape()`, et spécifiez la couleur et la forme du distracteur à dessiner. Cela suppose qu'il existe une fonction `draw_shape()`, même si nous ne l'avons pas encore définie.\n\nMaintenant, nous définissons la fonction qui dessine les distracteurs dans la condition Color Feature (au-dessus du reste du script jusqu'à présent) :\n\n```js\n/**\n * Dessine un seul distracteur dans la condition feature-color : un objet qui\n * a une couleur différente de la cible, mais peut avoir n'importe quelle forme.\n * @param c Un Canvas.\n * @param x Une coordonnée x.\n * @param y Une coordonnée y.\n **/\nfunction draw_feature_color_distractor(c, x, y) {\n    let shapes = ['cercle', 'carré']\n    let shape = random.pick(shapes)\n    let color\n    if (vars.target_color === 'jaune') {\n        color = 'bleu'\n    } else if (vars.target_color === 'bleu') {\n        color = 'jaune'\n    } else {\n        throw 'Invalid target_color: ' + vars.target_color\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nQue se passe-t-il ici ? Nous ...\n\n- Sélectionnez au hasard une forme.\n- Choisissez une couleur bleue si la cible est jaune, et une couleur jaune si la cible est bleue.\n- Si `target_color` n'est ni 'jaune' ni 'bleu', `throw` une erreur - plus de programmation défensive !\n- Appelez une autre fonction, `draw_shape()`, et spécifiez la couleur et la forme du distracteur à dessiner. Cela suppose qu'il existe une fonction `draw_shape()`, même si nous ne l'avons pas encore définie.\n\n__Implémenter le niveau détaillé__\n\nMaintenant, nous descendons jusqu'aux détails en définissant la fonction qui dessine réellement une forme sur le canevas (au-dessus du reste du script jusqu'à présent) :"
  },
  "```js\n/**\n * Draws a single shape.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n * @param color A color (yellow or blue)\n * @param shape A shape (square or circle)\n **/\nfunction draw_shape(c, x, y, color, shape) {\n    if (shape === 'square') {\n        // Parameters are passed as an Object!\n        c.rect({x:x-25, y:y-25, w:50, h:50, color:color, fill:true})\n    } else if (shape === 'circle') {\n        // Parameters are passed as an Object!\n        c.circle({x:x, y:y, r:25, color:color, fill:true})\n    } else {\n        throw 'Invalid shape: ' + shape\n    }\n    if (color !== 'yellow' && color !== 'blue') {\n        throw 'Invalid color: ' + color\n    }\n}\n```\n\nWhat happens here? We …\n\n- Check which shape should be drawn. For squares, we add a `rect()` element to the canvas. For circles, we add a `circle()` element.\n- Check if the the shape is either a square or a circle, and if not `throw` and error. This is another example of defensive programming! We're making sure that we haven't accidentally specified an invalid shape.\n- Check if the the color is neither yellow nor blue, and if not `throw` and error.\n\nImportantly, `Canvas` functions accept a single object (`{}`) that specifies all parameters by name, like so:\n\n```js\n// Correct: pass a single object that contains all parameters by name\nc.rect({x:x-25, y:y-25, w:50, h:50, color:color, fill:true})\n// Incorrect: do not pass parameters by order\n// c.rect(x-25, y-25, 50, 50, color, true)\n// Incorrect: named parameters are not supported in JavaScript\n// c.rect(x=x-25, y=y-25, w=50, h=50, color=color, fill=true)\n```\n\n__Implement the Run phase__\n\nBecause we have done all the hard work in the Prepare phase, the Run phase is just:\n\n```js\npersistent.c.show()\n```\n\nNote that we have assigned the canvas as a property of the `persistent` object in the Prepare phase, which is why we can refer to it also in the Run phase.\n\nThat's it! Now you have drawn a full visual-search display. And, importantly, you have done so in a way that is easy to understand, because of top-down programming, and safe, because of defensive programming.\n\n\n## Step 7: Define the correct response\n\nTo know if the participant responds correctly, we need to know the correct response. You can define this explicitly in the *block_loop* (as done in the beginner tutorial); but here we're going to use some simple JavaScript that checks whether the target is present or not, and defines the correct response accordingly.\n\nTo do this, insert a new INLINE_JAVASCRIPT at the start of *trial_sequence*, and rename it to *correct_response_script*. In the Prepare phase, enter the following code:\n\n```js\nif (vars.target_present === 'present') {\n    vars.correct_response = 'right'\n} else if (vars.target_present === 'absent') {\n    vars.correct_response = 'left'\n} else {\n    throw 'target_present should be absent or present, not ' + vars.target\n}\n```\n\nWhat happens here? We …\n\n- Check whether the target is present or not. If the target is present, the correct response is 'right' (the right arrow key); if the target is absent, the correct response is 'left' (the left arrow key). The experimental variable `correct_response` is automatically used by OpenSesame; therefore, we don't need to explicitly indicate that this variable contains the correct response.\n- Check if the target is either present or absent, and if not `throw` an error—another example of defensive programming.\n\n## Step 8: Give per-trial feedback\n\nFeedback after every trial can motivate participants; however, per-trial feedback should not interfere with the flow of the experiment. A good way to give per-trial feedback is to briefly show a green fixation dot after a correct response, and a red fixation dot after an incorrect response.\n\nTo do this:": {
    "fr": "```js\n/**\n * Dessine une forme unique.\n * @param c Un Canvas.\n * @param x Une coordonnée x.\n * @param y Une coordonnée y.\n * @param color Une couleur (jaune ou bleue)\n * @param shape Une forme (carré ou cercle)\n **/\nfunction draw_shape(c, x, y, color, shape) {\n    if (shape === 'carré') {\n        // Les paramètres sont passés sous forme d'objet !\n        c.rect({x:x-25, y:y-25, w:50, h:50, color:color, fill:true})\n    } else if (shape === 'cercle') {\n        // Les paramètres sont passés sous forme d'objet !\n        c.circle({x:x, y:y, r:25, color:color, fill:true})\n    } else {\n        throw 'Forme invalide: ' + shape\n    }\n    if (color !== 'jaune' && color !== 'bleue') {\n        throw 'Couleur invalide: ' + color\n    }\n}\n```\n\nQue se passe-t-il ici ? Nous …\n\n- Vérifions quelle forme doit être dessinée. Pour les carrés, nous ajoutons un élément `rect()` au canvas. Pour les cercles, nous ajoutons un élément `circle()`.\n- Vérifions si la forme est un carré ou un cercle, et sinon, nous \"lançons\" une erreur. Ceci est un autre exemple de programmation défensive ! Nous nous assurons que nous n'avons pas accidentellement spécifié une forme invalide.\n- Vérifions si la couleur n'est ni jaune ni bleue, et si ce n'est pas le cas, nous lançons une erreur.\n\nImportant, les fonctions `Canvas` acceptent un seul objet (`{}`) qui spécifie tous les paramètres par nom, comme suit :\n\n```js\n// Correct : passez un seul objet qui contient tous les paramètres par nom\nc.rect({x:x-25, y:y-25, w:50, h:50, color:color, fill:true})\n// Incorrect : ne passez pas les paramètres par ordre\n// c.rect(x-25, y-25, 50, 50, color, true)\n// Incorrect : les paramètres nommés ne sont pas pris en charge en JavaScript\n// c.rect(x=x-25, y=y-25, w=50, h=50, color=color, fill=true)\n```\n\n__Implémentez la phase Run__\n\nComme nous avons fait tout le travail difficile dans la phase Prepare, la phase Run est juste :\n\n```js\npersistent.c.show()\n```\n\nNotez que nous avons attribué le canvas en tant que propriété de l'objet `persistent` dans la phase Prepare, c'est pourquoi nous pouvons également nous y référer dans la phase Run.\n\nC'est tout ! Maintenant, vous avez dessiné un affichage complet de recherche visuelle. Et, surtout, vous l'avez fait d'une manière facile à comprendre, grâce à la programmation du haut vers le bas et sûre, grâce à la programmation défensive.\n\n\n## Étape 7 : Définir la bonne réponse\n\nPour savoir si le participant répond correctement, nous devons connaître la bonne réponse. Vous pouvez la définir explicitement dans *block_loop* (comme indiqué dans le tutoriel pour débutants) ; mais ici, nous allons utiliser un simple JavaScript qui vérifie si la cible est présente ou non et définit la réponse correcte en conséquence.\n\nPour ce faire, insérez un nouveau INLINE_JAVASCRIPT au début de *trial_sequence* et renommez-le *correct_response_script*. Dans la phase Prepare, entrez le code suivant :\n\n```js\nif (vars.target_present === 'présent') {\n    vars.correct_response = 'right'\n} else if (vars.target_present === 'absent') {\n    vars.correct_response = 'left'\n} else {\n    throw 'target_present doit être absent ou présent, pas ' + vars.target\n}\n```\n\nQue se passe-t-il ici ? Nous …\n\n- Vérifions si la cible est présente ou non. Si la cible est présente, la réponse correcte est 'right' (la touche fléchée vers la droite) ; si la cible est absente, la réponse correcte est 'left' (la touche fléchée vers la gauche). La variable expérimentale `correct_response` est automatiquement utilisée par OpenSesame ; par conséquent, nous n'avons pas besoin d'indiquer explicitement que cette variable contient la bonne réponse.\n- Vérifions si la cible est soit présente, soit absente, et si ce n'est pas le cas, nous lançons une erreur - un autre exemple de programmation défensive.\n\n## Étape 8 : Donner un retour d'information par essai\n\nUn retour d'information après chaque essai peut motiver les participants ; cependant, un retour d'information par essai ne doit pas interférer avec le déroulement de l'expérience. Une bonne manière de donner un retour d'information par essai est de montrer brièvement un point de fixation vert après une réponse correcte et un point de fixation rouge après une réponse incorrecte.\n\nPour ce faire :"
  },
  "- Call `draw_canvas()`, which returns a `Canvas` object that we store as `c`; in other words, `c` is a `Canvas` object that corresponds the search display. This assumes that there is a function `draw_canvas()`, even though we haven't defined it yet.\n\nA `Canvas` object is a single display; it is, in a sense, the Python counterpart of a SKETCHPAD. See also:\n\n- %link:manual/python/canvas%\t \n\nWe now go one step down by defining `draw_canvas()` (above the rest of the script so far):\n\n~~~ .python\ndef draw_canvas():\n\n\t\"\"\"\n\tDraws the search canvas.\n\n\tReturns:\n\tA Canvas.\n\t\"\"\"\n\n\tc = Canvas()\n\txy_list = xy_random(n=var.set_size, width=500, height=500, min_dist=75)\n\tif var.target_present == 'present':\n\t\tx, y = xy_list.pop()\n\t\tdraw_target(c, x, y)\n\telif var.target_present != 'absent':\n\t\traise Exception(\n\t\t\t'Invalid value for target_present %s' % var.target_present)\t\t\n\tfor x, y in xy_list:\n\t\tdraw_distractor(c, x, y)\n\treturn c\n~~~\n\n\nWhat happens here? We …\n\n- Create an empty canvas, `c`, using the factory function `Canvas()`.\n- Generate a list of random `x, y` coordinates, called `xy_list`, using another common function, `xy_random()`. This list determines where the stimuli are shown.\n- Check if the experimental variable `target_present` has the value 'present'; if so, `pop()` one `x, y` tuple from `xy_list`, and draw the target at this location. This assumes that there is a function `draw_target()`, even though we haven't defined it yet.\n- If `target_present` is neither 'present' nor 'absent', we raise an `Exception`; this is defensive programming, and protects us from typos (e.g. if we had accidentally entered 'presenr' instead of 'present').\n- Loop through all remaining `x, y` tuples and draw a distractor at each position. This assumes that there is a function `draw_distractor()`, even though we haven't defined it yet.\n- Return `c`, which now has the search display drawn onto it.\n\nThere are several common functions, such as `Canvas()` and `xy_random()`, which are always available. See:\n\n- %link:manual/python/common%\n\nExperimental variables are stored as properties of the `var` object. That's why you write `var.set_size` and not directly `set_size`. See:\n\n- %link:var%\n\n__Implement the intermediate level__\n\nWe now go one more step down by defining `draw_target` (above the rest of the script so far):\n\n~~~ .python\ndef draw_target(c, x, y):\n\n\t\"\"\"\n\tDraws the target.\n\n\targuments:\n\tc:\tA Canvas.\n\tx:\tAn x coordinate.\n\ty:\tA y coordinate.\n\t\"\"\"\n\n\tdraw_shape(c, x, y, color=var.target_color, shape=var.target_shape)\n~~~\n\nWhat happens here? We …\n\n- Call another function, `draw_shape()`, and specify the color and shape that needs to be drawn. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nWe also define `draw_distractor` (above the rest of the script so far):\n\n~~~ .python\ndef draw_distractor(c, x, y):\n\n\t\"\"\"\n\tDraws a single distractor.\n\n\tArguments:\n\tc:\tA Canvas.\n\tx:\tAn x coordinate.\n\ty:\tA y coordinate.\n\t\"\"\"\n\n\tif var.condition == 'conjunction':\n\t\tdraw_conjunction_distractor(c, x, y)\n\telif var.condition == 'feature_shape':\n\t\tdraw_feature_shape_distractor(c, x, y)\n\telif var.condition == 'feature_color':\n\t\tdraw_feature_color_distractor(c, x, y)\n\telse:\n\t\traise Exception('Invalid condition: %s' % var.condition)\n~~~\n\nWhat happens here? We …\n\n- Call another function to draw a more specific distractor depending on the Condition.\n- Check whether `var.condition` has any of the expected values. If not, we raise an `Exception`. This is defensive programming! Without this check, if we made a typo somewhere, the distractor might simply not be shown without causing an error message.\n\nNow we define the function that draws distractors in the Conjunction condition (above the rest of the script so far):\n\n~~~ .python\nimport random\n\n\ndef draw_conjunction_distractor(c, x, y):\n\n\t\"\"\"\n\tDraws a single distractor in the conjunction condition: an object that\n\tcan have any shape and color, but cannot be identical to the target.": {
    "fr": "- Appelez `draw_canvas()`, qui renvoie un objet `Canvas` que nous stockons sous le nom de `c` ; en d'autres termes, `c` est un objet `Canvas` qui correspond à l'affichage de recherche. Cela suppose qu'il existe une fonction `draw_canvas()`, même si nous ne l'avons pas encore définie.\n\nUn objet `Canvas` est un seul affichage ; c'est en quelque sorte l'équivalent Python d'un SKETCHPAD. Voir aussi :\n\n- %link:manual/python/canvas%\n\nNous définissons maintenant `draw_canvas()` (au-dessus du reste du script) :\n\n~~~ .python\ndef draw_canvas():\n\n\t\"\"\"\n\tDessine le canevas de recherche.\n\n\tRetour :\n\tUn Canvas.\n\t\"\"\"\n\n\tc = Canvas()\n\txy_list = xy_random(n=var.set_size, width=500, height=500, min_dist=75)\n\tif var.target_present == 'present':\n\t\tx, y = xy_list.pop()\n\t\tdraw_target(c, x, y)\n\telif var.target_present != 'absent':\n\t\traise Exception(\n\t\t\t'Valeur invalide pour target_present %s' % var.target_present)\t\t\n\tfor x, y in xy_list:\n\t\tdraw_distractor(c, x, y)\n\treturn c\n~~~\n\nQue se passe-t-il ici ? Nous…\n\n- Créons un canevas vide, `c`, en utilisant la fonction usine `Canvas()`.\n- Générons une liste de coordonnées aléatoires `x, y`, appelée `xy_list`, en utilisant une autre fonction courante, `xy_random()`. Cette liste détermine où les stimuli sont affichés.\n- Vérifiez si la variable expérimentale `target_present` a la valeur 'present' ; si c'est le cas, `pop()` un tuple `x, y` de `xy_list`, et dessinez la cible à cet endroit. Cela suppose qu'il existe une fonction `draw_target()`, même si nous ne l'avons pas encore définie.\n- Si `target_present` n'est ni 'present' ni 'absent', nous levons une `Exception` ; c'est de la programmation défensive, et cela nous protège des erreurs de frappe (par exemple, si nous avions accidentellement saisi 'presenr' au lieu de 'present').\n- Parcourez tous les tuples `x, y` restants et dessinez un distracteur à chaque position. Cela suppose qu'il y a une fonction `draw_distractor()`, même si nous ne l'avons pas encore définie.\n- Retourne `c`, qui a maintenant l'affichage de recherche dessiné dessus.\n\nIl existe plusieurs fonctions courantes, telles que `Canvas()` et `xy_random()`, qui sont toujours disponibles. Voir :\n\n- %link:manual/python/common%\n\nLes variables expérimentales sont stockées en tant que propriétés de l'objet `var`. C'est pourquoi vous écrivez `var.set_size` et non directement `set_size`. Voir :\n\n- %link:var%\n\n__Mettre en œuvre le niveau intermédiaire__\n\nNous allons maintenant définir `draw_target` (au-dessus du reste du script) :\n\n~~~ .python\ndef draw_target(c, x, y):\n\n\t\"\"\"\n\tDessine la cible.\n\n\targuments :\n\tc : Un Canvas.\n\tx : Une coordonnée x.\n\ty : Une coordonnée y.\n\t\"\"\"\n\n\tdraw_shape(c, x, y, color=var.target_color, shape=var.target_shape)\n~~~\n\nQue se passe-t-il ici ? Nous…\n\n- Appelons une autre fonction, `draw_shape()`, et spécifions la couleur et la forme à dessiner. Cela suppose qu'il existe une fonction `draw_shape()`, même si nous ne l'avons pas encore définie.\n\nNous définissons également `draw_distractor` (au-dessus du reste du script) :\n\n~~~ .python\ndef draw_distractor(c, x, y):\n\n\t\"\"\"\n\tDessine un seul distracteur.\n\n\tArguments :\n\tc : Un Canvas.\n\tx : Une coordonnée x.\n\ty : Une coordonnée y.\n\t\"\"\"\n\n\tif var.condition == 'conjunction':\n\t\tdraw_conjunction_distractor(c, x, y)\n\telif var.condition == 'feature_shape':\n\t\tdraw_feature_shape_distractor(c, x, y)\n\telif var.condition == 'feature_color':\n\t\tdraw_feature_color_distractor(c, x, y)\n\telse:\n\t\traise Exception('Condition invalide : %s' % var.condition)\n~~~\n\nQue se passe-t-il ici ? Nous…\n\n- Appelons une autre fonction pour dessiner un distracteur plus spécifique en fonction de la condition.\n- Vérifiez si `var.condition` a l'une des valeurs attendues. Sinon, nous levons une `Exception`. C'est de la programmation défensive ! Sans cette vérification, si nous avions fait une erreur de frappe quelque part, le distracteur pourrait simplement ne pas être affiché sans provoquer de message d'erreur.\n\nMaintenant, nous définissons la fonction qui dessine les distracteurs dans la condition Conjonction (au-dessus du reste du script) :\n\n~~~ .python\nimport random\n\n\ndef draw_conjunction_distractor(c, x, y):\n\n\t\"\"\"\n\tDessine un seul distracteur dans la condition de conjonction : un objet qui\n\tpeut avoir n'importe quelle forme et couleur, mais ne peut pas être identique à la cible."
  },
  "- Insert two new SKETCHPADs into *trial_sequence*, just after *keyboard_response*.\n- Rename one SKETCHPAD to *green_dot*, draw a central green fixation dot onto it, and change its duration to 500.\n- Rename the other SKETCHPAD to *red_dot*, draw a central red fixation dot onto it, and change its duration to 500.\n\nOf course, only one of the two dots should be shown on each trial. To accomplish this, we will specify run-if statements in *trial_sequence*:\n\n- Change the run-if statement for *green_dot* to '[correct] = 1', indicating that it should only be shown after a correct response.\n- Change the run-if statement for *red_dot* to '[correct] = 0', indicating that it should only be shown after an incorrect response.\n\nThe variable `correct` is automatically created if the variable `correct_response` is available; that's why we defined `correct_response` in step 7. For more information about variables and run-if statements, see:\n\n- %link:manual/variables%\n\nThe *trial_sequence* should now look like %FigStep8.\n\n<notranslate>\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  The *trial_sequence* at the end of step 8.\n</notranslate>\n\n\n## Step 9: Checking compatibility\n\nWhen you want to run an experiment in a browser, you cannot use all of OpenSesame's functionality. To check whether your experiment is able to run in a browser, you can use the OSWeb compatibility check by going to Menu → Tools → OSweb. If you've followed all the steps of this tutorial, the compatibility check will fail with the following warning (%FigCompatibilityCheck):\n\n<notranslate>\nfigure:\n id: FigCompatibilityCheck\n source: compatibility-check.png\n caption: |\n  The compatibility check may give warnings or errors.\n</notranslate>\n\nThis is a warning that the *logger* has the option 'Log all variables' enabled. Enabling this option is recommended when running an experiment on the desktop, in which case it's no problem to collect a lot of unnecessary information. However, enabling this option is *not* recommend when running an experiment online, because doing so results in unnecessarily large data files and consumes an unnecessary amount of bandwidth.\n\nTherefore, go the *logger*, disable the 'Log all variables' option, and select only those variables that you actually need. You can do that by opening the variable inspector and dragging variables into the *logger* table (%FigLogger).\n\n<notranslate>\nfigure:\n id: FigLogger\n source: logger.png\n caption: |\n  Logging only relevant variables is recommended when running an experiment online to save bandwidth.\n</notranslate>\n\n\nFor a list of functionality that is supported by OSWeb, see:\n\n- %link:manual/osweb/osweb%\n\n\n## Finished!\n\nCongratulations, the experiment is complete! You can give it a test run by pressing on the toolbar button that shows a green circle with a gray play button inside (shortcut: `Alt+Ctrl+W`).\n\nIf the experiment doesn't work on the first try: Don't worry, and calmly figure out where the mistake comes from. Crashes are part of the normal development process. But you can save yourself a lot of time and headache by working in a structured way, as we have done in this tutorial.\n\n## References\n\n<div class='reference' markdown='1'>\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nTreisman, A. M., & Gelade, G. (1980). A feature-integration theory of attention. *Cognitive Psychology*, 12(1), 97–136. doi:10.1016/0010-0285(80)90005-5\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html\n": {
    "fr": "- Insérez deux nouveaux SKETCHPADs dans *trial_sequence*, juste après *keyboard_response*.\n- Renommez un SKETCHPAD en *green_dot*, dessinez un point de fixation vert central dessus, et changez sa durée à 500.\n- Renommez l'autre SKETCHPAD en *red_dot*, dessinez un point de fixation rouge central dessus, et changez sa durée à 500.\n\nBien sûr, un seul des deux points doit être affiché à chaque essai. Pour ce faire, nous préciserons les instructions run-if dans *trial_sequence* :\n\n- Changez l'instruction run-if pour *green_dot* en '[correct] = 1', indiquant qu'il ne doit être affiché qu'après une réponse correcte.\n- Changez l'instruction run-if pour *red_dot* en '[correct] = 0', indiquant qu'il ne doit être affiché qu'après une réponse incorrecte.\n\nLa variable `correct` est automatiquement créée si la variable `correct_response` est disponible ; c'est pourquoi nous avons défini `correct_response` à l'étape 7. Pour plus d'informations sur les variables et les instructions run-if, voir :\n\n- %link:manual/variables%\n\nLe *trial_sequence* devrait maintenant ressembler à %FigStep8.\n\n<notranslate>\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  Le *trial_sequence* à la fin de l'étape 8.\n</notranslate>\n\n\n## Étape 9 : Vérification de la compatibilité\n\nLorsque vous souhaitez exécuter une expérience dans un navigateur, vous ne pouvez pas utiliser toutes les fonctionnalités d'OpenSesame. Pour vérifier si votre expérience peut fonctionner dans un navigateur, vous pouvez utiliser la vérification de compatibilité OSWeb en allant dans Menu → Outils → OSweb. Si vous avez suivi toutes les étapes de ce didacticiel, la vérification de compatibilité échouera avec l'avertissement suivant (%FigCompatibilityCheck):\n\n<notranslate>\nfigure:\n id: FigCompatibilityCheck\n source: compatibility-check.png\n caption: |\n  La vérification de compatibilité peut donner des avertissements ou des erreurs.\n</notranslate>\n\nCeci est un avertissement que le *logger* a l'option 'Log all variables' activée. Activer cette option est recommandé lors de l'exécution d'une expérience sur le bureau, auquel cas il ne pose aucun problème de collecter beaucoup d'informations inutiles. Toutefois, cette option n'est *pas* recommandée lors de l'exécution d'une expérience en ligne, car cela entraîne des fichiers de données inutilement volumineux et consomme une quantité inutile de bande passante.\n\nPar conséquent, allez dans le *logger*, désactivez l'option 'Log all variables' et sélectionnez uniquement les variables dont vous avez réellement besoin. Vous pouvez le faire en ouvrant l'inspecteur de variables et en faisant glisser les variables dans le tableau du *logger* (%FigLogger).\n\n<notranslate>\nfigure:\n id: FigLogger\n source: logger.png\n caption: |\n  La journalisation des variables pertinentes uniquement est recommandée lors de l'exécution d'une expérience en ligne pour économiser de la bande passante.\n</notranslate>\n\n\nPour une liste des fonctionnalités prises en charge par OSWeb, voir :\n\n- %link:manual/osweb/osweb%\n\n## Terminé !\n\nFélicitations, l'expérience est terminée ! Vous pouvez faire un essai en appuyant sur le bouton de la barre d'outils qui affiche un cercle vert avec un bouton de lecture gris à l'intérieur (raccourci : `Alt+Ctrl+W`).\n\nSi l'expérience ne fonctionne pas du premier coup : Ne vous inquiétez pas et déterminez calmement d'où vient l'erreur. Les plantages font partie du processus de développement normal. Mais vous pouvez vous épargner beaucoup de temps et de maux de tête en travaillant de manière structurée, comme nous l'avons fait dans ce tutoriel.\n\n## Références\n\n<div class='reference' markdown='1'>\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: Un éditeur graphique d'expérimentations open-source pour les sciences sociales. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nTreisman, A. M., & Gelade, G. (1980). Une théorie de l'intégration des caractéristiques de l'attention. *Cognitive Psychology*, 12(1), 97–136. doi:10.1016/0010-0285(80)90005-5\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html"
  },
  "\targuments:\n\tc:\tA Canvas.\n\tx:\tAn x coordinate.\n\ty:\tA y coordinate.\n\t\"\"\"\n\n\tconjunctions = [\n\t\t('yellow', 'circle'),\n\t\t('blue', 'circle'),\n\t\t('yellow', 'square'),\n\t\t('blue', 'square'),\n\t\t]\n\tconjunctions.remove( (var.target_color, var.target_shape) )\n\tcolor, shape = random.choice(conjunctions)\n\tdraw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We …\n\n- Define a list, `conjunctions`, of all possible color and shape combinations.\n- Remove the target from this list; this is necessary, because the distractor cannot be identical to the target.\n- Randomly select one of the color and shape combinations from `conjunctions`.\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nIn addition, we …\n\n- Add the line `import random` to the top of the script. This is necessary so that we can use functions that are part of the `random` module, such as `random.choice()`.\n\nNow we define the function that draws distractors in the Shape Feature condition (right below the `import` statement):\n\n~~~ .python\ndef draw_feature_shape_distractor(c, x, y):\n\n\t\"\"\"\n\tDraws a single distractor in the feature-shape condition: an object that\n\thas a different shape from the target, but can have any color.\n\n\tArguments:\n\tc:\tA Canvas.\n\tx:\tAn x coordinate.\n\ty:\tA y coordinate.\n\t\"\"\"\t\t\n\n\tcolors = ['yellow', 'blue']\n\tcolor = random.choice(colors)\n\tif var.target_shape == 'circle':\n\t\tshape = 'square'\n\telif var.target_shape == 'square':\n\t\tshape = 'circle'\n\telse:\n\t\traise Exception('Invalid target_shape: %s' % var.target_shape)\n\tdraw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We …\n\n- Randomly select a color.\n- Choose a square shape if the target is a circle, and a circle shape if the target is square.\n- If `target_shape` is neither 'circle' nor 'square', raise an `Exception`—more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nNow we define the function that draws distractors in the Color Feature condition (right below the `import` statement):\n\n~~~ .python\ndef draw_feature_color_distractor(c, x, y):\n\n\t\"\"\"\n\tDraws a single distractor in the feature-color condition: an object that\n\thas a different color from the target, but can have any shape.\n\n\tArguments:\n\tc:\tA Canvas.\n\tx:\tAn x coordinate.\n\ty:\tA y coordinate.\n\t\"\"\"\n\n\tshapes = ['circle', 'square']\n\tshape = random.choice(shapes)\n\tif var.target_color == 'yellow':\n\t\tcolor = 'blue'\n\telif var.target_color == 'blue':\n\t\tcolor = 'yellow'\n\telse:\n\t\traise Exception('Invalid target_color: %s' % var.target_color)\n\tdraw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We …\n\n- Randomly select a shape.\n- Choose a blue color if the target is yellow, and a yellow color if the target is blue.\n- If `target_color` is neither 'yellow' nor 'blue', raise an `Exception`—more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\n__Implement the detailed level__\n\nNow we go all the way down to the details by defining the function that actually draws a shape to the canvas (right below the `import` statement):\n\n~~~ .python\ndef draw_shape(c, x, y, color, shape):\n\n\t\"\"\"\n\tDraws a single shape.\n\n\tArguments:\n\tc:\t\tA Canvas.\n\tx:\t\tAn x coordinate.\n\ty:\t\tA y coordinate.\n\tcolor:\tA color (yellow or blue)\n\tshape:\tA shape (square or circle)\n\t\"\"\"\t\t": {
    "fr": "\targuments :\n\tc : Un Canvas.\n\tx : Une coordonnée x.\n\ty : Une coordonnée y.\n\t\"\"\"\n\n\tconjonctions = [\n\t\t('jaune', 'cercle'),\n\t\t('bleu', 'cercle'),\n\t\t('jaune', 'carré'),\n\t\t('bleu', 'carré'),\n\t\t]\n\tconjonctions.remove((var.target_color, var.target_shape))\n\tcouleur, forme = random.choice(conjonctions)\n\tdraw_shape(c, x, y, color=couleur, shape=forme)\n~~~\n\nQue se passe-t-il ici ? Nous ...\n\n- Définissons une liste, `conjonctions`, de toutes les combinaisons possibles de couleurs et de formes.\n- Supprimons la cible de cette liste ; cela est nécessaire, car le distracteur ne peut pas être identique à la cible.\n- Sélectionnons aléatoirement l'une des combinaisons de couleurs et de formes de `conjonctions`.\n- Appelons une autre fonction, `draw_shape()`, et spécifions la couleur et la forme du distracteur à dessiner. Cela suppose qu'il existe une fonction `draw_shape()`, même si nous ne l'avons pas encore définie.\n\nDe plus, nous …\n\n- Ajoutons la ligne `import random` en haut du script. Ceci est nécessaire pour que nous puissions utiliser des fonctions qui font partie du module `random`, telles que `random.choice()`.\n\nMaintenant, nous définissons la fonction qui dessine les distracteurs dans la condition \"Shape Feature\" (juste en dessous de l'instruction `import`) :\n\n~~~ .python\ndef draw_feature_shape_distractor(c, x, y):\n\n\t\"\"\"\n\tDessine un seul distracter dans la condition \"shape-feature\" : un objet qui\n\ta une forme différente de celle de la cible, mais peut avoir n'importe quelle couleur.\n\n\tArguments:\n\tc : Un Canvas.\n\tx : Une coordonnée x.\n\ty : Une coordonnée y.\n\t\"\"\"\n\n\tcouleurs = ['jaune', 'bleu']\n\tcouleur = random.choice(couleurs)\n\tif var.target_shape == 'cercle':\n\t\tforme = 'carré'\n\telif var.target_shape == 'carré':\n\t\tforme = 'cercle'\n\telse :\n\t\traise Exception('Invalid target_shape: %s' % var.target_shape)\n\tdraw_shape(c, x, y, color=couleur, shape=forme)\n~~~\n\nQue se passe-t-il ici ? Nous …\n\n- Sélectionnons aléatoirement une couleur.\n- Choisissons une forme carrée si la cible est un cercle, et une forme circulaire si la cible est un carré.\n- Si `target_shape` n'est ni 'cercle' ni 'carré', levons une `Exception` - plus de programmation défensive !\n- Appelons une autre fonction, `draw_shape()`, et spécifions la couleur et la forme du distracteur à dessiner. Cela suppose qu'il existe une fonction `draw_shape()`, même si nous ne l'avons pas encore définie.\n\nMaintenant, nous définissons la fonction qui dessine les distracteurs dans la condition \"Color Feature\" (juste en dessous de l'instruction `import`) :\n\n~~~ .python\ndef draw_feature_color_distractor(c, x, y):\n\n\t\"\"\"\n\tDessine un seul distracter dans la condition \"feature-color\" : un objet qui\n\ta une couleur différente de celle de la cible, mais peut avoir n'importe quelle forme.\n\n\tArguments:\n\tc : Un Canvas.\n\tx : Une coordonnée x.\n\ty : Une coordonnée y.\n\t\"\"\"\n\n\tformes = ['cercle', 'carré']\n\tforme = random.choice(formes)\n\tif var.target_color == 'jaune':\n\t\tcouleur = 'bleu'\n\telif var.target_color == 'bleu':\n\t\tcouleur = 'jaune'\n\telse :\n\t\traise Exception('Invalid target_color: %s' % var.target_color)\n\tdraw_shape(c, x, y, color=couleur, shape=forme)\n~~~\n\nQue se passe-t-il ici ? Nous …\n\n- Sélectionnons aléatoirement une forme.\n- Choisissons une couleur bleue si la cible est jaune, et une couleur jaune si la cible est bleue.\n- Si `target_color` n'est ni 'jaune' ni 'bleu', levons une `Exception` - plus de programmation défensive !\n- Appelons une autre fonction, `draw_shape()`, et spécifions la couleur et la forme du distracteur à dessiner. Cela suppose qu'il existe une fonction `draw_shape()`, même si nous ne l'avons pas encore définie.\n\n__Mettre en œuvre le niveau détaillé__\n\nMaintenant, nous descendons jusqu'aux détails en définissant la fonction qui dessine réellement une forme sur le canevas (juste en dessous de l'instruction `import`) :\n\n~~~ .python\ndef draw_shape(c, x, y, color, shape):\n\n\t\"\"\"\n\tDessine une seule forme.\n\n\tArguments :\n\tc :\t\tUn Canvas.\n\tx :\t\tUne coordonnée x.\n\ty :\t\tUne coordonnée y.\n\tcolor :\tUne couleur (jaune ou bleu)\n\tshape :\tUne forme (carré ou cercle)\n\t\"\"\""
  },
  "For a single trial we need a SEQUENCE. For a block of trials, we need to repeat this SEQUENCE multiple times. Therefore, for a block of trials we need to wrap a LOOP around a SEQUENCE. Drag a LOOP from the item toolbar onto *new_reset_feedback*. Next, drag a SEQUENCE from the item toolbar onto the newly created LOOP, and select 'Insert into new_loop' in the pop-up menu that appears. (We will get back to this in Step 3.)\n\n__Append a feedback item__\n\nAfter every block of trials we want to give feedback to the participant, so that the participant knows how well he/ she is doing. For this we need a FEEDBACK item. Drag a FEEDBACK from the item toolbar onto *new_loop*, and select 'Insert after loop' in the pop-up menu that appears. (We will get back to this in Step 10.)\n\n__Give the new items sensible names__\n\nRename: (See Step 1 if you don't remember how to do this.)\n\n- *new_loop* to *block_loop*\n- *new_sequence* to *trial_sequence*\n- *new_reset_feedback* to *reset_feedback*\n- *new_feedback* to *feedback*\n\nThe overview of your experiment now looks like %FigStep2. Remember to save your experiment regularly.\n\n<notranslate>\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The overview area at the end of Step 2.\n</notranslate>\n\n## Step 3: Fill the block loop with independent variables\n\nAs the name suggests, *block_loop* corresponds to a single block of trials. In the previous step we created the *block_loop*, but we still need to define the independent variables that will be varied within the block. Our experiment has three independent variables:\n\n- __gaze_cue__ can be 'left' or 'right'.\n- __target_pos__ (the position of the target) can be '-300' or '300'. These values reflect the X-coordinate of the target in pixels (0 = center). Using the coordinates directly, rather than 'left' and 'right', will be convenient when we create the target displays (see Step 5).\n- __target_letter__ (the target letter) can be 'F' or 'H'.\n\nTherefore, our experiment has 2 x 2 x 2 = 8 levels. Although 8 levels is not that many (most experiments will have more), we don't need to enter all possible combinations by hand. Click on *block_loop* in the overview to open its tab. Now click on the 'Full-factorial design' button. In the variable wizard, you simply define all variables by typing the name in the first row and the levels in the rows below the name (see %FigVariableWizard). If you select 'Ok', you will see that *block_loop* has been filled with all 8 possible combinations.\n\n<notranslate>\nfigure:\n id: FigVariableWizard\n source: variable-wizard.png\n caption: |\n  The loop variable wizard in Step 3.\n</notranslate>\n\nIn the resulting loop table, each row corresponds to one run of *trial_sequence*. Because, in our case, one run of *trial_sequence* corresponds to one trial, each row in our loop table corresponds to one trial. Each column corresponds to one variable, which can have a different value on each trial.\n\nBut we are not done yet. We need to add three more variables: the location of the distractor, the correct response, and the congruency.": {
    "fr": "Pour une seule essai, nous avons besoin d'une SÉQUENCE. Pour un bloc d'essais, nous devons répéter cette SÉQUENCE plusieurs fois. Par conséquent, pour un bloc d'essais, nous devons entourer une BOUCLE autour d'une SÉQUENCE. Faites glisser une BOUCLE depuis la barre d'outils des éléments sur *new_reset_feedback*. Ensuite, faites glisser une SÉQUENCE depuis la barre d'outils des éléments sur la BOUCLE nouvellement créée, et sélectionnez 'Insérer dans new_loop' dans le menu contextuel qui apparaît. (Nous reviendrons sur ce point à l'étape 3.)\n\n__Ajoutez un élément de feedback__\n\nAprès chaque bloc d'essais, nous voulons donner un retour d'information au participant, afin qu'il sache comment il/elle se débrouille. Pour cela, nous avons besoin d'un élément FEEDBACK. Faites glisser un FEEDBACK depuis la barre d'outils des éléments sur *new_loop*, et sélectionnez 'Insérer après la boucle' dans le menu contextuel qui apparaît. (Nous reviendrons sur ce point à l'étape 10.)\n\n__Donnez des noms logiques aux nouveaux éléments__\n\nRenommez : (Voir l'étape 1 si vous ne vous souvenez pas comment faire.)\n\n- *new_loop* en *block_loop*\n- *new_sequence* en *trial_sequence*\n- *new_reset_feedback* en *reset_feedback*\n- *new_feedback* en *feedback*\n\nL'aperçu de votre expérience ressemble maintenant à %FigStep2. N'oubliez pas d'enregistrer régulièrement votre expérience.\n\n<notranslate>\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  La zone d'aperçu à la fin de l'étape 2.\n</notranslate>\n\n## Étape 3 : Remplir la boucle de blocs avec des variables indépendantes\n\nComme son nom l'indique, *block_loop* correspond à un seul bloc d'essais. Dans l'étape précédente, nous avons créé le *block_loop*, mais nous devons encore définir les variables indépendantes qui seront modifiées à l'intérieur du bloc. Notre expérience a trois variables indépendantes :\n\n- __gaze_cue__ peut être 'gauche' ou 'droite'.\n- __target_pos__ (la position de la cible) peut être '-300' ou '300'. Ces valeurs reflètent l'abscisse X de la cible en pixels (0 = centre). Utiliser les coordonnées directement, plutôt que 'gauche' et 'droite', sera pratique lorsque nous créerons les affichages cibles (voir étape 5).\n- __target_letter__ (la lettre cible) peut être 'F' ou 'H'.\n\nPar conséquent, notre expérience a 2 x 2 x 2 = 8 niveaux. Bien que 8 niveaux ne soit pas si élevé (la plupart des expériences en auront plus), nous n'avons pas besoin de saisir toutes les combinaisons possibles manuellement. Cliquez sur *block_loop* dans l'aperçu pour ouvrir son onglet. Cliquez maintenant sur le bouton 'Plan factoriel complet'. Dans l'assistant des variables, vous définissez simplement toutes les variables en tapant le nom dans la première rangée et les niveaux dans les rangées sous le nom (voir %FigVariableWizard). Si vous sélectionnez 'Ok', vous verrez que *block_loop* a été rempli avec les 8 combinaisons possibles.\n\n<notranslate>\nfigure:\n id: FigVariableWizard\n source: variable-wizard.png\n caption: |\n  L'assistant des variables de boucle à l'étape 3.\n</notranslate>\n\nDans le tableau des boucles résultant, chaque ligne correspond à une exécution de *trial_sequence*. Comme, dans notre cas, une exécution de *trial_sequence* correspond à un essai, chaque ligne de notre tableau de boucle correspond à un essai. Chaque colonne correspond à une variable, qui peut avoir une valeur différente à chaque essai.\n\nMais nous n'avons pas encore terminé. Nous devons ajouter trois autres variables : l'emplacement du distractor, la réponse correcte et la congruence."
  },
  "\tif shape == 'square':\n\t\tc += Rect(x=x-25, y=y-25, w=50, h=50, color=color, fill=True)\n\telif shape == 'circle':\n\t\tc += Circle(x=x, y=y, r=25, color=color, fill=True)\n\telse:\n\t\traise Exception('Invalid shape: %s' % shape)\n\tif color not in ['yellow', 'blue']:\n\t\traise Exception('Invalid color: %s' % color)\n~~~\n\nWhat happens here? We …\n\n- Check which shape should be drawn. For squares, we add a `Rect()` element to the canvas. For circles, we add a `Circle()` element.\n- Check if the the shape is either a square or a circle, and if not raise an `Exception`. This is another example of defensive programming! We're making sure that we haven't accidentally specified an invalid shape.\n- Check if the the color is neither yellow nor blue, and if not raise an `Exception`.\n\n__Implement the Run phase__\n\nBecause we have done all the hard work in the Prepare phase, the Run phase is just:\n\n~~~ .python\nc.show()\n~~~\n\nThat's it! Now you have drawn a full visual-search display. And, importantly, you have done so in a way that is easy to understand, because of top-down programming, and safe, because of defensive programming.\n\n\n## Step 7: Define the correct response\n\nTo know if the participant responds correctly, we need to know the correct response. You can define this explicitly in the *block_loop* (as done in the beginner tutorial); but here we're going to use a simple Python script that checks whether the target is present or not, and defines the correct response accordingly.\n\nTo do this, insert a new INLINE_SCRIPT at the start of *trial_sequence*, and rename it to *correct_response_script*. In the Prepare phase, enter the following code:\n\n~~~ .python\nif var.target_present == 'present':\n\tvar.correct_response = 'right'\nelif var.target_present == 'absent':\n\tvar.correct_response = 'left'\nelse:\n\traise Exception('target_present should be absent or present, not %s' % var.target)\n~~~\n\nWhat happens here? We …\n\n- Check whether the target is present or not. If the target is present, the correct response is 'right' (the right arrow key); if the target is absent, the correct response is 'left' (the left arrow key). The experimental variable `var.correct_response` is automatically used by OpenSesame; therefore, we don't need to explicitly indicate that this variable contains the correct response.\n- Check if the target is either present or absent, and if not raise an `Exception`—another example of defensive programming.\n\n## Step 8: Give per-trial feedback\n\nFeedback after every trial can motivate participants; however, per-trial feedback should not interfere with the flow of the experiment. A good way to give per-trial feedback is to briefly show a green fixation dot after a correct response, and a red fixation dot after an incorrect response.\n\nTo do this:\n\n- Insert two new SKETCHPADs into *trial_sequence*, just after *keyboard_response*.\n- Rename one SKETCHPAD to *green_dot*, draw a central green fixation dot onto it, and change its duration to 500.\n- Rename the other SKETCHPAD to *red_dot*, draw a central red fixation dot onto it, and change its duration to 500.\n\nOf course, only one of the two dots should be shown on each trial. To accomplish this, we will specify run-if statements in *trial_sequence*:\n\n- Change the run-if statement for *green_dot* to '[correct] = 1', indicating that it should only be shown after a correct response.\n- Change the run-if statement for *red_dot* to '[correct] = 0', indicating that it should only be shown after an incorrect response.\n\nThe variable `correct` is automatically created if the variable `correct_response` is available; that's why we defined `correct_response` in step 7. For more information about variables and run-if statements, see:\n\n- %link:manual/variables%\n\nThe *trial_sequence* should now look like %FigStep8.\n\n<notranslate>\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  The *trial_sequence* at the end of step 8.\n</notranslate>\n\n## Finished!": {
    "fr": "\tsi shape == 'carré':\n\t\tc += Rect(x=x-25, y=y-25, w=50, h=50, color= couleur, fill=True)\n\telif shape == 'cercle':\n\t\tc += Circle(x=x, y=y, r=25, color= couleur, fill=True)\n\telse:\n\t\traise Exception('Forme invalide : %s' % shape)\n\tif color not in ['jaune', 'bleu']:\n\t\traise Exception('Couleur invalide : %s' % couleur)\n~~~\n\nQue se passe-t-il ici ? Nous …\n\n- Vérifions quelle forme doit être dessinée. Pour les carrés, nous ajoutons un élément `Rect()` au canevas. Pour les cercles, nous ajoutons un élément `Circle()`.\n- Vérifions si la forme est un carré ou un cercle, et si ce n'est pas le cas, nous levons une `Exception`. C'est un autre exemple de programmation défensive! Nous nous assurons que nous n'avons pas accidentellement spécifié une forme invalide.\n- Vérifions si la couleur n'est ni jaune ni bleue, et si ce n'est pas le cas, nous levons une `Exception`.\n\n__Mettez en œuvre la phase Run__\n\nParce que nous avons fait tout le travail difficile dans la phase Prepare, la phase Run est juste:\n\n~~~ .python\nc.show()\n~~~\n\nC'est tout! Maintenant, vous avez dessiné un affichage complet de recherche visuelle. Et, surtout, vous avez fait cela d'une manière facile à comprendre, grâce à la programmation descendante, et sûre, grâce à la programmation défensive.\n\n\n## Étape 7: Définir la réponse correcte\n\nPour savoir si le participant répond correctement, nous devons connaître la réponse correcte. Vous pouvez la définir explicitement dans le *block_loop* (comme cela a été fait dans le didacticiel pour débutants); mais ici, nous allons utiliser un simple script Python qui vérifie si la cible est présente ou non et définit la réponse correcte en conséquence.\n\nPour ce faire, insérez un nouveau INLINE_SCRIPT au début de *trial_sequence* et renommez-le en *correct_response_script*. Dans la phase Prepare, saisissez le code suivant:\n\n~~~ .python\nif var.target_present == 'présent':\n\tvar.correct_response = 'droite'\nelif var.target_present == 'absent':\n\tvar.correct_response = 'gauche'\nelse:\n\traise Exception(\"target_present doit être absent ou présent, pas %s\" % var.target)\n~~~\n\nQue se passe-t-il ici ? Nous …\n\n- Vérifions si la cible est présente ou non. Si la cible est présente, la réponse correcte est 'droite' (la touche flèche droite); si la cible est absente, la réponse correcte est 'gauche' (la touche flèche gauche). La variable expérimentale `var.correct_response` est automatiquement utilisée par OpenSesame; par conséquent, nous n'avons pas besoin d'indiquer explicitement que cette variable contient la réponse correcte.\n- Vérifions si la cible est présente ou absente, et si ce n'est pas le cas, nous levons une `Exception` : un autre exemple de programmation défensive.\n\n## Étape 8: Donner des commentaires par essai\n\nDes commentaires après chaque essai peuvent motiver les participants; cependant, les commentaires par essai ne doivent pas interférer avec le déroulement de l'expérience. Une bonne façon de donner des commentaires par essai est de montrer brièvement un point de fixation vert après une réponse correcte et un point de fixation rouge après une réponse incorrecte.\n\nPour ce faire:\n\n- Insérez deux nouveaux SKETCHPADs dans *trial_sequence*, juste après *keyboard_response*.\n- Renommez un SKETCHPAD en *green_dot*, dessinez un point de fixation vert central dessus et changez sa durée à 500.\n- Renommez l'autre SKETCHPAD en *red_dot*, dessinez un point de fixation rouge central dessus et changez sa durée à 500.\n\nBien sûr, un seul des deux points doit être montré à chaque essai. Pour ce faire, nous spécifierons des instructions run-if dans *trial_sequence* :\n\n- Changez l'instruction run-if pour *green_dot* en '[correct] = 1', indiquant qu'il doit être montré seulement après une réponse correcte.\n- Changez l'instruction run-if pour *red_dot* en '[correct] = 0', indiquant qu'il doit être montré seulement après une réponse incorrecte.\n\nLa variable `correct` est automatiquement créée si la variable `correct_response` est disponible; c'est pourquoi nous avons défini `correct_response` à l'étape 7. Pour plus d'informations sur les variables et les instructions run-if, voir :\n\n- %link:manuel/variables%\n\nLe *trial_sequence* doit maintenant ressembler à %FigStep8.\n\n<notranslate>\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  Le *trial_sequence* à la fin de l'étape 8.\n</notranslate>\n\n## Terminé!"
  },
  "Congratulations, the experiment is complete! You can give it a test run by pressing on the blue double-arrow button (shortcut: `Ctrl+W`).\n\nIf the experiment doesn't work on the first try: Don't worry, and calmly figure out where the mistake comes from. Crashes are part of the normal development process. But you can save yourself a lot of time and headache by working in a structured way, as we have done in this tutorial.\n\n## References\n\n<div class='reference' markdown='1'>\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nTreisman, A. M., & Gelade, G. (1980). A feature-integration theory of attention. *Cognitive Psychology*, 12(1), 97–136. doi:10.1016/0010-0285(80)90005-5\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html\n": {
    "fr": "Félicitations, l'expérience est terminée ! Vous pouvez la tester en appuyant sur le bouton double-flèche bleu (raccourci : `Ctrl+W`).\n\nSi l'expérience ne fonctionne pas du premier coup : Ne vous inquiétez pas et cherchez calmement d'où vient l'erreur. Les crashs font partie du processus de développement normal. Mais vous pouvez vous épargner beaucoup de temps et de maux de tête en travaillant de manière structurée, comme nous l'avons fait dans ce tutoriel.\n\n## Références\n\n<div class='reference' markdown='1'>\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: Un éditeur d'expériences graphiques open source pour les sciences sociales. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nTreisman, A. M., & Gelade, G. (1980). Une théorie d'intégration des caractéristiques de l'attention. *Cognitive Psychology*, 12(1), 97–136. doi:10.1016/0010-0285(80)90005-5\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html"
  },
  "- __dist_pos__ -- On the first row of the first empty column, enter 'dist_pos'. This automatically adds a new experimental variable named 'dist_pos'. In the rows below, enter '300' wherever 'target_pos' is -300, and '-300' wherever 'target_pos' is 300. In other words, the target and the distractor should be positioned opposite from each other.\n- __correct_response__ -- Create another variable, in another empty column, with the name 'correct_response'. Set 'correct_response' to 'z' where 'target_letter' is 'F', and to 'm' where 'target_letter' is 'H'. This means that the participant should press the 'z' key if she sees an 'F' and the 'm' key if she sees an 'H'. (Feel free to choose different keys if 'z' and 'm' are awkward on your keyboard layout; for example, 'w' and 'n' are better on AZERTY keyboards.)\n- __congruency__ -- Create another variable with the name 'congruency'. Set 'congruency' to 'congruent' where 'target_pos' is '-300' and 'gaze_cue' is 'left', and where 'target_pos' is '300' and 'gaze_cue' is 'right'. In other words, a trial is congruent if the face looks at the target. Set 'congruency' to 'incronguent' for the trials on which the face looks at the distractor. The 'congruency' variable is not necessary to run the experiment; however, it is useful for analyzing the data later on.\n\nWe need to do one last thing. 'Repeat' is currently set to '1.00'. This means that each cycle will be executed once. So the block now consists of 8 trials, which is a bit short. A reasonable length for a block of trials is 24, so set 'Repeat' to 3.00 (3 repeats x 8 cycles = 24 trials). You don't need to change 'Order', because 'random' is exactly what we want.\n\nThe *block_loop* now looks like %FigStep3. Remember to save your experiment regularly.\n\n<notranslate>\nfigure:\n id: FigStep3\n source: step3.png\n caption: \"The *block_loop* at the end of Step 3.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can prepare your loop table in your favorite spreadsheet program and copy-paste it into the LOOP variable table.\n\n__Tip__ -- You can specify your loop table in a separate file (in `.xlsx` or `.csv`) format, and use this file directly. To do so, select 'file' under 'Source'.\n\n__Tip__ -- You can set 'Repeat' to a non-integer number. For example, by setting 'Repeat' to '0.5', only half the trials (randomly selected) are executed.\n\n</div>\n\n## Step 4: Add images and sound files to the file pool\n\nFor our stimuli, we will use images from file. In addition, we will play a sound if the participant makes an error. For this we need a sound file.\n\nYou can download the required files here (in most webbrowsers you can right-click the links and choose 'Save Link As' or a similar option):\n\n- [gaze_neutral.png](/img/beginner-tutorial/gaze_neutral.png)\n- [gaze_left.png](/img/beginner-tutorial/gaze_left.png)\n- [gaze_right.png](/img/beginner-tutorial/gaze_right.png)\n- [incorrect.ogg](/img/beginner-tutorial/incorrect.ogg)\n\nAfter you have downloaded these files (to your desktop, for example), you can add them to the file pool. If the file pool is not already visible (by default on the right side of the window), click on the 'Show file pool' button in the main toolbar (shortcut: `Ctrl+P`). The easiest way to add the four files to the file pool is to drag them from the desktop (or wherever you have downloaded the files to) into the file pool. Alternatively, you can click on the '+' button in the file pool and add files using the file select dialog that appears. The file pool will be automatically saved with your experiment.\n\nYour file pool now looks like %FigStep4. Remember to save your experiment regularly.\n\n<notranslate>\nfigure:\n id: FigStep4\n source: step4.png\n caption: \"The file pool at the end of Step 4.\"\n</notranslate>\n\n## Step 5: Fill the trial sequence with items\n\nA trial in our experiment looks as follows:": {
    "fr": "- __dist_pos__ -- Sur la première ligne de la première colonne vide, saisissez 'dist_pos'. Cela ajoute automatiquement une nouvelle variable expérimentale nommée 'dist_pos'. Dans les lignes ci-dessous, saisissez '300' lorsque 'target_pos' est -300, et '-300' lorsque 'target_pos' est 300. En d'autres termes, la cible et le distracteur doivent être positionnés à l'opposé l'un de l'autre.\n- __correct_response__ -- Créez une autre variable, dans une autre colonne vide, avec le nom 'correct_response'. Définissez 'correct_response' sur 'z' lorsque 'target_letter' est 'F', et sur 'm' lorsque 'target_letter' est 'H'. Cela signifie que le participant doit appuyer sur la touche 'z' s'il voit un 'F' et sur la touche 'm' s'il voit un 'H'. (N'hésitez pas à choisir d'autres touches si 'z' et 'm' sont gênantes sur la disposition de votre clavier; par exemple, 'w' et 'n' sont meilleures sur les claviers AZERTY.)\n- __congruency__ -- Créez une autre variable avec le nom 'congruency'. Définissez 'congruency' sur 'congruent' lorsque 'target_pos' est '-300' et 'gaze_cue' est 'left', et lorsque 'target_pos' est '300' et 'gaze_cue' est 'right'. En d'autres termes, un essai est congruent si le visage regarde la cible. Définissez 'congruency' sur 'incronguent' pour les essais où le visage regarde le distracteur. La variable 'congruency' n'est pas nécessaire pour exécuter l'expérience; cependant, elle est utile pour analyser les données ultérieurement.\n\nNous devons faire encore une dernière chose. 'Repeat' est actuellement défini sur '1.00'. Cela signifie que chaque cycle sera exécuté une fois. Le bloc est donc composé de 8 essais, ce qui est un peu court. Une longueur raisonnable pour un bloc d'essais est de 24, donc définissez 'Repeat' sur 3.00 (3 répétitions x 8 cycles = 24 essais). Vous n'avez pas besoin de changer 'Order', car 'random' est exactement ce que nous voulons.\n\nLe *block_loop* ressemble maintenant à %FigStep3. N'oubliez pas d'enregistrer régulièrement votre expérience.\n\n<notranslate>\nfigure:\n id: FigStep3\n source: step3.png\n caption: \"Le *block_loop* à la fin de l'étape 3.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Encadré__\n\n__Astuce__ -- Vous pouvez préparer votre tableau de boucle dans votre programme de tableur préféré et le copier-coller dans le tableau des variables LOOP.\n\n__Astuce__ -- Vous pouvez spécifier votre tableau de boucle dans un fichier séparé (au format `.xlsx` ou `.csv`) et utiliser ce fichier directement. Pour ce faire, sélectionnez 'file' sous 'Source'.\n\n__Astuce__ -- Vous pouvez définir 'Repeat' avec un nombre non entier. Par exemple, en définissant 'Repeat' sur '0.5', seuls la moitié des essais (sélectionnés au hasard) sont exécutés.\n\n</div>\n\n## Étape 4 : Ajoutez des images et des fichiers sonores à la pool de fichiers\n\nPour nos stimuli, nous utiliserons des images provenant de fichiers. De plus, nous jouerons un son si le participant commet une erreur. Pour cela, nous avons besoin d'un fichier sonore.\n\nVous pouvez télécharger les fichiers requis ici (dans la plupart des navigateurs, vous pouvez cliquer avec le bouton droit sur les liens et choisir 'Enregistrer le lien sous' ou une option similaire) :\n\n- [gaze_neutral.png](/img/beginner-tutorial/gaze_neutral.png)\n- [gaze_left.png](/img/beginner-tutorial/gaze_left.png)\n- [gaze_right.png](/img/beginner-tutorial/gaze_right.png)\n- [incorrect.ogg](/img/beginner-tutorial/incorrect.ogg)\n\nUne fois que vous avez téléchargé ces fichiers (sur votre bureau, par exemple), vous pouvez les ajouter à la pool de fichiers. Si la pool de fichiers n'est pas déjà visible (par défaut à droite de la fenêtre), cliquez sur le bouton 'Afficher la pool de fichiers' dans la barre d'outils principale (raccourci : `Ctrl+P`). La manière la plus simple d'ajouter les quatre fichiers à la pool de fichiers est de les faire glisser du bureau (ou de l'endroit où vous les avez téléchargés) dans la pool de fichiers. Vous pouvez également cliquer sur le bouton '+' dans la pool de fichiers et ajouter des fichiers en utilisant la boîte de dialogue de sélection de fichiers qui apparaît. La pool de fichiers sera enregistrée automatiquement avec votre expérience.\n\nVotre pool de fichiers ressemble maintenant à %FigStep4. N'oubliez pas d'enregistrer régulièrement votre expérience.\n\n<notranslate>\nfigure:\n id: FigStep4\n source: step4.png\n caption: \"La pool de fichiers à la fin de l'étape 4.\"\n</notranslate>\n\n## Étape 5 : Remplissez la séquence d'essai avec des éléments\n\nUn essai dans notre expérience se présente comme suit :"
  },
  "1. __Fixation dot__ -- 750 ms, SKETCHPAD item\n2. __Neutral gaze__ -- 750 ms, SKETCHPAD item\n3. __Gaze cue__ -- 500 ms, SKETCHPAD item\n4. __Target__  -- 0 ms, SKETCHPAD item\n5. __Response collection__ \t-- KEYBOARD_RESPONSE item\n6. __Play a sound if response was incorrect__ --  SAMPLER item\n7. __Log response to file__ -- LOGGER item\n\nClick on *trial_sequence* in the overview to open the *trial_sequence* tab. Pick up a SKETCHPAD from the item toolbar and drag it into the *trial_sequence*. Repeat this three more times, so that *trial_sequence* contains four SKETCHPADs. Next, select and append a KEYBOARD_RESPONSE item, a SAMPLER item, and a LOGGER item.\n\nAgain, we will rename the new items, to make sure that the *trial_sequence* is easy to understand. Rename:\n\n- *new_sketchpad* to *fixation_dot*\n- *new_sketchpad_1* to *neutral_gaze*\n- *new_sketchpad_2* to *gaze_cue*\n- *new_sketchpad_3* to *target*\n- *new_keyboard_response* to *keyboard_response*\n- *new_sampler* to *incorrect_sound*\n- *new_logger* to *logger*\n\nBy default, items are always executed, which is indicated by the run-if expression `True`. However, we want to change this for the *incorrect_sound* item, which should only be executed if an error was made. To do this, we need to change the 'Run if' expression to `correct == 0` in the *trial_sequence* tab. This works, because the *keyboard_response* item automatically creates a `correct` variable, which is set to `1` (correct), `0` (incorrect), or `undefined` (this relies on the `correct_response` variable that was defined in Step 3). The double equals sign is Python syntax and indicates that you want to compare whether the two things are equal to each other, in this case whether the variable `correct` is equal to 0. To change a run-if expression, double click on it (shortcut: `F3`).\n\nThe *trial_sequence* now looks like %FigStep5.\n\n<notranslate>\nfigure:\n id: FigStep5\n source: step5.png\n caption: \"The *trial_sequence* at the end of Step 5.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a SKETCHPAD item?__ -- A SKETCHPAD is used to present visual stimuli: text, geometric shapes, fixation dots, Gabor patches, etc. You can draw on the SKETCHPAD using the built-in drawing tools.\n\n__What is a KEYBOARD_RESPONSE item?__ -- A KEYBOARD_RESPONSE item collects a single participant's response from the keyboard.\n\n__What is a SAMPLER item?__ -- A SAMPLER item plays a sound from a sound file.\n\n__What is a LOGGER item?__ -- A LOGGER item writes data to the log file. This is very important: If you forget to include a LOGGER item, no data will be logged during the experiment!\n\n__Tip__ -- Variables and conditional \"if\" expressions are very powerful! To learn more about them, see:\n\n- %link:manual/variables%\n\n</div>\n\n## Step 6: Draw the sketchpad items\n\nThe SKETCHPAD items that we have created in Step 5 are still blank. It's time to do some drawing!\n\n__Set the background color to white__\n\nClick on *fixation_dot* in the overview area to open its tab. The SKETCHPAD is still dark gray, while the images that we have downloaded have a white background. Oops, we forgot to set the background color of the experiment to white (it is dark gray by default)! Click on 'Tutorial: Gaze cuing' in the overview area to open the 'General properties' tab. Change 'Foreground' to 'black' and 'Background' to 'white'.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- For more fine-grained control over colors, you can also use the hexadecimal RGB notation (e.g., `#FF000` for red), use various color spaces, or use the color-picker tool. See also:\n\n- %link:manual/python/canvas%\n\n</div>\n\n__Draw the fixation dot__": {
    "fr": "1. __Point de fixation__ -- 750 ms, élément SKETCHPAD\n2. __Regard neutre__ -- 750 ms, élément SKETCHPAD\n3. __Indice de regard__ -- 500 ms, élément SKETCHPAD\n4. __Cible__ -- 0 ms, élément SKETCHPAD\n5. __Collecte de réponse__ -- élément KEYBOARD_RESPONSE\n6. __Jouer un son si la réponse est incorrecte__ -- élément SAMPLER\n7. __Enregistrer la réponse dans un fichier__ -- élément LOGGER\n\nCliquez sur *trial_sequence* dans l'aperçu pour ouvrir l'onglet *trial_sequence*. Prenez un SKETCHPAD dans la barre d'outils des éléments et faites-le glisser dans le *trial_sequence*. Répétez cette opération trois fois de plus, de sorte que *trial_sequence* contienne quatre SKETCHPADs. Ensuite, sélectionnez et ajoutez un élément KEYBOARD_RESPONSE, un élément SAMPLER et un élément LOGGER.\n\nDe nouveau, nous allons renommer les nouveaux éléments, pour nous assurer que le *trial_sequence* est facile à comprendre. Renommez :\n\n- *new_sketchpad* en *fixation_dot*\n- *new_sketchpad_1* en *neutral_gaze*\n- *new_sketchpad_2* en *gaze_cue*\n- *new_sketchpad_3* en *target*\n- *new_keyboard_response* en *keyboard_response*\n- *new_sampler* en *incorrect_sound*\n- *new_logger* en *logger*\n\nPar défaut, les éléments sont toujours exécutés, ce qui est indiqué par l'expression run-if `True`. Cependant, nous voulons changer cela pour l'élément *incorrect_sound*, qui ne doit être exécuté que si une erreur a été commise. Pour ce faire, il faut modifier l'expression \"Run if\" en `correct == 0` dans l'onglet *trial_sequence*. Ceci fonctionne, car l'élément *keyboard_response* crée automatiquement une variable `correct`, qui est définie à `1` (correct), `0` (incorrect) ou `undefined` (cela repose sur la variable `correct_response` définie à l'étape 3). Le double signe égal est la syntaxe Python et indique que vous voulez comparer si les deux choses sont égales entre elles, dans ce cas si la variable `correct` est égale à 0. Pour modifier une expression run-if, double-cliquez dessus (raccourci : `F3`).\n\nLe *trial_sequence* ressemble maintenant à %FigStep5.\n\n<notranslate>\nfigure :\n id: FigStep5\n source: step5.png\n caption: \"Le *trial_sequence* à la fin de l'étape 5.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Encadré__\n\n__Qu'est-ce qu'un élément SKETCHPAD ?__ -- Un SKETCHPAD est utilisé pour présenter des stimuli visuels : texte, formes géométriques, points de fixation, patchs Gabor, etc. Vous pouvez dessiner sur le SKETCHPAD en utilisant les outils de dessin intégrés.\n\n__Qu'est-ce qu'un élément KEYBOARD_RESPONSE ?__ -- Un élément KEYBOARD_RESPONSE recueille une seule réponse du participant à partir du clavier.\n\n__Qu'est-ce qu'un élément SAMPLER ?__ -- Un élément SAMPLER lit un son à partir d'un fichier son.\n\n__Qu'est-ce qu'un élément LOGGER ?__ -- Un élément LOGGER écrit des données dans le fichier de journalisation. C'est très important : si vous oubliez d'inclure un élément LOGGER, aucune donnée ne sera enregistrée pendant l'expérience !\n\n__Astuce__ -- Les variables et les expressions conditionnelles \"if\" sont très puissantes ! Pour en savoir plus sur elles, consultez:\n\n- %link:manual/variables%\n\n</div>\n\n## Étape 6 : Dessiner les éléments sketchpad\n\nLes éléments SKETCHPAD que nous avons créés à l'étape 5 sont toujours vides. Il est temps de faire quelques dessins !\n\n__Définir la couleur d'arrière-plan en blanc__\n\nCliquez sur *fixation_dot* dans la zone d'aperçu pour ouvrir son onglet. Le SKETCHPAD est toujours gris foncé, alors que les images que nous avons téléchargées ont un fond blanc. Oups, nous avons oublié de définir la couleur d'arrière-plan de l'expérience en blanc (elle est gris foncé par défaut) ! Cliquez sur 'Tutoriel : Gaze cuing' dans la zone d'aperçu pour ouvrir l'onglet 'Propriétés générales'. Changez 'Avant-plan' en 'noir' et 'Arrière-plan' en 'blanc'.\n\n<div class='info-box' markdown='1'>\n\n__Encadré__\n\n__Astuce__ -- Pour un contrôle plus précis des couleurs, vous pouvez également utiliser la notation hexadécimale RVB (par exemple, `#FF000` pour le rouge), utiliser différents espaces colorimétriques ou utiliser l'outil sélecteur de couleurs. Voir aussi :\n\n- %link:manual/python/canvas%\n\n</div>\n\n__Dessinez le point de fixation__"
  },
  "Go back to the *fixation_dot* by clicking on *fixation_dot* in the overview. Now select the fixation-dot element by clicking on the button with the crosshair. If you move your cursor over the sketchpad, you can see the screen coordinates in the top-right. Set the (foreground) color to 'black'. Click on the center of the screen (0, 0) to draw a central fixation dot.\n\nFinally, change the 'Duration' field from 'keypress' to '745', because we want the fixation dot to be presented for 750 ms. Wait ... *why didn't we just specify a duration of 750 ms?* The reason for this is that the actual display-presentation duration is always rounded up to a value that is compatible with your monitor's refresh rate. This may sound complicated, but for most purposes the following rules of thumb are sufficient:\n\n1. Choose a duration that is possible given your monitor's refresh rate. For example, if your monitor's refresh rate is 60 Hz, it means that every frame lasts 16.7 ms (= 1000 ms/60 Hz). Therefore, on a 60 Hz monitor, you should always select a duration that is a multiple of 16.7 ms, such as 16.7, 33.3, 50, 100, etc.\n2. In the duration field of the SKETCHPAD specify a duration that is a few milliseconds less than what you're aiming for. So if you want to present a SKETCHPAD for 50 ms, choose a duration of 45. If you want to present a SKETCHPAD for 1000 ms, choose a duration of 995. Etcetera.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- For a detailed discussion of experimental timing, see:\n\n- %link:timing%\n\n__Tip__ -- The duration of a SKETCHPAD can be a value in milliseconds, but you can also enter 'keypress' or 'mouseclick' to collect a keyboard press or mouse click respectively. In this case a SKETCHPAD will work much the same as a KEYBOARD_RESPONSE item (but with fewer options).\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n__Draw the neutral gaze__\n\nOpen the *neutral_gaze* SKETCHPAD. Now select the image tool by clicking on the button with the mountain-landscape-like icon. Click on the center of the screen (0, 0). The 'Select file from pool' dialog will appear. Select the file `gaze_neutral.png` and click on the 'Select' button. The neutral gaze image will now stare at you from the center of the screen! Finally, like before, change the 'Duration' field from 'keypress' to '745'. (And note again that this means a duration of 750 ms on most monitors!)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- OpenSesame can handle a wide variety of image formats. However, some (non-standard) `.bmp` formats are known to cause trouble. If you find that a `.bmp` image is not shown, you can convert it to a different format, such as `.png`. You can convert images easily with free tools such as [GIMP].\n</div>\n\n__Draw the gaze cue__\n\nOpen the *gaze_cue* SKETCHPAD, and again select the image tool. Click on the center of the screen (0, 0) and select the file `gaze_left.png`.\n\nBut we are not done yet! Because the gaze cue should not always be 'left', but should depend on the variable `gaze_cue`, which we have defined in Step 3. However, by drawing the `gaze_left.png` image to the SKETCHPAD, we have generated a script that needs only a tiny modification to make sure that the proper image is shown. Click on the 'Select view' button at the top-right of the *gaze_cue* tab and select 'View script'. You will now see the script that corresponds to the sketchpad that we have just created:\n\n~~~ .python\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=True x=0 y=0 z_index=0\n~~~\n\nThe only thing that we need to do is replace `gaze_left.png` with `gaze_{gaze_cue}.png`. This means that OpenSesame uses the variable `gaze_cue` (which has the values `left` and `right`) to determine which image should be shown.": {
    "fr": "Revenez au *fixation_dot* en cliquant sur *fixation_dot* dans l'aperçu. Sélectionnez maintenant l'élément du point de fixation en cliquant sur le bouton avec la croix. Si vous déplacez votre curseur sur le sketchpad, vous pouvez voir les coordonnées de l'écran en haut à droite. Définissez la couleur (de premier plan) sur 'noir'. Cliquez au centre de l'écran (0, 0) pour dessiner un point de fixation central.\n\nEnfin, changez le champ 'Durée' de 'keypress' à '745', car nous voulons que le point de fixation soit présenté pendant 750 ms. Attendez... *pourquoi n'avons-nous pas simplement spécifié une durée de 750 ms?* La raison en est que la durée réelle de présentation de l'affichage est toujours arrondie à une valeur compatible avec le taux de rafraîchissement de votre écran. Cela peut paraître compliqué, mais pour la plupart des utilisations, les règles de base suivantes sont suffisantes:\n\n1. Choisissez une durée qui est possible étant donné le taux de rafraîchissement de votre écran. Par exemple, si le taux de rafraîchissement de votre écran est de 60 Hz, cela signifie que chaque image dure 16,7 ms (= 1000 ms / 60 Hz). Par conséquent, sur un écran de 60 Hz, vous devez toujours choisir une durée qui est un multiple de 16,7 ms, comme 16,7, 33,3, 50, 100, etc.\n2. Dans le champ de durée du SKETCHPAD, indiquez une durée de quelques millisecondes de moins que ce que vous visez. Ainsi, si vous souhaitez présenter un SKETCHPAD pendant 50 ms, choisissez une durée de 45. Si vous voulez présenter un SKETCHPAD pendant 1000 ms, choisissez une durée de 995. Etc.\n\n<div class='info-box' markdown='1'>\n\n__Boîte d'informations__\n\n__Astuce__ - Pour une discussion détaillée sur le chronométrage expérimental, consultez:\n\n- %link:timing%\n\n__Astuce__ - La durée d'un SKETCHPAD peut être une valeur en millisecondes, mais vous pouvez également saisir 'keypress' ou 'mouseclick' pour collecter une pression sur une touche ou un clic de souris respectivement. Dans ce cas, un SKETCHPAD fonctionnera de manière très similaire à un élément KEYBOARD_RESPONSE (mais avec moins d'options).\n\n__Astuce__ - Assurez-vous que la couleur (de premier plan) est réglée sur noir. Sinon, vous dessinerez en blanc sur blanc et vous ne verrez rien !\n\n</div>\n\n__Dessinez le regard neutre__\n\nOuvrez le SKETCHPAD *neutral_gaze*. Sélectionnez maintenant l'outil image en cliquant sur le bouton avec l'icône de paysage montagneux. Cliquez au centre de l'écran (0, 0). La boîte de dialogue 'Sélectionner un fichier dans la base' apparaîtra. Sélectionnez le fichier `gaze_neutral.png` et cliquez sur le bouton 'Sélectionner'. L'image du regard neutre vous fixera maintenant depuis le centre de l'écran ! Enfin, comme précédemment, changez le champ 'Durée' de 'keypress' à '745'. (Et notez à nouveau que cela signifie une durée de 750 ms sur la plupart des écrans!)\n\n<div class='info-box' markdown='1'>\n\n__Boîte d'informations__\n\n__Astuce__ - OpenSesame peut gérer une grande variété de formats d'image. Cependant, certains formats `.bmp` (non standard) sont connus pour causer des problèmes. Si vous constatez qu'une image `.bmp` n'est pas affichée, vous pouvez la convertir en un format différent, tel que `.png`. Vous pouvez facilement convertir des images avec des outils gratuits tels que [GIMP].\n</div>\n\n__Dessinez le repère du regard__\n\nOuvrez le SKETCHPAD *gaze_cue* et sélectionnez à nouveau l'outil image. Cliquez au centre de l'écran (0, 0) et sélectionnez le fichier `gaze_left.png`.\n\nMais nous n'avons pas encore terminé! Parce que le repère du regard ne doit pas toujours être 'à gauche', mais doit dépendre de la variable `gaze_cue`, que nous avons définie à l'étape 3. Cependant, en dessinant l'image `gaze_left.png` sur le SKETCHPAD, nous avons généré un script qui nécessite seulement une petite modification pour s'assurer que l'image appropriée est affichée. Cliquez sur le bouton 'Sélectionner la vue' en haut à droite de l'onglet *gaze_cue* et sélectionnez 'Voir le script'. Vous verrez maintenant le script qui correspond au sketchpad que nous venons de créer:\n\n~~~ .python\nset duration keypress\nset description \"Affiche les stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=True x=0 y=0 z_index=0\n~~~\n\nLa seule chose que nous devons faire est de remplacer `gaze_left.png` par `gaze_{gaze_cue}.png`. Cela signifie qu'OpenSesame utilise la variable `gaze_cue` (qui a les valeurs `left` et `right`) pour déterminer quelle image doit être affichée."
  },
  "While we are at it, we might as well change the duration to '495' (rounded up to 500!). The script now looks like this:\n\n~~~ .python\nset duration 495\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_{gaze_cue}.png\" scale=1 show_if=True x=0 y=0 z_index=0\n~~~\n\nClick the 'Apply' button at the top right to apply your changes to the script and return to the regular item controls. OpenSesame will warn you that the image cannot be shown, because it is defined using variables, and a placeholder image will be shown instead. Don't worry, the correct image will be shown during the experiment!\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- The variable inspector (shortcut: `Ctrl+I`) is a powerful way to find out which variables have been defined in your experiment, and which values they have (see %FigVariableInspector). When your experiment is not running, most variables don't have a value yet. But when you run your experiment in a window, while having the variable inspector visible, you can see variables changing in real time. This is very useful for debugging your experiment.\n\n<notranslate>\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: \"The variable inspector is a convenient way to get an overview of the variables that exist in your experiment.\"\n</notranslate>\n\n</div>\n\n__Draw the target__\n\nWe want three objects to be part of the target display: the target letter, the distractor letter, and the gaze cue (see %FigGazeCuing). As before, we will start by creating a static display using the SKETCHPAD editor. After this, we will only need to make minor changes to the script so that the exact display depends on the variables.\n\nClick on *target* in the overview to open the target tab and like before, draw the `gaze_left.png` image at the center of the screen. Now select the draw text tool by clicking on the button with the 'A' icon. Change the foreground color to 'black' (if it isn't already). The default font size is 18 px, which is a bit small for our purpose, so change the font size to 32 px. Now click on (-320, 0) in the SKETCHPAD (the X-coordinate does not need to be exactly 320, since we will change this to a variable anyway). Enter \"{target_letter}\" in the dialog that appears, to draw the target letter (when drawing text, you can use variables directly). Similarly, click on (320, 0) and draw an 'X' (the distractor is always an 'X').\n\nNow open the script editor by clicking on the 'Select view' button at the top-right of the tab and selecting 'View script'. The script looks like this:\n\n~~~ .python\nset duration keypress\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=True x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=\"{target_letter}\" x=-320 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=X x=320 y=0 z_index=0\n~~~\n\nLike before, change `gaze_left.png` to `gaze_{gaze_cue}.png`. We also need to make the position of the target and the distractor depend on the variables `target_pos` and `dist_pos` respectively. To do this, simply change `-320` to `{target_pos}` and `320` to `{dist_pos}`. Make sure that you leave the `0`, which is the Y-coordinate. The script now looks like this:\n\n~~~ .python\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_{gaze_cue}.png\" scale=1 show_if=True x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=\"{target_letter}\" x={target_pos} y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=X x={dist_pos} y=0 z_index=0\n~~~\n\nClick on the 'Apply' button to apply the script and go back to the regular item controls.": {
    "fr": "Tant qu'à faire, nous pourrions aussi changer la durée à '495' (arrondi à 500 !). Le script ressemble maintenant à ceci :\n\n~~~ .python\nset duration 495\nset description \"Affiche les stimuli\"\ndraw image center=1 file=\"gaze_{gaze_cue}.png\" scale=1 show_if=True x=0 y=0 z_index=0\n~~~\n\nCliquez sur le bouton 'Appliquer' en haut à droite pour appliquer vos modifications au script et revenir aux contrôles d'éléments normaux. OpenSesame vous avertira que l'image ne peut être affichée, car elle est définie à l'aide de variables, et une image substitut sera affichée à la place. Ne vous inquiétez pas, l'image correcte sera affichée pendant l'expérience !\n\n<div class='info-box' markdown='1'>\n\n__Boîte d'informations__\n\n__Astuce__ -- L'inspecteur de variables (raccourci : `Ctrl+I`) est un moyen puissant de découvrir quelles variables ont été définies dans votre expérience et quelles valeurs elles ont (voir %FigVariableInspector). Lorsque votre expérience ne fonctionne pas, la plupart des variables n'ont pas encore de valeur. Mais lorsque vous exécutez votre expérience dans une fenêtre, tout en ayant l'inspecteur de variables visible, vous pouvez voir les variables changer en temps réel. Cela est très utile pour déboguer votre expérience.\n\n<notranslate>\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: \"L'inspecteur de variables est un moyen pratique d'avoir un aperçu des variables qui existent dans votre expérience.\"\n</notranslate>\n\n</div>\n\n__Dessiner la cible__\n\nNous voulons que trois objets fassent partie de l'affichage de la cible : la lettre cible, la lettre distractrice et l'indice de regard (voir %FigGazeCuing). Comme auparavant, nous commencerons par créer un affichage statique à l'aide de l'éditeur SKETCHPAD. Ensuite, nous n'aurons besoin d'apporter que de légères modifications au script pour que l'affichage exact dépende des variables.\n\nCliquez sur *target* dans l'aperçu pour ouvrir l'onglet cible et, comme avant, dessinez l'image `gaze_left.png` au centre de l'écran. Sélectionnez maintenant l'outil de dessin de texte en cliquant sur le bouton avec l'icône 'A'. Changez la couleur de premier plan en 'noir' (si ce n'est pas déjà le cas). La taille de la police par défaut est de 18 px, ce qui est un peu petit pour notre objectif, alors changez la taille de la police à 32 px. Maintenant, cliquez sur (-320, 0) dans le SKETCHPAD (la coordonnée X n'a pas besoin d'être exactement 320, puisque nous la changerons de toute façon en variable). Entrez \"{target_letter}\" dans la boîte de dialogue qui apparaît, pour dessiner la lettre cible (lorsque vous dessinez du texte, vous pouvez utiliser directement les variables). De même, cliquez sur (320, 0) et dessinez un 'X' (le distracteur est toujours un 'X').\n\nOuvrez maintenant l'éditeur de script en cliquant sur le bouton \"Sélectionner la vue\" en haut à droite de l'onglet et en sélectionnant \"Voir le script\". Le script ressemble à ceci :\n\n~~~ .python\nset duration keypress\nset duration keypress\nset description \"Affiche les stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=True x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=\"{target_letter}\" x=-320 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=X x=320 y=0 z_index=0\n~~~\n\nComme précédemment, changez `gaze_left.png` en `gaze_{gaze_cue}.png`. Nous devons également faire en sorte que la position de la cible et du distracteur dépende des variables `target_pos` et `dist_pos` respectivement. Pour ce faire, changez simplement `-320` en `{target_pos}` et `320` en `{dist_pos}`. Assurez-vous de laisser le `0`, qui est la coordonnée Y. Le script ressemble maintenant à ceci :\n\n~~~ .python\nset duration keypress\nset description \"Affiche les stimuli\"\ndraw image center=1 file=\"gaze_{gaze_cue}.png\" scale=1 show_if=True x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=\"{target_letter}\" x={target_pos} y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=X x={dist_pos} y=0 z_index=0\n~~~\n\nCliquez sur le bouton \"Appliquer\" pour appliquer le script et revenir aux contrôles d'éléments normaux."
  },
  "Finally, set the 'Duration' field to '0'. This does not mean that the target is presented for only 0 ms, but that the experiment will advance to the next item (the *keyboard_response*) right away. Since the *keyboard_response* waits for a response, but doesn't change what's on the screen, the target will remain visible until a response has been given.\n\nRemember to save your experiment regularly.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- Each element of a SKETCHPAD has a 'Show if' option, which specifies when the element should be shown. You can use this to hide/ show elements from a SKETCHPAD depending on certain variables, similar to run-if statements in a SEQUENCE.\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n## Step 7: Configure the keyboard response item\n\nClick on *keyboard_response* in the overview to open its tab. You see three options: Correct response, Allowed responses, Timeout, and Event type.\n\nWe have already set the `correct_response` variable in Step 3. Unless we explicitly specify a correct response, OpenSesame automatically uses the `correct_response` variable if it is available. Therefore, we don't need to change the 'Correct response' field here.\n\nWe do need to set the allowed responses. Enter 'z;m' in the allowed-responses field (or other keys if you have chosen different response keys). The semicolon is used to separate responses. The KEYBOARD_RESPONSE now only accepts 'z' and 'm' keys. All other key presses are ignored, with the exception of 'escape', which pauses the experiment.\n\nWe also want to set a timeout, which is the maximum interval that the KEYBOARD_RESPONSE waits before deciding that the response is incorrect and setting the 'response' variable to 'None'. '2000' (ms) is a good value.\n\nWe don't need to change the Event type, because we want the participant to respond by pressing a key (keypress, the default) and not by releasing a key (keyrelease).\n\nThe KEYBOARD_RESPONSE now looks like %FigStep7.\n\n<notranslate>\nfigure:\n id: FigStep7\n source: step7.png\n caption: \"The KEYBOARD_RESPONSE at the end of Step 7.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- By default, the KEYBOARD_RESPONSE will use the `correct_response` variable to determine whether a response was correct. But you can use a different variable as well. To do this, enter a variable name between curly braces (`{my_variable}`) in the correct response field.\n\n__Tip__ -- If 'flush pending key presses' is enabled (it is by default), all pending key presses are discarded when the KEYBOARD_RESPONSE item is called. This prevents carry-over effects, which might otherwise occur if the participant accidentally presses a key during a non-response part of the trial.\n\n__Tip__ -- To use special keys, such as '/' or the up-arrow key, you can use key names (e.g., 'up' and 'space') or associated characters (e.g., '/' and ']'). The 'List available keys' button provides an overview of all valid key names.\n\n</div>\n\n## Step 8: Configure the incorrect (sampler) item\n\nThe *incorrect_sound* item doesn't need much work: We only need to select the sound that should be played. Click on *incorrect_sound* in the overview to open its tab. Click on the 'Browse' button and select `incorrect.ogg` from the file pool.\n\nThe sampler now looks like %FigStep8.\n\n<notranslate>\nfigure:\n id: FigStep8\n source: step8.png\n caption: \"The *incorrect_sound* item at the end of Step 8.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can use variables to specify which sound should be played by using a variable name between curly braces as (part of) the file name. For example: `{a_word}.ogg`\n\n__Tip__ -- The SAMPLER handles files in `.ogg`, `.mp3`, and `.wav` format. If you have sound files in a different format, [Audacity] is a great free tool to convert sound files (and much more).\n\n</div>": {
    "fr": "Enfin, réglez le champ 'Duration' sur '0'. Cela ne signifie pas que la cible est présentée pour seulement 0 ms, mais que l'expérience passera à l'élément suivant (le *keyboard_response*) immédiatement. Comme le *keyboard_response* attend une réponse, mais ne change pas ce qui est affiché à l'écran, la cible restera visible jusqu'à ce qu'une réponse soit donnée.\n\nN'oubliez pas d'enregistrer régulièrement votre expérience.\n\n<div class='info-box' markdown='1'>\n\n__Boîte d'information__\n\n__Astuce__ -- Chaque élément d'un SKETCHPAD a une option 'Show if', qui spécifie quand l'élément doit être affiché. Vous pouvez utiliser cela pour masquer / afficher des éléments d'un SKETCHPAD en fonction de certaines variables, de manière similaire aux déclarations run-if dans une SEQUENCE.\n\n__Astuce__ -- Assurez-vous que la couleur (de premier plan) est réglée sur noir. Sinon, vous dessinerez en blanc sur blanc et vous ne verrez rien!\n\n</div>\n\n## Étape 7: Configurer l'élément de réponse au clavier\n\nCliquez sur *keyboard_response* dans l'aperçu pour ouvrir son onglet. Vous voyez trois options: Correct response, Allowed responses, Timeout et Event type.\n\nNous avons déjà défini la variable `correct_response` à l'étape 3. Sauf si nous spécifions explicitement une réponse correcte, OpenSesame utilise automatiquement la variable `correct_response` si elle est disponible. Par conséquent, nous n'avons pas besoin de modifier le champ 'Correct response' ici.\n\nNous devons définir les réponses autorisées. Entrez 'z;m' dans le champ allowed-responses (ou d'autres touches si vous avez choisi des touches de réponse différentes). Le point-virgule est utilisé pour séparer les réponses. Le KEYBOARD_RESPONSE n'accepte désormais que les touches 'z' et 'm'. Toutes les autres pressions de touches sont ignorées, à l'exception de 'échap', qui met l'expérience en pause.\n\nNous voulons également définir un délai d'attente, qui est l'intervalle maximum que le KEYBOARD_RESPONSE attend avant de décider que la réponse est incorrecte et de régler la variable 'response' sur 'Aucune'. '2000' (ms) est une bonne valeur.\n\nNous n'avons pas besoin de modifier le type d'événement, car nous voulons que le participant réponde en appuyant sur une touche (keypress, par défaut) et non en relâchant une touche (keyrelease).\n\nLe KEYBOARD_RESPONSE ressemble maintenant à %FigStep7.\n\n<notranslate>\nfigure:\n id: FigStep7\n source: step7.png\n caption: \"Le KEYBOARD_RESPONSE à la fin de l'étape 7.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Boîte d'information__\n\n__Astuce__ -- Par défaut, le KEYBOARD_RESPONSE utilise la variable `correct_response` pour déterminer si une réponse était correcte. Mais vous pouvez utiliser une variable différente également. Pour ce faire, entrez un nom de variable entre crochets (`{my_variable}`) dans le champ correct response.\n\n__Astuce__ -- Si 'flush pending key presses' est activé (c'est le cas par défaut), toutes les pressions de touches en attente sont supprimées lorsque l'élément KEYBOARD_RESPONSE est appelé. Cela évite les effets de report, qui pourraient sinon se produire si le participant appuie accidentellement sur une touche pendant une partie non responsive du procès.\n\n__Astuce__ -- Pour utiliser des touches spéciales, comme '/' ou la touche flèche vers le haut, vous pouvez utiliser des noms de touches (par exemple 'up' et 'space') ou des caractères associés (par exemple '/' et ']'). Le bouton 'List available keys' fournit un aperçu de tous les noms de touches valides.\n\n</div>\n\n## Étape 8: Configurer l'élément incorrect (sampler)\n\nL'élément *incorrect_sound* ne nécessite pas beaucoup de travail: nous devons seulement sélectionner le son qui doit être joué. Cliquez sur *incorrect_sound* dans l'aperçu pour ouvrir son onglet. Cliquez sur le bouton 'Parcourir' et sélectionnez `incorrect.ogg` dans le fichier pool.\n\nLe sampler ressemble maintenant à %FigStep8.\n\n<notranslate>\nfigure:\n id: FigStep8\n source: step8.png\n caption: \"L'élément *incorrect_sound* à la fin de l'étape 8.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__ Boîte d'information__\n\n__Astuce__ -- Vous pouvez utiliser des variables pour spécifier quel son doit être joué en utilisant un nom de variable entre crochets en tant que (partie de) nom de fichier. Par exemple: `{a_word}.ogg`\n\n__Astuce__ -- Le SAMPLER gère les fichiers aux formats `.ogg`, `.mp3` et `.wav`. Si vous avez des fichiers audio dans un autre format, [Audacity] est un excellent outil gratuit pour convertir les fichiers audio (et bien plus).\n\n</div>"
  },
  "## Step 9: Configure the variable logger\n\nActually, we don't need to configure the variable LOGGER, but let's take a look at it anyway. Click on *logger* in the overview to open its tab. You see that the option 'Automatically log all variables' is selected. This means that OpenSesame logs everything, which is fine.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- If you like your log-files clean, you can disable the 'Automatically log all variables' option and manually select variables, either by entering variable names manually ('Add custom variable'), or by dragging variables from the variable inspector into the LOGGER table. You can also leave the 'Automatically log all variables' option enabled and exclude variables that you are not interested in.\n\n__The one tip to rule them all__ -- Always triple-check whether all the necessary variables are logged in your experiment! The best way to check this is to run the experiment and investigate the resulting log files.\n\n</div>\n\n## Step 10: Draw the feedback item\n\nAfter every block of trials, we want to present feedback to the participant to let him/ her know how well he/ she is doing. Therefore, in Step 2, we added a FEEDBACK item, simply named *feedback* to the end of *block_sequence*.\n\nClick on *feedback* in the overview to open its tab, select the draw text tool, change the foreground color to 'black' (if it isn't already), and click at (0, 0). Now enter the following text:\n\n```text\nEnd of block\n\nYour average response time was {avg_rt} ms\nYour accuracy was {acc} %\n\nPress any key to continue\n```\n\nBecause we want the feedback item to remain visible as long as the participant wants (i.e. until he/ she presses a key), we leave 'Duration' field set to 'keypress'.\n\nThe feedback item now looks like %FigStep_10.\n\n<notranslate>\nfigure:\n id: FigStep_10\n source: step10.png\n caption: \"The feedback item at the end of Step 10.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a feedback item?__ -- A FEEDBACK item is almost identical to a SKETCHPAD item. The only difference is that a FEEDBACK item is not prepared in advance. This means that you can use it to present feedback, which requires up-to-date information about a participant's response. You should not use FEEDBACK items to present time-critical displays, because the fact that it is not prepared in advance means that its timing properties are not as good as that of the SKETCHPAD item. See also:\n\n- %link:visual%\n\n__Feedback and variables__ -- Response items automatically keep track of the accuracy and average response time of the participant in the variables 'acc' (synonym: 'accuracy') and 'avg_rt' (synonym: 'average_response_time') respectively. See also:\n\n- %link:manual/variables%\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n## Step 11: Set the length of the practice phase and experimental phase\n\nWe have previously created the *practice_loop* and *experiment_loop* items, which both call *block_sequence* (i.e., a block of trials). However, right now they call *block_sequence* only once, which means that both the practice and the experimental phase consist of only a single block of trials.\n\nClick on *practice_loop* to open its tab and set 'Repeat' to '2.00'. This means that the practice phase consists of two blocks.\n\nClick on *experimental_loop* to open its tab and set 'Repeat' to '8.00'. This means that the experimental phase consists of eight blocks.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can create a variable `practice` in both *practice_loop* and *experimental_loop* and set it to 'yes' and 'no' respectively. This is an easy way of keeping track of which trials were part of the practice phase.\n\n</div>\n\n## Step 12: Write the instruction, end_of_practice and end_of_experiment forms": {
    "fr": "## Étape 9 : Configurer le variable LOGGER\n\nEn réalité, nous n'avons pas besoin de configurer le LOGGER variable, mais jetons-y un coup d'œil quand même. Cliquez sur *logger* dans l'aperçu pour ouvrir son onglet. Vous voyez que l'option \"Enregistrer automatiquement toutes les variables\" est sélectionnée. Cela signifie qu'OpenSesame enregistre tout, ce qui est très bien.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Conseil__ - Si vous aimez avoir des fichiers de journalisation propres, vous pouvez désactiver l'option \"Enregistrer automatiquement toutes les variables\" et sélectionner manuellement les variables, soit en entrant manuellement les noms des variables (\"Ajouter une variable personnalisée\"), soit en faisant glisser les variables à partir de l'inspecteur de variables dans le tableau LOGGER. Vous pouvez également laisser l'option \"Enregistrer automatiquement toutes les variables\" activée et exclure les variables qui ne vous intéressent pas.\n\n__The one tip to rule them all__ -- Vérifiez toujours trois fois si toutes les variables nécessaires sont enregistrées dans votre expérience ! La meilleure façon de vérifier cela est de lancer l'expérience et d'analyser les fichiers de journalisation résultants.\n\n</div>\n\n## Étape 10 : Dessiner l'élément de feedback\n\nAprès chaque bloc d'essais, nous voulons présenter un feedback au participant pour le/la informer de sa performance. C'est pourquoi, à l'étape 2, nous avons ajouté un élément FEEDBACK, simplement nommé *feedback* à la fin de *block_sequence*.\n\nCliquez sur *feedback* dans l'aperçu pour ouvrir son onglet, sélectionnez l'outil de dessin de texte, changez la couleur d'avant-plan en 'noir' (si ce n'est pas déjà fait), et cliquez à (0, 0). Entrez maintenant le texte suivant :\n\n```text\nFin du bloc\n\nVotre temps de réponse moyen était de {avg_rt} ms\nVotre précision était de {acc} %\n\nAppuyez sur n'importe quelle touche pour continuer\n```\n\nPuisque nous voulons que l'élément de feedback reste visible aussi longtemps que le participant le souhaite (c'est-à-dire jusqu'à ce qu'il/elle appuie sur une touche), nous laissons le champ \"Durée\" défini sur \"touche enfoncée\".\n\nL'élément de feedback ressemble maintenant à %FigStep_10.\n\n<notranslate>\nfigure:\n id: FigStep_10\n source: step10.png\n caption: \"L'élément de feedback à la fin de l'étape 10.\"\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Qu'est-ce qu'un élément de feedback ?__ - Un élément FEEDBACK est presque identique à un élément SKETCHPAD. La seule différence est qu'un élément FEEDBACK n'est pas préparé à l'avance. Cela signifie que vous pouvez l'utiliser pour présenter un feedback, qui nécessite des informations à jour sur la réponse d'un participant. Vous ne devez pas utiliser d'éléments FEEDBACK pour présenter des affichages sensibles au temps, car le fait qu'ils ne soient pas préparés à l'avance signifie que leurs propriétés de synchronisation ne sont pas aussi bonnes que celles de l'élément SKETCHPAD. Voir aussi:\n\n- %link:visual%\n\n__Feedback et variables__ - Les éléments de réponse suivent automatiquement la précision et le temps de réponse moyen du participant dans les variables 'acc' (synonyme : 'accuracy') et 'avg_rt' (synonyme : 'average_response_time') respectivement. Voir aussi :\n\n- %link:manual/variables%\n\n__Conseil__ - Assurez-vous que la couleur (de premier plan) est réglée sur noir. Sinon, vous dessinerez du blanc sur du blanc et vous ne verrez rien !\n\n</div>\n\n## Étape 11 : Définir la durée de la phase de pratique et de la phase expérimentale\n\nNous avons précédemment créé les éléments *practice_loop* et *experiment_loop*, qui appellent tous deux *block_sequence* (c'est-à-dire un bloc d'essais). Cependant, pour l'instant, ils n'appellent *block_sequence* qu'une seule fois, ce qui signifie que la phase de pratique et la phase expérimentale ne comportent qu'un seul bloc d'essais chacune.\n\nCliquez sur *practice_loop* pour ouvrir son onglet et définissez \"Répéter\" sur \"2.00\". Cela signifie que la phase de pratique se compose de deux blocs.\n\nCliquez sur *experimental_loop* pour ouvrir son onglet et définissez \"Répéter\" sur \"8.00\". Cela signifie que la phase expérimentale se compose de huit blocs.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Conseil__ -- Vous pouvez créer une variable `practice` dans *practice_loop* et *experimental_loop* et la définir respectivement sur 'yes' et 'no'. C'est un moyen facile de garder une trace des essais qui faisaient partie de la phase de pratique.\n\n</div>\n\n## Étape 12 : Rédiger les formulaires d'instruction, de fin de pratique et de fin d'expérience"
  },
  "I think you can handle this step your own! Simply open the appropriate items and add some text to present instructions, an end-of-practice message, and an end-of-experiment message.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can use a subset of HTML tags to format your text. For example, *&lt;b&gt;this will be bold&lt;b&gt;* and *&lt;span color='red'&gt;this will be red&lt;span&gt;*. For more information, see:\n\n- %link:text%\n\n</div>\n\n## Step 13: Run the experiment!\n\nYou're done! Click on the 'Run in window' (shortcut: `Ctrl+W`) or 'Run fullscreen' (shortcut: `Ctrl+R`) buttons in the toolbar to run your experiment.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- A test run is executed even faster by clicking the orange 'Run in window' button (shortcut: `Ctrl+Shift+W`), which doesn't ask you how to save the logfile (and should therefore only be used for testing purposes).\n\n</div>\n\n\n## Understanding errors\n\nBeing able to understand error messages is a crucial skill when working with OpenSeame. After all, a newly built experiment rarely runs immediately without any errors!\n\nLet's say that we made a mistake during one of the steps above. When trying to run the experiment, we get the following error message (%FigErrorMessage):\n\n<notranslate>\nfigure:\n id: FigErrorMessage\n source: error-message.png\n caption: \"An error message in OpenSesame.\"\n</notranslate>\n\nThe error message starts with a name, in this case `FStringError`, which indicates the general type of error. This is followed by a short explanatory text, in this case 'Failed to evaluate f-string expression in the following text: gaze_{gaze_ceu}.png`. Even without understanding what an f-string is (it's a string that contains Python code between curly braces), it's clear that there is something wrong with the text '{gaze_ceu}.png'.\n\nThe error message also indicates that the error comes from the prepare phase of the *gaze_cue* item.\n\nFinally, the error message indicates what specifically went wrong when evaluating the text 'gaze_{gaze_ceu}.png': the name 'gaze_ceu' is not defined.\n\nWhile reading the error message carefully, the cause and solution probably already came to your mind: we made a simple spelling mistake in the *gaze_cue* item, writing '{gaze_ceu}' instead of '{gaze_cue}'! And this resulted in an error because there is no variable with the name `gaze_ceu`. This can be easily fixed by opening the script of the *gaze_cue* item and fixing the typo.\n\n\n## Finally: Some general considerations regarding timing and backend selection\n\nIn the 'General properties' tab of the experiment (the tab that you open by clicking on the experiment name), you can select a backend. The backend is the layer of software that controls the display, input devices, sound, etc. Most experiments work with all backends, but there are reasons to prefer one backend over the other, mostly related to timing. Currently there are four backends (depending on your system, not all three may be available):\n\n- __psycho__ -- a hardware-accelerated backend based on PsychoPy [(Peirce, 2007)][references]. This is the default.\n- __xpyriment__ -- a hardware-accelerated backend based on Expyriment [(Krause & Lindeman, 2013)][references]\n- __legacy__ -- a 'safe' backend, based on PyGame. It provides reliable performance on most platforms, but, due to a lack of hardware acceleration, its timing properties are not as good as those of the other backends.\n- __osweb__ -- runs experiments in a browser [(Mathôt & March, 2022)][references].\n\nSee also:\n\n- %link:backends%\n- %link:timing%\n\n\n## References\n\n<div class='reference' markdown='1'>\n\nBrand, A., & Bradley, M. T. (2011). Assessing the effects of technical variance on the statistical outcomes of web experiments measuring response times. *Social Science Computer Review*. doi:10.1177/0894439311415604": {
    "fr": "Je pense que vous pouvez gérer cette étape vous-même ! Ouvrez simplement les éléments appropriés et ajoutez du texte pour présenter les instructions, un message de fin de pratique et un message de fin d'expérience.\n\n<div class='info-box' markdown='1'>\n\n__Boîte d'arrière-plan__\n\n__Astuce__ -- Vous pouvez utiliser un sous-ensemble de balises HTML pour formater votre texte. Par exemple, *&lt;b&gt;ceci sera en gras&lt;b&gt;* et *&lt;span color='red'&gt;ceci sera en rouge&lt;span&gt;*. Pour plus d'informations, consultez :\n\n- %link:text%\n\n</div>\n\n## Étape 13 : Exécuter l'expérience !\n\nC'est terminé ! Cliquez sur les boutons 'Exécuter dans une fenêtre' (raccourci : `Ctrl+W`) ou 'Exécuter en plein écran' (raccourci : `Ctrl+R`) dans la barre d'outils pour lancer votre expérience.\n\n<div class='info-box' markdown='1'>\n\n__Boîte d'arrière-plan__\n\n__Astuce__ -- Un test est exécuté encore plus rapidement en cliquant sur le bouton orange 'Exécuter dans une fenêtre' (raccourci : `Ctrl+Shift+W`), qui ne vous demande pas comment enregistrer le fichier journal (et doit donc être utilisé uniquement à des fins de test).\n\n</div>\n\n\n## Comprendre les erreurs\n\nÊtre capable de comprendre les messages d'erreur est une compétence essentielle lorsqu'on travaille avec OpenSeame. Après tout, une expérience nouvellement construite fonctionne rarement immédiatement sans erreur !\n\nSupposons que nous ayons fait une erreur lors de l'une des étapes ci-dessus. Lorsque nous essayons d'exécuter l'expérience, nous obtenons le message d'erreur suivant (%FigErrorMessage) :\n\n<notranslate>\nfigure:\n id: FigErrorMessage\n source: error-message.png\n caption: \"Un message d'erreur dans OpenSesame.\"\n</notranslate>\n\nLe message d'erreur commence par un nom, dans ce cas `FStringError`, qui indique le type général d'erreur. Il est suivi d'un court texte explicatif, dans ce cas \"Échec de l'évaluation de l'expression f-string dans le texte suivant : gaze_{gaze_ceu}.png\". Même sans comprendre ce qu'est une f-string (c'est une chaîne de caractères qui contient du code Python entre accolades), il est clair qu'il y a un problème avec le texte '{gaze_ceu}.png'.\n\nLe message d'erreur indique également que l'erreur provient de la phase de préparation de l'élément *gaze_cue*.\n\nEnfin, le message d'erreur indique ce qui s'est mal passé lors de l'évaluation du texte 'gaze_{gaze_ceu}.png' : le nom 'gaze_ceu' n'est pas défini.\n\nEn lisant attentivement le message d'erreur, la cause et la solution vous sont probablement déjà venues à l'esprit : nous avons fait une simple faute de frappe dans l'élément *gaze_cue*, en écrivant '{gaze_ceu}' au lieu de '{gaze_cue}' ! Et cela a entraîné une erreur car il n'y a pas de variable avec le nom `gaze_ceu`. Il suffit d'ouvrir le script de l'élément *gaze_cue* et de corriger la faute de frappe.\n\n\n## Enfin : Quelques considérations générales concernant le timing et la sélection du backend\n\nDans l'onglet 'Propriétés générales' de l'expérience (l'onglet que vous ouvrez en cliquant sur le nom de l'expérience), vous pouvez sélectionner un backend. Le backend est la couche logicielle qui contrôle l'affichage, les périphériques d'entrée, le son, etc. La plupart des expériences fonctionnent avec tous les backends, mais il y a des raisons de préférer un backend à un autre, principalement liées au timing. Actuellement, il existe quatre backends (selon votre système, les trois ne sont peut-être pas disponibles) :\n\n- __psycho__ -- un backend accéléré matériellement basé sur PsychoPy [(Peirce, 2007)][references]. C'est le choix par défaut.\n- __xpyriment__ -- un backend accéléré matériellement basé sur Expyriment [(Krause & Lindeman, 2013)][references]\n- __legacy__ -- un backend 'sûr', basé sur PyGame. Il offre des performances fiables sur la plupart des plates-formes, mais, en raison de l'absence d'accélération matérielle, ses propriétés de temporisation ne sont pas aussi bonnes que celles des autres backends.\n- __osweb__ -- exécute des expériences dans un navigateur [(Mathôt & March, 2022)][references].\n\nVoir aussi :\n\n- %link:backends%\n- %link:timing%\n\n\n## Références\n\n<div class='reference' markdown='1'>\n\nBrand, A., & Bradley, M. T. (2011). Évaluation des effets de la variance technique sur les résultats statistiques des expériences Web mesurant les temps de réponse. *Social Science Computer Review*. doi:10.1177/0894439311415604"
  },
  "Damian, M. F. (2010). Does variability in human performance outweigh imprecision in response devices such as computer keyboards? *Behavior Research Methods*, *42*, 205-211. doi:10.3758/BRM.42.1.205\n\nFriesen, C. K., & Kingstone, A. (1998). The eyes have it! Reflexive orienting is triggered by nonpredictive gaze. *Psychonomic Bulletin & Review*, *5*, 490–495. doi:10.3758/BF03208827\n\nKrause, F., & Lindemann, O. (2013). Expyriment: A Python library for cognitive and neuroscientific experiments. *Behavior Research Methods*. doi:10.3758/s13428-013-0390-6\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nMathôt, S., & March, J. (2022). Conducting linguistic experiments online with OpenSesame and OSWeb. *Language Learning*. doi:10.1111/lang.12509\n\nPeirce, J. W. (2007). PsychoPy: Psychophysics software in Python. *Journal of Neuroscience Methods*, *162*(1-2), 8-13. doi:10.1016/j.jneumeth.2006.11.017\n\nUlrich, R., & Giray, M. (1989). Time resolution of clocks: Effects on reaction time measurement—Good news for bad clocks. *British Journal of Mathematical and Statistical Psychology*, *42*(1), 1-12. doi:10.1111/j.2044-8317.1989.tb01111.x\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html\n[gimp]: http://www.gimp.org/\n[audacity]: http://audacity.sourceforge.net/\n[python inline scripting]: /python/about\n": {
    "fr": "Damian, M. F. (2010). La variabilité de la performance humaine l'emporte-t-elle sur l'imprécision des dispositifs de réponse tels que les claviers d'ordinateur ? *Behavior Research Methods*, *42*, 205-211. doi:10.3758/BRM.42.1.205\n\nFriesen, C. K., & Kingstone, A. (1998). Les yeux l'ont ! L'orientation réflexive est déclenchée par un regard non prédictif. *Psychonomic Bulletin & Review*, *5*, 490–495. doi:10.3758/BF03208827\n\nKrause, F., & Lindemann, O. (2013). Expyriment : une bibliothèque Python pour les expériences cognitives et neuroscientifiques. *Behavior Research Methods*. doi:10.3758/s13428-013-0390-6\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame : un générateur d'expériences open-source et graphique pour les sciences sociales. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nMathôt, S., & March, J. (2022). Réalisation d'expériences linguistiques en ligne avec OpenSesame et OSWeb. *Language Learning*. doi:10.1111/lang.12509\n\nPeirce, J. W. (2007). PsychoPy : logiciel de psychophysique en Python. *Journal of Neuroscience Methods*, *162*(1-2), 8-13. doi:10.1016/j.jneumeth.2006.11.017\n\nUlrich, R., & Giray, M. (1989). Résolution temporelle des horloges : effets sur la mesure du temps de réaction - bonnes nouvelles pour les mauvaises horloges. *British Journal of Mathematical and Statistical Psychology*, *42*(1), 1-12. doi:10.1111/j.2044-8317.1989.tb01111.x\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.fr.html\n[gimp]: http://www.gimp.org/\n[audacity]: http://audacity.sourceforge.net/\n[python inline scripting]: /python/about"
  },
  "APS tutorial": {
    "fr": "Tutoriel APS"
  },
  "Cats, dogs, and capybaras": {
    "fr": "Chats, chiens et capybaras"
  },
  "\n<notranslate>\nfigure:\n id: FigCapybara\n source: capybara.png\n caption: |\n  A capybara.\n</notranslate>\n\n\n<notranslate>[TOC]</notranslate>\n\n\n## About\n\nWe will create a simple animal-filled multisensory integration task, in which participants see a picture of a dog, cat, or capybara. A meow or a bark is played while the picture is shown. The participant reports whether a dog or a cat is shown, by clicking with the mouse on a response button on the screen. No response should be given when a capybara is shown: those are catch trials.\n\nWe make two simple predictions:\n\n- Participants should be faster to identify dogs when a barking sound is played, and faster to identify cats when a meowing sound is played. In other words, we expect a multisensory congruency effect.\n- When participants see a capybara, they are more likely to report seeing a dog when they hear a bark, and more likely to report seeing a cat when they hear a meow. In other words, false alarms are biased by the sound.\n\n\n## Tutorial\n\n### Step 1: Download and start OpenSesame\n\nOpenSesame is available for Windows, Linux, Mac OS, and Android (runtime only). This tutorial is written for OpenSesame 3.3.X. You can download OpenSesame from here:\n\n- %link:download%\n\nWhen you start OpenSesame, you will be given a choice of template experiments, and (if any) a list of recently opened experiments (see %FigStartUp).\n\n<notranslate>\nfigure:\n id: FigStartUp\n source: start-up.png\n caption: |\n  The OpenSesame window on start-up.\n</notranslate>\n\nThe *Extended template* provides a good starting point for creating trial-based experiments. However, in this tutorial we will create the entire experiment from scratch. Therefore, we will continue with the 'default template', which is already loaded when OpenSesame is launched (%FigDefaultTemplate). Therefore, simply close the 'Get started!' and (if shown) 'Welcome!' tabs.\n\n<notranslate>\nfigure:\n id: FigDefaultTemplate\n source: default-template.png\n caption: |\n  The structure of the 'Default template' as seen in the overview area.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 1: Basics**\n\nOpenSesame experiments are collections of *items*. An item is a small chunk of functionality that, for example, can be used to present visual stimuli (the SKETCHPAD item) or to record key presses (the KEYBOARD_RESPONSE item). Items have a type and a name. For example, you might have two items of the type KEYBOARD_RESPONSE with the names *t1_response* and *t2_response*. To make the distinction between item types and item names clear, we will use THIS_STYLE for types, and *this style* for names.\n\nTo give structure to your experiment, two types of items are especially important: the LOOP and the SEQUENCE. Understanding how you can combine LOOPs and SEQUENCEs to build experiments is perhaps the trickiest part of working with OpenSesame, so let's get that out of the way first.\n\nA LOOP is where, in most cases, you define your independent variables. In a LOOP you can create a table in which each column corresponds to a variable, and each row corresponds to a single run of the 'item to run'. To make this more concrete, let's consider the following *block_loop* (unrelated to this tutorial):\n\n<notranslate>\nfigure:\n id: FigLoopTable\n source: loop-table.png\n caption: |\n  An example of variables defined in a loop table. (This example is not related to the experiment created in this tutorial.)\n</notranslate>\n\nThis *block_loop* will execute *trial_sequence* four times. Once while `soa` is 100 and `target` is 'F', once while `soa` is 100 and `target` is 'H', etc. The order in which the rows are walked through is random by default, but can also be set to sequential in the top-right of the tab.": {
    "fr": "<notranslate>\nfigure:\n id: FigCapybara\n source: capybara.png\n caption: |\n  Un capybara.\n</notranslate>\n\n\n<notranslate>[TOC]</notranslate>\n\n\n## À propos\n\nNous allons créer une tâche d'intégration multisensorielle simple remplie d'animaux, dans laquelle les participants voient une photo d'un chien, d'un chat ou d'un capybara. Un miaulement ou un aboiement est joué pendant que l'image est affichée. Le participant indique si un chien ou un chat est montré, en cliquant avec la souris sur un bouton de réponse à l'écran. Aucune réponse ne doit être donnée lorsqu'un capybara est montré : ce sont des essais pièges.\n\nNous faisons deux prédictions simples :\n\n- Les participants devraient être plus rapides à identifier les chiens lorsqu'un son d'aboiement est joué, et plus rapides à identifier les chats lorsqu'un son de miaulement est joué. En d'autres termes, nous nous attendons à un effet de congruence multisensorielle.\n- Lorsque les participants voient un capybara, ils sont plus susceptibles de signaler qu'ils voient un chien lorsqu'ils entendent un aboiement, et plus susceptibles de signaler qu'ils voient un chat lorsqu'ils entendent un miaulement. En d'autres termes, les fausses alertes sont biaisées par le son.\n\n\n## Tutoriel\n\n### Étape 1 : Téléchargez et démarrez OpenSesame\n\nOpenSesame est disponible pour Windows, Linux, Mac OS et Android (exécution uniquement). Ce tutoriel est rédigé pour OpenSesame 3.3.X. Vous pouvez télécharger OpenSesame à partir d'ici :\n\n- %link:download%\n\nLorsque vous démarrez OpenSesame, on vous proposera de choisir parmi des expériences modèles et (le cas échéant) une liste d'expériences récemment ouvertes (voir %FigStartUp).\n\n<notranslate>\nfigure:\n id: FigStartUp\n source: start-up.png\n caption: |\n  La fenêtre d'OpenSesame au démarrage.\n</notranslate>\n\nLe *modèle étendu* fournit un bon point de départ pour créer des expériences basées sur des essais. Cependant, dans ce tutoriel, nous créerons l'ensemble de l'expérience à partir de zéro. Nous continuerons donc avec le \"modèle par défaut\", qui est déjà chargé lors du lancement d'OpenSesame (%FigDefaultTemplate). Fermez simplement les onglets \"Commencer !\" et (si affiché) \"Bienvenue!\".\n\n<notranslate>\nfigure:\n id: FigDefaultTemplate\n source: default-template.png\n caption: |\n  La structure du \"modèle par défaut\" vue dans la zone d'aperçu.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 1 : Les bases**\n\nLes expériences OpenSesame sont des collections d' *items*. Un item est un petit morceau de fonctionnalité qui, par exemple, peut être utilisé pour présenter des stimuli visuels (l'item SKETCHPAD) ou pour enregistrer des pressions de touches (l'item KEYBOARD_RESPONSE). Les items ont un type et un nom. Par exemple, vous pourriez avoir deux items du type KEYBOARD_RESPONSE avec les noms *t1_response* et *t2_response*. Pour bien distinguer les types et les noms d'items, nous utiliserons CE_STYLE pour les types et *ce style* pour les noms.\n\nPour donner une structure à votre expérience, deux types d'items sont particulièrement importants : la LOOP et la SEQUENCE. Comprendre comment vous pouvez combiner des LOOPs et des SEQUENCEs pour construire des expériences est peut-être la partie la plus délicate du travail avec OpenSesame, alors abordons ce point en premier.\n\nUne LOOP est l'endroit où, dans la plupart des cas, vous définissez vos variables indépendantes. Dans une LOOP, vous pouvez créer un tableau dans lequel chaque colonne correspond à une variable et chaque ligne correspond à une seule exécution de l' \"item à exécuter\". Pour rendre cela plus concret, considérons la *block_loop* suivante (sans rapport avec ce tutoriel) :\n\n<notranslate>\nfigure:\n id: FigLoopTable\n source: loop-table.png\n caption: |\n  Un exemple de variables définies dans un tableau de boucle. (Cet exemple n'est pas lié à l'expérience créée dans ce tutoriel.)\n</notranslate>\n\nCette *block_loop* exécutera *trial_sequence* quatre fois. Une fois avec `soa` à 100 et `target` à 'F', une fois avec `soa` à 100 et `target` à 'H', etc. L'ordre dans lequel les lignes sont parcourues est aléatoire par défaut, mais peut également être réglé sur séquentiel dans le coin supérieur droit de l'onglet."
  },
  "~~~ .yaml\nname: opensesame_3.2.1-py2.7-win32-1\nchannels:\n- cogsci\n- conda-forge\n- defaults\ndependencies:\n- anaconda-client=1.6.3=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.5=py27_0\n- bleach=1.5.0=py27_0\n- bzip2=1.0.6=vc9_3\n- certifi=2016.2.28=py27_0\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.1.2=py_0\n- qscintilla2=2.9.3=py27_vc9_0\n- requests-oauthlib=0.6.2=py_0\n- webcolors=1.5=py27_0\n- colorama=0.3.9=py27_0\n- configparser=3.5.0=py27_0\n- decorator=4.1.2=py27_0\n- entrypoints=0.2.3=py27_0\n- enum34=1.1.6=py27_0\n- freetype=2.5.5=vc9_2\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- html5lib=0.999=py27_0\n- icu=57.1=vc9_0\n- ipykernel=4.6.1=py27_0\n- ipython=5.3.0=py27_0\n- ipython_genutils=0.2.0=py27_0\n- ipywidgets=6.0.0=py27_0\n- jinja2=2.9.6=py27_0\n- jpeg=9b=vc9_0\n- jsonschema=2.6.0=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=5.1.0=py27_0\n- jupyter_console=5.2.0=py27_0\n- jupyter_core=4.3.0=py27_0\n- libpng=1.6.30=vc9_1\n- libtiff=4.0.6=vc9_3\n- markdown=2.6.9=py27_0\n- markupsafe=1.0=py27_0\n- mistune=0.7.4=py27_0\n- mkl=2017.0.3=0\n- nbconvert=5.2.1=py27_0\n- nbformat=4.4.0=py27_0\n- notebook=5.0.0=py27_0\n- numpy=1.13.1=py27_0\n- olefile=0.44=py27_0\n- openssl=1.0.2l=vc9_0\n- pandocfilters=1.4.2=py27_0\n- path.py=10.3.1=py27_0\n- pathlib2=2.3.0=py27_0\n- pickleshare=0.7.4=py27_0\n- pillow=4.2.1=py27_0\n- pip=9.0.1=py27_1\n- prompt_toolkit=1.0.15=py27_0\n- pyflakes=1.6.0=py27_0\n- pygments=2.2.0=py27_0\n- pyopengl=3.1.1a1=np113py27_0\n- pyopengl-accelerate=3.1.1a1=np113py27_0\n- pyqt=5.6.0=py27_2\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.13=1\n- python-dateutil=2.6.1=py27_0\n- pytz=2017.2=py27_0\n- pyyaml=3.12=py27_0\n- pyzmq=16.0.2=py27_0\n- qt=5.6.2=vc9_6\n- qtawesome=0.4.4=py27_0\n- qtconsole=4.3.1=py27_0\n- qtpy=1.3.1=py27_0\n- requests=2.14.2=py27_0\n- scandir=1.5=py27_0\n- scipy=0.19.1=np113py27_0\n- setuptools=36.4.0=py27_1\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.18=py27_0\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.5.0.1=py27_0\n- testpath=0.3.1=py27_0\n- tornado=4.5.2=py27_0\n- traitlets=4.3.2=py27_0\n- vc=9=0\n- vs2008_runtime=9.00.30729.5054=0\n- wcwidth=0.1.7=py27_0\n- wheel=0.29.0=py27_0\n- widgetsnbextension=3.0.2=py27_0\n- win_unicode_console=0.5=py27_0\n- wincertstore=0.2=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.11=vc9_0\n- ffmpeg=3.4.1\n- pip:\n  - arrow==0.7.0\n  - backports-abc==0.5\n  - backports.shutil-get-terminal-size==1.0.0\n  - backports.ssl-match-hostname==3.5.0.1\n  - cffi==1.11.2\n  - configobj==5.0.6\n  - et-xmlfile==1.0.1\n  - expyriment==0.9.0\n  - fastnumbers==2.0.2\n  - future==0.16.0\n  - humanize==0.5.1\n  - imageio==2.2.0\n  - ipython-genutils==0.2.0\n  - jdcal==1.3\n  - json-tricks==3.11.0\n  - jupyter-client==5.1.0\n  - jupyter-console==5.2.0\n  - jupyter-core==4.3.0\n  - mediadecoder==0.1.5\n  - moviepy==0.2.3.2\n  - oauthlib==1.1.2\n  - openpyxl==2.4.9\n  - opensesame-extension-osf==1.1.1\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-plugin-psychopy==0.5.0\n  - opensesame-windows-launcher==0.4.1\n  - prettytable==0.7.2\n  - prompt-toolkit==1.0.15\n  - psychopy==1.85.3\n  - pyaudio==0.2.11\n  - pycparser==2.18\n  - pygame==1.9.3\n  - pyglet==1.3.0\n  - python-bidi==0.4.0\n  - python-datamatrix==0.8.1 # Updated in 3.2.1\n  - python-fileinspector==1.0.2\n  - python-opensesame==3.2.1 # Updated in 3.2.1\n  - python-pseudorandom==0.2.2\n  - python-pygaze==0.6.0a23\n  - python-qdatamatrix==0.1.18\n  - python-qnotifications==1.1.1\n  - python-qosf==1.2.2\n  - python-qprogedit==4.0.11\n  - python-qtpip==0.1.5\n  - requests-oauthlib==0.6.2\n  - sounddevice==0.3.9\n  - tqdm==4.19.5\n  - webcolors==1.5\n  - win-unicode-console==0.5\n  - yolk3k==0.9\n~~~\n\n\n### Windows Python 3.6": {
    "fr": "~~~ .yaml\nname: opensesame_3.2.1-py3.6-win32-1\nchannels:\n- cogsci\n- conda-forge\n- defaults\ndependencies:\n- anaconda-client=1.6.3=py36_0\n- appdirs=1.4.3=py36h7ae7562_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.1.2=py_0\n- qscintilla2=2.9.4=py36_vc9_1\n- qt=5.6.2=vc14_7\n- requests-oauthlib=0.6.2=py_0\n- webcolors=1.7.0=py_0\n- backports=1.0=py36_1\n- backports.functools_lru_cache=1.4=py36_1\n- backports.shutil_get_terminal_size=1.0.0=py36_2\n- bzip2=1.0.6=vc14_1\n- certifi=2016.2.28=py36_0\n- clyent=1.2.2=py36_0\n- colorama=0.3.9=py36_0\n- entrypoints=0.2.3=py36_0\n- freetype=2.5.5=vc14_2\n- get_terminal_size=1.0.0=py36_0\n- icu=57.1=vc14_1\n- ipykernel=4.6.1=py36_0\n- ipython=6.1.0=py36_1\n- ipython_genutils=0.2.0=py36_0\n- ipywidgets=6.0.0=py36_0\n- jinja2=2.9.6=py36_0\n- jpeg=9b=vc14_0\n- jsonschema=2.6.0=py36_0\n- jupyter=1.0.0=py36_3\n- jupyter_client=5.1.0=py36_0\n- jupyter_console=5.2.0=py36_0\n- jupyter_core=4.3.0=py36_0\n- libpng=1.6.30=vc14_1\n- libtiff=4.0.6=vc14_3\n- markdown=2.6.9=py36_0\n- markupsafe=1.0=py36_0\n- mistune=0.7.4=py36_0\n- nbconvert=5.2.1=py36_0\n- nbformat=4.4.0=py36_0\n- notebook=5.0.0=py36_0\n- numpy=1.13.1=py36_0\n- olefile=0.44=py36_0\n- openssl=1.0.2l=vc14_0\n- pandocfilters=1.4.2=py36_0\n- path.py=10.3.1=py36_0\n- pathlib2=2.3.0=py36_0\n- pickleshare=0.7.4=py36_0\n- pillow=4.2.1=py36_0\n- pip=9.0.1=py36_1\n- prompt_toolkit=1.0.15=py36_0\n- pyflakes=1.6.0=py36_0\n- pygments=2.2.0=py36_0\n- pyopengl=3.1.1a1=np113py36_0\n- pyopengl-accelerate=3.1.1a1=np113py36_0\n- pyqt=5.6.0=py36_2\n- pyreadline=2.1=py36_0\n- pyserial=2.7=py36_0\n- python=3.6.2=0\n- python-dateutil=2.6.1=py36_0\n- pytz=2017.2=py36_0\n- pyyaml=3.12=py36_0\n- pyzmq=16.0.2=py36_0\n- sip=4.18=py36_0\n- six=1.10.0=py36_0\n- sqlite=3.13.0=vc14_1\n- testpath=0.3.1=py36_0\n- tornado=4.5.2=py36_0\n- traitlets=4.3.2=py36_0\n- wheel=0.29.0=py36_0\n- widgetsnbextension=3.0.2=py36_0\n- win_unicode_console=0.5=py36_0\n- wincertstore=0.2=py36_0\n- zlib=1.2.11=vc14_0\n- pip:\n  - appdirs==1.4.3\n  - arrow==0.7.0\n  - backports.shutil-get-terminal-size==1.0.0\n  - et-xmlfile==1.0.1\n  - expyriment==0.9.0\n  - future==0.16.0\n  - humanize==0.5.1\n  - imageio==2.2.0\n  - ipython-genutils==0.2.0\n  - jdcal==1.3\n  - json-tricks==3.11.0\n  - jupyter-client==5.1.0\n  - jupyter-console==5.2.0\n  - jupyter-core==4.3.0\n  - mediadecoder==0.1.5\n  - moviepy==0.2.3.2\n  - oauthlib==1.1.2\n  - openpyxl==2.4.9\n  - opensesame-extension-osf==1.1.1\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-plugin-psychopy==0.5.0\n  - opensesame-windows-launcher==0.4.1\n  - prettytable==0.7.2\n  - prompt-toolkit==1.0.15\n  - pyaudio==0.2.11\n  - pygame==1.9.3\n  - pyglet==1.3.0\n  - python-bidi==0.4.0\n  - python-datamatrix==0.8.1 # Updated in 3.2.1\n  - python-fileinspector==1.0.2\n  - python-opensesame==3.2.1 # Updated in 3.2.1\n  - python-pseudorandom==0.2.2\n  - python-pygaze==0.6.0a23\n  - python-qdatamatrix==0.1.18\n  - python-qnotifications==1.1.1\n  - python-qosf==1.2.2\n  - python-qprogedit==4.0.11\n  - python-qtpip==0.1.5\n  - requests-oauthlib==0.6.2\n  - tqdm==4.19.5\n  - webcolors==1.7.0\n  - win-unicode-console==0.5.readline==6.2.4.1\n  - yolk3k==0.9\n~~~\n\n### Windows Python 3.6"
  },
  "How to contribute": {
    "fr": "Comment contribuer"
  },
  "EyeTribe": {
    "fr": "EyeTribe"
  },
  "Release notes for 2.9.6": {
    "fr": "Notes de version pour 2.9.6"
  },
  "Release notes for 3.3.6": {
    "fr": "Notes de version pour 3.3.6"
  },
  "Release notes for 3.1.1": {
    "fr": "Notes de version pour 3.1.1"
  },
  "Release notes for 0.27": {
    "fr": "Notes de version pour 0.27"
  },
  "Release notes for 2.8.0": {
    "fr": "Notes de version pour 2.8.0",
    "de": "Versionshinweise für 2.8.0"
  },
  "Release notes for 2.9.0": {
    "fr": "Notes de version pour 2.9.0"
  },
  "Release notes for 3.3.3": {
    "fr": "Notes de version pour 3.3.3",
    "de": "Versionshinweise für 3.3.3"
  },
  "The EyeTribe is supported through PyGaze. For more information, see:\n\n- %link:pygaze%\n": {
    "fr": "L'EyeTribe est pris en charge par PyGaze. Pour plus d'informations, consultez :\n\n- %link:pygaze%"
  },
  "Video playback": {
    "fr": "Lecture vidéo"
  },
  "OpenSesame 0.27 is almost completely backwards compatible with previous versions, except for the following differences:\n\n- `canvas.keyboard.get_key()` now returns a key as `unicode`, rather than as an `int` corresponding to an ASCII value. This change has been made to improve support for non-QWERTY keyboard layouts.\n- Response timeouts are now registered as `None`, rather than the string 'timeout'.\n- In the Windows release, the media_player plugin has been replaced in favour of the media_player_vlc plugin. This was necessary, because the libraries used by the old media_player are not compatible with Python 2.7.\n\nNotable changes:\n\n- Added Expyriment backend\n- Added form functionality\n- Improved Unicode support\n- Improved internationalization\n- Added quick run button\n- Add ecological alternative to S&V template\n- Numerous bug-fixes\n- Improved compatibility with Nexus 7 tablet\n\n": {
    "fr": "OpenSesame 0.27 est presque entièrement compatible avec les versions précédentes, à l'exception des différences suivantes :\n\n- `canvas.keyboard.get_key()` renvoie maintenant une touche en tant que `unicode`, plutôt qu'en tant que `int` correspondant à une valeur ASCII. Ce changement a été effectué pour améliorer la prise en charge des dispositions de clavier non-QWERTY.\n- Les délais d'attente des réponses sont désormais enregistrés comme `None`, plutôt que la chaîne 'timeout'.\n- Dans la version Windows, le plugin media_player a été remplacé en faveur du plugin media_player_vlc. Cela était nécessaire car les bibliothèques utilisées par l'ancien media_player ne sont pas compatibles avec Python 2.7.\n\nChangements notables :\n\n- Ajout du backend Expyriment\n- Ajout de la fonctionnalité de formulaire\n- Amélioration du support Unicode\n- Amélioration de l'internationalisation\n- Ajout d'un bouton de lancement rapide\n- Ajout d'une alternative écologique au modèle S&V\n- Nombreuses corrections de bugs\n- Amélioration de la compatibilité avec la tablette Nexus 7"
  },
  "Release notes for 3.2.7": {
    "fr": "Notes de version pour 3.2.7"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.3.3 *Lentiform Loewenfeld* is the third maintenance release in the 3.3 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.3 series.\n\nIf you are upgrading from OpenSesame 3.2 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for his work on OSWeb, the Mac OS package, and bug fixes\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.3.3\n- Better management of subprocesses\n\nrapunzel:\n\n- Updated to 0.4.7\n- Better management of subprocesses\n\npyqode.core\n\n- Updated to 3.0.0\n\npyqode.python\n\n- Updated to 3.0.0\n\nopensesame-plugin-media_player_mpy:\n\n- Updated to 0.1.11\n\nQOpenScienceFramework:\n\n- Updated to 1.3.1\n\n\n## Packages\n\n\n### Python 3.7 (standard)": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.3.3 *Lentiform Loewenfeld* est la troisième version de maintenance de la série 3.3. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.3.\n\nSi vous mettez à niveau depuis OpenSesame 3.2 ou une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour son travail sur OSWeb, le package Mac OS et les corrections de bugs\n\n\n## Corrections de bugs et améliorations\n\nopensesame :\n\n- Mis à jour vers 3.3.3\n- Meilleure gestion des sous-processus\n\nrapunzel :\n\n- Mis à jour vers 0.4.7\n- Meilleure gestion des sous-processus\n\npyqode.core\n\n- Mis à jour vers 3.0.0\n\npyqode.python\n\n- Mis à jour vers 3.0.0\n\nopensesame-plugin-media_player_mpy :\n\n- Mis à jour vers 0.1.11\n\nQOpenScienceFramework :\n\n- Mis à jour vers 1.3.1\n\n\n## Paquets\n\n\n### Python 3.7 (standard)"
  },
  "<notranslate>[TOC]</notranslate>\n\n\n## media_player_mpy plugin\n\nThe MEDIA_PLAYER_MPY plugin is based on MoviePy. It is included by default with the Windows and Mac OS packages of OpenSesame. If it is not installed, you can get it by installing the `opensesame-plugin-media-player-mpy` package, as described here:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>\n\nThe source code is hosted at:\n\n- <https://github.com/dschreij/opensesame-plugin-mediaplayer>\n\n\n## OpenCV\n\nOpenCV is a powerful computer vision library, which contains (among many other things) routines for reading video files.\n\n- <http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html>\n\nThe following example shows how to play back a video file, while drawing a red square on top of the video. This example assumes that you're using the legacy backend.\n\n~~~ .python\nimport cv2\nimport numpy\nimport pygame\n# Full path to the video file in file pool\npath = pool['myvideo.avi']\n# Open the video\nvideo = cv2.VideoCapture(path)\n# A loop to play the video file. This can also be a while loop until a key\n# is pressed. etc.\nfor i in range(100):\n    # Get a frame\n    retval, frame = video.read()\n    # Rotate it, because for some reason it otherwise appears flipped.\n    frame = numpy.rot90(frame)\n    # The video uses BGR colors and PyGame needs RGB\n    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    # Create a PyGame surface\n    surf = pygame.surfarray.make_surface(frame)\n    # Now you can draw whatever you want onto the PyGame surface!\n    pygame.draw.rect(surf, (255,0,0), (100, 100, 200, 200))\n    # Show the PyGame surface!\n    exp.surface.blit(surf, (0, 0))\n    pygame.display.flip()\n~~~\n": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## plugin media_player_mpy\n\nLe plugin MEDIA_PLAYER_MPY est basé sur MoviePy. Il est inclus par défaut avec les packages OpenSesame pour Windows et Mac OS. S'il n'est pas installé, vous pouvez l'obtenir en installant le package `opensesame-plugin-media-player-mpy`, comme décrit ici :\n\n- <https://rapunzel.cogsci.nl/manual/environment/>\n\nLe code source est hébergé à l'adresse suivante :\n\n- <https://github.com/dschreij/opensesame-plugin-mediaplayer>\n\n\n## OpenCV\n\nOpenCV est une puissante bibliothèque de vision par ordinateur, qui contient (entre autres choses) des routines pour lire des fichiers vidéo.\n\n- <http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html>\n\nL'exemple suivant montre comment lire un fichier vidéo tout en dessinant un carré rouge par-dessus la vidéo. Cet exemple suppose que vous utilisez le backend hérité.\n\n~~~ .python\nimport cv2\nimport numpy\nimport pygame\n# Chemin d'accès complet au fichier vidéo dans la file d'attente\npath = pool['myvideo.avi']\n# Ouvrir la vidéo\nvideo = cv2.VideoCapture(path)\n# Une boucle pour jouer le fichier vidéo. Cela peut aussi être une boucle while jusqu'à ce qu'une touche\n# soit pressée. etc.\nfor i in range(100):\n    # Obtenir une image\n    retval, frame = video.read()\n    # Le retourner, car pour une raison quelconque, il apparaît autrement inversé.\n    frame = numpy.rot90(frame)\n    # La vidéo utilise des couleurs BGR et PyGame a besoin de RGB\n    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    # Créer une surface PyGame\n    surf = pygame.surfarray.make_surface(frame)\n    # Maintenant, vous pouvez dessiner ce que vous voulez sur la surface PyGame !\n    pygame.draw.rect(surf, (255,0,0), (100, 100, 200, 200))\n    # Afficher la surface PyGame !\n    exp.surface.blit(surf, (0, 0))\n    pygame.display.flip()\n~~~"
  },
  "Sound": {
    "fr": "Son"
  },
  "## Changelog\n\n### New functionality and improvements\n\n- Add runner functionality\n- Improved exception handling\n- Migrate to QProgEdit editor component\n- Updated offline help pages\n- Improve support for non-Latin alphabets (#211)\n- Add correct-response option to touch_response plugin (#214)\n- Add style argument to canvas.fixdot()\n- Add item.set_response() convenience method\n- Add gamma and suppress-warnings options to psycho backend\n\n### Bugs fixed\n\n- Line wrapping causes double spaces (#203)\n- Keywords to `decode()` break compatibility with Python < 2.7 (#201)\n- Respect `focus=no` in `form_base` (#208)\n- Fix ugly exception on Escape press in joystick plugin (#162)\n- Correctly parse non-Unix line separators in HTML parser\n- Do not give ugly warning on close (#124)\n- Set subject_parity in Android runtime (#221)\n\n###  Debian packaging\n\n- Remove large template files\n\n### Windows packaging\n\n- Update included libraries. See `modules()` output below.\n\n~~~\nOpenSesame 2.8.0\nPython 2.7.6 (default, Nov 10 2013, 19:24:18) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 2.4.7\nQProgedit 1.0.0\nExpyriment 0.7.0b~opensesame2 (Revision 0b10a83590c31285a5d94b3b8479f302f1abc8f3; Python 2.7.6)\nNumPy 1.8.0\nPIL is available (version is unknown)\nPsychoPy 1.78.01\nPyAudio 0.2.7\nPyGame 1.9.1release\nPyglet 1.1.4\nPyOpenGL 3.0.2\nPyQt 4.10.3\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.3.1\nSciPy 0.13.2\n~~~\n\n[0.27.4 release notes]: /notes/0.27\n": {
    "fr": "## Journal des modifications\n\n### Nouvelles fonctionnalités et améliorations\n\n- Ajouter une fonctionnalité de lanceur\n- Gestion des exceptions améliorée\n- Migration vers le composant d'éditeur QProgEdit\n- Mise à jour des pages d'aide hors ligne\n- Améliorer la prise en charge des alphabets non latins (#211)\n- Ajouter l'option de réponse correcte au plugin touch_response (#214)\n- Ajouter un argument de style à canvas.fixdot()\n- Ajouter la méthode de commodité item.set_response()\n- Ajouter les options gamma et suppress-warnings au backend psycho\n\n### Bugs corrigés\n\n- Le retour à la ligne provoque des espaces doubles (#203)\n- Les mots-clés pour `decode()` sont incompatibles avec Python < 2.7 (#201)\n- Respecter `focus=no` dans `form_base` (#208)\n- Corriger l'exception inesthétique lors de l'appui sur Escape dans le plugin joystick (#162)\n- Analyser correctement les séparateurs de ligne non Unix dans le parseur HTML\n- Ne pas donner d'avertissement inesthétique lors de la fermeture (#124)\n- Définir subject_parity dans Android runtime (#221)\n\n### Paquets Debian\n\n- Supprimer les fichiers de modèle volumineux\n\n### Paquets Windows\n\n- Mettre à jour les bibliothèques incluses. Voir `modules()` output ci-dessous.\n\n~~~\nOpenSesame 2.8.0\nPython 2.7.6 (default, Nov 10 2013, 19:24:18) [MSC v.1500 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 2.4.7\nQProgedit 1.0.0\nExpyriment 0.7.0b~opensesame2 (Révision 0b10a83590c31285a5d94b3b8479f302f1abc8f3 ; Python 2.7.6)\nNumPy 1.8.0\nPIL est disponible (la version est inconnue)\nPsychoPy 1.78.01\nPyAudio 0.2.7\nPyGame 1.9.1release\nPyglet 1.1.4\nPyOpenGL 3.0.2\nPyQt 4.10.3\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.3.1\nSciPy 0.13.2\n~~~\n\n[0.27.4 notes de version]: /notes/0.27"
  },
  "OpenSesame 3.1.1 *Jazzy James* is the first maintenance release in the 3.1 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.1 series.\n\nIf you are upgrading from OpenSesame 3.0 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij ([@dschreij](https://github.com/dschreij)) for various code contributions\n- Philip Alday ([@palday](https://github.com/palday)) for fixing Markdown compatibility\n- Edwin Dalmaijer ([@esdalmaijer](https://github.com/esdalmaijer)) for his continued work on PyGaze\n- Eduart Ort ([@eort](https://github.com/eort)) for updating the German translation\n- Amandine Rey ([@amandinerey](https://github.com/amandinerey)) for (partly) updating the French translation\n\n(The translations were already included with 3.1.0, but I forgot to thank Eduard and Amandine. So here is a belated shout-out!)\n\n## Bugs fixed\n\n- Fix coding of timeout responses\n- Fix custom fonts\n- Fix close-application icon\n- Fix compatibility with older versions of `python-markdown`\n\n## Other updated packages\n\n- PyGaze (`python-pygaze`) has been updated to 0.6.0a16, fixing calibration issues with the EyeTribe.\n- QNotifications (`python-qnotifications`) has been updated to 1.1.0, fixing display issues when there are many notifications.\n": {
    "fr": "OpenSesame 3.1.1 *Jazzy James* est la première version de maintenance de la série 3.1. Elle contient des corrections de bogues et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.1.\n\nSi vous effectuez une mise à niveau depuis OpenSesame 3.0 ou une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij ([@dschreij](https://github.com/dschreij)) pour diverses contributions de code\n- Philip Alday ([@palday](https://github.com/palday)) pour avoir corrigé la compatibilité Markdown\n- Edwin Dalmaijer ([@esdalmaijer](https://github.com/esdalmaijer)) pour son travail continu sur PyGaze\n- Eduart Ort ([@eort](https://github.com/eort)) pour la mise à jour de la traduction allemande\n- Amandine Rey ([@amandinerey](https://github.com/amandinerey)) pour avoir (en partie) mis à jour la traduction française\n\n(Les traductions étaient déjà incluses avec la version 3.1.0, mais j'ai oublié de remercier Eduard et Amandine. Alors voici un clin d'œil en retard!)\n\n## Bugs corrigés\n\n- Correction du codage des réponses au temps d'attente\n- Correction des polices personnalisées\n- Correction de l'icône de fermeture de l'application\n- Correction de la compatibilité avec les anciennes versions de `python-markdown`\n\n## Autres paquets mis à jour\n\n- PyGaze (`python-pygaze`) a été mis à jour en version 0.6.0a16, corrigeant les problèmes de calibrage avec l'EyeTribe.\n- QNotifications (`python-qnotifications`) a été mis à jour en version 1.1.0, corrigeant les problèmes d'affichage lorsqu'il y a de nombreuses notifications."
  },
  "Release notes for 3.3.4": {
    "fr": "Notes de version pour 3.3.4"
  },
  "Release notes for 2.8.3": {
    "fr": "Notes de version pour 2.8.3"
  },
  "OpenSesame 2.9.6 is the sixth maintenance release in the 2.9 series. If you are upgrading from 2.8.3 or earlier, please also read the [2.9.0 release notes].\n\n## Credits\n\nThanks to Joshua Snell ([@Klemtonius](https://github.com/Klemtonius)) and Jarik den Hartog ([@JdenHartog](https://github.com/JdenHartog)) for their code contributions.\n\n## Changes\n\n### Improvements\n\n- Use the same default logfile in opensesamerun and opensesame\n- srbox plugin: turn off all lights on init\n- srbox plugin: don't search (non-existent) COM0 on Windows\n- Add visual drop indicator\n\n### Bugs fixed\n\n- Refresh file pool when opening experiment from command line ([#320](https://github.com/smathot/OpenSesame/issues/320))\n- Fix unicode bugs when launching opensesame and opensesamerun from command line ([#323](https://github.com/smathot/OpenSesame/issues/323))\n- Inform experiment of response variables in form_base plugin ([#325](https://github.com/smathot/OpenSesame/issues/325))\n- Refresh variable inspector on program start\n- Clear variables and comments before parsing item-definition strings ([#324](https://github.com/smathot/OpenSesame/issues/324))\n- Fix timeout issue in (deprecated) text_input plugin\n- Fix libsrbox example docstring\n\n### Windows packaging\n\n~~~\nOpenSesame 2.9.6\nPython 2.7.8 (default, Jun 30 2014, 16:03:49) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 2.4.10\nQProgedit 2.1.0\nExpyriment  (Revision ; Python 2.7.8)\nNumPy 1.9.1\nPIL is available (version is unknown)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.5.0~opensesame3\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.3\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.5.2\nSciPy 0.14.0\n~~~\n\n[2.9.0 release notes]: /notes/2.9.0/\n": {
    "fr": "OpenSesame 2.9.6 est la sixième version de maintenance de la série 2.9. Si vous mettez à jour depuis la version 2.8.3 ou une version antérieure, veuillez également lire les [notes de version 2.9.0].\n\n## Crédits\n\nMerci à Joshua Snell ([@Klemtonius](https://github.com/Klemtonius)) et Jarik den Hartog ([@JdenHartog](https://github.com/JdenHartog)) pour leurs contributions de code.\n\n## Modifications\n\n### Améliorations\n\n- Utiliser le même fichier de journal par défaut dans opensesamerun et opensesame\n- srbox plugin : éteindre toutes les lumières à l'initialisation\n- srbox plugin : ne pas rechercher (inexistant) COM0 sur Windows\n- Ajouter un indicateur de dépôt visuel\n\n### Bugs corrigés\n\n- Actualiser le gestionnaire de fichiers lors de l'ouverture de l'expérience depuis la ligne de commande ([#320](https://github.com/smathot/OpenSesame/issues/320))\n- Corriger les bugs Unicode lors du lancement d'opensesame et d'opensesamerun depuis la ligne de commande ([#323](https://github.com/smathot/OpenSesame/issues/323))\n- Informer l'expérience des variables de réponse dans le plugin form_base ([#325](https://github.com/smathot/OpenSesame/issues/325))\n- Actualiser l'inspecteur de variables au démarrage du programme\n- Effacer les variables et les commentaires avant d'analyser les chaînes de définition d'éléments ([#324](https://github.com/smathot/OpenSesame/issues/324))\n- Corriger le problème de délai d'attente dans le plugin text_input (déprécié)\n- Corriger l'exemple de chaîne de document libsrbox\n\n### Empaquetage Windows\n\n~~~\nOpenSesame 2.9.6\nPython 2.7.8 (default, Jun 30 2014, 16:03:49) [MSC v.1500 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 2.4.10\nQProgedit 2.1.0\nExpyriment (Révision ; Python 2.7.8)\nNumPy 1.9.1\nPIL est disponible (version inconnue)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.5.0~opensesame3\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.3\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.5.2\nSciPy 0.14.0\n~~~\n\n[Notes de version 2.9.0] : /notes/2.9.0/"
  },
  "Release notes for 3.3.8": {
    "fr": "Notes de version pour 3.3.8"
  },
  "OpenSesame 2.9.0 is the first release in the 2.9 series. It offers major usability improvements over the 2.8 series. If you are upgrading from 2.8.3 or earlier, please also read the [2.8.3 release notes].\n\n## Credits\n\n- Thanks to [Nicky Anderson](https://github.com/nccanderson) for her code contributions.\n- Thanks to [Eduard Ort](https://github.com/eort) for his contributions to the documentation.\n- Thanks to [Edwin Dalmaijer](https://github.com/esdalmaijer/) for his work on [PyGaze](/devices/pygaze).\n\n## Changelog\n\n__Bugs fixed__\n\n- The radius keyword to circle sketchpad elements now specifies radius, instead of diameter\n- Allow non-latin text input (#280)\n- Clean up temporary files on Windows (#282)\n- Fix incorrect line numbers in inline_script tracebacks (#281)\n- Fix detection of uppercase keys in psycho backend (#271)\n- Fix speciying synth frequency by key (#269)\n\n__Improvements__\n\n- Redesigned sketchpad GUI\n- Added quick-open-item feature\n- Added toggle-item-maximization feature\n- Drag-and-drop improvements\n- Script and controls now simultaneously editable\n- Realtime inline_script syntax checking\n- Introduce GUI extension framework\n\n### Windows packaging\n\n- Update included libraries. See `modules()` output below.\n- Includes a snapshot of PyGaze (0.5.0~opensesame-2)\n- Includes a slightly patched version of PsychoPy 1.80.05 that addresses an important issue with keypress timestamps. (Unchanged from 2.8.2.)\n\n~~~\nOpenSesame 2.9.0\nPython 2.7.6 (default, Nov 10 2013, 19:24:18) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 2.4.9\nQProgedit 2.0.4\nExpyriment 0.7.0 (Revision 7a6b73d; Python 2.7.6)\nNumPy 1.8.1\nPIL is available (version is unknown)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.5.0~opensesame-2\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.1\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.4.1\nSciPy 0.14.0\n~~~\n\n[2.8.3 release notes]: /notes/2.8.3\n": {
    "fr": "OpenSesame 2.9.0 est la première version de la série 2.9. Elle offre des améliorations majeures en matière d'utilisabilité par rapport à la série 2.8. Si vous mettez à niveau à partir de 2.8.3 ou une version antérieure, veuillez également lire les [notes de version 2.8.3].\n\n## Remerciements\n\n- Merci à [Nicky Anderson](https://github.com/nccanderson) pour ses contributions de code.\n- Merci à [Eduard Ort](https://github.com/eort) pour ses contributions à la documentation.\n- Merci à [Edwin Dalmaijer](https://github.com/esdalmaijer/) pour son travail sur [PyGaze](/devices/pygaze).\n\n## Journal des modifications\n\n__Bugs corrigés__\n\n- Le mot-clé radius des éléments circle sketchpad spécifie maintenant le rayon, au lieu du diamètre\n- Autoriser la saisie de texte non latin (#280)\n- Nettoyer les fichiers temporaires sous Windows (#282)\n- Corriger les numéros de ligne incorrects dans les tracebacks de inline_script (#281)\n- Corriger la détection des touches majuscules dans le backend psycho (#271)\n- Corriger la spécification de la fréquence de synth par clé (#269)\n\n__Améliorations__\n\n- Interface graphique sketchpad repensée\n- Ajout de la fonctionnalité d'ouverture rapide d'éléments\n- Ajout de la fonctionnalité de basculement de la maximisation des éléments\n- Améliorations du glisser-déposer\n- Script et contrôles désormais simultanément modifiables\n- Vérification de la syntaxe inline_script en temps réel\n- Introduction du cadre d'extension de l'interface graphique\n\n### Packaging Windows\n\n- Mise à jour des bibliothèques incluses. Voir la sortie `modules()` ci-dessous.\n- Comprend un instantané de PyGaze (0.5.0~opensesame-2)\n- Comprend une version légèrement modifiée de PsychoPy 1.80.05 qui corrige un problème important concernant les horodatages de frappe. (Inchangé depuis la version 2.8.2.)\n\n~~~\nOpenSesame 2.9.0\nPython 2.7.6 (default, Nov 10 2013, 19:24:18) [MSC v.1500 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 2.4.9\nQProgedit 2.0.4\nExpyriment 0.7.0 (Révision 7a6b73d; Python 2.7.6)\nNumPy 1.8.1\nPIL est disponible (la version est inconnue)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.5.0~opensesame-2\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.1\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.4.1\nSciPy 0.14.0\n~~~\n\n[Notes de version 2.8.3]: /notes/2.8.3"
  },
  "Release notes for 3.3.11": {
    "fr": "Notes de version pour 3.3.11"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.2.7 *Kafkaesque Koffka* is the seventh maintenance release in the 3.2 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.2 series.\n\nA notable improvement in this release is a significant update to the OSWeb extension (1.3.0.1). This now allows you to embed basic JavaScript in your experiment. For more information, see:\n\n- %link:manual/osweb/workflow%\n\nIf you are upgrading from OpenSesame 3.1 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for his work on OSWeb and the Mac OS package\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.2.7\n- %-- github: { repo: \"smathot/opensesame\", issue: 635 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 643 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 650 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 651 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 652 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 655 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 656 } --%\n\npython-datamatrix:\n\n- Updated to 0.9.14\n\npython-qprogedit:\n\n- Updated to 4.1.2\n\nopensesame-extension-osweb:\n\n- Updated 1.3.0.1\n\n\n## Packages\n\n\n### Windows Python 2.7": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.2.7 *Kafkaesque Koffka* est la septième version de maintenance de la série 3.2. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sécurisée pour tous ceux qui utilisent la série 3.2.\n\nUne amélioration notable dans cette version est une mise à jour importante de l'extension OSWeb (1.3.0.1). Cela vous permet désormais d'intégrer du JavaScript de base dans votre expérience. Pour plus d'informations, consultez :\n\n- %link:manual/osweb/workflow%\n\nSi vous mettez à niveau à partir d'OpenSesame 3.1 ou d'une version antérieure, veuillez consulter la liste des modifications importantes :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour son travail sur OSWeb et le package Mac OS\n\n## Corrections de bugs et améliorations\n\nopensesame :\n\n- Mis à jour en 3.2.7\n- %-- github: { repo: \"smathot/opensesame\", issue: 635 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 643 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 650 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 651 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 652 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 655 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 656 } --%\n\npython-datamatrix:\n\n- Mis à jour en 0.9.14\n\npython-qprogedit:\n\n- Mis à jour en 4.1.2\n\nopensesame-extension-osweb:\n\n- Mis à jour en 1.3.0.1\n\n## Packages\n\n### Windows Python 2.7"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.3.6 *Lentiform Loewenfeld* is the sixth maintenance release in the 3.3 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.3 series.\n\nIf you are upgrading from OpenSesame 3.2 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for his work on the Mac OS package\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.3.6\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 730 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 731 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 733 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 735 } --%\n- [Partial fix] %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 736 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 737 } --%\n\n\nrapunzel:\n\n- Updated to 0.4.14\n- Symbol switcher now supports JavaScript\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 12 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 13 } --%\n\n\npyqode.core:\n\n- Updated to 3.0.10\n\n\npyqode.python:\n\n- Updated to 3.1.0\n- New AutoPEP8 mode\n\n\nqdatamatrix:\n\n- Updated to 0.1.29\n- %-- github: { repo: \"open-cogsci/python-qdatamatrix\", issue: 6 } --%\n- %-- github: { repo: \"open-cogsci/python-qdatamatrix\", issue: 7 } --%\n\n\nosweb:\n\n- Updated to 1.3.11\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 28 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 38 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 40 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 44 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 51 } --%\n\n\nopensesame-extension-osweb:\n\n- Updated to 1.3.11.0\n- %-- github: { repo: \"open-cogsci/opensesame-extension-osweb\", issue: 16 } --%\n- %-- github: { repo: \"open-cogsci/opensesame-extension-osweb\", issue: 25 } --%\n- %-- github: { repo: \"open-cogsci/opensesame-extension-osweb\", issue: 26 } --%\n\n\npython-qtpip:\n\n- Updated to 0.3.0\n- %-- github: { repo: \"open-cogsci/python-qtpip\", issue: 1 } --%\n- %-- github: { repo: \"open-cogsci/python-qtpip\", issue: 2 } --%\n\n\npsychopy:\n\n- Updated to 2020.2.8\n\n\n## Packages\n\n\n### Python 3.7 (standard)": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.3.6 *Lentiform Loewenfeld* est la sixième version de maintenance de la série 3.3. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.3.\n\nSi vous mettez à niveau à partir d'OpenSesame 3.2 ou d'une version antérieure, veuillez consulter la liste des modifications importantes :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour son travail sur le package Mac OS\n\n\n## Corrections de bugs et améliorations\n\nopensesame:\n\n- Mis à jour en 3.3.6\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 730 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 731 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 733 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 735 } --%\n- [Correction partielle] %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 736 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 737 } --%\n\nrapunzel:\n\n- Mis à jour en 0.4.14\n- Le sélecteur de symboles prend désormais en charge JavaScript\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 12 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 13 } --%\n\npyqode.core:\n\n- Mis à jour en 3.0.10\n\npyqode.python:\n\n- Mis à jour en 3.1.0\n- Nouveau mode AutoPEP8\n\nqdatamatrix:\n\n- Mis à jour en 0.1.29\n- %-- github: { repo: \"open-cogsci/python-qdatamatrix\", issue: 6 } --%\n- %-- github: { repo: \"open-cogsci/python-qdatamatrix\", issue: 7 } --%\n\nosweb:\n\n- Mis à jour en 1.3.11\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 28 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 38 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 40 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 44 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 51 } --%\n\nopensesame-extension-osweb:\n\n- Mis à jour en 1.3.11.0\n- %-- github: { repo: \"open-cogsci/opensesame-extension-osweb\", issue: 16 } --%\n- %-- github: { repo: \"open-cogsci/opensesame-extension-osweb\", issue: 25 } --%\n- %-- github: { repo: \"open-cogsci/opensesame-extension-osweb\", issue: 26 } --%\n\npython-qtpip:\n\n- Mis à jour en 0.3.0\n- %-- github: { repo: \"open-cogsci/python-qtpip\", issue: 1 } --%\n- %-- github: { repo: \"open-cogsci/python-qtpip\", issue: 2 } --%\n\npsychopy:\n\n- Mis à jour en 2020.2.8\n\n## Paquets\n\n### Python 3.7 (standard)"
  },
  "<notranslate>[TOC]</notranslate>\n\n## Getting the latest source code\n\nThe OpenSesame source code is hosted on GitHub:\n\n- <https://github.com/smathot/OpenSesame>.\n\nGitHub provides a straightforward way for collaborating on a project. If you're not familiar with GitHub, you may want to take a look at their help site: <http://help.github.com/>.\n\nThe best (and easiest) way to contribute code is as follows:\n\n1. Create a GitHub account.\n2. Create a fork of OpenSesame <https://github.com/smathot/OpenSesame>.\n3. Modify your fork.\n4. Send a 'pull request', asking for your changes to be merged back into the main repository.\n\nEach major version of OpenSesame has its own branch. For example, the `ising` branch contains the code for 3.0 *Interactive Ising*. The `master` branch contains the code for the latest stable release.\n\n## Developing a plugin or extension\n\nFor plugin or extension development, see:\n\n- %link:dev/plugin%\n- %link:dev/extension%\n\n## Translate the user interface\n\nFor instructions on how to translate the user interface, see:\n\n- %link:dev/translate%\n\n## Coding-style guidelines\n\nThe goal is to maintain a readable and consistent code base. Therefore, please consider the following style guidelines when contributing code:\n\n### Exception handling\n\nExceptions should be handled via the `libopensesame.exceptions.osexception` class. For example:\n\n~~~ .python\nfrom libopensesame.exceptions import osexception\nraise osexception(u'An error occurred')\n~~~\n\n### Printing debug output\n\nDebug output should be handled via `libopensesame.debug.msg()`, and is shown only when OpenSesame is started with the `--debug` command-line argument. For example:\n\n~~~ .python\nfrom libopensesame import debug\ndebug.msg(u'This will be shown only in debug mode')\n~~~\n\n### Indentation\n\nIndentation should be tab based. *This is the most important style guideline of all*, because mixed indentation causes trouble and is time consuming to correct.\n\n### Names, doc-strings, and line wrapping\n\n- Names should be lower case, with words separated by underscorses.\n- Each function should be accompanied by an informative doc string, of the format shown below. If a doc-string is redundant, for example, because a function overrides another function that has a doc-string, please indicate where the full doc-string can be found.\n- Please do not have lines of code extend beyond 79 characters (where a tab counts as 4 characters), with the exception of long strings that are awkward to break up.\n\n~~~ .python\ndef a_function(argument, keyword=None):\n\n\t\"\"\"\n\tdesc:\n\t\tThis is a YAMLDoc-style docstring, which allows for a full specification\n\t\tof arguments. See also <https://github.com/smathot/python-yamldoc>.\n\n\targuments:\n\t\targument:   This is an argument.\n\n\tkeywords:\n\t\tkeyword:    This is a keyword.\n\n\treturns:\n\t\tThis function returns some values.\n\t\"\"\"\n\n\tpass\n\ndef a_simple_function():\n\n\t\"\"\"This is a simple doc-string\"\"\"\n\n\tpass\n\n~~~\n\n### Writing Python 2 and 3 compatible code\n\nCode should be compatible with Python 2.7 and 3.4 and above. To make it easer to write Python 2 and 3 compatible code, a few tricks are included in the `py3compat` module, which should *always* be imported in your script like so:\n\n~~~ .python\nfrom libopensesame.py3compat import *\n~~~\n\nThis module:\n\n- Remaps the Python-2 `str` and `unicode` types to the (roughly) equivalent Python-3 `bytes` and `str` types. Therefore you should code with `str` objects in most cases and `bytes` object in special cases.\n- Adds the following functions:\n  - `safe_decode(s, enc='utf-8', errors='strict')` turns any object into a `str` object\n  - `safe_encode(s, enc='utf-8', errors='strict')` turns any object into a `bytes` object\n- Adds a `py3` variable, which is `True` when running on Python 3 and `False` when running on Python 2.\n- Adds a `basestr` object when running on Python 3.\n\n### Unicode and strings\n\nAssure that all functionality is Unicode safe. For new code, use *only* Unicode strings internally.": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## Obtenir le dernier code source\n\nLe code source d'OpenSesame est hébergé sur GitHub :\n\n- <https://github.com/smathot/OpenSesame>.\n\nGitHub offre un moyen simple de collaborer sur un projet. Si vous n'êtes pas familier avec GitHub, vous pouvez consulter leur site d'aide : <http://help.github.com/>.\n\nLa meilleure (et la plus simple) façon de contribuer au code est la suivante :\n\n1. Créez un compte GitHub.\n2. Créez un fork d'OpenSesame <https://github.com/smathot/OpenSesame>.\n3. Modifiez votre fork.\n4. Envoyez une \"demande de tirage\" (pull request), demandant que vos modifications soient fusionnées dans le dépôt principal.\n\nChaque version majeure d'OpenSesame a sa propre branche. Par exemple, la branche `ising` contient le code pour la version 3.0 *Interactive Ising*. La branche `master` contient le code pour la dernière version stable.\n\n## Développer un plugin ou une extension\n\nPour le développement de plugin ou d'extension, voir :\n\n- %link:dev/plugin%\n- %link:dev/extension%\n\n## Traduire l'interface utilisateur\n\nPour des instructions sur comment traduire l'interface utilisateur, voir :\n\n- %link:dev/translate%\n\n## Directives de style de codage\n\nL'objectif est de maintenir une base de code lisible et cohérente. Par conséquent, veuillez prendre en compte les directives de style suivantes lors de la contribution au code :\n\n### Gestion des exceptions\n\nLes exceptions doivent être gérées via la classe `libopensesame.exceptions.osexception`. Par exemple :\n\n~~~ .python\nfrom libopensesame.exceptions import osexception\nraise osexception(u'Une erreur est survenue')\n~~~\n\n### Affichage des informations de débogage\n\nLes informations de débogage doivent être gérées via `libopensesame.debug.msg()` et sont affichées uniquement lorsque OpenSesame est lancé avec l'argument de ligne de commande `--debug`. Par exemple :\n\n~~~ .python\nfrom libopensesame import debug\ndebug.msg(u'Ceci sera affiché uniquement en mode débogage')\n~~~\n\n### Indentation\n\nL'indentation doit être basée sur des tabulations. *C'est la directive de style la plus importante de toutes*, car une indentation mixte cause des problèmes et prend du temps à corriger.\n\n### Noms, chaînes de documentation et enroulement de ligne\n\n- Les noms doivent être en minuscules, avec des mots séparés par des traits de soulignement.\n- Chaque fonction doit être accompagnée d'une chaîne de documentation informative, selon le format indiqué ci-dessous. Si une chaîne de documentation est redondante, par exemple parce qu'une fonction remplace une autre fonction qui possède une chaîne de documentation, veuillez indiquer où se trouve la chaîne de documentation complète.\n- Veuillez ne pas avoir de lignes de code qui s'étendent au-delà de 79 caractères (où une tabulation compte pour 4 caractères), à l'exception des longues chaînes de caractères qui sont difficiles à fragmenter.\n\n~~~ .python\ndef a_function(argument, mot_cle=None):\n\n    \"\"\"\n    desc:\n        Il s'agit d'une chaîne de documentation au format YAMLDoc, qui permet une\n        spécification complète des arguments. Voir aussi <https://github.com/smathot/python-yamldoc>.\n    \n    arguments:\n        argument:   Ceci est un argument.\n    \n    mots cles:\n        mot_cle:   Ceci est un mot clé.\n    \n    renvoie:\n        Cette fonction renvoie certaines valeurs.\n    \"\"\"\n    \n    pass\n    \ndef a_simple_function():\n\n    \"\"\"Ceci est une chaîne de documentation simple\"\"\"\n\n    pass\n\n~~~\n\n### Écriture de code compatible avec Python 2 et 3\n\nLe code doit être compatible avec Python 2.7 et 3.4 et versions ultérieures. Pour faciliter l'écriture de code compatible Python 2 et 3, quelques astuces sont incluses dans le module `py3compat`, qui doit *toujours* être importé dans votre script de cette manière :\n\n~~~ .python\nfrom libopensesame.py3compat import *\n~~~\n\nCe module :\n\n- Revoie les types Python-2 `str` et `unicode` vers les types Python-3 `bytes` et `str` (approximativement équivalents). Par conséquent, vous devez utiliser des objets `str` dans la plupart des cas et des objets `bytes` dans des cas particuliers.\n- Ajoute les fonctions suivantes :\n  - `safe_decode(s, enc='utf-8', errors='strict')` transforme n'importe quel objet en un objet `str`\n  - `safe_encode(s, enc='utf-8', errors='strict')` transforme n'importe quel objet en un objet `bytes`\n- Ajoute une variable `py3`, qui est `True` lorsqu'elle est exécutée sur Python 3 et `False` lorsqu'elle est exécutée sur Python 2.\n- Ajoute un objet `basestr` lorsqu'il est exécuté sur Python 3.\n\n### Unicode et chaînes de caractères\n\nAssurez-vous que toutes les fonctionnalités sont compatibles Unicode. Pour les nouveaux codes, utilisez *uniquement* les chaînes Unicode en interne."
  },
  "~~~ .python\nmy_value = 'a string' # not preferred\nmy_value = u'a string' # preferred\n~~~\n\nFor more information, see:\n\n- <http://docs.python.org/2/howto/unicode.html>\n\n### Other\n\nWith the exception of the guidelines shown above, please adhere to the following standard:\n\n- <http://www.python.org/dev/peps/pep-0008/#a-foolish-consistency-is-the-hobgoblin-of-little-minds>\n": {
    "fr": "~~~ .python\nmy_value = 'a string' # non préféré\nmy_value = u'a string' # préféré\n~~~\n\nPour plus d'informations, voir :\n\n- <http://docs.python.org/2/howto/unicode.html>\n\n### Autre\n\nÀ l'exception des directives présentées ci-dessus, veuillez respecter la norme suivante :\n\n- <http://www.python.org/dev/peps/pep-0008/#a-foolish-consistency-is-the-hobgoblin-of-little-minds>"
  },
  "OpenSesame 2.8.3 is the third maintenance release in the 2.8 series. If you are upgrading from 0.27.4 or earlier, please also read the [2.8.0 release notes].\n\n## Credits\n\nThanks to Timo Lüke for contributing a German translation, and Vladimir Kosonogov for contributing a Russian translation.\n\n## Changelog\n\n### Improvements\n\n- Add German translation (de_DE)\n- Add Russian translation (ru_RU)\n- Remember experiment and logfile folders on Android (#259)\n- Add show_virtual_keyboard() function to keyboard backends (#254)\n\n### Bugs fixed\n\n- Fix canvas.arrow() docstring\n- canvas.text_size() respects line breaks and formatting (#262)\n- Advanced loop settings are preserved in GUI (#263)\n\n### Windows packaging\n\n- Update included libraries. See `modules()` output below.\n- Includes a slightly patched version of PsychoPy 1.80.05 that addresses an important issue with keypress timestamps. (Unchanged from 2.8.2.)\n\n~~~\nOpenSesame 2.8.3\nPython 2.7.6 (default, Nov 10 2013, 19:24:18) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 2.4.9\nQProgedit 1.3.4\nExpyriment 0.7.0 (Revision 7a6b73d; Python 2.7.6)\nNumPy 1.8.1\nPIL is available (version is unknown)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.1\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.4.1\nSciPy 0.14.0\n~~~\n\n[2.8.0 release notes]: /notes/2.8.0\n": {
    "fr": "OpenSesame 2.8.3 est la troisième version de maintenance de la série 2.8. Si vous effectuez une mise à niveau depuis la version 0.27.4 ou antérieure, veuillez également lire les [notes de version 2.8.0].\n\n## Crédits\n\nMerci à Timo Lüke pour sa contribution en traduction allemande, et à Vladimir Kosonogov pour sa contribution en traduction russe.\n\n## Journal des modifications\n\n### Améliorations\n\n- Ajout de la traduction allemande (de_DE)\n- Ajout de la traduction russe (ru_RU)\n- Mémorisation des dossiers d'expérience et de fichiers journaux sur Android (#259)\n- Ajout de la fonction show_virtual_keyboard() aux backends de clavier (#254)\n\n### Bugs corrigés\n\n- Correction de la chaîne de caractères de documentation canvas.arrow()\n- canvas.text_size() prend en compte les sauts de ligne et la mise en forme (#262)\n- Les paramètres avancés de boucle sont conservés dans l'interface graphique (#263)\n\n### Packaging Windows\n\n- Mise à jour des bibliothèques incluses. Voir la sortie de `modules()` ci-dessous.\n- Inclut une version légèrement modifiée de PsychoPy 1.80.05 qui résout un problème important avec les horodatages de pression de touches. (Inchangé depuis 2.8.2.)\n\n~~~\nOpenSesame 2.8.3\nPython 2.7.6 (par défaut, 10 nov. 2013, 19:24:18) [MSC v.1500 32 bits (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 2.4.9\nQProgedit 1.3.4\nExpyriment 0.7.0 (Révision 7a6b73d; Python 2.7.6)\nNumPy 1.8.1\nPIL est disponible (la version est inconnue)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.1\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.4.1\nSciPy 0.14.0\n~~~\n\n[Notes de version 2.8.0]: /notes/2.8.0"
  },
  "Translate": {
    "fr": "Veuillez fournir le texte à traduire."
  },
  "Release notes for 3.0.6": {
    "fr": "Notes de version pour 3.0.6"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.3.8 *Lentiform Loewenfeld* is the eight maintenance release in the 3.3 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.3 series.\n\nIf you are upgrading from OpenSesame 3.2 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for his work on the Mac OS package\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.3.8\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 750 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 748 } --%\n\nrapunzel:\n\n- Updated to 0.5.14\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 24 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 23 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 22 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 21 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 20 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 19 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 18 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 17 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 16 } --%\n\npyqode.core:\n\n- Updated to 3.2.0\n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 7 } --%\n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 5 } --%\n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 4 } --%\n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 3 } --%\n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 2 } --%\n\nosweb:\n\n- Updated to 1.3.13\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 61 } --%\n\nopensesame-extension-osweb:\n\n- Udated to 1.3.13.0\n\n\n## Packages\n\n\n### Python 3.7 (standard)": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.3.8 *Lentiform Loewenfeld* est la huitième version de maintenance de la série 3.3. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sécurisée pour tous ceux qui utilisent la série 3.3.\n\nSi vous passez d'OpenSesame 3.2 ou d'une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour son travail sur le package Mac OS\n\n## Corrections de bugs et améliorations\n\nopensesame :\n\n- Mis à jour en 3.3.8\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 750 } --%\n- %-- github: { repo: \"open-cogsci/OpenSesame\", issue: 748 } --%\n\nrapunzel :\n\n- Mis à jour en 0.5.14\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 24 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 23 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 22 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 21 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 20 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 19 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 18 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 17 } --%\n- %-- github: { repo: \"open-cogsci/rapunzel\", issue: 16 } --%\n\npyqode.core :\n\n- Mis à jour en 3.2.0\n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 7 } --%\n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 5 } --%\n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 4 } --%\n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 3 } --%\n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 2 } --%\n\nosweb :\n\n- Mis à jour en 1.3.13\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 61 } --%\n\nopensesame-extension-osweb :\n\n- Mis à jour en 1.3.13.0\n\n## Packages\n\n### Python 3.7 (standard)"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.3.11 *Lentiform Loewenfeld* is the eleventh maintenance release in the 3.3 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.3 series.\n\nIf you are upgrading from OpenSesame 3.2 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Robbert van der Mijn (%-- github: {user: robbertmijn} --%) for his work on the Mac OS package\n- Fabrice Parmentier for helping to trace down a memory leak in OSWeb\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.3.11\n\nrapunzel:\n\n- Updated to 0.5.35\n\n\npython-datamatrix:\n\n- Updated to 0.13.2\n\n\npyqode.core:\n\n- Updated to 3.2.24\n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 16 } --% \n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 15 } --% \n\n\nosweb:\n\n- Updated to 1.4.4\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 69 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 70 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 71 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 72 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 73 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 74 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 75 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 79 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 80 } --% \n\n\nopensesame-extension-osweb\n\n- Updated to 1.4.4.0\n- %-- github: { repo: \"open-cogsci/opensesame-extension-osweb\", issue: 29 } --% \n\n\npygaze:\n\n- Update to 0.7.4\n- Fix compatibility with new EyeLink SDK\n\n\n## Packages\n\n### Windows Python 3.7 (standard)": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.3.11 *Lentiform Loewenfeld* est la onzième version de maintenance de la série 3.3. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.3.\n\nSi vous passez à OpenSesame 3.2 ou à une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Robbert van der Mijn (%-- github: {user: robbertmijn} --%) pour son travail sur le package Mac OS\n- Fabrice Parmentier pour avoir aidé à trouver une fuite de mémoire dans OSWeb\n\n## Corrections de bugs et améliorations\n\nopensesame :\n\n- Mise à jour vers 3.3.11\n\nrapunzel :\n\n- Mise à jour vers 0.5.35\n\npython-datamatrix :\n\n- Mise à jour vers 0.13.2\n\npyqode.core :\n\n- Mise à jour vers 3.2.24\n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 16 } --% \n- %-- github: { repo: \"open-cogsci/pyqode.core\", issue: 15 } --% \n\nosweb :\n\n- Mise à jour vers 1.4.4\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 69 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 70 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 71 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 72 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 73 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 74 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 75 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 79 } --% \n- %-- github: { repo: \"open-cogsci/osweb\", issue: 80 } --% \n\nopensesame-extension-osweb\n\n- Mise à jour vers 1.4.4.0\n- %-- github: { repo: \"open-cogsci/opensesame-extension-osweb\", issue: 29 } --% \n\npygaze :\n\n- Mise à jour vers 0.7.4\n- Correction de la compatibilité avec le nouveau SDK EyeLink\n\n## Packages\n\n### Windows Python 3.7 (standard)"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.3.4 *Lentiform Loewenfeld* is the fourth maintenance release in the 3.3 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.3 series.\n\nIf you are upgrading from OpenSesame 3.2 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for his work on OSWeb, the Mac OS package, and bug fixes\n- Stefano Orsolini (%-- github: {user: SO_yeah} --%) for his bug fix\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.3.4\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 707 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 708 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 709 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 711 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 715 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 716 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 717 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 718 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 720 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 721 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 722 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 724 } --%\n\npyqode.core\n\n- Updated to 3.0.8\n\npyqode.python\n\n- Updated to 3.0.2\n- %-- github: { repo: \"smathot/pyqode.python\", issue: 1 } --%\n\nrapunzel\n\n- Updated to 0.4.11\n\ndatamatrix\n\n- Updated to 0.11.0\n\nqnotifications\n\n- Updated to 2.0.6\n- %-- github: { repo: \"open-cogsci/QNotifications\", issue: 14 } --%\n\nopensesame-extension-osweb\n\n- Updated to 1.3.9.0\n\nosweb\n\n- Updated to 1.3.9\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 17 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 20 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 23 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 24 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 27 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 30 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 31 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 32 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 35 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 36 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 37 } --%\n\npsychopy\n\n- Updated to 2020.2.4.post1\n\n\n## Packages\n\n\n### Python 3.7 (standard)": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n\n## À propos de cette mise à jour\n\nOpenSesame 3.3.4 *Lentiform Loewenfeld* est la quatrième version de maintenance de la série 3.3. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à jour agréable et sûre pour tous ceux qui utilisent la série 3.3.\n\nSi vous passez d'OpenSesame 3.2 ou d'une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour son travail sur OSWeb, le package Mac OS et les corrections de bugs\n- Stefano Orsolini (%-- github: {user: SO_yeah} --%) pour sa correction de bug\n\n\n## Corrections de bugs et améliorations\n\nopensesame:\n\n- Mis à jour en 3.3.4\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 707 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 708 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 709 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 711 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 715 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 716 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 717 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 718 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 720 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 721 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 722 } --%\n- %-- github: { repo: \"smathot/OpenSesame\", issue: 724 } --%\n\npyqode.core\n\n- Mis à jour en 3.0.8\n\npyqode.python\n\n- Mis à jour en 3.0.2\n- %-- github: { repo: \"smathot/pyqode.python\", issue: 1 } --%\n\nrapunzel\n\n- Mis à jour en 0.4.11\n\ndatamatrix\n\n- Mis à jour en 0.11.0\n\nqnotifications\n\n- Mis à jour en 2.0.6\n- %-- github: { repo: \"open-cogsci/QNotifications\", issue: 14 } --%\n\nopensesame-extension-osweb\n\n- Mis à jour en 1.3.9.0\n\nosweb\n\n- Mis à jour en 1.3.9\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 17 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 20 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 23 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 24 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 27 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 30 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 31 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 32 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 35 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 36 } --%\n- %-- github: { repo: \"open-cogsci/osweb\", issue: 37 } --%\n\npsychopy\n\n- Mis à jour en 2020.2.4.post1\n\n\n## Paquets\n\n\n### Python 3.7 (standard)"
  },
  "The most common way to play sound is using the SAMPLER item, for playback of audio files, or the SYNTH item, for playback of simple beeps, etc.\n\n<notranslate>[TOC]</notranslate>\n\n## The sampler\n\nThe SAMPLER plays back a single sound file, typically from the file pool.\n\nSound files are always played back at the sampling rate that is used by the OpenSesame sampler backend. If your sample appears to be sped up (high pitch) or slowed down (low pitch), you can adjust the sampling rate of your sound file in a sound editor, or change the sampling rate used by the OpenSesame sampler backend (under 'Show backend settings and info' in the General tab).\n\nThe SAMPLER has a few options:\n\n- *Sound file* indicates the file to be played.\n- *Volume* between 0 (silent) and 1 (normal volume).\n- *Pan* turns the right (negative values) or left (positive values) channel down. For full panning, enter 'left' or 'right',\n- *Pitch* indicates the playback speed, where 1 corresponds to the original speed.\n- *Stop after* indicates for how long the sound file should be played. For example, a value of 100 ms means that playback will be stopped after 100 ms, regardless of how long the sound file is. A value of 0 ms means that the sound file will be played back completely.\n- *Fade in* indicates the fade-in time for the sound file. For example, a value of 100 ms means that the sound file will start silent, and build up to maximum value in 100 ms.\n- *Duration* indicates the duration of the sampler item, before the next item is presented. This doesn't need to match the length of the sound file. For example, if the duration of the sampler is set to 0 ms, OpenSesame will advance directly to the item that follows the SAMPLER (e.g., a sketchpad), *while the sound file continues playing in the background*. In addition to a numeric value, you can set duration to:\n\t- 'keypress' to wait for a key press\n\t- 'mouseclick' to wait for a mouse click\n\t- 'sound' to wait until the sampler has finished playing.\n\n## The synth\n\nThe SYNTH is a basic sound synthesizer.\n\nYou can specify a\nnumber of options:\n\n- *Waveform* can be set to sine, sawtooth, square, or white noise\n- *Attack* is the time it takes for the sound the reach maximum volume (i.e. fade in).\n- *Decay* is the time it takes for the sound to die out (i.e. fade out). Note that the decay occurs within the length of the sound.\n- *Volume* between 0 and 100%\n- *Pan* turns the right (negative values) or left (positive values) channel down. Setting pan to -20 or 20 completely mutes the right or left channel, respectively.\n- *Length* indicates the length of the sound (in milliseconds).\n- *Duration* indicates the duration of the SYNTH item, before the next item is presented. This doesn't need to match the length of the sound. For example, the duration of the SYNTH may be set to 0ms, in order to advance directly to the next item (e.g., a SKETCHPAD), while the sound continues playing in the background. In addition to a numeric value, you can set the duration to 'keypress', to wait for a keyboard press, 'mouseclick', to wait for a mouse click, or 'sound', to wait until the SYNTH has finished playing.\n\n## Sound playback in Python\n\nYou can use the SAMPLER object and the SYNTH function to present visual stimuli in Python:\n\n- %link:sampler%\n- %link:manual/python/common%\n\n\n## Audio Low Latency plugins\n\nThe main goal of the Audio Low Latency plugins, developed by Bob Rosbag, is to play and record audio with minimal and predictable latencies to achieve a high accuracy and precision. The `PyAlsaAudio` package which uses the Linux ALSA audio system provided the best results within Python. `PortAudio` and `sounddevice` are cross-platform and work on both Windows as Linux.\n\nThe plugins are not installed by default, but can be installed through pip:\n\n```bash\npip install opensesame-plugin-audio-low-latency\n```\n\nSee also:\n\n- <https://pypi.org/project/opensesame-plugin-audio-low-latency/>\n": {
    "fr": "La méthode la plus courante pour jouer un son est d'utiliser l'élément SAMPLER, pour la lecture de fichiers audio, ou l'élément SYNTH, pour la lecture de sons simples comme des bips, etc.\n\n<notranslate>[TOC]</notranslate>\n\n## Le sampler\n\nLe SAMPLER lit un seul fichier audio, généralement à partir du bassin de fichiers.\n\nLes fichiers audio sont toujours lus à la fréquence d'échantillonnage utilisée par le backend OpenSesame sampler. Si votre échantillon semble accéléré (hauteur élevée) ou ralenti (hauteur basse), vous pouvez ajuster la fréquence d'échantillonnage de votre fichier audio dans un éditeur audio, ou modifier la fréquence d'échantillonnage utilisée par le backend OpenSesame sampler (dans \"Afficher les paramètres et informations du backend\" dans l'onglet Général).\n\nLe SAMPLER a quelques options :\n\n- *Sound file* indique le fichier à lire.\n- *Volume* entre 0 (silence) et 1 (volume normal).\n- *Pan* baisse le canal droit (valeurs négatives) ou gauche (valeurs positives). Pour une panoramique complète, entrez \"left\" ou \"right\".\n- *Pitch* indique la vitesse de lecture, 1 correspondant à la vitesse d'origine.\n- *Stop after* indique combien de temps le fichier audio doit être lu. Par exemple, une valeur de 100 ms signifie que la lecture s'arrête après 100 ms, quelle que soit la durée du fichier audio. Une valeur de 0 ms signifie que le fichier audio sera lu en entier.\n- *Fade in* indique le temps de montée du volume pour le fichier audio. Par exemple, une valeur de 100 ms signifie que le fichier audio commencera en silence et atteindra la valeur maximale en 100 ms.\n- *Duration* indique la durée de l'élément SAMPLER avant la présentation de l'élément suivant. Cela n'a pas besoin de correspondre à la longueur du fichier audio. Par exemple, si la durée du SAMPLER est définie à 0 ms, OpenSesame passera directement à l'élément suivant le SAMPLER (par exemple, un sketchpad), *tandis que le fichier audio continuera à être lu en arrière-plan*. En plus d'une valeur numérique, vous pouvez définir la durée à :\n\t- 'keypress' pour attendre un appui sur une touche\n\t- 'mouseclick' pour attendre un clic de souris\n\t- 'sound' pour attendre que le sampler ait fini de lire.\n\n## Le synth\n\nLe SYNTH est un synthétiseur de son basique.\n\nVous pouvez spécifier un certain nombre d'options :\n\n- *Waveform* peut être réglé sur sinus, dent de scie, carré ou bruit blanc\n- *Attack* est le temps nécessaire pour que le son atteigne le volume maximum (c'est-à-dire montée du volume).\n- *Decay* est le temps nécessaire pour que le son s'éteigne (c'est-à-dire baisse du volume). Notez que la diminution se produit à l'intérieur de la longueur du son.\n- *Volume* entre 0 et 100%\n- *Pan* baisse le canal droit (valeurs négatives) ou gauche (valeurs positives). Régler la panoramique à -20 ou 20 coupe complètement le canal droit ou gauche, respectivement.\n- *Length* indique la longueur du son (en millisecondes).\n- *Duration* indique la durée de l'élément SYNTH avant la présentation de l'élément suivant. Cela n'a pas besoin de correspondre à la longueur du son. Par exemple, la durée du SYNTH peut être réglée sur 0 ms, afin de passer directement à l'élément suivant (par exemple, un SKETCHPAD), pendant que le son continue à être lu en arrière-plan. En plus d'une valeur numérique, vous pouvez définir la durée sur 'keypress', pour attendre un appui sur une touche de clavier, 'mouseclick', pour attendre un clic de souris, ou 'sound', pour attendre que le SYNTH ait fini de jouer.\n\n## Lecture de sons en Python\n\nVous pouvez utiliser l'objet SAMPLER et la fonction SYNTH pour présenter des stimuli visuels en Python :\n\n- %link:sampler%\n- %link:manual/python/common%\n\n## Plugins Audio Low Latency\n\nL'objectif principal des plugins Audio Low Latency, développés par Bob Rosbag, est de jouer et d'enregistrer des sons avec des latences minimales et prévisibles pour obtenir une grande précision et une grande exactitude. Le paquet `PyAlsaAudio` qui utilise le système audio Linux ALSA a donné les meilleurs résultats dans Python. `PortAudio` et `sounddevice` sont multiplateformes et fonctionnent sur Windows et Linux.\n\nLes plugins ne sont pas installés par défaut, mais peuvent être installés via pip :\n\n```bash\npip install opensesame-plugin-audio-low-latency\n```\n\nVoir aussi :\n\n- <https://pypi.org/project/opensesame-plugin-audio-low-latency/>"
  },
  "Visual stimuli": {
    "fr": "Stimuli visuels"
  },
  "~~~ .yaml\nname: opensesame_3.2.1-py3.6-win64-1\nchannels:\n- conda-forge\n- cogsci\n- defaults\ndependencies:\n- anaconda-client=1.6.5=py_0\n- asn1crypto=0.22.0=py36_0\n- bleach=2.0.0=py36_0\n- ca-certificates=2017.11.5=0\n- certifi=2017.11.5=py36_0\n- cffi=1.11.2=py36_0\n- chardet=3.0.4=py36_0\n- clyent=1.2.2=py36_0\n- colorama=0.3.9=py36_0\n- cryptography=2.1.4=py36_0\n- decorator=4.1.2=py36_0\n- entrypoints=0.2.3=py36_1\n- freetype=2.8.1=vc14_0\n- html5lib=1.0.1=py_0\n- icu=58.2=vc14_0\n- idna=2.6=py36_1\n- ipykernel=4.7.0=py36_0\n- ipython=6.2.1=py36_1\n- ipython_genutils=0.2.0=py36_0\n- ipywidgets=7.1.0=py36_0\n- jedi=0.10.2=py36_0\n- jinja2=2.10=py36_0\n- jpeg=9b=vc14_2\n- jsonschema=2.5.1=py36_0\n- jupyter=1.0.0=py36_0\n- jupyter_client=5.2.1=py36_0\n- jupyter_console=5.2.0=py36_0\n- jupyter_core=4.4.0=py_0\n- libpng=1.6.34=vc14_0\n- libtiff=4.0.9=vc14_0\n- markdown=2.6.9=py36_0\n- markupsafe=1.0=py36_0\n- mistune=0.8.3=py_0\n- nbconvert=5.3.1=py_1\n- nbformat=4.4.0=py36_0\n- notebook=5.2.2=py36_1\n- olefile=0.44=py36_0\n- openssl=1.0.2n=vc14_0\n- pandoc=2.1=0\n- pandocfilters=1.4.1=py36_0\n- pickleshare=0.7.4=py36_0\n- pillow=5.0.0=py36_0\n- pip=9.0.1=py36_1\n- prompt_toolkit=1.0.15=py36_0\n- pycparser=2.18=py36_0\n- pygments=2.2.0=py36_0\n- pyopengl=3.1.1a1=py36_0\n- pyopenssl=17.2.0=py36_0\n- pyqt=5.6.0=py36_4\n- pyserial=3.4=py36_0\n- pysocks=1.6.8=py36_1\n- python=3.6.4=0\n- python-dateutil=2.6.1=py36_0\n- pytz=2017.3=py_2\n- pyyaml=3.12=py36_1\n- pyzmq=16.0.2=py36_3\n- qscintilla2=2.9.3=py36_2\n- qt=5.6.2=vc14_1\n- qtconsole=4.3.1=py36_0\n- qtpy=1.3.1=py36_0\n- requests=2.18.4=py36_1\n- setuptools=38.4.0=py36_0\n- simplegeneric=0.8.1=py36_0\n- sip=4.18=py36_1\n- six=1.11.0=py36_1\n- sqlite=3.20.1=vc14_2\n- testpath=0.3.1=py36_0\n- tornado=4.5.3=py36_0\n- traitlets=4.3.2=py36_0\n- urllib3=1.22=py36_0\n- vc=14=0\n- vs2015_runtime=14.0.25420=0\n- wcwidth=0.1.7=py36_0\n- webencodings=0.5=py36_0\n- wheel=0.30.0=py36_2\n- widgetsnbextension=3.1.0=py36_0\n- win_inet_pton=1.0.1=py36_1\n- wincertstore=0.2=py36_0\n- yaml=0.1.7=vc14_0\n- zlib=1.2.11=vc14_0\n- mkl=2017.0.3=0\n- numpy=1.13.1=py36_0\n- pyopengl-accelerate=3.1.1a1=np113py36_0\n- scipy=0.19.1=np113py36_0\n- pip:\n  - arrow==0.12.0\n  - et-xmlfile==1.0.1\n  - expyriment==0.9.0\n  - fastnumbers==2.0.2\n  - future==0.16.0\n  - humanize==0.5.1\n  - imageio==2.1.2\n  - ipython-genutils==0.2.0\n  - jdcal==1.3\n  - jupyter-client==5.2.1\n  - jupyter-console==5.2.0\n  - jupyter-core==4.4.0\n  - mediadecoder==0.1.5\n  - moviepy==0.2.3.2\n  - oauthlib==2.0.6\n  - openpyxl==2.4.9\n  - opensesame-extension-osf==1.1.1\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - prettytable==0.7.2\n  - prompt-toolkit==1.0.15\n  - pyaudio==0.2.11\n  - pygame==1.9.3\n  - pyparallel==0.2.2\n  - python-bidi==0.4.0\n  - python-datamatrix==0.8.1 # Updated in 3.2.1\n  - python-fileinspector==1.0.2\n  - python-opensesame==3.2.1 # Updated in 3.2.1\n  - python-pseudorandom==0.2.2\n  - python-qdatamatrix==0.1.17\n  - python-qnotifications==1.1.1\n  - python-qosf==1.2.2\n  - python-qprogedit==4.0.11\n  - python-qtpip==0.1.5\n  - qtawesome==0.4.4\n  - requests-oauthlib==0.8.0\n  - sounddevice==0.3.10\n  - tqdm==4.11.2\n  - webcolors==1.7\n  - win-inet-pton==1.0.1\n  - yolk3k==0.9\n~~~\n": {
    "fr": "~~~ .yaml\nname: opensesame_3.2.1-py3.6-win64-1\nchannels:\n- conda-forge\n- cogsci\n- defaults\ndependencies:\n- anaconda-client=1.6.5=py_0\n- asn1crypto=0.22.0=py36_0\n- bleach=2.0.0=py36_0\n- certificats_ca=2017.11.5=0\n- certifi=2017.11.5=py36_0\n- cffi=1.11.2=py36_0\n- chardet=3.0.4=py36_0\n- clyent=1.2.2=py36_0\n- colorama=0.3.9=py36_0\n- cryptography=2.1.4=py36_0\n- decorator=4.1.2=py36_0\n- entrypoints=0.2.3=py36_1\n- freetype=2.8.1=vc14_0\n- html5lib=1.0.1=py_0\n- icu=58.2=vc14_0\n- idna=2.6=py36_1\n- ipykernel=4.7.0=py36_0\n- ipython=6.2.1=py36_1\n- ipython_genutils=0.2.0=py36_0\n- ipywidgets=7.1.0=py36_0\n- jedi=0.10.2=py36_0\n- jinja2=2.10=py36_0\n- jpeg=9b=vc14_2\n- jsonschema=2.5.1=py36_0\n- jupyter=1.0.0=py36_0\n- jupyter_client=5.2.1=py36_0\n- jupyter_console=5.2.0=py36_0\n- jupyter_core=4.4.0=py_0\n- libpng=1.6.34=vc14_0\n- libtiff=4.0.9=vc14_0\n- markdown=2.6.9=py36_0\n- markupsafe=1.0=py36_0\n- mistune=0.8.3=py_0\n- nbconvert=5.3.1=py_1\n- nbformat=4.4.0=py36_0\n- notebook=5.2.2=py36_1\n- olefile=0.44=py36_0\n- openssl=1.0.2n=vc14_0\n- pandoc=2.1=0\n- pandocfilters=1.4.1=py36_0\n- pickleshare=0.7.4=py36_0\n- pillow=5.0.0=py36_0\n- pip=9.0.1=py36_1\n- prompt_toolkit=1.0.15=py36_0\n- pycparser=2.18=py36_0\n- pygments=2.2.0=py36_0\n- pyopengl=3.1.1a1=py36_0\n- pyopenssl=17.2.0=py36_0\n- pyqt=5.6.0=py36_4\n- pyserial=3.4=py36_0\n- pysocks=1.6.8=py36_1\n- python=3.6.4=0\n- python-dateutil=2.6.1=py36_0\n- pytz=2017.3=py_2\n- pyyaml=3.12=py36_1\n- pyzmq=16.0.2=py36_3\n- qscintilla2=2.9.3=py36_2\n- qt=5.6.2=vc14_1\n- qtconsole=4.3.1=py36_0\n- qtpy=1.3.1=py36_0\n- requests=2.18.4=py36_1\n- setuptools=38.4.0=py36_0\n- simplegeneric=0.8.1=py36_0\n- sip=4.18=py36_1\n- six=1.11.0=py36_1\n- sqlite=3.20.1=vc14_2\n- testpath=0.3.1=py36_0\n- tornado=4.5.3=py36_0\n- traitlets=4.3.2=py36_0\n- urllib3=1.22=py36_0\n- vc=14=0\n- vs2015_runtime=14.0.25420=0\n- wcwidth=0.1.7=py36_0\n- webencodings=0.5=py36_0\n- wheel=0.30.0=py36_2\n- widgetsnbextension=3.1.0=py36_0\n- win_inet_pton=1.0.1=py36_1\n- wincertstore=0.2=py36_0\n- yaml=0.1.7=vc14_0\n- zlib=1.2.11=vc14_0\n- mkl=2017.0.3=0\n- numpy=1.13.1=py36_0\n- pyopengl-accelerate=3.1.1a1=np113py36_0\n- scipy=0.19.1=np113py36_0\n- pip:\n  - arrow==0.12.0\n  - et-xmlfile==1.0.1\n  - expyriment==0.9.0\n  - fastnumbers==2.0.2\n  - future==0.16.0\n  - humanize==0.5.1\n  - imageio==2.1.2\n  - ipython-genutils==0.2.0\n  - jdcal==1.3\n  - jupyter-client==5.2.1\n  - jupyter-console==5.2.0\n  - jupyter-core==4.4.0\n  - mediadecoder==0.1.5\n  - moviepy==0.2.3.2\n  - oauthlib==2.0.6\n  - openpyxl==2.4.9\n  - opensesame-extension-osf==1.1.1\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - prettytable==0.7.2\n  - prompt-toolkit==1.0.15\n  - pyaudio==0.2.11\n  - pygame==1.9.3\n  - pyparallel==0.2.2\n  - python-bidi==0.4.0\n  - python-datamatrix==0.8.1 # Mis à jour dans 3.2.1\n  - python-fileinspector==1.0.2\n  - python-opensesame==3.2.1 # Mis à jour dans 3.2.1\n  - python-pseudorandom==0.2.2\n  - python-qdatamatrix==0.1.17\n  - python-qnotifications==1.1.1\n  - python-qosf==1.2.2\n  - python-qprogedit==4.0.11\n  - python-qtpip==0.1.5\n  - qtawesome==0.4.4\n  - requests-oauthlib==0.8.0\n  - sounddevice==0.3.10\n  - tqdm==4.11.2\n  - webcolors==1.7\n  - win-inet-pton==1.0.1\n  - yolk3k==0.9\n~~~"
  },
  "Release notes for 4.0.0": {
    "fr": "Notes de publication pour 4.0.0"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.1.6 *Jazzy James* is the sixth maintenance release in the 3.1 series. This release fixes a regression that was introduced in 3.1.5, which caused a crash when multiple linked SKETCHPADs occurred in the same SEQUENCE.\n\nIf you are upgrading from OpenSesame 3.0 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n\n## Bug fixes and improvements\n\nOpenSesame:\n\n- Updated to 3.1.6\n- %-- github: { repo: \"smathot/opensesame\", issue: 508 } --%\n\n\n## Packages (Windows Python 2.7 package)\n\n\n### Detailed package information\n\n~~~ .yaml\nname: opensesame_3.1.6-py2.7-win32-1\nchannels:\n- cogsci\n- defaults\ndependencies:\n- python==2.7.12\n- anaconda-client=1.4.0=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.4=py27_0\n- bzip2=1.0.6=vc9_3\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.0.3=py_0\n- psychopy=1.82.01=py27_0\n- pygame=1.9.2a0=py27_0\n- pyglet=1.2.4=py27_0\n- python-datamatrix=0.4.4=py_0 # updated in 3.1.5\n- python-fileinspector=1.0.2=py_0 # updated in 3.1.3\n- python-opensesame=3.1.6=py_0 # updated in 3.1.6\n- python-pseudorandom=0.2.2=py27_0\n- python-pygaze=0.6.0a21=py_0 # Updated in 3.1.3\n- python-qdatamatrix=0.1.13=py_0 # updated in 3.1.5\n- python-qnotifications=1.1.1=py_0 # updated in 3.1.3\n- python-qosf=1.1.8=py_0\n- python-qprogedit=4.0.9=py_0 # updated in 3.1.5\n- qscintilla2=2.9.1=py27_vc9_0\n- requests-oauthlib=0.6.1=py_0\n- webcolors=1.5=py27_0\n- configparser=3.5.0b2=py27_1\n- decorator=4.0.10=py27_0\n- entrypoints=0.2.2=py27_0\n- freetype=2.5.5=vc9_1\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- ipykernel=4.3.1=py27_0\n- ipython=4.2.0=py27_0\n- ipython_genutils=0.1.0=py27_0\n- ipywidgets=4.1.1=py27_0\n- jinja2=2.8=py27_1\n- jpeg=8d=vc9_0\n- jsonschema=2.5.1=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=4.3.0=py27_0\n- jupyter_console=4.1.1=py27_0\n- jupyter_core=4.1.0=py27_0\n- libpng=1.6.22=vc9_0\n- libtiff=4.0.6=vc9_2\n- markdown=2.6.6=py27_0\n- markupsafe=0.23=py27_2\n- mistune=0.7.2=py27_0\n- mkl=11.3.3=1\n- nbconvert=4.2.0=py27_0\n- nbformat=4.0.1=py27_0\n- notebook=4.2.1=py27_0\n- numpy=1.11.1=py27_0\n- openssl=1.0.2h=vc9_0\n- path.py=8.2.1=py27_0\n- pickleshare=0.5=py27_0\n- pillow=3.2.0=py27_1\n- pip=8.1.2=py27_0\n- pyflakes=1.2.3=py27_0\n- pygments=2.1.3=py27_0\n- pyopengl=3.1.1a1=np111py27_0\n- pyopengl-accelerate=3.1.1a1=np111py27_0\n- pyqt=4.11.4=py27_6\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.12=0\n- python-dateutil=2.5.3=py27_0\n- pytz=2016.4=py27_0\n- pyyaml=3.11=py27_4\n- pyzmq=15.2.0=py27_0\n- qt=4.8.7=vc9_8\n- qtawesome=0.3.3=py27_0\n- qtconsole=4.2.1=py27_0\n- qtpy=1.0.2=py27_0\n- requests=2.10.0=py27_0\n- scipy=0.17.1=np111py27_1\n- setuptools=23.0.0=py27_0\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.16.9=py27_2\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.4.0.2=py27_1\n- tornado=4.3=py27_1\n- traitlets=4.2.1=py27_0\n- vs2008_runtime=9.00.30729.1=2\n- wheel=0.29.0=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.8=vc9_3\n- pip:\n  - cffi==1.7.0\n  - expyriment==0.8.0 # Upgrade manually to 0.8.1.opensesame2\n  - imageio==1.5\n  - mediadecoder==0.1.5\n  - moviepy==0.2.2.11  \n  - opensesame-extension-osf==1.0.12\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-windows-launcher==0.4.1\n  - pycparser==2.14\n  - python-bidi==0.4.0\n  - sounddevice==0.3.3\n  - tqdm==4.7.6\n  - pyaudio==0.2.9 # Added in 3.1.3\n  - openpyxl==2.4.0 # Added in 3.1.3\n  - fastnumbers==1.0.0 # Added in 3.1.5\n  - prettytable==0.7.2 # Added in 3.1.5\nprefix: opensesame_3.1.6-py2.7-win32-1\n~~~\n": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.1.6 *Jazzy James* est la sixième version de maintenance de la série 3.1. Cette version corrige une régression introduite dans la version 3.1.5, qui provoquait un plantage lorsqu'il y avait plusieurs SKETCHPAD liés dans la même SÉQUENCE.\n\nSi vous passez d'OpenSesame 3.0 ou d'une version antérieure, veuillez consulter la liste des modifications importantes :\n\n- %link:important-changes-3%\n\n## Corrections de bugs et améliorations\n\nOpenSesame :\n\n- Mis à jour en version 3.1.6\n- %-- github: { repo: \"smathot/opensesame\", issue: 508 } --%\n\n## Paquets (Windows Python 2.7 package)\n\n### Information détaillée sur les paquets\n\n~~~ .yaml\nnom: opensesame_3.1.6-py2.7-win32-1\ncanaux :\n- cogsci\n- defaults\ndépendances :\n- python==2.7.12\n- anaconda-client=1.4.0=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.4=py27_0\n- bzip2=1.0.6=vc9_3\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.0.3=py_0\n- psychopy=1.82.01=py27_0\n- pygame=1.9.2a0=py27_0\n- pyglet=1.2.4=py27_0\n- python-datamatrix=0.4.4=py_0 # mise à jour en 3.1.5\n- python-fileinspector=1.0.2=py_0 # mise à jour en 3.1.3\n- python-opensesame=3.1.6=py_0 # mise à jour en 3.1.6\n- python-pseudorandom=0.2.2=py27_0\n- python-pygaze=0.6.0a21=py_0 # Mise à jour en 3.1.3\n- python-qdatamatrix=0.1.13=py_0 # mise à jour en 3.1.5\n- python-qnotifications=1.1.1=py_0 # mise à jour en 3.1.3\n- python-qosf=1.1.8=py_0\n- python-qprogedit=4.0.9=py_0 # mise à jour en 3.1.5\n- qscintilla2=2.9.1=py27_vc9_0\n- requests-oauthlib=0.6.1=py_0\n- webcolors=1.5=py27_0\n- configparser=3.5.0b2=py27_1\n- decorator=4.0.10=py27_0\n- entrypoints=0.2.2=py27_0\n- freetype=2.5.5=vc9_1\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- ipykernel=4.3.1=py27_0\n- ipython=4.2.0=py27_0\n- ipython_genutils=0.1.0=py27_0\n- ipywidgets=4.1.1=py27_0\n- jinja2=2.8=py27_1\n- jpeg=8d=vc9_0\n- jsonschema=2.5.1=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=4.3.0=py27_0\n- jupyter_console=4.1.1=py27_0\n- jupyter_core=4.1.0=py27_0\n- libpng=1.6.22=vc9_0\n- libtiff=4.0.6=vc9_2\n- markdown=2.6.6=py27_0\n- markupsafe=0.23=py27_2\n- mistune=0.7.2=py27_0\n- mkl=11.3.3=1\n- nbconvert=4.2.0=py27_0\n- nbformat=4.0.1=py27_0\n- notebook=4.2.1=py27_0\n- numpy=1.11.1=py27_0\n- openssl=1.0.2h=vc9_0\n- path.py=8.2.1=py27_0\n- pickleshare=0.5=py27_0\n- pillow=3.2.0=py27_1\n- pip=8.1.2=py27_0\n- pyflakes=1.2.3=py27_0\n- pygments=2.1.3=py27_0\n- pyopengl=3.1.1a1=np111py27_0\n- pyopengl-accelerate=3.1.1a1=np111py27_0\n- pyqt=4.11.4=py27_6\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.12=0\n- python-dateutil=2.5.3=py27_0\n- pytz=2016.4=py27_0\n- pyyaml=3.11=py27_4\n- pyzmq=15.2.0=py27_0\n- qt=4.8.7=vc9_8\n- qtawesome=0.3.3=py27_0\n- qtconsole=4.2.1=py27_0\n- qtpy=1.0.2=py27_0\n- requests=2.10.0=py27_0\n- scipy=0.17.1=np111py27_1\n- setuptools=23.0.0=py27_0\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.16.9=py27_2\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.4.0.2=py27_1\n- tornado=4.3=py27_1\n- traitlets=4.2.1=py27_0\n- vs2008_runtime=9.00.30729.1=2\n- wheel=0.29.0=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.8=vc9_3\n- pip :\n  - cffi==1.7.0\n  - expyriment==0.8.0 # Mise à jour manuelle vers 0.8.1.opensesame2\n  - imageio==1.5\n  - mediadecoder==0.1.5\n  - moviepy==0.2.2.11\n  - opensesame-extension-osf==1.0.12\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-windows-launcher==0.4.1\n  - pycparser==2.14\n  - python-bidi==0.4.0\n  - sounddevice==0.3.3\n  - tqdm==4.7.6\n  - pyaudio==0.2.9 # Ajouté dans la version 3.1.3\n  - openpyxl==2.4.0 # Ajouté dans la version 3.1.3\n  - fastnumbers==1.0.0 # Ajouté dans la version 3.1.5\n  - prettytable==0.7.2 # Ajouté dans la version 3.1.5\npréfixe: opensesame_3.1.6-py2.7-win32-1\n~~~"
  },
  "~~~ .yaml\nname: opensesame_3.2.5a9-py2.7-win32-1\nchannels:\n- cogsci\n- conda-forge\n- defaults\ndependencies:\n- anaconda-client=1.6.3=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.5=py27_0\n- bleach=1.5.0=py27_0\n- bzip2=1.0.6=vc9_3\n- certifi=2016.2.28=py27_0\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.1.2=py_0\n- qscintilla2=2.9.3=py27_vc9_0\n- requests-oauthlib=0.6.2=py_0\n- webcolors=1.5=py27_0\n- colorama=0.3.9=py27_0\n- configparser=3.5.0=py27_0\n- decorator=4.1.2=py27_0\n- entrypoints=0.2.3=py27_0\n- enum34=1.1.6=py27_0\n- freetype=2.5.5=vc9_2\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- html5lib=0.999=py27_0\n- icu=57.1=vc9_0\n- ipykernel=4.6.1=py27_0\n- ipython=5.3.0=py27_0\n- ipython_genutils=0.2.0=py27_0\n- ipywidgets=6.0.0=py27_0\n- jinja2=2.9.6=py27_0\n- jpeg=9b=vc9_0\n- jsonschema=2.6.0=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=5.1.0=py27_0\n- jupyter_console=5.2.0=py27_0\n- jupyter_core=4.3.0=py27_0\n- libpng=1.6.30=vc9_1\n- libtiff=4.0.6=vc9_3\n- markdown=2.6.9=py27_0\n- markupsafe=1.0=py27_0\n- mistune=0.7.4=py27_0\n- mkl=2017.0.3=0\n- nbconvert=5.2.1=py27_0\n- nbformat=4.4.0=py27_0\n- notebook=5.0.0=py27_0\n- numpy=1.13.1=py27_0\n- olefile=0.44=py27_0\n- openssl=1.0.2l=vc9_0\n- pandocfilters=1.4.2=py27_0\n- path.py=10.3.1=py27_0\n- pathlib2=2.3.0=py27_0\n- pickleshare=0.7.4=py27_0\n- pillow=4.2.1=py27_0\n- pip=9.0.1=py27_1\n- prompt_toolkit=1.0.15=py27_0\n- pyflakes=1.6.0=py27_0\n- pygments=2.2.0=py27_0\n- pyopengl=3.1.1a1=np113py27_0\n- pyopengl-accelerate=3.1.1a1=np113py27_0\n- pyqt=5.6.0=py27_2\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.13=1\n- python-dateutil=2.6.1=py27_0\n- pytz=2017.2=py27_0\n- pyyaml=3.12=py27_0\n- pyzmq=16.0.2=py27_0\n- qt=5.6.2=vc9_6\n- qtawesome=0.4.4=py27_0\n- qtconsole=4.3.1=py27_0\n- qtpy=1.3.1=py27_0\n- requests=2.14.2=py27_0\n- scandir=1.5=py27_0\n- scipy=0.19.1=np113py27_0\n- setuptools=36.4.0=py27_1\n- shapely=1.6.2=py27_0 # Added in 3.2.5\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.18=py27_0\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.5.0.1=py27_0\n- testpath=0.3.1=py27_0\n- tornado=4.5.2=py27_0\n- traitlets=4.3.2=py27_0\n- vc=9=0\n- vs2008_runtime=9.00.30729.5054=0\n- wcwidth=0.1.7=py27_0\n- wheel=0.29.0=py27_0\n- widgetsnbextension=3.0.2=py27_0\n- win_unicode_console=0.5=py27_0\n- wincertstore=0.2=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.11=vc9_0\n- ffmpeg=3.4.1\n- pip:\n  - arrow==0.7.0\n  - backports-abc==0.5\n  - backports.shutil-get-terminal-size==1.0.0\n  - backports.ssl-match-hostname==3.5.0.1\n  - cffi==1.11.2\n  - configobj==5.0.6\n  - et-xmlfile==1.0.1\n  - http://files.cogsci.nl/software/opensesame/pre-releases/expyriment-0.9.1b2_11_gc100ee8-py2-none-any.whl\n  - fastnumbers==2.0.2\n  - future==0.16.0\n  - humanize==0.5.1\n  - imageio==2.2.0\n  - ipython-genutils==0.2.0\n  - jdcal==1.3\n  - json-tricks==3.11.0\n  - jupyter-client==5.1.0\n  - jupyter-console==5.2.0\n  - jupyter-core==4.3.0\n  - mediadecoder==0.1.5\n  - moviepy==0.2.3.2\n  - oauthlib==1.1.2\n  - openpyxl==2.4.9\n  - opensesame-extension-osf==1.1.1\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-plugin-psychopy==0.5.0\n  - opensesame-windows-launcher==0.4.2 # Updated in 3.2.2\n  - prettytable==0.7.2\n  - prompt-toolkit==1.0.15\n  - psychopy==1.85.3\n  - pyaudio==0.2.11\n  - pycparser==2.18\n  - pygame==1.9.3\n  - pyglet==1.3.0\n  - python-bidi==0.4.0\n  - python-datamatrix==0.9.4 # Updated in 3.2.5\n  - python-fileinspector==1.0.2\n  - python-opensesame==3.2.5a9 # Updated in 3.2.5\n  - python-pseudorandom==0.2.2\n  - python-pygaze==0.6.0a25 # Updated in 3.2.2\n  - python-qdatamatrix==0.1.18\n  - python_qnotifications==2.0.1 # Updated in 3.2.5\n  - python-qosf==1.2.3 # Updated in 3.2.3\n  - python-qprogedit==4.0.11\n  - python-qtpip==0.1.5\n  - requests-oauthlib==0.6.2\n  - sounddevice==0.3.9\n  - tqdm==4.19.5\n  - webcolors==1.5\n  - win-unicode-console==0.5\n  - yolk3k==0.9\n~~~\n": {
    "fr": "~~~ .yaml\nname: opensesame_3.2.5a9-py2.7-win32-1\nchannels:\n- cogsci\n- conda-forge\n- defaults\ndependencies:\n- anaconda-client=1.6.3=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.5=py27_0\n- bleach=1.5.0=py27_0\n- bzip2=1.0.6=vc9_3\n- certifi=2016.2.28=py27_0\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.1.2=py_0\n- qscintilla2=2.9.3=py27_vc9_0\n- requests-oauthlib=0.6.2=py_0\n- webcolors=1.5=py27_0\n- colorama=0.3.9=py27_0\n- configparser=3.5.0=py27_0\n- decorator=4.1.2=py27_0\n- entrypoints=0.2.3=py27_0\n- enum34=1.1.6=py27_0\n- freetype=2.5.5=vc9_2\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- html5lib=0.999=py27_0\n- icu=57.1=vc9_0\n- ipykernel=4.6.1=py27_0\n- ipython=5.3.0=py27_0\n- ipython_genutils=0.2.0=py27_0\n- ipywidgets=6.0.0=py27_0\n- jinja2=2.9.6=py27_0\n- jpeg=9b=vc9_0\n- jsonschema=2.6.0=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=5.1.0=py27_0\n- jupyter_console=5.2.0=py27_0\n- jupyter_core=4.3.0=py27_0\n- libpng=1.6.30=vc9_1\n- libtiff=4.0.6=vc9_3\n- markdown=2.6.9=py27_0\n- markupsafe=1.0=py27_0\n- mistune=0.7.4=py27_0\n- mkl=2017.0.3=0\n- nbconvert=5.2.1=py27_0\n- nbformat=4.4.0=py27_0\n- notebook=5.0.0=py27_0\n- numpy=1.13.1=py27_0\n- olefile=0.44=py27_0\n- openssl=1.0.2l=vc9_0\n- pandocfilters=1.4.2=py27_0\n- path.py=10.3.1=py27_0\n- pathlib2=2.3.0=py27_0\n- pickleshare=0.7.4=py27_0\n- pillow=4.2.1=py27_0\n- pip=9.0.1=py27_1\n- prompt_toolkit=1.0.15=py27_0\n- pyflakes=1.6.0=py27_0\n- pygments=2.2.0=py27_0\n- pyopengl=3.1.1a1=np113py27_0\n- pyopengl-accelerate=3.1.1a1=np113py27_0\n- pyqt=5.6.0=py27_2\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.13=1\n- python-dateutil=2.6.1=py27_0\n- pytz=2017.2=py27_0\n- pyyaml=3.12=py27_0\n- pyzmq=16.0.2=py27_0\n- qt=5.6.2=vc9_6\n- qtawesome=0.4.4=py27_0\n- qtconsole=4.3.1=py27_0\n- qtpy=1.3.1=py27_0\n- requests=2.14.2=py27_0\n- scandir=1.5=py27_0\n- scipy=0.19.1=np113py27_0\n- setuptools=36.4.0=py27_1\n- shapely=1.6.2=py27_0 # Ajouté dans 3.2.5\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.18=py27_0\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.5.0.1=py27_0\n- testpath=0.3.1=py27_0\n- tornado=4.5.2=py27_0\n- traitlets=4.3.2=py27_0\n- vc=9=0\n- vs2008_runtime=9.00.30729.5054=0\n- wcwidth=0.1.7=py27_0\n- wheel=0.29.0=py27_0\n- widgetsnbextension=3.0.2=py27_0\n- win_unicode_console=0.5=py27_0\n- wincertstore=0.2=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.11=vc9_0\n- ffmpeg=3.4.1\n- pip:\n  - arrow==0.7.0\n  - backports-abc==0.5\n  - backports.shutil-get-terminal-size==1.0.0\n  - backports.ssl-match-hostname==3.5.0.1\n  - cffi==1.11.2\n  - configobj==5.0.6\n  - et-xmlfile==1.0.1\n  - http://files.cogsci.nl/software/opensesame/pre-releases/expyriment-0.9.1b2_11_gc100ee8-py2-none-any.whl\n  - fastnumbers==2.0.2\n  - future==0.16.0\n  - humanize==0.5.1\n  - imageio==2.2.0\n  - ipython-genutils==0.2.0\n  - jdcal==1.3\n  - json-tricks==3.11.0\n  - jupyter-client==5.1.0\n  - jupyter-console==5.2.0\n  - jupyter-core==4.3.0\n  - mediadecoder==0.1.5\n  - moviepy==0.2.3.2\n  - oauthlib==1.1.2\n  - openpyxl==2.4.9\n  - opensesame-extension-osf==1.1.1\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-plugin-psychopy==0.5.0\n  - opensesame-windows-launcher==0.4.2 # Mis à jour dans 3.2.2\n  - prettytable==0.7.2\n  - prompt-toolkit==1.0.15\n  - psychopy==1.85.3\n  - pyaudio==0.2.11\n  - pycparser==2.18\n  - pygame==1.9.3\n  - pyglet==1.3.0\n  - python-bidi==0.4.0\n  - python-datamatrix==0.9.4 # Mis à jour dans 3.2.5\n  - python-fileinspector==1.0.2\n  - python-opensesame==3.2.5a9 # Mis à jour dans 3.2.5\n  - python-pseudorandom==0.2.2\n  - python-pygaze==0.6.0a25 # Mis à jour dans 3.2.2\n  - python-qdatamatrix==0.1.18\n  - python_qnotifications==2.0.1 # Mis à jour dans 3.2.5\n  - python-qosf==1.2.3 # Mis à jour dans 3.2.3\n  - python-qprogedit==4.0.11\n  - python-qtpip==0.1.5\n  - requests-oauthlib==0.6.2\n  - sounddevice==0.3.9\n  - tqdm==4.19.5\n  - webcolors==1.5\n  - win-unicode-console==0.5\n  - yolk3k==0.9\n~~~"
  },
  "~~~ .yaml\nname: opensesame_3.2.8-py2.7-win32-1\nchannels:\n- cogsci\n- conda-forge\n- defaults\ndependencies:\n- anaconda-client=1.6.3=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.5=py27_0\n- bleach=1.5.0=py27_0\n- bzip2=1.0.6=vc9_3\n- certifi=2016.2.28=py27_0\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.1.2=py_0\n- qscintilla2=2.9.3=py27_vc9_0\n- requests-oauthlib=0.6.2=py_0\n- webcolors=1.5=py27_0\n- colorama=0.3.9=py27_0\n- configparser=3.5.0=py27_0\n- decorator=4.1.2=py27_0\n- entrypoints=0.2.3=py27_0\n- enum34=1.1.6=py27_0\n- freetype=2.5.5=vc9_2\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- html5lib=0.999=py27_0\n- icu=57.1=vc9_0\n- ipykernel=4.6.1=py27_0\n- ipython=5.3.0=py27_0\n- ipython_genutils=0.2.0=py27_0\n- ipywidgets=6.0.0=py27_0\n- jinja2=2.9.6=py27_0\n- jpeg=9b=vc9_0\n- jsonschema=2.6.0=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=5.1.0=py27_0\n- jupyter_console=5.2.0=py27_0\n- jupyter_core=4.3.0=py27_0\n- libpng=1.6.30=vc9_1\n- libtiff=4.0.6=vc9_3\n- markdown=2.6.9=py27_0\n- markupsafe=1.0=py27_0\n- mistune=0.7.4=py27_0\n- mkl=2017.0.3=0\n- nbconvert=5.2.1=py27_0\n- nbformat=4.4.0=py27_0\n- notebook=5.0.0=py27_0\n- numpy=1.13.1=py27_0\n- olefile=0.44=py27_0\n- openssl=1.0.2l=vc9_0\n- pandocfilters=1.4.2=py27_0\n- path.py=10.3.1=py27_0\n- pathlib2=2.3.0=py27_0\n- pickleshare=0.7.4=py27_0\n- pillow=4.2.1=py27_0\n- pip=9.0.1=py27_1\n- prompt_toolkit=1.0.15=py27_0\n- pyflakes=1.6.0=py27_0\n- pygments=2.2.0=py27_0\n- pyopengl=3.1.1a1=np113py27_0\n- pyopengl-accelerate=3.1.1a1=np113py27_0\n- pyqt=5.6.0=py27_2\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.13=1\n- python-dateutil=2.6.1=py27_0\n- pytz=2017.2=py27_0\n- pyyaml=3.12=py27_0\n- pyzmq=16.0.2=py27_0\n- qt=5.6.2=vc9_6\n- qtawesome=0.5.7 # Updated in 3.2.8\n- qtconsole=4.3.1=py27_0\n- qtpy=1.3.1=py27_0\n- requests=2.14.2=py27_0\n- scandir=1.5=py27_0\n- scipy=0.19.1=np113py27_0\n- setuptools=36.4.0=py27_1\n- shapely=1.6.2=py27_0 # Added in 3.2.5\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.18=py27_0\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.5.0.1=py27_0\n- testpath=0.3.1=py27_0\n- tornado=4.5.2=py27_0\n- traitlets=4.3.2=py27_0\n- vc=9=0\n- vs2008_runtime=9.00.30729.5054=0\n- wcwidth=0.1.7=py27_0\n- wheel=0.29.0=py27_0\n- widgetsnbextension=3.0.2=py27_0\n- win_unicode_console=0.5=py27_0\n- wincertstore=0.2=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.11=vc9_0\n- ffmpeg=3.4.1\n- pip:\n  - arrow==0.7.0\n  - backports-abc==0.5\n  - backports.shutil-get-terminal-size==1.0.0\n  - backports.ssl-match-hostname==3.5.0.1\n  - cffi==1.11.2\n  - configobj==5.0.6\n  - et-xmlfile==1.0.1\n  - expyriment-0.9.1b2_11_gc100ee8-py2-none-any.whl\n  - fastnumbers==2.0.2\n  - future==0.16.0\n  - humanize==0.5.1\n  - imageio==2.2.0\n  - ipython-genutils==0.2.0\n  - jdcal==1.3\n  - json-tricks==3.11.0\n  - jupyter-client==5.1.0\n  - jupyter-console==5.2.0\n  - jupyter-core==4.3.0\n  - mediadecoder==0.1.5\n  - moviepy==0.2.3.2\n  - oauthlib==1.1.2\n  - openpyxl==2.4.9\n  - opensesame-extension-osf==1.2.0 # Updated in 3.2.8\n  - opensesame_extension_osweb==1.3.3.0 # Updated in 3.2.8\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-plugin-psychopy==0.5.0\n  - opensesame-windows-launcher==0.4.2 # Updated in 3.2.2\n  - prettytable==0.7.2\n  - prompt-toolkit==1.0.15\n  - psychopy==1.85.3\n  - pyaudio==0.2.11\n  - pycparser==2.18\n  - pygame==1.9.3\n  - pyglet==1.3.0\n  - python-bidi==0.4.0\n  - python-datamatrix==0.9.14 # Updated in 3.2.7\n  - python-fileinspector==1.0.2\n  - python-opensesame==3.2.8 # Updated in 3.2.8\n  - python-pseudorandom==0.2.2\n  - python-pygaze==0.6.0a25 # Updated in 3.2.2\n  - python-qdatamatrix==0.1.18\n  - python-qnotifications==2.0.3 # Updated in 3.2.6\n  - python-qosf==1.3.0 # Updated in 3.2.8\n  - python-qprogedit==4.1.0 # Updated in 3.2.7\n  - python-qtpip==0.2.0 # Updated in 3.2.6\n  - js2py==0.60 # New in 3.2.7\n  - requests-oauthlib==0.6.2\n  - sounddevice==0.3.9\n  - tqdm==4.19.5\n  - webcolors==1.5\n  - win-unicode-console==0.5\n  - yolk3k==0.9\n~~~\n": {
    "fr": "~~~ .yaml\nname: opensesame_3.2.8-py2.7-win32-1\nchannels:\n- cogsci\n- conda-forge\n- defaults\ndependencies:\n- anaconda-client=1.6.3=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.5=py27_0\n- bleach=1.5.0=py27_0\n- bzip2=1.0.6=vc9_3\n- certifi=2016.2.28=py27_0\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.1.2=py_0\n- qscintilla2=2.9.3=py27_vc9_0\n- requests-oauthlib=0.6.2=py_0\n- webcolors=1.5=py27_0\n- colorama=0.3.9=py27_0\n- configparser=3.5.0=py27_0\n- decorator=4.1.2=py27_0\n- entrypoints=0.2.3=py27_0\n- enum34=1.1.6=py27_0\n- freetype=2.5.5=vc9_2\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- html5lib=0.999=py27_0\n- icu=57.1=vc9_0\n- ipykernel=4.6.1=py27_0\n- ipython=5.3.0=py27_0\n- ipython_genutils=0.2.0=py27_0\n- ipywidgets=6.0.0=py27_0\n- jinja2=2.9.6=py27_0\n- jpeg=9b=vc9_0\n- jsonschema=2.6.0=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=5.1.0=py27_0\n- jupyter_console=5.2.0=py27_0\n- jupyter_core=4.3.0=py27_0\n- libpng=1.6.30=vc9_1\n- libtiff=4.0.6=vc9_3\n- markdown=2.6.9=py27_0\n- markupsafe=1.0=py27_0\n- mistune=0.7.4=py27_0\n- mkl=2017.0.3=0\n- nbconvert=5.2.1=py27_0\n- nbformat=4.4.0=py27_0\n- notebook=5.0.0=py27_0\n- numpy=1.13.1=py27_0\n- olefile=0.44=py27_0\n- openssl=1.0.2l=vc9_0\n- pandocfilters=1.4.2=py27_0\n- path.py=10.3.1=py27_0\n- pathlib2=2.3.0=py27_0\n- pickleshare=0.7.4=py27_0\n- pillow=4.2.1=py27_0\n- pip=9.0.1=py27_1\n- prompt_toolkit=1.0.15=py27_0\n- pyflakes=1.6.0=py27_0\n- pygments=2.2.0=py27_0\n- pyopengl=3.1.1a1=np113py27_0\n- pyopengl-accelerate=3.1.1a1=np113py27_0\n- pyqt=5.6.0=py27_2\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.13=1\n- python-dateutil=2.6.1=py27_0\n- pytz=2017.2=py27_0\n- pyyaml=3.12=py27_0\n- pyzmq=16.0.2=py27_0\n- qt=5.6.2=vc9_6\n- qtawesome=0.5.7 # Mis à jour dans 3.2.8\n- qtconsole=4.3.1=py27_0\n- qtpy=1.3.1=py27_0\n- requests=2.14.2=py27_0\n- scandir=1.5=py27_0\n- scipy=0.19.1=np113py27_0\n- setuptools=36.4.0=py27_1\n- shapely=1.6.2=py27_0 # Ajouté dans 3.2.5\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.18=py27_0\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.5.0.1=py27_0\n- testpath=0.3.1=py27_0\n- tornado=4.5.2=py27_0\n- traitlets=4.3.2=py27_0\n- vc=9=0\n- vs2008_runtime=9.00.30729.5054=0\n- wcwidth=0.1.7=py27_0\n- wheel=0.29.0=py27_0\n- widgetsnbextension=3.0.2=py27_0\n- win_unicode_console=0.5=py27_0\n- wincertstore=0.2=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.11=vc9_0\n- ffmpeg=3.4.1\n- pip:\n  - arrow==0.7.0\n  - backports-abc==0.5\n  - backports.shutil-get-terminal-size==1.0.0\n  - backports.ssl-match-hostname==3.5.0.1\n  - cffi==1.11.2\n  - configobj==5.0.6\n  - et-xmlfile==1.0.1\n  - expyriment-0.9.1b2_11_gc100ee8-py2-none-any.whl\n  - fastnumbers==2.0.2\n  - future==0.16.0\n  - humanize==0.5.1\n  - imageio==2.2.0\n  - ipython-genutils==0.2.0\n  - jdcal==1.3\n  - json-tricks==3.11.0\n  - jupyter-client==5.1.0\n- jupyter-console==5.2.0\n- jupyter-core==4.3.0\n- mediadecoder==0.1.5\n- moviepy==0.2.3.2\n- oauthlib==1.1.2\n- openpyxl==2.4.9\n- opensesame-extension-osf==1.2.0 # Mis à jour dans 3.2.8\n- opensesame_extension_osweb==1.3.3.0 # Mis à jour dans 3.2.8\n- opensesame-plugin-media-player-mpy==0.1.6\n- opensesame-plugin-psychopy==0.5.0\n- opensesame-windows-launcher==0.4.2 # Mis à jour dans 3.2.2\n- prettytable==0.7.2\n- prompt-toolkit==1.0.15\n- psychopy==1.85.3\n- pyaudio==0.2.11\n- pycparser==2.18\n- pygame==1.9.3\n- pyglet==1.3.0\n- python-bidi==0.4.0\n- python-datamatrix==0.9.14 # Mis à jour dans 3.2.7\n- python-fileinspector==1.0.2\n- python-opensesame==3.2.8 # Mis à jour dans 3.2.8\n- python-pseudorandom==0.2.2\n- python-pygaze==0.6.0a25 # Mis à jour dans 3.2.2\n- python-qdatamatrix==0.1.18\n- python-qnotifications==2.0.3 # Mis à jour dans 3.2.6\n- python-qosf==1.3.0 # Mis à jour dans 3.2.8\n- python-qprogedit==4.1.0 # Mis à jour dans 3.2.7\n- python-qtpip==0.2.0 # Mis à jour dans 3.2.6\n- js2py==0.60 # Nouveau dans 3.2.7\n- requests-oauthlib==0.6.2\n- sounddevice==0.3.9\n- tqdm==4.19.5\n- webcolors==1.5\n- win-unicode-console==0.5\n- yolk3k==0.9\n~~~"
  },
  "Release notes for 3.2.4": {
    "fr": "Notes de publication pour la version 3.2.4",
    "de": "Veröffentlichungsnotizen für 3.2.4"
  },
  "\nIf you want to provide a translation, it's recommended to first send an inquiry to <s.mathot@cogsci.nl> or post a message on the [forum](https://forum.cogsci.nl/) to make sure that your language is not already being worked on.\n\nVery little technical skill is needed to contribute a translation!\n\n<notranslate>[TOC]</notranslate>\n\n\n## Starting OpenSesame with a specific language\n\nBy default, OpenSesame uses the default locale of your operating system if a translation is available, and falls back to English if a translation is not available. To start OpenSesame with a specific language, you can open change the Language option under Menu → Tools → Preferences.\n\n\n## How to translate\n\n\n### Translating Markdown tabs\n\n\n#### How to translate Markdown tabs\n\nMarkdown tabs are the website-like tabs that present text and basic options. An example of a Markdown tab is the Get Started tab that you see when you launch OpenSesame.\n\nTo translate a Markdown tab, first locate the untranslated (English) `.md` file. In the case of the Get Started tab, this is:\n\n- `opensesame_extensions\\get_started\\get_started.md`\n\nNext, copy this original file to `[original folder]\\locale\\[your locale code]\\get_started.md`. So, if you're working on a French (`fr_FR`) translation, you would copy the original `get_started.md` to (creating subfolders if they don't exist yet):\n\t\n- `opensesame_extensions\\get_started\\locale\\fr_FR\\get_started.md`\n\nFinally, simply open the to-be-translated `get_started.md` in a text editor, and translate it.\n\n\n#### A list of Markdown tabs that need to be translated\n\nIn the [OpenSesame source code](https://github.com/smathot/opensesame):\n\n- `opensesame_extensions/update_checker/failed.md`\n- `opensesame_extensions/update_checker/update-available.md`\n- `opensesame_extensions/update_checker/up-to-date.md`\n- `opensesame_extensions/toolbar_menu/system-information.md`\n- `opensesame_extensions/help/offline_help.md`\n- `opensesame_extensions/bug_report/failure.md`\n- `opensesame_extensions/bug_report/report.md`\n- `opensesame_extensions/bug_report/success.md`\n- `opensesame_extensions/after_experiment/finished.md`\n- `opensesame_extensions/system_information/system-information.md`\n- `opensesame_extensions/get_started/get_started.md`\n- `opensesame_extensions/opensesame_3_notifications/new-user.md`\n- `opensesame_extensions/opensesame_3_notifications/old-experiment.md`\n- `opensesame_extensions/opensesame_3_notifications/new-experiment.md`\n- `opensesame_plugins/notepad/notepad.md`\n- `opensesame_plugins/port_reader/port_reader.md`\n- `opensesame_plugins/repeat_cycle/repeat_cycle.md`\n- `opensesame_plugins/quest_staircase_init/quest_staircase_init.md`\n- `opensesame_plugins/parallel/parallel.md`\n- `opensesame_plugins/advanced_delay/advanced_delay.md`\n- `opensesame_plugins/joystick/joystick.md`\n- `opensesame_plugins/reset_feedback/reset_feedback.md`\n- `opensesame_plugins/fixation_dot/fixation_dot.md`\n- `opensesame_plugins/touch_response/touch_response.md`\n- `opensesame_plugins/external_script/external_script.md`\n- `opensesame_plugins/quest_staircase_next/quest_staircase_next.md`\n- `opensesame_plugins/video_player/video_player.md`\n- `opensesame_resources/help/missing.md`\n- `opensesame_resources/help/new_item_warning.md`\n\nIn the [Rapunzel source code](https://github.com/smathot/rapunzel):\n\n- `opensesame_extensions/RapunzelWelcome/rapunzel_welcome.md`\n\n\n### Translating the source code and user interface\n\n\n#### Step 1: Download translatables.ts\n\nIf you are starting a translation from scratch, then you start from `translatables.ts`, which contains all the strings that are to be translated. OpenSesame and Rapunzel each have their own version of this file, both of which need to be translated.\n\nIn the [OpenSesame source code](https://github.com/smathot/OpenSesame/), this file can be found at:\n\n- `opensesame_resources/ts/translatables.ts`\n\nIn the [Rapunzel source code](https://github.com/smathot/rapunzel/), this file can be found at:": {
    "fr": "Si vous souhaitez proposer une traduction, il est recommandé d'envoyer d'abord une demande à <s.mathot@cogsci.nl> ou de poster un message sur le [forum](https://forum.cogsci.nl/) pour vous assurer que votre langue n'est pas déjà en cours de traduction.\n\nTrès peu de compétences techniques sont nécessaires pour contribuer à une traduction !\n\n<notranslate>[TOC]</notranslate>\n\n\n## Démarrer OpenSesame avec une langue spécifique\n\nPar défaut, OpenSesame utilise la langue par défaut de votre système d'exploitation si une traduction est disponible, et revient à l'anglais si une traduction n'est pas disponible. Pour démarrer OpenSesame avec une langue spécifique, vous pouvez modifier l'option Langue dans Menu → Outils → Préférences.\n\n\n## Comment traduire\n\n\n### Traduire les onglets Markdown\n\n\n#### Comment traduire les onglets Markdown\n\nLes onglets Markdown sont les onglets de type site web qui présentent du texte et des options de base. Un exemple d'onglet Markdown est l'onglet Démarrer que vous voyez lorsque vous lancez OpenSesame.\n\nPour traduire un onglet Markdown, localisez d'abord le fichier `.md` non traduit (anglais). Dans le cas de l'onglet Démarrer, il s'agit de :\n\n- `opensesame_extensions\\get_started\\get_started.md`\n\nEnsuite, copiez ce fichier original vers `[dossier original]\\locale\\[votre code de langue]\\get_started.md`. Ainsi, si vous travaillez sur une traduction française (`fr_FR`), vous copieriez le fichier `get_started.md` original vers (en créant des sous-dossiers s'ils n'existent pas encore) :\n\n- `opensesame_extensions\\get_started\\locale\\fr_FR\\get_started.md`\n\nEnfin, ouvrez simplement le fichier `get_started.md` à traduire dans un éditeur de texte et traduisez-le.\n\n\n#### Liste des onglets Markdown à traduire\n\nDans le [code source d'OpenSesame](https://github.com/smathot/opensesame) :\n\n- `opensesame_extensions/update_checker/failed.md`\n- `opensesame_extensions/update_checker/update-available.md`\n- `opensesame_extensions/update_checker/up-to-date.md`\n- `opensesame_extensions/toolbar_menu/system-information.md`\n- `opensesame_extensions/help/offline_help.md`\n- `opensesame_extensions/bug_report/failure.md`\n- `opensesame_extensions/bug_report/report.md`\n- `opensesame_extensions/bug_report/success.md`\n- `opensesame_extensions/after_experiment/finished.md`\n- `opensesame_extensions/system_information/system-information.md`\n- `opensesame_extensions/get_started/get_started.md`\n- `opensesame_extensions/opensesame_3_notifications/new-user.md`\n- `opensesame_extensions/opensesame_3_notifications/old-experiment.md`\n- `opensesame_extensions/opensesame_3_notifications/new-experiment.md`\n- `opensesame_plugins/notepad/notepad.md`\n- `opensesame_plugins/port_reader/port_reader.md`\n- `opensesame_plugins/repeat_cycle/repeat_cycle.md`\n- `opensesame_plugins/quest_staircase_init/quest_staircase_init.md`\n- `opensesame_plugins/parallel/parallel.md`\n- `opensesame_plugins/advanced_delay/advanced_delay.md`\n- `opensesame_plugins/joystick/joystick.md`\n- `opensesame_plugins/reset_feedback/reset_feedback.md`\n- `opensesame_plugins/fixation_dot/fixation_dot.md`\n- `opensesame_plugins/touch_response/touch_response.md`\n- `opensesame_plugins/external_script/external_script.md`\n- `opensesame_plugins/quest_staircase_next/quest_staircase_next.md`\n- `opensesame_plugins/video_player/video_player.md`\n- `opensesame_resources/help/missing.md`\n- `opensesame_resources/help/new_item_warning.md`\n\nDans le [code source de Rapunzel](https://github.com/smathot/rapunzel) :\n\n- `opensesame_extensions/RapunzelWelcome/rapunzel_welcome.md`\n\n\n### Traduire le code source et l'interface utilisateur\n\n\n#### Étape 1 : Télécharger translatables.ts\n\nSi vous commencez une traduction à partir de zéro, vous commencez par `translatables.ts`, qui contient toutes les chaînes de caractères à traduire. OpenSesame et Rapunzel ont chacun leur propre version de ce fichier, qui doivent toutes deux être traduites.\n\nDans le [code source d'OpenSesame](https://github.com/smathot/OpenSesame/), ce fichier se trouve à :\n\n- `opensesame_resources/ts/translatables.ts`\n\nDans le [code source de Rapunzel](https://github.com/smathot/rapunzel/), ce fichier se trouve à :"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.2.4 *Kafkaesque Koffka* is the fourth maintenance release in the 3.2 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.2 series.\n\nIf you are upgrading from OpenSesame 3.1 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for his work on the Mac OS package\n- Wolfgang Walther (%-- github: {user: wolfgangwalther} --%) for his code contributions\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.2.4\n- %-- github: { repo: \"smathot/opensesame\", issue: 610 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 615 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 616 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 617 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 613 } --%\n\n\npython-qosf:\n\n- Updated to 1.2.3\n\n\n## Packages\n\n\n### Windows Python 2.7": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.2.4 *Kafkaesque Koffka* est la quatrième version de maintenance de la série 3.2. Elle contient des corrections de bogues et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.2.\n\nSi vous mettez à niveau à partir d'OpenSesame 3.1 ou d'une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour son travail sur le package Mac OS\n- Wolfgang Walther (%-- github: {user: wolfgangwalther} --%) pour ses contributions au code\n\n\n## Corrections de bogues et améliorations\n\nopensesame :\n\n- Mis à jour vers 3.2.4\n- %-- github: { repo: \"smathot/opensesame\", issue: 610 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 615 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 616 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 617 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 613 } --%\n\n\npython-qosf :\n\n- Mis à jour vers 1.2.3\n\n\n## Paquets\n\n\n### Windows Python 2.7"
  },
  "The most common way to present visual stimuli is using the SKETCHPAD item, or, for non-time-critical stimuli, the FEEDBACK item.\n\n\n<notranslate>[TOC]</notranslate>\n\n\n## Using the sketchpad and feedback items\n\nThe SKETCHPAD and FEEDBACK item offer basic what-you-see-is-what-you get drawing tools (%FigSketchpad).\n\n<notranslate>\nfigure:\n id: FigSketchpad\n source: sketchpad.png\n caption: The SKETCHPAD provides built-in drawing tools.\n</notranslate>\n\n\n## The difference between sketchpad and feedback items\n\nThe SKETCHPAD and FEEDBACK items are identical in most ways, except for two important differences.\n\n\n### Sketchpad items are prepared in advance, feedback items are not\n\nThe contents of a SKETCHPAD are prepared during the prepare phase of the SEQUENCE that it is part of. This is necessary to ensure accurate timing: It allows the SKETCHPAD to be shown right away during the run phase, without any delays due to stimulus preparation. However, the downside of this is that the contents of a SKETCHPAD cannot depend on what happens during the SEQUENCE that it is part of. For example, you cannot use a SKETCHPAD to provide immediate feedback on the response time collected by a KEYBOARD_RESPONSE item (assuming that the SKETCHPAD and KEYBOARD_RESPONSE are part of the same sequence.)\n\nIn contrast, the contents of a FEEDBACK item are only prepared when they are actually shown, that is, during the run phase of the SEQUENCE that it is part of. This makes it possible to provide feedback on things that just happened--hence the name. However, the FEEDBACK item should not be used to present time-critical stimuli, because it suffers from delays due to stimulus preparation.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Feedback variables are (by default) reset by feedback items\n\nThe FEEDBACK item has an option 'Reset feedback variables'. When this option is enabled (it is by default), feedback variables are reset when the FEEDBACK item is shown.\n\nFor more information about feedback variables, see:\n\n- %link:manual/variables%\n\n\n## Presenting visual stimuli in Python inline script\n\n### Accessing a SKETCHPAD in Python\n\nYou can access the `Canvas` object for a SKETCHPAD as the items `canvas` property. For example, say that your SKETCHPAD is called *my_sketchpad*, and contains an image elements with the name 'my_image'. You could then have this image rotate with the following script:\n\n~~~ .python\nmy_canvas = items['my_sketchpad'].canvas\nfor angle in range(360):\n\tmy_canvas['my_image'].rotation = angle\n\tmy_canvas.show()\n~~~\n\n\n### Creating a Canvas in Python\n\nYou can use the `Canvas` object to present visual stimuli in Python:\n\n- %link:manual/python/canvas%\n": {
    "fr": "La façon la plus courante de présenter des stimuli visuels est d'utiliser l'élément SKETCHPAD, ou, pour les stimuli non critiques en termes de temps, l'élément FEEDBACK.\n\n<notranslate>[TOC]</notranslate>\n\n## Utilisation des éléments sketchpad et feedback\n\nLes éléments SKETCHPAD et FEEDBACK offrent des outils de dessin basiques de type \"ce que vous voyez est ce que vous obtenez\" (%FigSketchpad).\n\n<notranslate>\nfigure :\n id: FigSketchpad\n source: sketchpad.png\n caption: Le SKETCHPAD fournit des outils de dessin intégrés.\n</notranslate>\n\n## La différence entre les éléments sketchpad et feedback\n\nLes éléments SKETCHPAD et FEEDBACK sont identiques à bien des égards, à l'exception de deux différences importantes.\n\n### Les éléments Sketchpad sont préparés à l'avance, les éléments feedback ne le sont pas\n\nLe contenu d'un SKETCHPAD est préparé pendant la phase de préparation de la SEQUENCE à laquelle il appartient. Cela est nécessaire pour garantir un timing précis : il permet au SKETCHPAD d'être affiché immédiatement pendant la phase d'exécution, sans aucun retard dû à la préparation du stimulus. Cependant, l'inconvénient de cela est que le contenu d'un SKETCHPAD ne peut pas dépendre de ce qui se passe pendant la SEQUENCE à laquelle il appartient. Par exemple, vous ne pouvez pas utiliser un SKETCHPAD pour fournir un retour immédiat sur le temps de réponse collecté par un élément KEYBOARD_RESPONSE (en supposant que le SKETCHPAD et le KEYBOARD_RESPONSE font partie de la même séquence).\n\nEn revanche, le contenu d'un élément FEEDBACK n'est préparé que lorsqu'il est effectivement affiché, c'est-à-dire pendant la phase d'exécution de la SEQUENCE à laquelle il appartient. Cela permet de fournir un retour d'information sur les événements qui viennent de se produire - d'où le nom. Cependant, l'élément FEEDBACK ne doit pas être utilisé pour présenter des stimuli critiques en termes de temps, car il souffre de retards dus à la préparation du stimulus.\n\nPour plus d'informations sur la stratégie de préparation-exécution, voir :\n\n- %link:prepare-run%\n\n### Les variables de retour d'information sont (par défaut) réinitialisées par les éléments feedback\n\nL'élément FEEDBACK a une option \"Réinitialiser les variables de feedback\". Lorsque cette option est activée (elle l'est par défaut), les variables de feedback sont réinitialisées lorsque l'élément FEEDBACK est affiché.\n\nPour plus d'informations sur les variables de feedback, voir :\n\n- %link:manual/variables%\n\n## Présenter des stimuli visuels dans un script Python en ligne\n\n### Accéder à un SKETCHPAD en Python\n\nVous pouvez accéder à l'objet `Canvas` pour un SKETCHPAD en tant que propriété `canvas` de l'élément. Par exemple, disons que votre SKETCHPAD s'appelle *my_sketchpad* et contient un élément image nommé 'my_image'. Vous pourriez alors faire pivoter cette image avec le script suivant :\n\n~~~ .python\nmy_canvas = items['my_sketchpad'].canvas\nfor angle in range(360):\n\tmy_canvas['my_image'].rotation = angle\n\tmy_canvas.show()\n~~~\n\n### Créer un Canvas en Python\n\nVous pouvez utiliser l'objet `Canvas` pour présenter des stimuli visuels en Python :\n\n- %link:manual/python/canvas%"
  },
  "OpenSesame 3.0.6 is the sixth maintenance release in the 3.0 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.0 series.\n\nA notable improvement in this release is that we now have a standard OSX package! So no more waiting and using outdated packages for Mackies! Thanks do Daniel Schreij ([@dscreij](https://github.com/dschreij/)) for his great work on this.\n\nIf you are upgrading from OpenSesame 2.9.7 or earlier, please see the list of important changes in OpenSesame 3.0:\n\n- [Important changes in 3.0](/miscellaneous/important-changes-3/)\n\n### Bugs fixed\n\n- Fix a crash when adding an empty list to the file pool\n- Handle exotic variable types better in variable inspector (#388)\n- Fix initial state of auto_example plugin (#389)\n- Catch errors in file pool\n- Fix background-color changes with psycho backend\n- Catch non osexception Exceptions during script validation\n- Add console property to sketchpad base_element\n- Avoid setting config values to QPyNullVariant (#397)\n- Don't set fullscreen as property of experiment in opensesamerun (#392)\n- Don't allow line breaks in sketchpad-element scripts\n\n### Improvements\n\n- Add `experiment_file` experimental variable, which contains the file name of the experiment (#387)\n- Catch warnings when creating a new item and provide an informative message\n- Update default logfile location after save as (#370)\n- Improve file-type icons in file pool\n- Add deprecation warning to parallel plugin (use coroutines instead)\n- Allow external links in user hints\n- Move image element to top in sketchpad to make it more easily discoverable\n\n### Windows packaging\n\nPython 2.7 release (recommended):\n\n~~~\nOpenSesame 3.0.6\nPython 2.7.10 (default, May 23 2015, 09:40:32) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 3.0.0\nQProgedit 3.2.2\nExpyriment  (Python 2.7.10)\nIPython 3.2.0\nNumPy 1.9.2\nPIL is available (version is unknown)\nPsychoPy 1.82.01\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.6.0a8\nPyglet 1.2.3\nPyOpenGL 3.1.0\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.6.2\nSciPy 0.15.1\n~~~\n\nPython 3.4 release (experimental):\n\n~~~\nOpenSesame 3.0.6\nPython 3.4.3 (v3.4.3:9b73f1c3e601, Feb 24 2015, 22:43:06) [MSC v.1600 32 bit (Intel)]\nOpenCV is not available\nOpenCV 2 is not available\nQProgedit 3.2.2\nExpyriment is not available (or version is unknown)\nIPython 4.0.0\nNumPy 1.9.3\nPIL is available (version is unknown)\nPsychoPy not available (or version is unknown)\nPyAudio 0.2.9\nPyGame 1.9.2a0\nPyGaze is not available\nPyglet not available (or version is unknown)\nPyOpenGL 3.1.1b1\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.4.0\npython-markdown 2.6.2\nSciPy 0.16.1\n~~~\n\n### Mac OS packaging\n\n~~~\nOpenSesame 3.0.6\nPython 2.7.11 |Continuum Analytics, Inc.| (default, Dec 6 2015, 18:57:58)\n[GCC 4.2.1 (Apple Inc. build 5577)]\nOpenCV is not available\nOpenCV2 3.1.0\nQProgedit 3.2.2\nExpyriment 0.8.0-41-g147b7d7 (Python 2.7.11)\nIPython 4.1.1\nNumPy 1.10.4\nPIL is available (version is unknown)\nPsychoPy 1.82.01\nPyAudio 0.2.7\nPyGame 1.9.2a0\nPyGaze is not available\nPyglet 1.2.4\nPyOpenGL 3.1.1a1\nPyQt 4.11.4\nPySerial 3.0.1\npython-bidi 0.4.0\npython-markdown 2.6.5\nSciPy 0.17.0\n~~~~\n": {
    "fr": "OpenSesame 3.0.6 est la sixième version de maintenance de la série 3.0. Elle contient des corrections de bugs et des améliorations mineures et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.0.\n\nUne amélioration notable de cette version est que nous avons maintenant un package standard OSX ! Ainsi, plus d'attente et d'utilisation de packages obsolètes pour les utilisateurs de Mac ! Merci à Daniel Schreij ([@dscreij](https://github.com/dschreij/)) pour son excellent travail à ce sujet.\n\nSi vous passez d'OpenSesame 2.9.7 ou une version antérieure, veuillez consulter la liste des changements importants dans OpenSesame 3.0 :\n\n- [Changements importants dans la version 3.0](/miscellaneous/important-changes-3/)\n\n### Bugs corrigés\n\n- Correction d'un crash lors de l'ajout d'une liste vide à la sélection de fichiers\n- Gérer mieux les types de variables exotiques dans l'inspecteur de variables (#388)\n- Correction de l'état initial du plugin auto_example (#389)\n- Attraper les erreurs dans la sélection de fichiers\n- Correction du changement de couleur d'arrière-plan avec le backend psycho\n- Attraper les exceptions non osexception lors de la validation du script\n- Ajout de la propriété console à l'élément sketchpad base_element\n- Éviter de définir les valeurs de configuration sur QPyNullVariant (#397)\n- Ne pas définir plein écran comme propriété de l'expérience dans opensesamerun (#392)\n- Ne pas autoriser les sauts de ligne dans les scripts d'éléments de sketchpad\n\n### Améliorations\n\n- Ajout de la variable expérimentale `experiment_file`, qui contient le nom de fichier de l'expérience (#387)\n- Attraper les avertissements lors de la création d'un nouvel élément et fournir un message informatif\n- Mise à jour de l'emplacement du fichier journal par défaut après l'enregistrement sous (#370)\n- Amélioration des icônes de type de fichier dans la sélection de fichiers\n- Ajout d'un avertissement de dépréciation au plugin parallel (utiliser les coroutines à la place)\n- Autoriser les liens externes dans les astuces d'utilisation\n- Déplacer l'élément image vers le haut de sketchpad pour le rendre plus facile à découvrir\n\n### Packaging Windows\n\nVersion Python 2.7 (recommandée) :\n\n~~~\nOpenSesame 3.0.6\nPython 2.7.10 (default, May 23 2015, 09:40:32) [MSC v.1500 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 3.0.0\nQProgedit 3.2.2\nExpyriment  (Python 2.7.10)\nIPython 3.2.0\nNumPy 1.9.2\nPIL est disponible (la version est inconnue)\nPsychoPy 1.82.01\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.6.0a8\nPyglet 1.2.3\nPyOpenGL 3.1.0\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.6.2\nSciPy 0.15.1\n~~~\n\nVersion Python 3.4 (expérimentale) :\n\n~~~\nOpenSesame 3.0.6\nPython 3.4.3 (v3.4.3:9b73f1c3e601, Feb 24 2015, 22:43:06) [MSC v.1600 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV 2 n'est pas disponible\nQProgedit 3.2.2\nExpyriment n'est pas disponible (ou la version est inconnue)\nIPython 4.0.0\nNumPy 1.9.3\nPIL est disponible (la version est inconnue)\nPsychoPy n'est pas disponible (ou la version est inconnue)\nPyAudio 0.2.9\nPyGame 1.9.2a0\nPyGaze n'est pas disponible\nPyglet n'est pas disponible (ou la version est inconnue)\nPyOpenGL 3.1.1b1\nPyQt 4.11.4\nPySerial 2.7\npython-bidi 0.4.0\npython-markdown 2.6.2\nSciPy 0.16.1\n~~~\n\n### Packaging Mac OS\n\n~~~\nOpenSesame 3.0.6\nPython 2.7.11 |Continuum Analytics, Inc.| (default, Dec 6 2015, 18:57:58)\n[GCC 4.2.1 (Apple Inc. build 5577)]\nOpenCV n'est pas disponible\nOpenCV2 3.1.0\nQProgedit 3.2.2\nExpyriment 0.8.0-41-g147b7d7 (Python 2.7.11)\nIPython 4.1.1\nNumPy 1.10.4\nPIL est disponible (la version est inconnue)\nPsychoPy 1.82.01\nPyAudio 0.2.7\nPyGame 1.9.2a0\nPyGaze n'est pas disponible\n_pyglet 1.2.4\nPyOpenGL 3.1.1a1\nPyQt 4.11.4\nPySerial 3.0.1\npython-bidi 0.4.0\npython-markdown 2.6.5\nSciPy 0.17.0\n~~~"
  },
  "A SEQUENCE consists of a series of items that are executed one after another. A prototypical SEQUENCE is the *trial_sequence*, which corresponds to a single trial. For example, a basic *trial_sequence* might consist of a SKETCHPAD, to present a stimulus, a KEYBOARD_RESPONSE, to collect a response, and a LOGGER, to write the trial information to the log file.\n\n<notranslate>\nfigure:\n id: FigExampleSequence\n source: example-sequence.png\n caption: |\n  An example of a SEQUENCE item used as a trial sequence. (This example is not related to the experiment created in this tutorial.)\n</notranslate>\n\nYou can combine LOOPs and SEQUENCEs in a hierarchical way, to create trial blocks, and practice and experimental phases. For example, the *trial_sequence* is called by the *block_loop*. Together, these correspond to a single block of trials. One level up, the *block_sequence* is called by the *practice_loop*. Together, these correspond to the practice phase of the experiment.\n\n</div>\n\n\n### Step 2: Add a block_loop and trial_sequence\n\nThe default template starts with three items: A NOTEPAD called *getting_started*, a SKETCHPAD called *welcome*, and a SEQUENCE called *experiment*. We don't need *getting_started* and *welcome*, so let's remove these right away. To do so, right-click on these items and select 'Delete'. Don't remove *experiment*, because it is the entry for the experiment (i.e. the first item that is called when the experiment is started).\n\nOur experiment will have a very simple structure. At the top of the hierarchy is a LOOP, which we will call *block_loop*. The *block_loop* is the place where we will define our independent variables (see also Background box 1). To add a LOOP to your experiment, drag the LOOP icon from the item toolbar onto the *experiment* item in the overview area.\n\nA LOOP item needs another item to run; usually, and in this case as well, this is a SEQUENCE. Drag the SEQUENCE item from the item toolbar onto the *new_loop* item in the overview area. OpenSesame will ask whether you want to insert the SEQUENCE into or after the LOOP. Select 'Insert into new_loop'.\n\nBy default, items have names such as *new_sequence*, *new_loop*, *new_sequence_2*, etc. These names are not very informative, and it is good practice to rename them. Item names must consist of alphanumeric characters and/ or underscores. To rename an item, double-click on the item in the overview area. Rename *new_sequence* to *trial_sequence* to indicate that it will correspond to a single trial. Rename *new_loop* to *block_loop* to indicate that will correspond to a block of trials.\n\nThe overview area of our experiment now looks as in %FigStep3.\n\n<notranslate>\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  The overview area at the end of Step 2.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 3: Unused items**\n\n__Tip__ — Deleted items are still available in the Unused Items bin, until you select 'Permanently delete unused items' in the Unused Items tab. You can re-add deleted items to your experiment by dragging them out of the Unused Items bin into a SEQUENCE or LOOP.\n\n</div>\n\n### Step 3: Import images and sound files\n\nFor this experiment, we will use images of cats, dogs, and capybaras. We will also use sound samples of meows and barks. You can download all the required files from here:\n\n- %static:attachments/cats-dogs-capybaras/stimuli.zip%": {
    "fr": "Une SEQUENCE est composée d'une série d'éléments exécutés les uns après les autres. Une SEQUENCE prototype est la *trial_sequence*, qui correspond à un essai unique. Par exemple, une *trial_sequence* de base pourrait être composée d'un SKETCHPAD, pour présenter un stimulus, d'une KEYBOARD_RESPONSE, pour recueillir une réponse, et d'un LOGGER, pour écrire les informations de l'essai dans le fichier journal.\n\n<notranslate>\nfigure:\n id: FigExampleSequence\n source: example-sequence.png\n caption: |\n  Un exemple d'un élément SEQUENCE utilisé comme séquence d'essai. (Cet exemple n'est pas lié à l'expérience créée dans ce tutoriel.)\n</notranslate>\n\nVous pouvez combiner les LOOPs et les SEQUENCEs de manière hiérarchique pour créer des blocs d'essais, ainsi que des phases de pratique et d'expérimentation. Par exemple, la *trial_sequence* est appelée par la *block_loop*. Ensemble, ils correspondent à un bloc unique d'essais. Un niveau plus haut, la *block_sequence* est appelée par la *practice_loop*. Ensemble, ils correspondent à la phase de pratique de l'expérience.\n\n</div>\n\n\n### Étape 2 : Ajouter une block_loop et une trial_sequence\n\nLe modèle par défaut commence avec trois éléments : un NOTEPAD appelé *getting_started*, un SKETCHPAD appelé *welcome* et une SEQUENCE appelée *experiment*. Nous n'avons pas besoin de *getting_started* et *welcome*, alors supprimons-les tout de suite. Pour ce faire, faites un clic droit sur ces éléments et sélectionnez 'Supprimer'. Ne supprimez pas *experiment*, car c'est l'entrée de l'expérience (c'est-à-dire le premier élément appelé lorsque l'expérience commence).\n\nNotre expérience aura une structure très simple. Au sommet de la hiérarchie se trouve une LOOP, que nous appellerons *block_loop*. Le *block_loop* est l'endroit où nous définirons nos variables indépendantes (voir aussi l'encadré 1 en arrière-plan). Pour ajouter une LOOP à votre expérience, faites glisser l'icône LOOP de la barre d'outils des éléments sur l'élément *experiment* dans la zone d'aperçu.\n\nUn élément LOOP a besoin d'un autre élément pour fonctionner ; généralement, et dans ce cas également, il s'agit d'une SEQUENCE. Faites glisser l'élément SEQUENCE de la barre d'outils des éléments sur l'élément *new_loop* dans la zone d'aperçu. OpenSesame vous demandera si vous voulez insérer la SEQUENCE dans ou après la LOOP. Sélectionnez 'Insérer dans new_loop'.\n\nPar défaut, les éléments ont des noms tels que *new_sequence*, *new_loop*, *new_sequence_2*, etc. Ces noms ne sont pas très informatifs et il est recommandé de les renommer. Les noms des éléments doivent être composés de caractères alphanumériques et/ou de traits de soulignement. Pour renommer un élément, double-cliquez sur l'élément dans la zone d'aperçu. Renommez *new_sequence* en *trial_sequence* pour indiquer qu'il correspondra à un essai unique. Renommez *new_loop* en *block_loop* pour indiquer qu'il correspondra à un bloc d'essais.\n\nLa zone d'aperçu de notre expérience ressemble maintenant à celle présentée en %FigStep3.\n\n<notranslate>\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  La zone d'aperçu à la fin de l'étape 2.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 3 : Éléments inutilisés**\n\n__Astuce__ — Les éléments supprimés sont toujours disponibles dans la corbeille des éléments inutilisés, jusqu'à ce que vous sélectionniez 'Supprimer définitivement les éléments inutilisés' dans l'onglet Éléments inutilisés. Vous pouvez réajouter des éléments supprimés à votre expérience en les faisant glisser hors de la corbeille des éléments inutilisés dans une SEQUENCE ou LOOP.\n\n</div>\n\n### Étape 3 : Importer des images et des fichiers sonores\n\nPour cette expérience, nous utiliserons des images de chats, de chiens et de capybaras. Nous utiliserons également des échantillons sonores de miaulements et d'aboiements. Vous pouvez télécharger tous les fichiers requis à partir d'ici :\n\n- %static:attachments/cats-dogs-capybaras/stimuli.zip%"
  },
  "OpenSesame 4.0 *Melodramatic Milgram* is a major new release with many new features and improvements.\n\n\n<notranslate>[TOC]</notranslate>\n\n## Important: Backwards incompatible changes\n\n- Logging of variables has changed slightly. Specifically, variables that are defined in the user interface, such as columns in a `loop` table or explicitly selected variables in a `logger`, are always logged. Variables that are defined in an `inline_script` or `inline_javascript` are only logged if they are numbers (`int` and `float`), strings (`str` and `bytes`), and `None` values. This is to avoid log files from becoming unreasonably large due to logging of long lists and other large values.\n- The content of `<script>` tags in `inline_html` items is not evaluated. This is no longer necessary, because you can simply refer to experimental variables as you would elsewhere in JavaScript (see below).\n- Conditional expressions are only interpreted as OpenSesame script if they contain variable references using the square-bracket notation or the words 'always' or 'never'. Otherwise they are interpreted as Python expressions as described below.\n  \n## New OpenSesame Python module (no GUI)\n\nFor those of you who prefer coding over using a GUI: You can now use OpenSesame as a Python module.\n\n```python\nfrom libopensesame.python_workspace_api import \\\n  Experiment, Canvas, Keyboard, Text\n\n# Initialize the experiment window using the legacy backend\nexp, win, clock, log = Experiment(canvas_backend='legacy')\n# Prepare a stimulus canvas and a keyboard\ncnv = Canvas()\ncnv += Text('Hello world')\nkb = Keyboard()\n# Show the canvas, wait for a key press, and then end the experiment\ncnv.show()\nkb.get_key()\nexp.end()\n```\n\nSee also:\n\n- %link:manual/python/nogui%\n\n## Improved integration with Python and JavaScript\n\nThe integration between OpenSesame and Python (on the desktop)/ JavaScript (in the browser) is now more intuitive. Specifically, OpenSesame-specific syntax has partly been replaced by standard Python/ JavaScript syntax, and there is no longer a distinction between experimental variables and global variables in Python/ JavaScript.\n\n\n### {} instead of []: Support for formatted string literals (f-strings)\n\nThe preferred notation for referring to variables in the user interface is now using curly braces (`{my_var}`), rather than square brackets (`[my_var]`).\n\nYou can even include full Python expressions within curly braces. For example, the following text on a SKETCHPAD will include the text 'Well done!' if accuracy is above 70% and the text 'Try harder!' otherwise.\n\n```text\nYour accuray is {acc} %. {'Well done!' if acc > 70 else 'Try harder!'}\n```\n\nWhen running an experiment with OSWeb in a browser, the Python code inside curly braces is automatically converted to JavaScript. This means that you can use the same Python expressions inside curly braces on the desktop and in a browser.\n\nFor more information, see:\n\n- <https://docs.python.org/3/reference/lexical_analysis.html#f-strings>\n\n\n### Support for Python-style conditional expressions\n\nThe preferred syntax for run-if, break-if, show-if, and other conditional expressions is Python, rather than OpenSesame script. This means that the following run-if expression results in an item only being run when the variable `correct` equals 1, that is, after a correct response. (This is also related to the fact that experimental variables are now globals, see below.)\n\n```python\ncorrect == 1\n```\n\nWhen running an experiment with OSWeb in a browser, Python conditional expressions are automatically converted to JavaScript. This means that you can use the same Python run-if, break-if, show-if, and other conditional expressions on the desktop and in a browser.\n\n\n### Persistent JavaScript workspace\n\nThe JavaScript workspace is now persistent. This means that you can define a function or variable in one `inline_javascript` and then refer to it in another `inline_javascript`.\n\n\n### Experimental variables are globals": {
    "fr": "OpenSesame 4.0 *Melodramatic Milgram* est une nouvelle version majeure avec de nombreuses nouvelles fonctionnalités et améliorations.\n\n<notranslate>[TOC]</notranslate>\n\n## Important : Changements incompatibles avec les versions précédentes\n\n- La journalisation des variables a légèrement changé. Plus précisément, les variables définies dans l'interface utilisateur, telles que les colonnes d'un tableau `loop` ou les variables explicitement sélectionnées dans un élément `logger`, sont toujours enregistrées. Les variables définies dans un `inline_script` ou un `inline_javascript` ne sont enregistrées que si elles sont des nombres (`int` et `float`), des chaînes de caractères (`str` et `bytes`) et des valeurs `None`. Ceci afin d'éviter que les fichiers de journalisation ne deviennent déraisonnablement volumineux en raison de l'enregistrement de longues listes et d'autres grandes valeurs.\n- Le contenu des balises `<script>` dans les éléments `inline_html` n'est pas évalué. Ce n'est plus nécessaire, car vous pouvez simplement vous référer aux variables expérimentales comme vous le feriez ailleurs en JavaScript (voir ci-dessous).\n- Les expressions conditionnelles ne sont interprétées comme du script OpenSesame que si elles contiennent des références de variables utilisant la notation entre crochets ou les mots 'always' ou 'never'. Sinon, elles sont interprétées comme des expressions Python, comme décrit ci-dessous.\n  \n## Nouveau module Python OpenSesame (sans interface graphique)\n\nPour ceux d'entre vous qui préfèrent coder plutôt que d'utiliser une interface graphique : vous pouvez désormais utiliser OpenSesame en tant que module Python.\n\n```python\nfrom libopensesame.python_workspace_api import \\\n  Experiment, Canvas, Keyboard, Text\n\n# Initialiser la fenêtre d'expérience en utilisant le backend hérité\nexp, win, clock, log = Experiment(canvas_backend='legacy')\n# Préparer un canvas de stimuli et un clavier\ncnv = Canvas()\ncnv += Text('Hello world')\nkb = Keyboard()\n# Affiche le canevas, attend une touche, puis termine l'expérience\ncnv.show()\nkb.get_key()\nexp.end()\n```\n\nVoir aussi :\n\n- %link:manuel/python/nogui%\n\n## Intégration améliorée avec Python et JavaScript\n\nL'intégration entre OpenSesame et Python (sur le bureau)/ JavaScript (dans le navigateur) est maintenant plus intuitive. Plus précisément, la syntaxe spécifique d'OpenSesame a été en partie remplacée par la syntaxe standard de Python/ JavaScript, et il n'y a plus de distinction entre les variables expérimentales et les variables globales en Python/ JavaScript.\n\n### {} instead of []: Support pour les chaînes de caractères formatées (f-strings)\n\nLa notation préférée pour faire référence aux variables dans l'interface utilisateur est maintenant en utilisant des accolades (`{my_var}`), plutôt que des crochets (`[my_var]`).\n\nVous pouvez même inclure des expressions Python complètes entre accolades. Par exemple, le texte suivant sur un SKETCHPAD inclura le texte 'Bien joué !' si la précision est supérieure à 70% et le texte 'Essaie encore !' sinon.\n\n```text\nVotre précision est de {acc} %. {'Bien joué !' if acc > 70 else 'Essaie encore !'}\n```\n\nLors de l'exécution d'une expérience avec OSWeb dans un navigateur, le code Python entre accolades est automatiquement converti en JavaScript. Cela signifie que vous pouvez utiliser les mêmes expressions Python entre accolades sur le bureau et dans un navigateur.\n\nPour plus d'informations, voir :\n\n- <https://docs.python.org/3/reference/lexical_analysis.html#f-strings>\n\n\n### Prise en charge des expressions conditionnelles de style Python\n\nLa syntaxe préférée pour les expressions run-if, break-if, show-if et autres expressions conditionnelles est en Python, plutôt qu'en script OpenSesame. Cela signifie que l'expression run-if suivante a pour résultat que l'élément ne s'exécute que lorsque la variable `correct` est égale à 1, c'est-à-dire après une réponse correcte. (Cela est également lié au fait que les variables expérimentales sont désormais globales, voir ci-dessous.)\n\n```python\ncorrect == 1\n```\n\nLors de l'exécution d'une expérience avec OSWeb dans un navigateur, les expressions conditionnelles Python sont automatiquement converties en JavaScript. Cela signifie que vous pouvez utiliser les mêmes expressions conditionnelles run-if, break-if, show-if et autres en Python sur le bureau et dans un navigateur.\n\n### Espace de travail JavaScript persistant\n\nL'espace de travail JavaScript est maintenant persistant. Cela signifie que vous pouvez définir une fonction ou une variable dans un `inline_javascript` puis vous y référer dans un autre `inline_javascript`.\n\n### Les variables expérimentales sont globales"
  },
  "Experimental variables, such as `response_time` and variables defined in LOOP items, are now global variables within Python and JavaScript. This means that you no longer have to use the `var` (Python) or `vars` object, but can directly refer experimental variables by their name.\n\nPython:\n\n```python\n# Access an existing experimental variable by its name\nprint('response = ', response)\n# Define a new experimental variable (which can be used also in the GUI)\nnew_experimental_variable = 'example'\n```\n\nJavaScript:\n\n```javascript\n// Access an existing experimental variable by its name\nconsole.log('response = ' + response)\n// Define a new experimental variable (which can be used also in the GUI)\n// Note: Variables defined using `let` are *not* globally available!\nvar new_experimental_variable = 'example'\n```\n\n## Improved user interface\n\nThere have been usability improvements through the user interface:\n\n- Improved icons: The open and save icons have been redesigned because they were experienced as unclear by some users\n- Run-if, break-if, show-if, and other conditional expressions are annotated for clarity ('Always run')\n- OSWeb now appears as a backend\n- Items that are not compatible with the experiment settings are disabled\n- Items in an experiment can be disabled. This is mostly useful for development purposes, for example to temporarily disable the instructions.\n- Error messages are now much more informative.\n- A new updater extension automatically checks for updates to selected packages. This provides an easy way to keep OpenSesame up to date without having to re-download and re-install the software.\n\n\n## Interleaved Quest staircase\n\nThe `quest_staircase_init` and `quest_staircase_next` items now accept a name, which allows you to run multiple Quest procedures in parallel. This is mostly useful if you want to run independent, interleaved Quest procedures for different experimental conditions.\n\n\n## For developers: Improved plugin and extension API\n\nThe plugin and extension API has been simplified and revised to reflect current best practices in Python development:\n\n- %link:dev/plugin%\n- %link:dev/extension%\n": {
    "fr": "Les variables expérimentales, telles que `response_time` et les variables définies dans les éléments LOOP, sont désormais des variables globales au sein de Python et JavaScript. Cela signifie que vous n'avez plus besoin d'utiliser l'objet `var` (Python) ou `vars`, mais pouvez directement faire référence aux variables expérimentales par leur nom.\n\nPython :\n\n```python\n# Accéder à une variable expérimentale existante par son nom\nprint('response = ', response)\n# Définir une nouvelle variable expérimentale (qui peut aussi être utilisée dans l'interface graphique)\nnew_experimental_variable = 'exemple'\n```\n\nJavaScript:\n\n```javascript\n// Accéder à une variable expérimentale existante par son nom\nconsole.log('response = ' + response)\n// Définir une nouvelle variable expérimentale (qui peut aussi être utilisée dans l'interface graphique)\n// Remarque : Les variables définies avec `let` ne sont *pas* globalement disponibles !\nvar new_experimental_variable = 'exemple'\n```\n\n## Amélioration de l'interface utilisateur\n\nDes améliorations de l'ergonomie ont été apportées à l'interface utilisateur :\n\n- Icônes améliorées : Les icônes d'ouverture et de sauvegarde ont été repensées car elles étaient considérées comme peu claires par certains utilisateurs\n- Les expressions conditionnelles telles que Run-if, break-if, show-if, et autres, sont annotées pour plus de clarté ('Toujours exécuter')\n- OSWeb apparaît désormais comme un backend\n- Les éléments qui ne sont pas compatibles avec les paramètres de l'expérience sont désactivés\n- Les éléments d'une expérience peuvent être désactivés. Ceci est principalement utile pour les besoins de développement, par exemple pour désactiver temporairement les instructions.\n- Les messages d'erreur sont maintenant beaucoup plus informatifs.\n- Une nouvelle extension de mise à jour vérifie automatiquement les mises à jour des packages sélectionnés. Cela offre un moyen facile de maintenir OpenSesame à jour sans avoir à télécharger et réinstaller le logiciel.\n\n\n## Escalier Quest entrelacé\n\nLes éléments `quest_staircase_init` et `quest_staircase_next` acceptent désormais un nom, ce qui vous permet d'exécuter plusieurs procédures Quest en parallèle. Ceci est principalement utile si vous souhaitez exécuter des procédures Quest indépendantes et entrelacées pour différentes conditions expérimentales.\n\n## Pour les développeurs : API améliorée pour les plugins et extensions\n\nL'API des plugins et extensions a été simplifiée et révisée pour refléter les meilleures pratiques actuelles en matière de développement Python :\n\n- %link:dev/plugin%\n- %link:dev/extension%"
  },
  "- `opensesame_extensions/RapunzelLocale/translatables.ts`\n\nYou can either download or clone the source code and directly open these files. Or you can view them through GitHub. In the last case, at the top-right of the file, you will see a 'Raw' link. Right-click on this link and select 'Save file as' (or something along those lines, depending on your browser) to save the file your disk.\n\n\n#### Step 2: Install Qt Linguist\n\nQt Linguist is a graphical tool that will assist you in the translation process. It's user friendly, and allows you to simply select a string of (English) text and enter a translation.\n\n__Windows__\n\nYou can download a standalone version of Qt Linguist from here:\n\n- <https://github.com/thurask/Qt-Linguist/releases>\n\n\n__Mac OS__\n\nYou can download a standalone version of Qt Linguist from here:\n- <https://github.com/lelegard/qtlinguist-installers/releases>\n\n__Linux__\n\nOn Linux, Qt Linguist is generally available in the repositories. For example, on Ubuntu it can be installed with:\n\n\tsudo apt-get install qttools5-dev-tools\n\n\n#### Step 3: Open translatables.ts in Qt Linguist\n\nNow start Qt Linguist and open `translatables.ts`. You will first be asked to enter a source and target language. Leave the source as it is: 'POSIX/ Any country'. The target language should be set to the language that you will translate OpenSesame into. Leave the Country/Region option at 'Any country'. You can change these settings later via Menu → Edit → Translation file settings.\n\nNow you can start translating! On the left you will see a list of 'contexts'. These indicate in which context the text is shown, which is helpful. To translate, simply click on the first source text-string in the first context, enter an appropriate translation, and press `Ctrl+Enter` to advance to the next string.\n\nSome strings will contain HTML tags, like so:\n\n\tSize<br /><i>in pixels</i>\n\nIn this case, only change the text and leave the HTML tags as they are. So, for a Dutch translation this would become:\n\n\tGrootte<br /><i>in pixels</i>\n\nAlso, some strings contain wildcards, like so:\n\n\tTell me more about the %s item\n\nThese `%s` (and `%d`, `%f`, `{}`, etc.) wildcards are blanks that are filled in on-the-fly by OpenSesame. Please respect these (removing a wild-card will crash the program!) and try to build an appropriate translation around them. So, for a Dutch translation this would become:\n\n\tVertel me meer over het %s item\n\n\n#### Step 4: Compile your translation to `.qm` and test it\n\nOpenSesame doesn't use the `.ts` file directly, but requires a file in `.qm` format. You can create this file easily from within Qt Linguist by selecting 'File → Release as'. Create a `.qm` file with the same name (except for the extension) as the original file.\n\nFor OpenSesame, this file should be saved to (change `fr_FR` to the appropriate locale):\n\n- `opensesame_resources/locale/fr_FR.qm`\n\nFor Rapunzel, this file should be save to (change `fr_FR` to the appropriate locale):\n\n- `opensesame_extensions/RapunzelLocale/fr_FR.qm`\n\n\n## Save and submit your translations\n\n\n### Send by e-mail\n\nOnce you are satisfied with your translations, send the translated `.ts` file and all translated `md` files to <s.mathot@cogsci.nl>.\n\n\n### Submit through GitHub\n\nYou can also submit (and update) your translation via GitHub. First, add your translation to your fork of OpenSesame, as `opensesame_resources/ts/ll_RR.ts`, where `ll` corresponds to the language and `RR` to the region. For example, `en_US` is US english, `fr_FR` is French, and `zh_CN` is Chinese. You can find a list of valid regions and languages [here](http://www.iana.org/assignments/language-subtag-registry).\n\nSimilarly, add all translated `.md` files to your fork of OpenSesame.\n\nFinally, submit a pull request to have your translation included in OpenSesame.\n\n\n## Updating an existing translation": {
    "fr": "- `opensesame_extensions/RapunzelLocale/translatables.ts`\n\nVous pouvez soit télécharger ou cloner le code source et ouvrir directement ces fichiers. Ou vous pouvez les visualiser via GitHub. Dans ce dernier cas, en haut à droite du fichier, vous verrez un lien 'Raw'. Faites un clic droit sur ce lien et sélectionnez 'Enregistrer le fichier sous' (ou quelque chose du genre, selon votre navigateur) pour enregistrer le fichier sur votre disque.\n\n#### Étape 2 : Installer Qt Linguist\n\nQt Linguist est un outil graphique qui vous aidera dans le processus de traduction. Il est convivial et vous permet de simplement sélectionner une chaîne de texte (en anglais) et de saisir une traduction.\n\n__Windows__\n\nVous pouvez télécharger une version autonome de Qt Linguist ici :\n\n- <https://github.com/thurask/Qt-Linguist/releases>\n\n__Mac OS__\n\nVous pouvez télécharger une version autonome de Qt Linguist ici :\n- <https://github.com/lelegard/qtlinguist-installers/releases>\n\n__Linux__\n\nSur Linux, Qt Linguist est généralement disponible dans les dépôts. Par exemple, sur Ubuntu, il peut être installé avec :\n\n\tsudo apt-get install qttools5-dev-tools\n\n#### Étape 3 : Ouvrir translatables.ts dans Qt Linguist\n\nLancez Qt Linguist et ouvrez `translatables.ts`. Vous serez d'abord invité à saisir une langue source et une langue cible. Laissez la source telle quelle : 'POSIX/ Any country'. La langue cible doit être réglée sur la langue dans laquelle vous traduirez OpenSesame. Laissez l'option Pays/Région sur 'Any country'. Vous pouvez modifier ces paramètres ultérieurement via Menu → Edit → Translation file settings.\n\nVous pouvez maintenant commencer à traduire ! Sur la gauche, vous verrez une liste de 'contexts'. Ceux-ci indiquent dans quel contexte le texte est affiché, ce qui est utile. Pour traduire, cliquez simplement sur la première chaîne de texte source dans le premier contexte, saisissez une traduction appropriée et appuyez sur `Ctrl+Enter` pour passer à la chaîne suivante.\n\nCertaines chaînes contiendront des balises HTML, comme ceci :\n\n\tSize<br /><i>in pixels</i>\n\nDans ce cas, ne changez que le texte et laissez les balises HTML telles quelles. Ainsi, pour une traduction en français, cela deviendrait :\n\n\tTaille<br /><i>en pixels</i>\n\nDe plus, certaines chaînes contiennent des caractères génériques, comme ceci :\n\n\tTell me more about the %s item\n\nCes caractères génériques `%s` (et `%d`, `%f`, `{}`, etc.) sont des espaces qui sont remplis à la volée par OpenSesame. Veuillez les respecter (la suppression d'un caractère générique fera planter le programme!) et essayez de construire une traduction appropriée autour d'eux. Ainsi, pour une traduction en français, cela deviendrait :\n\n\tParlez-moi davantage de l'élément %s\n\n#### Étape 4 : Compiler votre traduction en `.qm` et la tester\n\nOpenSesame n'utilise pas directement le fichier `.ts`, mais nécessite un fichier au format `.qm`. Vous pouvez créer ce fichier facilement à partir de Qt Linguist en sélectionnant 'File → Release as'. Créez un fichier `.qm` avec le même nom (à l'exception de l'extension) que le fichier original.\n\nPour OpenSesame, ce fichier doit être enregistré sous (changer `fr_FR` par la langue appropriée) :\n\n- `opensesame_resources/locale/fr_FR.qm`\n\nPour Rapunzel, ce fichier doit être sauvegardé sous (changer `fr_FR` par la langue appropriée) :\n\n- `opensesame_extensions/RapunzelLocale/fr_FR.qm`\n\n## Enregistrez et soumettez vos traductions\n\n### Envoyer par e-mail\n\nUne fois que vous êtes satisfait de vos traductions, envoyez le fichier `.ts` traduit et tous les fichiers `md` traduits à <s.mathot@cogsci.nl>.\n\n### Soumettre via GitHub\n\nVous pouvez également soumettre (et mettre à jour) votre traduction via GitHub. D'abord, ajoutez votre traduction à votre fork d'OpenSesame, sous `opensesame_resources/ts/ll_RR.ts`, où `ll` correspond à la langue et `RR` à la région. Par exemple, `en_US` est l'anglais américain, `fr_FR` est le français et `zh_CN` est le chinois. Vous pouvez trouver une liste des régions et langues valides [ici](http://www.iana.org/assignments/language-subtag-registry).\n\nDe même, ajoutez tous les fichiers `.md` traduits à votre fork d'OpenSesame.\n\nEnfin, soumettez une demande d'extraction (pull request) pour que votre traduction soit incluse dans OpenSesame.\n\n## Mettre à jour une traduction existante"
  },
  "The process to update an existing translation is similar to that described above for creating a new translation. The crucial difference is that you don't start with `resources/ts/translatables.ts`, but with a non-blank translation file, such as `resources/ts/fr_FR.ts`.\n": {
    "fr": "Le processus de mise à jour d'une traduction existante est similaire à celui décrit ci-dessus pour la création d'une nouvelle traduction. La différence cruciale est que vous ne commencez pas avec `resources/ts/translatables.ts`, mais avec un fichier de traduction non vide, tel que `resources/ts/fr_FR.ts`."
  },
  "Creating a plugin": {
    "fr": "Création d'un plugin"
  },
  "~~~ .yaml\nname: opensesame_3.2.4-py2.7-win32-1\nchannels:\n- cogsci\n- conda-forge\n- defaults\ndependencies:\n- anaconda-client=1.6.3=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.5=py27_0\n- bleach=1.5.0=py27_0\n- bzip2=1.0.6=vc9_3\n- certifi=2016.2.28=py27_0\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.1.2=py_0\n- qscintilla2=2.9.3=py27_vc9_0\n- requests-oauthlib=0.6.2=py_0\n- webcolors=1.5=py27_0\n- colorama=0.3.9=py27_0\n- configparser=3.5.0=py27_0\n- decorator=4.1.2=py27_0\n- entrypoints=0.2.3=py27_0\n- enum34=1.1.6=py27_0\n- freetype=2.5.5=vc9_2\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- html5lib=0.999=py27_0\n- icu=57.1=vc9_0\n- ipykernel=4.6.1=py27_0\n- ipython=5.3.0=py27_0\n- ipython_genutils=0.2.0=py27_0\n- ipywidgets=6.0.0=py27_0\n- jinja2=2.9.6=py27_0\n- jpeg=9b=vc9_0\n- jsonschema=2.6.0=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=5.1.0=py27_0\n- jupyter_console=5.2.0=py27_0\n- jupyter_core=4.3.0=py27_0\n- libpng=1.6.30=vc9_1\n- libtiff=4.0.6=vc9_3\n- markdown=2.6.9=py27_0\n- markupsafe=1.0=py27_0\n- mistune=0.7.4=py27_0\n- mkl=2017.0.3=0\n- nbconvert=5.2.1=py27_0\n- nbformat=4.4.0=py27_0\n- notebook=5.0.0=py27_0\n- numpy=1.13.1=py27_0\n- olefile=0.44=py27_0\n- openssl=1.0.2l=vc9_0\n- pandocfilters=1.4.2=py27_0\n- path.py=10.3.1=py27_0\n- pathlib2=2.3.0=py27_0\n- pickleshare=0.7.4=py27_0\n- pillow=4.2.1=py27_0\n- pip=9.0.1=py27_1\n- prompt_toolkit=1.0.15=py27_0\n- pyflakes=1.6.0=py27_0\n- pygments=2.2.0=py27_0\n- pyopengl=3.1.1a1=np113py27_0\n- pyopengl-accelerate=3.1.1a1=np113py27_0\n- pyqt=5.6.0=py27_2\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.13=1\n- python-dateutil=2.6.1=py27_0\n- pytz=2017.2=py27_0\n- pyyaml=3.12=py27_0\n- pyzmq=16.0.2=py27_0\n- qt=5.6.2=vc9_6\n- qtawesome=0.4.4=py27_0\n- qtconsole=4.3.1=py27_0\n- qtpy=1.3.1=py27_0\n- requests=2.14.2=py27_0\n- scandir=1.5=py27_0\n- scipy=0.19.1=np113py27_0\n- setuptools=36.4.0=py27_1\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.18=py27_0\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.5.0.1=py27_0\n- testpath=0.3.1=py27_0\n- tornado=4.5.2=py27_0\n- traitlets=4.3.2=py27_0\n- vc=9=0\n- vs2008_runtime=9.00.30729.5054=0\n- wcwidth=0.1.7=py27_0\n- wheel=0.29.0=py27_0\n- widgetsnbextension=3.0.2=py27_0\n- win_unicode_console=0.5=py27_0\n- wincertstore=0.2=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.11=vc9_0\n- ffmpeg=3.4.1\n- pip:\n  - arrow==0.7.0\n  - backports-abc==0.5\n  - backports.shutil-get-terminal-size==1.0.0\n  - backports.ssl-match-hostname==3.5.0.1\n  - cffi==1.11.2\n  - configobj==5.0.6\n  - et-xmlfile==1.0.1\n  - http://files.cogsci.nl/software/opensesame/pre-releases/expyriment-0.9.1b2_11_gc100ee8-py2-none-any.whl\n  - fastnumbers==2.0.2\n  - future==0.16.0\n  - humanize==0.5.1\n  - imageio==2.2.0\n  - ipython-genutils==0.2.0\n  - jdcal==1.3\n  - json-tricks==3.11.0\n  - jupyter-client==5.1.0\n  - jupyter-console==5.2.0\n  - jupyter-core==4.3.0\n  - mediadecoder==0.1.5\n  - moviepy==0.2.3.2\n  - oauthlib==1.1.2\n  - openpyxl==2.4.9\n  - opensesame-extension-osf==1.1.1\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-plugin-psychopy==0.5.0\n  - opensesame-windows-launcher==0.4.2 # Updated in 3.2.2\n  - prettytable==0.7.2\n  - prompt-toolkit==1.0.15\n  - psychopy==1.85.3\n  - pyaudio==0.2.11\n  - pycparser==2.18\n  - pygame==1.9.3\n  - pyglet==1.3.0\n  - python-bidi==0.4.0\n  - python-datamatrix==0.8.3 # Updated in 3.2.2\n  - python-fileinspector==1.0.2\n  - python-opensesame==3.2.4 # Updated in 3.2.4\n  - python-pseudorandom==0.2.2\n  - python-pygaze==0.6.0a25 # Updated in 3.2.2\n  - python-qdatamatrix==0.1.18\n  - python-qnotifications==1.1.1\n  - python-qosf==1.2.3 # Updated in 3.2.3\n  - python-qprogedit==4.0.11\n  - python-qtpip==0.1.5\n  - requests-oauthlib==0.6.2\n  - sounddevice==0.3.9\n  - tqdm==4.19.5\n  - webcolors==1.5\n  - win-unicode-console==0.5\n  - yolk3k==0.9\n~~~\n\n\n### Windows Python 3.6": {
    "fr": "~~~ .yaml\nname: opensesame_3.2.4-py3.6-win32-1\nchannels:\n- cogsci\n- conda-forge\n- defaults\ndependencies:\n- anaconda-client=1.6.3=py36_0\n- backports=1.0=py36_1\n- backports.shutil_get_terminal_size=1.0.0=py36_2\n- bleach=1.5.0=py36_0\n- bzip2=1.0.6=vc14_1\n- certifi=2016.2.28=py36_0\n- clyent=1.2.2=py36_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.1.2=py_0\n- qscintilla2=2.9.3=py36_vc14_0\n- requests_oauthlib=0.6.2=py_0\n- webcolors=1.5=py36_0\n- colorama=0.3.9=py36_0\n- decorator=4.1.2=py36_0\n- entrypoints=0.2.3=py36_0\n- freetype=2.5.5=vc14_2\n- html5lib=0.999=py36_0\n- icu=57.1=vc14_0\n- ipykernel=4.6.1=py36_0\n- ipython=6.1.0=py36_0\n- ipython_genutils=0.2.0=py36_0\n- ipywidgets=6.0.0=py36_0\n- jinja2=2.9.6=py36_0\n- jpeg=9b=vc14_0\n- jsonschema=2.6.0=py36_0\n- jupyter=1.0.0=py36_4\n- jupyter_client=5.1.0=py36_0\n- jupyter_console=5.2.0=py36_0\n- jupyter_core=4.3.0=py36_0\n- libpng=1.6.30=vc14_1\n- libtiff=4.0.6=vc14_3\n- markupsafe=1.0=py36_0\n- mistune=0.7.4=py36_0\n- mkl=2017.0.3=0\n- nbconvert=5.2.1=py36_0\n- nbformat=4.4.0=py36_0\n- notebook=5.0.0=py36_0\n- numpy=1.13.1=py36_0\n- olefile=0.44=py36_0\n- openssl=1.0.2l=vc14_0\n- pandocfilters=1.4.2=py36_0\n- path.py=10.3.1=py36_0\n- pathlib2=2.3.0=py36_0\n- pickleshare=0.7.4=py36_0\n- pillow=4.2.1=py36_0\n- pip=9.0.1=py36_1\n- prompt_toolkit=1.0.15=py36_0\n- pygments=2.2.0=py36_0\n- pyopengl=3.1.1a1=np113py36_0\n- pyopengl-accelerate=3.1.1a1=np113py36_0\n- pyqt=5.6.0=py36_2\n- readline=6.2=2\n- setentrypoints=0.1.6.1=py36_0\n- simplegeneric=0.8.1=py36_1\n- sip=4.18=py36_0\n- six=1.10.0=py36_0\n- sqlite=3.13.0=vc14_1\n- vs2015_runtime=14.0.25420=0\n- wcwidth=0.1.7=py36_0\n- wheel=0.29.0=py36_0\n- widgetsnbextension=3.0.2=py36_0\n- zlib=1.2.11=vc14_0\n- ffmpeg=3.4.1\n- pip:\n  - arrow==0.7.0\n  - backports.shutil-get-terminal-size==1.0.0\n  - cffi==1.11.2\n  - configobj==5.0.6\n  - et-xmlfile==1.0.1\n  - http://files.cogsci.nl/software/opensesame/pre-releases/expyriment-0.9.1b2_11_gc100ee8-py2-none-any.whl\n  - fastnumbers==2.0.2\n  - future==0.16.0\n  - humanize==0.5.1\n  - imageio==2.2.0\n  - ipython-genutils==0.2.0\n  - jdcal==1.3\n  - json-tricks==3.11.0\n  - jupyter-client==5.1.0\n  - jupyter-console==5.2.0\n  - jupyter-core==4.3.0\n  - mediadecoder==0.1.5\n  - moviepy==0.2.3.2\n  - oauthlib==1.1.2\n  - openpyxl==2.4.9\n  - opensesame-extension-osf==1.1.1\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-plugin-psychopy==0.5.0\n  - opensesame-windows-launcher==0.4.2 # Updated in 3.2.2\n  - prettytable==0.7.2\n  - prompt-toolkit==1.0.15\n  - psychopy==1.85.3\n  - pyaudio==0.2.11\n  - pycparser==2.18\n  - pygame==1.9.3\n  - pyglet==1.3.0\n  - python-bidi==0.4.0\n  - python-datamatrix==0.8.3 # Updated in 3.2.2\n  - python-fileinspector==1.0.2\n  - python-opensesame==3.2.4 # Updated in 3.2.4\n  - python-pseudorandom==0.2.2\n  - python-pygaze==0.6.0a25 # Updated in 3.2.2\n  - python-qdatamatrix==0.1.18\n  - python-qnotifications==1.1.1\n  - python-qosf==1.2.3 # Updated in 3.2.3\n  - python-qprogedit==4.0.11\n  - python-qtpip==0.1.5\n  - requests-oauthlib==0.6.2\n  - sounddevice==0.3.9\n  - tqdm==4.19.5\n  - webcolors==1.5\n  - yolk3k==0.9\n~~~\n\n### Windows Python 3.6"
  },
  "Download `stimuli.zip` and extract it somewhere (to your desktop, for example). Next, in OpenSesame, click on the 'Show file pool' button in the main toolbar (or: Menu →View → Show file pool). This will show the file pool, by default on the right side of the window. The easiest way to add the stimuli to the file pool is by dragging them from the desktop (or wherever you have extracted the files to) into the file pool. Alternatively, you can click on the '+' button in the file pool and add files using the file-selection dialog that appears. The file pool will automatically be saved with your experiment.\n\nAfter you have added all stimuli, your file pool looks as in %FigStep4.\n\n<notranslate>\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  The file pool at the end of Step 3.\n</notranslate>\n\n### Step 4: Define the experimental variables in the block_loop\n\nConceptually, our experiment has a fully crossed 3×2 design: We have three types of visual stimuli (cats, dogs, and capybaras) which occur in combination with two types of auditory stimuli (meows and barks). However, we have five exemplars for each stimulus type: five meow sounds, five capybara pictures, etc. From a technical point of view, it therefore makes sense to treat our experiment as a 5×5×3×2 design, in which picture number and sound number are factors with five levels.\n\nOpenSesame is very good at generating full-factorial designs. First, open *block_loop* by clicking on it in the overview area. Next, click on the Full-Factorial Design button. This will open a wizard for generating full-factorial designs, which works in a straightforward way: Every column corresponds to an experimental variable (i.e. a factor). The first row is the name of the variable, the rows below contain all possible values (i.e. levels). In our case, we can specify our 5×5×3×2 design as shown in %FigLoopWizard.\n\n<notranslate>\nfigure:\n id: FigLoopWizard\n source: loop-wizard.png\n caption: |\n  The loop wizard generates full-factorial designs.\n</notranslate>\n\nAfter clicking 'Ok', you will see that there is now a LOOP table with four rows, one for each experimental variable. There are 150 cycles (=5×5×3×2), which means that we have 150 unique trials. Your LOOP table now looks as in %FigStep5.\n\n<notranslate>\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  The LOOP table at the end of Step 4.\n</notranslate>\n\n### Step 5: Add items to the trial sequence\n\nOpen *trial_sequence*, which is still empty. It's time to add some items! Our basic *trial_sequence* is:\n\n1. A SKETCHPAD to display a central fixation dot for 500 ms\n2. A SAMPLER to play an animal sound\n3. A SKETCHPAD to display an animal picture\n4. A MOUSE_RESPONSE to collect a response\n5. A LOGGER to write the data to file\n\nTo add these items, simply drag them one by one from the item toolbar into the *trial_sequence*. If you accidentally drop items in the wrong place, you can simply re-order them by dragging and dropping. Once all items are in the correct order, give each of them a sensible name. The overview area now looks as in %FigStep6.\n\n<notranslate>\nfigure:\n id: FigStep6\n source: step6.png\n caption: |\n  The overview area at the end of Step 5.\n</notranslate>\n\n### Step 6: Define the central fixation dot\n\nClick on *fixation_dot* in the overview area. This opens a basic drawing board that you can use to design your visual stimuli. To draw a central fixation dot, first click on the crosshair icon, and then click on the center of the display, i.e. at position (0, 0).\n\nWe also need to specify for how long the fixation dot is visible. To do so, change the duration from 'keypress' to 495 ms, in order to specify a 500 ms duration. (See Background box 4 for an explanation.)\n\nThe *fixation_dot* item now looks as in %FigStep7.\n\n<notranslate>\nfigure:\n id: FigStep7\n source: step7.png\n caption: |\n  The *fixation_dot* item at the end of Step 6.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 4: Selecting the correct duration**": {
    "fr": "Téléchargez `stimuli.zip` et extrayez-le quelque part (sur votre bureau, par exemple). Ensuite, dans OpenSesame, cliquez sur le bouton 'Afficher le pool de fichiers' dans la barre d'outils principale (ou : Menu → Affichage → Afficher le pool de fichiers). Ceci affichera le pool de fichiers, par défaut sur le côté droit de la fenêtre. La manière la plus simple d'ajouter les stimuli au pool de fichiers est de les faire glisser depuis le bureau (ou l'endroit où vous avez extrait les fichiers) dans le pool de fichiers. Sinon, vous pouvez cliquer sur le bouton '+' dans le pool de fichiers et ajouter des fichiers en utilisant la boîte de dialogue de sélection de fichiers qui apparaît. Le pool de fichiers sera automatiquement sauvegardé avec votre expérience.\n\nAprès avoir ajouté tous les stimuli, votre pool de fichiers ressemble à celui de %FigStep4.\n\n<notranslate>\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  Le pool de fichiers à la fin de l'étape 3.\n</notranslate>\n\n### Étape 4 : Définir les variables expérimentales dans le bloc_loop\n\nConceptuellement, notre expérience a un design entièrement croisé 3×2 : Nous avons trois types de stimuli visuels (chats, chiens et capybaras) qui se produisent en combinaison avec deux types de stimuli auditifs (miaulements et aboiements). Cependant, nous avons cinq exemples pour chaque type de stimulus : cinq sons de miaulement, cinq images de capybara, etc. D'un point de vue technique, il est donc logique de traiter notre expérience comme un design 5×5×3×2, dans lequel le numéro de l'image et le numéro du son sont des facteurs avec cinq niveaux.\n\nOpenSesame est très bon pour générer des designs factoriels complets. Tout d'abord, ouvrez *block_loop* en cliquant dessus dans la zone d'aperçu. Ensuite, cliquez sur le bouton Design factoriel complet. Ceci ouvrira un assistant pour générer des designs factoriels complets, qui fonctionne de manière simple : Chaque colonne correspond à une variable expérimentale (c.-à-d. un facteur). La première ligne est le nom de la variable, les lignes ci-dessous contiennent toutes les valeurs possibles (c.-à-d. les niveaux). Dans notre cas, nous pouvons spécifier notre design 5×5×3×2 comme indiqué dans %FigLoopWizard.\n\n<notranslate>\nfigure:\n id: FigLoopWizard\n source: loop-wizard.png\n caption: |\n  L'assistant de boucle génère des designs factoriels complets.\n</notranslate>\n\nAprès avoir cliqué sur 'Ok', vous verrez qu'il y a maintenant une table LOOP avec quatre rangées, une pour chaque variable expérimentale. Il y a 150 cycles (=5×5×3×2), ce qui signifie que nous avons 150 essais uniques. Votre table LOOP ressemble maintenant à celle de %FigStep5.\n\n<notranslate>\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  La table LOOP à la fin de l'étape 4.\n</notranslate>\n\n### Étape 5 : Ajouter des éléments à la séquence d'essais\n\nOuvrez *trial_sequence*, qui est toujours vide. Il est temps d'ajouter des éléments ! Notre *trial_sequence* de base est :\n\n1. Un SKETCHPAD pour afficher un point de fixation central pendant 500 ms\n2. Un SAMPLER pour jouer un son d'animal\n3. Un SKETCHPAD pour afficher une image d'animal\n4. Un MOUSE_RESPONSE pour recueillir une réponse\n5. Un LOGGER pour écrire les données dans un fichier\n\nPour ajouter ces éléments, faites-les glisser un par un depuis la barre d'outils des éléments dans la *trial_sequence*. Si vous déposez accidentellement des éléments au mauvais endroit, vous pouvez simplement les réorganiser en les faisant glisser et en les déposant. Une fois que tous les éléments sont dans le bon ordre, donnez à chacun d'eux un nom sensé. La zone d'aperçu ressemble maintenant à celle de %FigStep6.\n\n<notranslate>\nfigure:\n id: FigStep6\n source: step6.png\n caption: |\n  La zone d'aperçu à la fin de l'étape 5.\n</notranslate>\n\n### Étape 6 : Définir le point de fixation central\n\nCliquez sur *fixation_dot* dans la zone d'aperçu. Cela ouvre un tableau de dessin de base que vous pouvez utiliser pour concevoir vos stimuli visuels. Pour dessiner un point de fixation central, cliquez d'abord sur l'icône de la croix, puis cliquez sur le centre de l'affichage, c'est-à-dire à la position (0, 0).\n\nNous devons également spécifier combien de temps le point de fixation est visible. Pour ce faire, changez la durée de 'keypress' à 495 ms, afin de spécifier une durée de 500 ms. (Voir le cadre d'information 4 pour une explication.)\n\nL'élément *fixation_dot* ressemble désormais à celui de %FigStep7.\n\n<notranslate>\nfigure:\n id: FigStep7\n source: step7.png\n caption: |\n  L'élément *fixation_dot* à la fin de l'étape 6.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré d'information 4 : Sélectionner la bonne durée**"
  },
  "<notranslate>[TOC]</notranslate>\n\n\n## What is an OpenSesame plugin?\n\n*Plugins* are extra items that appear in the OpenSesame item toolbar. Plugins add functionality that you can use in experiments. (To add functionality to the OpenSesame user interface, you need an [*extension*](%url:extension%).)\n\n\n\n## Relevant files\n\nOne or more plugins are put together in a plugin package, which is always a subpackage of `opensesame_plugins` (which is itself a so-called implicit namespace package, but that's a technical detail that is not very important). Let's say that your plugin package is called `example`, and that it contains a single plugin (there can be more) called `example_plugin`. This would correspond to the following file-and-folder structure:\n\n```\nopensesame_plugins/\n    example/\n        __init__.py                  # can be empty but must exist\n        example_plugin/\n            __init__.py              # contains plugin information\n            example_plugin.py        # contains plugin class\n            example_plugin.png       # 16 x 16 icon (optional)\n            example_plugin_large.png # 32 x 32 icon (optional)\n            example_plugin.md        # Help file in Markdown format (optional)\n```\n\n## Icons\n\nEach plug-in needs an icon, which you can specify in one of two ways:\n\n- Include two icon files in the plugin folder as shown above:\n    - A 16x16 px png file called `[plugin_name].png`; and\n    - A 32x32 px png file called `[plugin_name]_large.png`.\n- Or specify an `icon` name in the plugin information (`__init__.py`). If you do this, the plugin icon will be taken from the icon theme.\n\n\n## Help file\n\nYou can provide a help file in Markdown or HTML format. To add a Markdown help file, simply create a file called `[plugin_name].md` in the plugin folder. For an HTML help file, create a file called `[plugin_name].html`. Markdown format is preferred, because it is easier to read. Strictly speaking, the help file is optional, and your plugin will work without it. However, an informative help file is an essential part of a good plugin.\n\n\n## Defining the GUI\n\nThe plugin information (`__init__.py`) defines (at least) a docstring, a `category` variable, and a `controls` variable.\n\nThe `controls` variable is a list of `dict` elements that define the GUI controls. The most important fields are:\n\n- `type` specifies the type of the control. Possible values:\n\t- `checkbox` is a checkable box (`QtGui.QCheckBox`)\n\t- `color_edit` is a color-selection widget (`libqtopensesame.widgets.color_edit.ColorEdit`)\n\t- `combobox` is a drop-down box with multiple options (`QtGui.QComboBox`)\n\t- `editor` is a multiline text editor (using PyQode)\n\t- `filepool` is a file-selection widget (`QtGui.QLineEdit`)\n\t- `line_edit` is a single-line text input (`QtGui.QLineEdit`)\n\t- `spinbox` is a text-based numeric-value selector (`QtGui.QSpinBox`)\n\t- `slider` is a sliding numeric-value selector (`QtGui.QSlider`)\n\t- `text` is a non-interactive text string (`QtGui.QLabel`)\n- `var` specifies the name of the variable that should be set using the control (not applicable if `type` is `text`).\n- `label` specifies the text label for the control.\n- `name` (optional) specifies under which name the widget should be added to the plugin object, so that it can be referred to as `self.[name]`.\n- `tooltip` (optional) an informative tooltip.\n\n\n```python\n\"\"\"A docstring with a description of the plugin\"\"\"\n\n# The category determines the group for the plugin in the item toolbar\ncategory = \"Visual stimuli\"\n# Defines the GUI controls\ncontrols = [\n    {\n        \"type\": \"checkbox\",\n        \"var\": \"checkbox\",\n        \"label\": \"Example checkbox\",\n        \"name\": \"checkbox_widget\",\n        \"tooltip\": \"An example checkbox\"\n    }, {\n        \"type\": \"color_edit\",\n        \"var\": \"color\",\n        \"label\": \"Color\",\n        \"name\": \"color_widget\",\n        \"tooltip\": \"An example color edit\"\n    }\n]\n```\n\nSee the [example](#examples) plugin for a list of all controls and options.": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## Qu'est-ce qu'un plugin OpenSesame ?\n\nLes *Plugins* sont des éléments supplémentaires qui apparaissent dans la barre d'outils des éléments OpenSesame. Les plugins ajoutent des fonctionnalités que vous pouvez utiliser dans les expérimentations. (Pour ajouter des fonctionnalités à l'interface utilisateur d'OpenSesame, vous avez besoin d'une [*extension*](%url:extension%).)\n\n## Fichiers pertinents\n\nUn ou plusieurs plugins sont regroupés dans un package de plugins, qui est toujours un sous-paquet de `opensesame_plugins` (qui est lui-même un soi-disant paquet de noms implicite, mais c'est un détail technique qui n'est pas très important). Disons que votre package de plugins s'appelle `example`, et qu'il contient un seul plugin (il peut y en avoir plus) appelé `example_plugin`. Ceci correspondrait à la structure de fichiers et de dossiers suivante :\n\n```\nopensesame_plugins/\n    example/\n        __init__.py                  # peut être vide mais doit exister\n        example_plugin/\n            __init__.py              # contient les informations sur le plugin\n            example_plugin.py        # contient la classe du plugin\n            example_plugin.png       # icône 16 x 16 (facultatif)\n            example_plugin_large.png # icône 32 x 32 (facultatif)\n            example_plugin.md        # fichier d'aide au format Markdown (facultatif)\n```\n\n## Icônes\n\nChaque plugin a besoin d'une icône, que vous pouvez spécifier de deux façons :\n\n- Inclure deux fichiers d'icônes dans le dossier du plugin comme indiqué ci-dessus :\n    - Un fichier png de 16x16 px appelé `[plugin_name].png` et ;\n    - Un fichier png de 32x32 px appelé `[plugin_name]_large.png`.\n- Ou spécifier un nom d'`icône` dans les informations du plugin (`__init__.py`). Si vous faites cela, l'icône du plugin sera prise dans le thème des icônes.\n\n## Fichier d'aide\n\nVous pouvez fournir un fichier d'aide au format Markdown ou HTML. Pour ajouter un fichier d'aide au format Markdown, créez simplement un fichier appelé `[plugin_name].md` dans le dossier du plugin. Pour un fichier d'aide en HTML, créez un fichier appelé `[plugin_name].html`. Le format Markdown est préféré, car il est plus facile à lire. Strictement parlant, le fichier d'aide est facultatif, et votre plugin fonctionnera sans lui. Cependant, un fichier d'aide informatif est une partie essentielle d'un bon plugin.\n\n## Définir l'interface graphique\n\nLes informations sur le plugin (`__init__.py`) définissent (au moins) une chaîne de caractères, une variable `category` et une variable `controls`.\n\nLa variable `controls` est une liste d'éléments `dict` qui définissent les contrôles de l'interface graphique. Les champs les plus importants sont :\n\n- `type` spécifie le type de contrôle. Valeurs possibles :\n\t- `checkbox` est une case à cocher (`QtGui.QCheckBox`)\n\t- `color_edit` est un widget de sélection de couleur (`libqtopensesame.widgets.color_edit.ColorEdit`)\n\t- `combobox` est une boîte déroulante avec plusieurs options (`QtGui.QComboBox`)\n\t- `editor` est un éditeur de texte sur plusieurs lignes (utilisant PyQode)\n\t- `filepool` est un widget de sélection de fichier (`QtGui.QLineEdit`)\n\t- `line_edit` est une entrée de texte sur une seule ligne (`QtGui.QLineEdit`)\n\t- `spinbox` est un sélecteur de valeur numérique basé sur du texte (`QtGui.QSpinBox`)\n\t- `slider` est un sélecteur de valeur numérique glissant (`QtGui.QSlider`)\n\t- `text` est une chaîne de texte non interactive (`QtGui.QLabel`)\n- `var` spécifie le nom de la variable qui doit être définie à l'aide du contrôle (non applicable si `type` est `text`).\n- `label` spécifie l'étiquette de texte pour le contrôle.\n- `name` (facultatif) spécifie sous quel nom le widget doit être ajouté à l'objet plugin, de sorte qu'il puisse être référencé en tant que `self.[name]`.\n- `tooltip` (facultatif) un tooltip informatif.\n\n```python\n\"\"\"A docstring with a description of the plugin\"\"\"\n\n# La catégorie détermine le groupe pour le plugin dans la barre d'outils de l'item\ncategory = \"Stimuli visuels\"\n# Définit les contrôles de l'interface graphique\ncontrols = [\n    {\n        \"type\": \"checkbox\",\n        \"var\": \"checkbox\",\n        \"label\": \"Exemple de case à cocher\",\n        \"name\": \"widget_checkbox\",\n        \"tooltip\": \"Un exemple de case à cocher\"\n    }, {\n        \"type\": \"color_edit\",\n        \"var\": \"color\",\n        \"label\": \"Couleur\",\n        \"name\": \"widget_color\",\n        \"tooltip\": \"Un exemple de modification de couleur\"\n    }\n]\n```\n\nVoir le plugin [exemple](#examples) pour une liste de tous les contrôles et options."
  },
  "Why specify a duration of 495 if we want a duration of 500 ms? The reason for this is that the actual display-presentation duration is always rounded up to a value that is compatible with your monitor's refresh rate. This may sound complicated, but for most purposes the following rules of thumb are sufficient:\n\n1. Choose a duration that is possible given your monitor's refresh rate. For example, if your monitor's refresh rate is 60 Hz, this means that every frame lasts 16.7 ms (=1000 ms/60 Hz). Therefore, on a 60 Hz monitor, you should always select a duration that is a multiple of 16.7 ms, such as 16.7, 33.3, 50, 100, etc.\n2. In the duration field of the SKETCHPAD specify a duration that is a few milliseconds shorter than what you're aiming for. So if you want to present a SKETCHPAD for 50 ms, choose a duration of 45. If you want to present a SKETCHPAD for 1000 ms, choose a duration of 995. Etcetera.\n\nFor a detailed discussion of experimental timing, see:\n\n- %link:timing%\n\n</div>\n\n\n### Step 7: Define the animal sound\n\nOpen *animal_sound*. The SAMPLER item provides a number of options, the most important being the sound file that should be played. Click on the browse button to open the file-pool selection dialog, and select one of the sound files, such as `bark1.ogg`.\n\nOf course, we don't want to play the same sound over-and-over again! Instead, we want to select a sound based on the variables `sound` and `sound_nr` that we have defined in the *block_loop* (Step 5). To do this, simply replace the part of the string that you want to have depend on a variable by the name of that variable between square brackets. More specifically, 'bark1.ogg' becomes '[sound][sound_nr].ogg', because we want to replace 'bark' by the value of the variable `sound` and '1' by the value of `sound_nr`.\n\nWe also need to change the duration of the SAMPLER. By default, the duration is 'sound', which means that the experiment will pause while the sound is playing. Change the duration to 0. This does not mean that the sound will be played for only 0 ms, but that the experiment will advance right away to the next item, while the sound continues to play in the background. The item *animal_sound* now looks as shown in %FigStep8.\n\n<notranslate>\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  The item *animal_sound* at the end of Step 7.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 5: Variables**\n\nFor more information about using variables, see:\n\n- %link:manual/variables%\n\n</div>\n\n### Step 8: Define the animal picture\n\nOpen *animal_picture*. Select the image tool by clicking on the button with the landscape-like icon. Click on the center (0, 0) of the display. In the File Pool dialog that appears, select `capybara1.png`. The capybara's sideways glance will now lazily stare at you from the center of the display. But of course, we don't always want to show the same capybara. Instead, we want to have the image depend on the variables `animal` and `pic_nr` that we have defined in the *block_loop* (Step 4).\n\nWe can use essentially the same trick as we did for *animal_sound*, although things work slightly differently for images. First, right-click on the capybara and select 'Edit script'. This allows you to edit the following line of OpenSesame script that corresponds to the capybara picture:\n\n```python\ndraw image center=1 file=\"capybara1.png\" scale=1 show_if=always x=0 y=0 z_index=0\n```\n\nNow change the name of image file from 'capybara.png' to '[animal][pic_nr].png':\n\n```python\ndraw image center=1 file=\"[animal][pic_nr].png\" scale=1 show_if=always x=0 y=0 z_index=0\n```\n\nClick on 'Ok' to apply the change. The capybara is now gone, replaced by a placeholder image, and OpenSesame tells you that one object is not shown, because it is defined using variables. Don't worry, it will be shown during the experiment!\n\nWe also add two response circles:": {
    "fr": "Pourquoi spécifier une durée de 495 si nous voulons une durée de 500 ms ? La raison en est que la durée réelle de présentation de l'affichage est toujours arrondie à une valeur compatible avec la fréquence de rafraîchissement de votre moniteur. Cela peut sembler compliqué, mais pour la plupart des besoins, les règles générales suivantes sont suffisantes :\n\n1. Choisissez une durée qui est possible compte tenu de la fréquence de rafraîchissement de votre moniteur. Par exemple, si la fréquence de rafraîchissement de votre moniteur est de 60 Hz, cela signifie que chaque image dure 16,7 ms (= 1000 ms/60 Hz). Par conséquent, sur un moniteur de 60 Hz, vous devez toujours sélectionner une durée qui est un multiple de 16,7 ms, comme 16,7, 33,3, 50, 100, etc.\n2. Dans le champ de durée du SKETCHPAD, spécifiez une durée qui est de quelques millisecondes plus courte que ce que vous visez. Donc, si vous voulez présenter un SKETCHPAD pendant 50 ms, choisissez une durée de 45. Si vous voulez présenter un SKETCHPAD pendant 1000 ms, choisissez une durée de 995. Etc.\n\nPour une discussion détaillée sur le temps expérimental, voir :\n\n- %link:timing%\n\n</div>\n\n\n### Étape 7 : Définir le son de l'animal\n\nOuvrez *animal_sound*. L'élément SAMPLER offre un certain nombre d'options, la plus importante étant le fichier son qui doit être joué. Cliquez sur le bouton parcourir pour ouvrir la boîte de dialogue de sélection de la file-pool, et sélectionnez l'un des fichiers son, comme `bark1.ogg`.\n\nBien sûr, nous ne voulons pas toujours jouer le même son ! Au lieu de cela, nous voulons sélectionner un son en fonction des variables `sound` et `sound_nr` que nous avons définies dans la boucle *block_loop* (étape 5). Pour ce faire, il suffit de remplacer la partie de la chaîne que vous voulez dépendre d'une variable par le nom de cette variable entre crochets. Plus précisément, 'bark1.ogg' devient '[sound][sound_nr].ogg', car nous voulons remplacer 'bark' par la valeur de la variable `sound` et '1' par la valeur de `sound_nr`.\n\nNous devons également changer la durée du SAMPLER. Par défaut, la durée est 'sound', ce qui signifie que l'expérience sera en pause pendant la lecture du son. Changez la durée à 0. Cela ne signifie pas que le son sera joué pendant seulement 0 ms, mais que l'expérience passera tout de suite à l'élément suivant, pendant que le son continue de jouer en arrière-plan. L'élément *animal_sound* ressemble maintenant à ce qui est montré dans %FigStep8.\n\n<notranslate>\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  L'élément *animal_sound* à la fin de l'étape 7.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 5 : Variables**\n\nPour plus d'informations sur l'utilisation des variables, voir :\n\n- %link:manual/variables%\n\n</div>\n\n### Étape 8 : Définir l'image de l'animal\n\nOuvrez *animal_picture*. Sélectionnez l'outil image en cliquant sur le bouton avec l'icône de paysage. Cliquez sur le centre (0, 0) de l'affichage. Dans la boîte de dialogue File Pool qui apparaît, sélectionnez `capybara1.png`. Le regard latéral du capybara vous fixera paresseusement depuis le centre de l'affichage. Mais bien sûr, nous ne voulons pas toujours montrer le même capybara. Au lieu de cela, nous voulons que l'image dépende des variables `animal` et `pic_nr` que nous avons définies dans la boucle *block_loop* (étape 4).\n\nNous pouvons utiliser essentiellement la même astuce que nous avons fait pour *animal_sound*, bien que les choses fonctionnent légèrement différemment pour les images. Tout d'abord, faites un clic droit sur le capybara et sélectionnez \"Modifier le script\". Cela vous permet de modifier la ligne de script OpenSesame suivante correspondant à l'image du capybara :\n\n```python\ndraw image center=1 file=\"capybara1.png\" scale=1 show_if=always x=0 y=0 z_index=0\n```\n\nMaintenant, changez le nom du fichier image de 'capybara.png' en '[animal][pic_nr].png' :\n\n```python\ndraw image center=1 file=\"[animal][pic_nr].png\" scale=1 show_if=always x=0 y=0 z_index=0\n```\n\nCliquez sur \"Ok\" pour appliquer le changement. Le capybara a maintenant disparu, remplacé par une image réservée, et OpenSesame vous dit qu'un objet n'est pas affiché, car il est défini à l'aide de variables. Ne vous inquiétez pas, il sera affiché pendant l'expérience !\n\nNous ajoutons également deux cercles de réponse :"
  },
  "~~~ .yaml\nname: opensesame_3.2.4-py3.6-win64-1\nchannels:\n- conda-forge\n- cogsci\n- defaults\ndependencies:\n- anaconda-client=1.6.5=py_0\n- asn1crypto=0.22.0=py36_0\n- bleach=2.0.0=py36_0\n- ca-certificates=2017.11.5=0\n- certifi=2017.11.5=py36_0\n- cffi=1.11.2=py36_0\n- chardet=3.0.4=py36_0\n- clyent=1.2.2=py36_0\n- colorama=0.3.9=py36_0\n- cryptography=2.1.4=py36_0\n- decorator=4.1.2=py36_0\n- entrypoints=0.2.3=py36_1\n- freetype=2.8.1=vc14_0\n- html5lib=1.0.1=py_0\n- icu=58.2=vc14_0\n- idna=2.6=py36_1\n- ipykernel=4.7.0=py36_0\n- ipython=6.2.1=py36_1\n- ipython_genutils=0.2.0=py36_0\n- ipywidgets=7.1.0=py36_0\n- jedi=0.10.2=py36_0\n- jinja2=2.10=py36_0\n- jpeg=9b=vc14_2\n- jsonschema=2.5.1=py36_0\n- jupyter=1.0.0=py36_0\n- jupyter_client=5.2.1=py36_0\n- jupyter_console=5.2.0=py36_0\n- jupyter_core=4.4.0=py_0\n- libpng=1.6.34=vc14_0\n- libtiff=4.0.9=vc14_0\n- markdown=2.6.9=py36_0\n- markupsafe=1.0=py36_0\n- mistune=0.8.3=py_0\n- nbconvert=5.3.1=py_1\n- nbformat=4.4.0=py36_0\n- notebook=5.2.2=py36_1\n- olefile=0.44=py36_0\n- openssl=1.0.2n=vc14_0\n- pandoc=2.1=0\n- pandocfilters=1.4.1=py36_0\n- pickleshare=0.7.4=py36_0\n- pillow=5.0.0=py36_0\n- pip=9.0.1=py36_1\n- prompt_toolkit=1.0.15=py36_0\n- pycparser=2.18=py36_0\n- pygments=2.2.0=py36_0\n- pyopengl=3.1.1a1=py36_0\n- pyopenssl=17.2.0=py36_0\n- pyqt=5.6.0=py36_4\n- pyserial=3.4=py36_0\n- pysocks=1.6.8=py36_1\n- python=3.6.4=0\n- python-dateutil=2.6.1=py36_0\n- pytz=2017.3=py_2\n- pyyaml=3.12=py36_1\n- pyzmq=16.0.2=py36_3\n- qscintilla2=2.9.3=py36_2\n- qt=5.6.2=vc14_1\n- qtconsole=4.3.1=py36_0\n- qtpy=1.3.1=py36_0\n- requests=2.18.4=py36_1\n- setuptools=38.4.0=py36_0\n- simplegeneric=0.8.1=py36_0\n- sip=4.18=py36_1\n- six=1.11.0=py36_1\n- sqlite=3.20.1=vc14_2\n- testpath=0.3.1=py36_0\n- tornado=4.5.3=py36_0\n- traitlets=4.3.2=py36_0\n- urllib3=1.22=py36_0\n- vc=14=0\n- vs2015_runtime=14.0.25420=0\n- wcwidth=0.1.7=py36_0\n- webencodings=0.5=py36_0\n- wheel=0.30.0=py36_2\n- widgetsnbextension=3.1.0=py36_0\n- win_inet_pton=1.0.1=py36_1\n- wincertstore=0.2=py36_0\n- yaml=0.1.7=vc14_0\n- zlib=1.2.11=vc14_0\n- mkl=2017.0.3=0\n- numpy=1.13.1=py36_0\n- pyopengl-accelerate=3.1.1a1=np113py36_0\n- scipy=0.19.1=np113py36_0\n- pip:\n  - arrow==0.12.0\n  - et-xmlfile==1.0.1\n  - expyriment==0.9.0\n  - fastnumbers==2.0.2\n  - future==0.16.0\n  - humanize==0.5.1\n  - imageio==2.1.2\n  - ipython-genutils==0.2.0\n  - jdcal==1.3\n  - jupyter-client==5.2.1\n  - jupyter-console==5.2.0\n  - jupyter-core==4.4.0\n  - mediadecoder==0.1.5\n  - moviepy==0.2.3.2\n  - oauthlib==2.0.6\n  - openpyxl==2.4.9\n  - opensesame-extension-osf==1.1.1\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - prettytable==0.7.2\n  - prompt-toolkit==1.0.15\n  - pyaudio==0.2.11\n  - pygame==1.9.3\n  - pyparallel==0.2.2\n  - python-bidi==0.4.0\n  - python-datamatrix==0.8.3 # Updated in 3.2.2\n  - python-fileinspector==1.0.2\n  - python-opensesame==3.2.4 # Updated in 3.2.4\n  - python-pseudorandom==0.2.2\n  - python-qdatamatrix==0.1.18 # Updated in 3.2.2\n  - python-qnotifications==1.1.1\n  - python-qosf==1.2.3 # Updated in 3.2.3\n  - python-qprogedit==4.0.11\n  - python-qtpip==0.1.5\n  - qtawesome==0.4.4\n  - requests-oauthlib==0.8.0\n  - sounddevice==0.3.10\n  - tqdm==4.11.2\n  - webcolors==1.7\n  - win-inet-pton==1.0.1\n  - yolk3k==0.9\n~~~\n": {
    "fr": "~~~ .yaml\nname: opensesame_3.2.4-py3.6-win64-1\nchannels:\n- conda-forge\n- cogsci\n- defaults\ndependencies:\n- anaconda-client=1.6.5=py_0\n- asn1crypto=0.22.0=py36_0\n- bleach=2.0.0=py36_0\n- ca-certificates=2017.11.5=0\n- certifi=2017.11.5=py36_0\n- cffi=1.11.2=py36_0\n- chardet=3.0.4=py36_0\n- clyent=1.2.2=py36_0\n- colorama=0.3.9=py36_0\n- cryptography=2.1.4=py36_0\n- decorator=4.1.2=py36_0\n- entrypoints=0.2.3=py36_1\n- freetype=2.8.1=vc14_0\n- html5lib=1.0.1=py_0\n- icu=58.2=vc14_0\n- idna=2.6=py36_1\n- ipykernel=4.7.0=py36_0\n- ipython=6.2.1=py36_1\n- ipython_genutils=0.2.0=py36_0\n- ipywidgets=7.1.0=py36_0\n- jedi=0.10.2=py36_0\n- jinja2=2.10=py36_0\n- jpeg=9b=vc14_2\n- jsonschema=2.5.1=py36_0\n- jupyter=1.0.0=py36_0\n- jupyter_client=5.2.1=py36_0\n- jupyter_console=5.2.0=py36_0\n- jupyter_core=4.4.0=py_0\n- libpng=1.6.34=vc14_0\n- libtiff=4.0.9=vc14_0\n- markdown=2.6.9=py36_0\n- markupsafe=1.0=py36_0\n- mistune=0.8.3=py_0\n- nbconvert=5.3.1=py_1\n- nbformat=4.4.0=py36_0\n- notebook=5.2.2=py36_1\n- olefile=0.44=py36_0\n- openssl=1.0.2n=vc14_0\n- pandoc=2.1=0\n- pandocfilters=1.4.1=py36_0\n- pickleshare=0.7.4=py36_0\n- pillow=5.0.0=py36_0\n- pip=9.0.1=py36_1\n- prompt_toolkit=1.0.15=py36_0\n- pycparser=2.18=py36_0\n- pygments=2.2.0=py36_0\n- pyopengl=3.1.1a1=py36_0\n- pyopenssl=17.2.0=py36_0\n- pyqt=5.6.0=py36_4\n- pyserial=3.4=py36_0\n- pysocks=1.6.8=py36_1\n- python=3.6.4=0\n- python-dateutil=2.6.1=py36_0\n- pytz=2017.3=py_2\n- pyyaml=3.12=py36_1\n- pyzmq=16.0.2=py36_3\n- qscintilla2=2.9.3=py36_2\n- qt=5.6.2=vc14_1\n- qtconsole=4.3.1=py36_0\n- qtpy=1.3.1=py36_0\n- requests=2.18.4=py36_1\n- setuptools=38.4.0=py36_0\n- simplegeneric=0.8.1=py36_0\n- sip=4.18=py36_1\n- six=1.11.0=py36_1\n- sqlite=3.20.1=vc14_2\n- testpath=0.3.1=py36_0\n- tornado=4.5.3=py36_0\n- traitlets=4.3.2=py36_0\n- urllib3=1.22=py36_0\n- vc=14=0\n- vs2015_runtime=14.0.25420=0\n- wcwidth=0.1.7=py36_0\n- webencodings=0.5=py36_0\n- wheel=0.30.0=py36_2\n- widgetsnbextension=3.1.0=py36_0\n- win_inet_pton=1.0.1=py36_1\n- wincertstore=0.2=py36_0\n- yaml=0.1.7=vc14_0\n- zlib=1.2.11=vc14_0\n- mkl=2017.0.3=0\n- numpy=1.13.1=py36_0\n- pyopengl-accelerate=3.1.1a1=np113py36_0\n- scipy=0.19.1=np113py36_0\n- pip:\n  - arrow==0.12.0\n  - et-xmlfile==1.0.1\n  - expyriment==0.9.0\n  - fastnumbers==2.0.2\n  - future==0.16.0\n  - humanize==0.5.1\n  - imageio==2.1.2\n  - ipython-genutils==0.2.0\n  - jdcal==1.3\n  - jupyter-client==5.2.1\n  - jupyter-console==5.2.0\n  - jupyter-core==4.4.0\n  - mediadecoder==0.1.5\n  - moviepy==0.2.3.2\n  - oauthlib==2.0.6\n  - openpyxl==2.4.9\n  - opensesame-extension-osf==1.1.1\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - prettytable==0.7.2\n  - prompt-toolkit==1.0.15\n  - pyaudio==0.2.11\n  - pygame==1.9.3\n  - pyparallel==0.2.2\n  - python-bidi==0.4.0\n  - python-datamatrix==0.8.3 # Mis à jour dans 3.2.2\n  - python-fileinspector==1.0.2\n  - python-opensesame==3.2.4 # Mis à jour dans 3.2.4\n  - python-pseudorandom==0.2.2\n  - python-qdatamatrix==0.1.18 # Mis à jour dans 3.2.2\n  - python-qnotifications==1.1.1\n  - python-qosf==1.2.3 # Mis à jour dans 3.2.3\n  - python-qprogedit==4.0.11\n  - python-qtpip==0.1.5\n  - qtawesome==0.4.4\n  - requests-oauthlib==0.8.0\n  - sounddevice==0.3.10\n  - tqdm==4.11.2\n  - webcolors==1.7\n  - win-inet-pton==1.0.1\n  - yolk3k==0.9\n~~~\n"
  },
  "\n## Writing the plugin code\n\nThe main plugin code is placed in `[plugin_name].py`. This file generally contains only a single class named `[PluginName].py`, that is, a class with the CamelCase equivalent of the plugin name, which inherits from `libopensesame.item.Item`. A basic plugin class looks like this:\n\n\n```python\nfrom libopensesame.py3compat import *\nfrom libopensesame.item import Item\nfrom libqtopensesame.items.qtautoplugin import QtAutoPlugin\nfrom openexp.canvas import Canvas\n\n\nclass ExamplePlugin(Item):\n    \"\"\"An example plugin that shows a simple canvas. The class name\n    should be the CamelCase version of the folder_name and file_name. So in\n    this case both the plugin folder (which is a Python package) and the\n    .py file (which is a Python module) are called example_plugin, whereas\n    the class is called ExamplePlugin.\n    \"\"\"\n    def reset(self):\n        \"\"\"Resets plug-in to initial values.\"\"\"\n        # Here we provide default values for the variables that are specified\n        # in __init__.py. If you do not provide default values, the plug-in\n        # will work, but the variables will be undefined when they are not\n        # explicitly # set in the GUI.\n        self.var.checkbox = 'yes'  # yes = checked, no = unchecked\n        self.var.color = 'white'\n        self.var.option = 'Option 1'\n        self.var.file = ''\n        self.var.text = 'Default text'\n        self.var.spinbox_value = 1\n        self.var.slider_value = 1\n        self.var.script = 'print(10)'\n\n    def prepare(self):\n        \"\"\"The preparation phase of the plug-in goes here.\"\"\"\n        # Call the parent constructor.\n        super().prepare()\n        # Here simply prepare a canvas with a fixatio dot.\n        self.c = Canvas(self.experiment)\n        self.c.fixdot()\n\n    def run(self):\n        \"\"\"The run phase of the plug-in goes here.\"\"\"\n        # self.set_item_onset() sets the time_[item name] variable. Optionally,\n        # you can pass a timestamp, such as returned by canvas.show().\n        self.set_item_onset(self.c.show())\n```\n\n\nIf you want to implement custom GUI controls for your plugin, you also need to implement a `Qt[PluginName]` class in the same file. This is illustrated in the [example](#examples) plugin. If you don't implement this class, a default GUI will be created based on the controls as defined in `__init__.py`.\n\n\n## Experimental variables\n\nExperimental variables are properties of the `var` object. An example is `self.var.my_line_edit_var` from the example above. These variables that define the plugin, and are parsed to and from the OpenSesame script. See also:\n\n- %link:manual/variables%\n\n\n## Building a package and uploading to pypi\n\nThe easiest way to build a package for your plugin is by defined a `pyproject.toml` file and using `poetry` to build the package and upload it to `pypi`.\n\n- <https://python-poetry.org/>\n\nAn example `pyproject.toml` file looks as follows:\n\n```toml\n[tool.poetry]\nname = \"opensesame-plugin-example\"\nversion = \"0.0.1\"\ndescription = \"An example plugin for OpenSesame\"\nauthors = [\"Sebastiaan Mathôt <s.mathot@cogsci.nl>\"]\nreadme = \"readme.md\"\npackages = [\n    {include = \"opensesame_plugins\"},\n]\n\n[tool.poetry.dependencies]\npython = \">= 3.7\"\nopensesame-core = \">= 4.0.0a0\"\n\n[build-system]\nrequires = [\"poetry-core\"]\nbuild-backend = \"poetry.core.masonry.api\"\n```\n\nOnce you have add this file to the root folder of your plugin code, you can build a `.whl` package by running:\n\n```bash\npoetry build\n```\n\nOnce you have succesfully built a package, create an account on <https://pypi.org/>, create an API token for your account, and authenticate `poetry` like this:\n\n```bash\npoetry config pypi-token.pypi [api_token]\n```\n\nOnce this is done, you can publish your package to PyPi by running the following command:\n\n```bash\npoetry publish\n```\n\n\nYour users will now be able to pip-install your plugin!\n\n```bash\npip install opensesame-plugin-example\n```\n\n\n## Examples\n\nFor a working example, see:": {
    "fr": "## Écrire le code du plugin\n\nLe code principal du plugin est placé dans `[nom_du_plugin].py`. Ce fichier contient généralement une seule classe nommée `[NomDuPlugin].py`, c'est-à-dire une classe avec l'équivalent CamelCase du nom du plugin, qui hérite de `libopensesame.item.Item`. Une classe de plugin de base ressemble à ceci :\n\n```python\nfrom libopensesame.py3compat import *\nfrom libopensesame.item import Item\nfrom libqtopensesame.items.qtautoplugin import QtAutoPlugin\nfrom openexp.canvas import Canvas\n\nclass ExemplePlugin(Item):\n    \"\"\"Un exemple de plugin qui affiche un simple canevas. Le nom de la classe\n    doit être la version CamelCase du nom_du_dossier et du nom_du_fichier. Ainsi, dans\n    ce cas, le dossier du plugin (qui est un package Python) et le \n    fichier .py (qui est un module Python) sont tous deux appelés exemple_plugin, tandis que\n    la classe est appelée ExemplePlugin.\n    \"\"\"\n    def reset(self):\n        \"\"\"Réinitialise le plug-in aux valeurs initiales.\"\"\"\n        # Ici, nous fournissons des valeurs par défaut pour les variables qui sont spécifiées\n        # dans __init__.py. Si vous ne fournissez pas de valeurs par défaut, le plug-in\n        # fonctionnera, mais les variables seront indéfinies lorsqu'elles ne sont pas\n        # explicitement définies dans l'interface graphique.\n        self.var.checkbox = 'yes'  # yes = coché, no = décoché\n        self.var.color = 'white'\n        self.var.option = 'Option 1'\n        self.var.file = ''\n        self.var.text = 'Texte par défaut'\n        self.var.spinbox_value = 1\n        self.var.slider_value = 1\n        self.var.script = 'print(10)'\n\n    def prepare(self):\n        \"\"\"La phase de préparation du plug-in se fait ici.\"\"\"\n        # Appelez le constructeur parent.\n        super().prepare()\n        # Ici, préparez simplement un canevas avec un point de fixation.\n        self.c = Canvas(self.experiment)\n        self.c.fixdot()\n\n    def run(self):\n        \"\"\"La phase d'exécution du plug-in se fait ici.\"\"\"\n        # self.set_item_onset() définit la variable time_[nom de l'élément]. En option,\n        # vous pouvez passer un horodatage, tel que renvoyé par canvas.show().\n        self.set_item_onset(self.c.show())\n```\n\nSi vous souhaitez implémenter des contrôles d'interface graphique personnalisés pour votre plugin, vous devez également implémenter une classe `Qt[NomDuPlugin]` dans le même fichier. Ceci est illustré dans le plugin [exemple](#exemples). Si vous n'implémentez pas cette classe, une interface graphique par défaut sera créée sur la base des contrôles tels que définis dans `__init__.py`.\n\n## Variables expérimentales\n\nLes variables expérimentales sont des propriétés de l'objet `var`. Un exemple est `self.var.my_line_edit_var` de l'exemple ci-dessus. Ces variables qui définissent le plugin, et sont analysées vers et depuis le script OpenSesame. Voir aussi :\n\n- %link:manuel/variables%\n\n## Construire un paquet et le télécharger sur pypi\n\nLa manière la plus simple de construire un paquet pour votre plugin est de définir un fichier `pyproject.toml` et d'utiliser `poetry` pour construire le paquet et le télécharger sur `pypi`.\n\n- <https://python-poetry.org/>\n\nUn exemple de fichier `pyproject.toml` est le suivant :\n\n```toml\n[tool.poetry]\nname = \"opensesame-plugin-example\"\nversion = \"0.0.1\"\ndescription = \"Un exemple de plugin pour OpenSesame\"\nauthors = [\"Sebastiaan Mathôt <s.mathot@cogsci.nl>\"]\nreadme = \"readme.md\"\npackages = [\n    {include = \"opensesame_plugins\"},\n]\n\n[tool.poetry.dependencies]\npython = \">= 3.7\"\nopensesame-core = \">= 4.0.0a0\"\n\n[build-system]\nrequires = [\"poetry-core\"]\nbuild-backend = \"poetry.core.masonry.api\"\n```\n\nUne fois que vous avez ajouté ce fichier au dossier racine de votre code de plugin, vous pouvez construire un paquet `.whl` en exécutant :\n\n```bash\npoetry build\n```\n\nUne fois que vous avez construit avec succès un paquet, créez un compte sur <https://pypi.org/>, créez un jeton API pour votre compte, et authentifiez `poetry` comme ceci :\n\n```bash\npoetry config pypi-token.pypi [api_token]\n```\n\nUne fois cela fait, vous pouvez publier votre paquet sur PyPi en exécutant la commande suivante :\n\n```bash\npoetry publish\n```\n\nVos utilisateurs pourront maintenant installer votre plugin avec pip !\n\n```bash\npip install opensesame-plugin-example\n```\n\n## Exemples\n\nPour un exemple fonctionnel, voir :"
  },
  "- <https://github.com/open-cogsci/opensesame-plugin-example>\n\nOther examples can be found in the `opensesame_plugins` folder of the OpenSesame source code:\n\n- <https://github.com/open-cogsci/OpenSesame/tree/milgram/opensesame_plugins/core>\n": {
    "fr": "- <https://github.com/open-cogsci/opensesame-plugin-example>\n\nD'autres exemples peuvent être trouvés dans le dossier `opensesame_plugins` du code source d'OpenSesame :\n\n- <https://github.com/open-cogsci/OpenSesame/tree/milgram/opensesame_plugins/core>"
  },
  "- One circle with the name 'dog' on the left side of the screen. (To remind the participant of the response rule, you can add a text element with the text 'dog' to the circle. This is purely visual.)\n- One circle with the name 'cat' on the right side of the screen. (To remind the participant of the response rule, you can add a text element with the text 'cat' to the circle.)\n\nWe are going to use these circles as *regions of interest* for our mouse responses. More specifically, because we have given the circles names, our *mouse_response* item will be able to check whether the mouse click falls inside one of these circles. We will get back to this in the Step 9.\n\nFinally, set 'Duration' field to '0'. This does not mean that the picture is presented for only 0 ms, but that the experiment will advance to the next item (*response*) right away. Since *response* waits for a response, but doesn't change what's on the screen, the target will remain visible until a response has been given.\n\n<notranslate>\nfigure:\n id: FigStep9\n source: step9.png\n caption: |\n  The *animal_picture* SKETCHPAD at the end of Step 8.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Background box 6: Image formats**\n\n__Tip__ -- OpenSesame can handle a wide variety of image formats. However, some (non-standard) `.bmp` formats are known to cause trouble. If you find that a `.bmp` image is not shown, you may want to consider using a different format, such as `.png`. You can convert images easily with free tools such as [GIMP].\n\n</div>\n\n\n### Step 9: Define the response\n\nOpen the *mouse_response* item. This is a MOUSE_RESPONSE item, which collects a single mouse click (or release). There are a few options:\n\n- __Correct response__ — this is where you can indicate which mouse button is the correct response. However, we will determine whether a response is correct based on where the participant clicks, and not based on which button is clicked, so we can leave this field empty.\n- __Allowed responses__ is a semicolon-separated list of mouse buttons that are accepted. Let's set this to 'left_button'.\n- __Timeout__ indicates a duration after which the response will be set to 'None', and the experiment will continue. A timeout is important in our experiment, because participants need to have the opportunity to *not* respond when they see a capybara. So let's set the timeout to 2000.\n- __Linked sketchpad__ indicates a SKETCHPAD of which the elements should be used as regions of interest. We will select *animal_picture*. Now, if we click on the element with the name 'cat', the variable `cursor_roi` will automatically be set to 'cat'.\n- __Visible mouse cursor__ - Indicates that the mouse cursor should be shown during response collection. We need to enable this, so that participants can see where they click.\n- __Flush pending mouse clicks__ indicates that we should only accept new key mouse clicks. This is best left enabled (it is by default).\n\n<notranslate>\nfigure:\n id: FigStep10\n source: step10.png\n caption: |\n  The *mouse_response* MOUSE_RESPONSE at the end of Step 9.\n</notranslate>\n\n\n### Step 10: Define the logger\n\nWe don't need to configure the LOGGER, because its default settings are fine; but let's take a look at it anyway. Click on *logger* in the overview area to open it. You see that the option 'Log all variables (recommended)' is selected. This means that OpenSesame logs everything, which is fine.\n\n<div class='info-box' markdown='1'>\n\n**Background box 8: Always check your data!**\n\n__The one tip to rule them all__ — Always triple-check whether all necessary variables are logged in your experiment! The best way to check this is to run the experiment and investigate the resulting log files.\n\n</div>\n\n### Step 11: Finished! (Sort of …)\n\nYou should now be able to run your experiment. There is still a lot of room for improvement, and you will work on polishing the experiment as part of the Extra Assignments below. But the basic structure is there!": {
    "fr": "- Un cercle avec le nom 'chien' sur le côté gauche de l'écran. (Pour rappeler au participant la règle de réponse, vous pouvez ajouter un élément de texte avec le texte 'chien' au cercle. C'est purement visuel.)\n- Un cercle avec le nom 'chat' sur le côté droit de l'écran. (Pour rappeler au participant la règle de réponse, vous pouvez ajouter un élément de texte avec le texte 'chat' au cercle.)\n\nNous allons utiliser ces cercles comme *régions d'intérêt* pour nos réponses à la souris. Plus précisément, parce que nous avons donné un nom aux cercles, notre élément *mouse_response* pourra vérifier si le clic de la souris se situe à l'intérieur de l'un de ces cercles. Nous y reviendrons dans l'étape 9.\n\nEnfin, réglez le champ 'Durée' sur '0'. Cela ne signifie pas que l'image est présentée pendant seulement 0 ms, mais que l'expérience passera à l'élément suivant (*response*) immédiatement après. Comme *response* attend une réponse, mais ne change pas ce qui est affiché à l'écran, la cible restera visible jusqu'à ce qu'une réponse soit donnée.\n\n<notranslate>\nfigure:\n id: FigStep9\n source: step9.png\n caption: |\n  Le SKETCHPAD *animal_picture* à la fin de l'étape 8.\n</notranslate>\n\n<div class='info-box' markdown='1'>\n\n**Encadré 6 : Formats d'images**\n\n__Astuce__ -- OpenSesame peut gérer une grande variété de formats d'images. Cependant, certains formats `.bmp` (non standard) sont connus pour causer des problèmes. Si vous constatez qu'une image `.bmp` n'est pas affichée, vous pouvez envisager d'utiliser un format différent, comme `.png`. Vous pouvez facilement convertir des images avec des outils gratuits tels que [GIMP].\n\n</div>\n\n\n### Étape 9 : Définir la réponse\n\nOuvrez l'élément *mouse_response*. Il s'agit d'un élément MOUSE_RESPONSE, qui collecte un seul clic de souris (ou relâchement). Il y a quelques options :\n\n- __Correct response__ — c'est ici que vous pouvez indiquer quel bouton de la souris est la bonne réponse. Cependant, nous déterminerons si une réponse est correcte en fonction de l'endroit où le participant clique, et non en fonction du bouton sur lequel il clique, donc nous pouvons laisser ce champ vide.\n- __Allowed responses__ est une liste de boutons de souris séparés par des points-virgules qui sont acceptés. Réglons-le sur 'left_button'.\n- __Timeout__ indique une durée après laquelle la réponse sera définie sur 'Aucune', et l'expérience continuera. Un délai d'expiration est important dans notre expérience, car les participants doivent avoir la possibilité de *ne pas* répondre lorsqu'ils voient un capybara. Réglons donc le délai d'expiration sur 2000.\n- __Linked sketchpad__ indique un SKETCHPAD dont les éléments doivent être utilisés comme régions d'intérêt. Nous sélectionnerons *animal_picture*. Maintenant, si nous cliquons sur l'élément avec le nom 'chat', la variable `cursor_roi` sera automatiquement définie sur 'chat'.\n- __Visible mouse cursor__ - Indique que le curseur de la souris doit être affiché pendant la collecte de la réponse. Nous devons activer cela, afin que les participants puissent voir où ils cliquent.\n- __Flush pending mouse clicks__ indique que nous ne devrions accepter que les nouveaux clics de souris. Il est préférable de laisser cette option activée (c'est le cas par défaut).\n\n<notranslate>\nfigure:\n id: FigStep10\n source: step10.png\n caption: |\n  Le MOUSE_RESPONSE *mouse_response* à la fin de l'étape 9.\n</notranslate>\n\n\n### Étape 10 : Définir le logger\n\nNous n'avons pas besoin de configurer le LOGGER, car ses paramètres par défaut sont corrects ; mais jetons-y un coup d'œil quand même. Cliquez sur *logger* dans la zone de vue d'ensemble pour l'ouvrir. Vous voyez que l'option \"Log all variables (recommended)\" est sélectionnée. Cela signifie qu'OpenSesame enregistre tout, ce qui est bien.\n\n<div class='info-box' markdown='1'>\n\n**Encadré 8 : Vérifiez toujours vos données !**\n\n__Le conseil ultime__ — Vérifiez toujours trois fois si toutes les variables nécessaires sont consignées dans votre expérience ! La meilleure façon de vérifier cela est de lancer l'expérience et d'examiner les fichiers journaux résultants.\n\n</div>\n\n### Étape 11 : Terminé ! (En quelque sorte …)\n\nVous devriez maintenant être en mesure d'exécuter votre expérience. Il y a encore beaucoup de place pour l'amélioration, et vous travaillerez sur le polissage de l'expérience dans le cadre des Missions supplémentaires ci-dessous. Mais la structure de base est là !"
  },
  "Click on the 'Run fullscreen' (`Control+R`) button in the main toolbar to give it a test run.\n\n<div class='info-box' markdown='1'>\n\n**Background box 11: Quick run**\n\n__Tip__ — A test run is executed even faster by clicking the orange 'Run in window' button, which doesn't ask you how to save the logfile (and should therefore only be used for testing purposes).\n\n</div>\n\n\n## Extra assignments\n\nThe extra assignments below are for you to solve on your own. The solutions to these assignments can be found in the [experiment file](https://osf.io/2gr3a/). But the best way to learn is to solve them yourself!\n\n\n### Easy: Add an instruction and goodbye screen\n\n- SKETCHPAD and FORM_TEXT_DISPLAY items can present text\n- Good instructions are short and concrete\n\n\n### Easy: Inspect the data\n\n- Run the experiment once on yourself. You can reduce the number of trials by setting the Repeat value of the *block_loop* to less than one.\n- Open the data file in Excel, LibreOffice, or JASP\n\n\n### Medium: Provide feedback on every trial\n\n- To do this, you need to have have already defined a correct response! (See below.)\n- A good, unobtrusive way to provide feedback is by briefly presenting a red dot after an incorrect response, and a green dot after a correct response\n- Use Run If statements!\n\n\n### Medium: Counterbalance the response rule\n\n- The variable `subject_parity` is 'even' or 'odd'\n- Use two different animal-picture SKETCHPAD and MOUSE_RESPONSE items for even and odd participants\n\n\n### Medium: Don't repeat the same animal picture\n\n- You can specify randomization constraints as advanced loop operations\n\n\n### Difficult: Determine whether the response was correct\n\n- This requires an INLINE_SCRIPT\n- Set the variable `correct` to 0 for an incorrect response, and to 1 for a correct response\n- If a timeout occurs, the variable `response` is the string 'None'\n- Otherwise, the variable `cursor_roi` contains a semicolon-separated list of all element names (from the linked SKETCHPAD) that were clicked. It is possible to click on more than one element, for example if the animal picture and response circle overlap\n\n\n### Difficult: Divide the trials into multiple blocks\n\n- Add a SKETCHPAD to the end of the trial_sequence that invites participants to take a short break\n- Use a Run If statement to run this SKETCHPAD only after every 15 trials\n- You need the modulo (`%`) operator to do this, as well as the variable `count_trial_sequence`\n\n\n### Difficult: Adapt the experiment for running online\n\n- This requires an INLINE_JAVASCRIPT\n- Currently, OSWeb does not support linking a MOUSE_RESPONSE to a SKETCHPAD. This means that you need to use the determine `cursor_x` variable to determine where the participant clicked, and whether the response was correct.\n- OSWeb does not support INLINE_SCRIPT items\n\n\n## References\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314–324. doi:10.3758/s13428-011-0168-7\n{: .reference}\n": {
    "fr": "Cliquez sur le bouton \"Exécuter en plein écran\" (`Control+R`) dans la barre d'outils principale pour faire un essai.\n\n<div class='info-box' markdown='1'>\n\n**Boîte contextuelle 11 : Exécution rapide**\n\n__Astuce__ — Un test est exécuté encore plus rapidement en cliquant sur le bouton orange \"Exécuter dans la fenêtre\", qui ne vous demande pas comment enregistrer le fichier de journal (et ne doit donc être utilisé qu'à des fins de test).\n\n</div>\n\n\n## Travaux pratiques supplémentaires\n\nLes travaux pratiques supplémentaires ci-dessous sont à résoudre par vos soins. Les solutions de ces travaux peuvent être trouvées dans le [fichier d'expérience](https://osf.io/2gr3a/). Mais la meilleure façon d'apprendre est de les résoudre vous-même !\n\n### Facile : Ajouter un écran d'instruction et d'au revoir\n\n- Les éléments SKETCHPAD et FORM_TEXT_DISPLAY peuvent présenter du texte\n- Les bonnes instructions sont courtes et concrètes\n\n### Facile : Inspecter les données\n\n- Exécutez l'expérience une fois sur vous-même. Vous pouvez réduire le nombre d'essais en définissant la valeur Répéter du *block_loop* à moins de un.\n- Ouvrez le fichier de données dans Excel, LibreOffice ou JASP\n\n### Moyen : Fournir un retour d'information à chaque essai\n\n- Pour ce faire, vous devez avoir déjà défini une réponse correcte ! (voir ci-dessous).\n- Une bonne façon discrète de fournir un retour d'information est de présenter brièvement un point rouge après une réponse incorrecte et un point vert après une réponse correcte\n- Utilisez des instructions Run If !\n\n### Moyen : Contrebalancer la règle de réponse\n\n- La variable `subject_parity` est 'even' ou 'odd'\n- Utilisez deux éléments SKETCHPAD et MOUSE_RESPONSE différents pour les participants pairs et impairs\n\n### Moyen : Ne pas répéter la même image d'animal\n\n- Vous pouvez spécifier des contraintes de randomisation sous forme d'opérations de boucle avancées\n\n### Difficile : Déterminer si la réponse était correcte\n\n- Ceci nécessite un INLINE_SCRIPT\n- Définissez la variable `correct` à 0 pour une réponse incorrecte et à 1 pour une réponse correcte\n- Si un délai d'attente se produit, la variable `response` est la chaîne 'None'\n- Sinon, la variable `cursor_roi` contient une liste séparée par des points-virgules de tous les noms d'éléments (du SKETCHPAD lié) qui ont été cliqués. Il est possible de cliquer sur plus d'un élément, par exemple si l'image de l'animal et le cercle de réponse se chevauchent\n\n### Difficile : Diviser les essais en plusieurs blocs\n\n- Ajoutez un SKETCHPAD à la fin de la séquence d'essais qui invite les participants à faire une courte pause\n- Utilisez une instruction Run If pour exécuter ce SKETCHPAD seulement après tous les 15 essais\n- Vous aurez besoin de l'opérateur modulo (`%`) pour faire cela, ainsi que de la variable `count_trial_sequence`\n\n### Difficile : Adapter l'expérience pour la réalisation en ligne\n\n- Ceci nécessite un INLINE_JAVASCRIPT\n- Actuellement, OSWeb ne prend pas en charge la liaison d'un MOUSE_RESPONSE à un SKETCHPAD. Cela signifie que vous devez utiliser la variable `cursor_x` pour déterminer où le participant a cliqué et si la réponse était correcte.\n- OSWeb ne prend pas en charge les éléments INLINE_SCRIPT\n\n## Références\n\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: Un générateur d'expériences graphiques open-source pour les sciences sociales. *Behavior Research Methods*, *44*(2), 314–324. doi:10.3758/s13428-011-0168-7\n{: .reference}"
  },
  "Runners": {
    "de": "Läufer",
    "fr": "Coureurs"
  },
  "Release notes for 3.0.5": {
    "fr": "Notes de version pour 3.0.5"
  },
  "What would you like to do?\n\n<div class=\"btn-group\" role=\"group\" aria-label=\"...\">\n    <a role=\"button\" class=\"btn btn-success\" id=\"cogsci-recommended-download-link\">\n        Determining recommended download …\n    </a>\n</div>\n": {
    "fr": "Que souhaitez-vous faire ?\n\n<div class=\"btn-group\" role=\"group\" aria-label=\"...\">\n    <a role=\"button\" class=\"btn btn-success\" id=\"cogsci-recommended-download-link\">\n        Déterminer le téléchargement recommandé …\n    </a>\n</div>"
  },
  "<script async src=\"//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js\"></script>\n<ins class=\"adsbygoogle\"\n     style=\"display:block; text-align:center;\"\n     data-ad-layout=\"in-article\"\n     data-ad-format=\"fluid\"\n     data-ad-client=\"ca-pub-9276598827173431\"\n     data-ad-slot=\"3863533093\"></ins>\n<script>\n     (adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n": {
    "fr": "<script async src=\"//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js\"></script>\n<ins class=\"adsbygoogle\"\n     style=\"display:block; text-align:center;\"\n     data-ad-layout=\"in-article\"\n     data-ad-format=\"fluid\"\n     data-ad-client=\"ca-pub-9276598827173431\"\n     data-ad-slot=\"3863533093\"></ins>\n<script>\n     (adsbygoogle = window.adsbygoogle || []).push({});\n</script>"
  },
  "## Timeout\n\nThe *Timeout* field indicates a timeout value in milliseconds, or 'infinite' for no timeout. When a timeout occurs, the following happens:\n\n- `response_time` is set to the timeout value, or rather to the time it takes for a timeout to be registered, which may deviate slightly from the timeout value.\n- `response` is set to 'None'. This means that you can specify 'None' for the correct response a timeout should occur; this can be useful, for example, in a go/no-go task, when the participant should withold a response on no-go trials.\n": {
    "fr": "## Délai d'attente\n\nLe champ *Timeout* indique une valeur de délai d'attente en millisecondes, ou 'infini' pour aucun délai d'attente. Lorsqu'un délai d'attente se produit, les actions suivantes se produisent :\n\n- `response_time` est défini sur la valeur du délai d'attente, ou plutôt sur le temps qu'il faut pour qu'un délai d'attente soit enregistré, ce qui peut varier légèrement par rapport à la valeur du délai d'attente.\n- `response` est défini sur 'None'. Cela signifie que vous pouvez spécifier 'None' comme réponse correcte lorsqu'un délai d'attente doit se produire; cela peut être utile, par exemple, dans une tâche de type go/no-go, lorsque le participant doit retenir une réponse lors des essais de type no-go."
  },
  "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# class __Button__\n\nThe `Button` widget is a clickable text string, by default surrounded\nby\na button-like frame.\n\n__Example (OpenSesame script):__\n\n~~~\nwidget 0 0 1\n1 button text='Click me!' center='yes' frame='yes' var='response'\n~~~\nDefining a button widget with Python inline code:\n\n__Example (Python):__\n~~~ .python\nform = Form()\nbutton = Button(text='Click me!', frame=True,\ncenter=True, var='response')\nform.set_widget(button, (0,0))\nform._exec()\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## coroutine(self)\n\nImplements the interaction. This can be overridden to implement\nmore complicated keyboard/ mouse interactions.\n\n\n\n\n## on_key_press(key)\n\nIs called whenever the widget is focused and the users enters a\nkey.\n\n\n__Parameters__\n\n- **key**: A key\n\n\n## on_mouse_click(pos)\n\nIs called when the user clicks on the button. Returns the button\ntext.\n\n\n__Parameters__\n\n- **pos**: An (x, y) coordinates tuple.\n\n__Returns__\n\n- The button text.\n\n\n## set_rect(rect)\n\nSets the widget geometry.\n\n\n__Parameters__\n\n- **rect**: A (left, top, width, height) tuple.\n\n\n## set_var(val, var=None)\n\nSets an experimental variable.\n\n\n__Parameters__\n\n- **val    A value.**: \n- **var**: A variable name, or None to use widget default.\n\n\n</div>\n\n": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# classe __Button__\n\nLe widget `Button` est un texte cliquable, entouré par défaut\npar\nun cadre en forme de bouton.\n\n__Exemple (OpenSesame script) :__\n\n~~~\nwidget 0 0 1\n1 button text='Cliquez-moi !' center='yes' frame='yes' var='response'\n~~~\nDéfinir un widget bouton avec un code Python en ligne :\n\n__Exemple (Python) :__\n~~~ .python\nform = Form()\nbutton = Button(text='Cliquez-moi !', frame=True,\ncenter=True, var='response')\nform.set_widget(button, (0,0))\nform._exec()\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## coroutine(self)\n\nImplémente l'interaction. Cette fonction peut être remplacée pour mettre en œuvre\ndes interactions clavier/souris plus complexes.\n\n\n\n\n## on_key_press(key)\n\nEst appelé chaque fois que le widget est sélectionné et que l'utilisateur entre une\ntouche.\n\n\n__Paramètres__\n\n- **key**: Une touche\n\n\n## on_mouse_click(pos)\n\nEst appelé lorsque l'utilisateur clique sur le bouton. Retourne le texte du bouton.\n\n\n__Paramètres__\n\n- **pos**: Un tuple de coordonnées (x, y).\n\n__Renvoie__\n\n- Le texte du bouton.\n\n\n## set_rect(rect)\n\nDéfinit la géométrie du widget.\n\n\n__Paramètres__\n\n- **rect**: Un tuple (left, top, width, height).\n\n\n## set_var(val, var=None)\n\nDéfinit une variable expérimentale.\n\n\n__Paramètres__\n\n- **val    Une valeur.**: \n- **var**: Un nom de variable, ou None pour utiliser la valeur par défaut du widget.\n\n\n</div>"
  },
  "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __items__\n\nThe `items` object provides dict-like access to the items. It's mainly\nuseful for programatically executing items.\n\nAn `items` object is created automatically when the experiment starts.\n\nIn addition to the functions listed below, the following semantics are\nsupported:\n\n__Example__\n\n~~~ .python\n# Programmatically prepare and run a sketchpad item.\nitems.execute('my_sketchpad')\n# Check if an item exists\nif 'my_sketchpad' in items:\n    print('my_sketchpad exists')\n# Delete an item\ndel items['my_sketchpad']\n# Walk through all item names\nfor item_name in items:\n    print(item_name)\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## execute(name)\n\nExecutes the run and prepare phases of an item, and updates the\nitem stack.\n\n\n__Parameters__\n\n- **name**: An item name.\n\n__Example__\n\n~~~ .python\nitems.execute('target_sketchpad')\n~~~\n\n\n\n## new(_type, name=None, script=None, allow_rename=True)\n\nCreates a new item.\n\n\n__Parameters__\n\n- **_type**: The item type.\n- **name**: The item name, or None to choose a unique name based on the item\ntype.\n- **script**: A definition script, or None to start with a blank item.\n- **allow_rename**: Indicates whether OpenSesame can use a different name from the one\nthat is provided as `name` to avoid duplicate names etc.\n\n__Returns__\n\n- The newly generated item.\n\n__Example__\n\n~~~ .python\nitems.new('sketchpad', name='my_sketchpad')\nitems['my_sketchpad'].prepare()\nitems['my_sketchpad'].run()\n~~~\n\n\n\n## prepare(name)\n\nExecutes the prepare phase of an item, and updates the item stack.\n\n\n__Parameters__\n\n- **name**: An item name.\n\n__Example__\n\n~~~ .python\nitems.prepare('target_sketchpad')\nitems.run('target_sketchpad')\n~~~\n\n\n\n## run(name)\n\nExecutes the run phase of an item, and updates the item stack.\n\n\n__Parameters__\n\n- **name**: An item name.\n\n__Example__\n\n~~~ .python\nitems.prepare('target_sketchpad')\nitems.run('target_sketchpad')\n~~~\n\n\n\n## valid_name(item_type, suggestion=None)\n\nGenerates a unique name that is valid and resembles the desired\nname.\n\n\n__Parameters__\n\n- **item_type**: The type of the item to suggest a name for.\n- **suggestion**: The desired name, or None to choose a name based on the item's\ntype.\n\n__Returns__\n\n- A unique name.\n\n__Example__\n\n~~~ .python\nvalid_name = items.valid_name('sketchpad', 'an invalid name')\n~~~\n\n\n\n</div>\n\n": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __items__\n\nL'objet `items` offre un accès de type dict aux éléments. Il est principalement\nutile pour exécuter des éléments de manière programmatique.\n\nUn objet `items` est créé automatiquement lorsque l'expérience commence.\n\nEn plus des fonctions répertoriées ci-dessous, les fonctionnalités suivantes sont\npris en charge:\n\n__Exemple__\n\n~~~ .python\n# Préparer et exécuter un élément sketchpad de manière programmatique.\nitems.execute('mon_sketchpad')\n# Vérifier si un élément existe\nif 'mon_sketchpad' in items:\n    print('mon_sketchpad existe')\n# Supprimer un élément\ndel items['mon_sketchpad']\n# Parcourir tous les noms d'éléments\nfor item_name in items:\n    print(item_name)\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## execute(name)\n\nExécute les phases de préparation et d'exécution d'un élément et met à jour le\npile d'éléments.\n\n__Paramètres__\n\n- **name**: Un nom d'élément.\n\n__Exemple__\n\n~~~ .python\nitems.execute('target_sketchpad')\n~~~\n\n\n\n## new(_type, name=None, script=None, allow_rename=True)\n\nCrée un nouvel élément.\n\n__Paramètres__\n\n- **_type**: Le type d'élément.\n- **name**: Le nom de l'élément, ou None pour choisir un nom unique basé sur le type d'élément.\n- **script**: Un script de définition, ou None pour démarrer avec un élément vierge.\n- **allow_rename**: Indique si OpenSesame peut utiliser un nom différent de celui\nfourni en tant que `name` pour éviter les noms en double, etc.\n\n__Renvoie__\n\n- L'élément nouvellement généré.\n\n__Exemple__\n\n~~~ .python\nitems.new('sketchpad', name = 'mon_sketchpad')\nitems['mon_sketchpad'].prepare()\nitems['mon_sketchpad'].run()\n~~~\n\n\n\n## prepare(name)\n\nExécute la phase de préparation d'un élément et met à jour la pile d'éléments.\n\n__Paramètres__\n\n- **name**: Un nom d'élément.\n\n__Exemple__\n\n~~~ .python\nitems.prepare('target_sketchpad')\nitems.run('target_sketchpad')\n~~~\n\n\n\n## run(name)\n\nExécute la phase d'exécution d'un élément et met à jour la pile d'éléments.\n\n__Paramètres__\n\n- **name**: Un nom d'élément.\n\n__Exemple__\n\n~~~ .python\nitems.prepare('target_sketchpad')\nitems.run('target_sketchpad')\n~~~\n\n\n\n## valid_name(item_type, suggestion=None)\n\nGénère un nom unique qui est valide et ressemble au nom souhaité.\n\n__Paramètres__\n\n- **item_type**: Le type de l'élément pour lequel suggérer un nom.\n- **suggestion**: Le nom souhaité, ou None pour choisir un nom basé sur le type de l'élément.\n\n__Renvoie__\n\n- Un nom unique.\n\n__Exemple__\n\n~~~ .python\nvalid_name = items.valid_name('sketchpad', 'un nom invalide')\n~~~\n\n\n\n</div>"
  },
  "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __srbox__\n\nIf you insert the srbox plugin at the start of your experiment, an\ninstance of SRBOX automatically becomes part of the experiment\nobject and\ncan be accessed within an inline_script item as SRBOX.\n\n__Important note1:__\n\nIf you do not specify a device, the plug-in will try to autodetect\nthe\nSR Box port. However, on some systems this freezes the experiment, so\nit is better to explicitly specify a device.\n\n__Important note 2:__\n\nYou\nneed to call [srbox.start] to put the SR Box in sending mode,\nbefore\ncalling [srbox.get_button_press] to collect a button press.\n\n__Example:__\n~~~ .python\nt0 = clock.time()\nsrbox.start()\nbutton, t1 = srbox.get_button_press(allowed_buttons=[1, 2],\n                                    require_state_change=True)\nif button == 1:\n    response_time = t1 - t0\nprint(f'Button 1 was pressed in {response_time} ms!')\nsrbox.stop()\n~~~\n<notranslate>[TOC]</notranslate>\n\n## get_button_press(allowed_buttons=None, timeout=None, require_state_change=False)\n\nCollects a button press from the SR box.\n\n\n__Parameters__\n\n- **allowed_buttons**: A list of buttons that are accepted or `None` to accept all\nbuttons. Valid buttons are integers 1 through 8.\n- **timeout**: A timeout value in milliseconds or `None` for no timeout.\n- **require_state_change    Indicates whether already pressed button should be accepted**: (False), or whether only a state change from unpressed to pressed\nis accepted (True).\n\n__Returns__\n\n- A `(button_list, timestamp)` tuple. `button_list` is `None` if no \nbutton was pressed (i.e. a timeout occurred).\n\n\n## send(ch)\n\nSends a single character to the SR Box. Send '`' to turn off all\nlights, 'a' for light 1 on, 'b' for light 2 on,'c' for lights\n1 and 2 on etc.\n\n\n__Parameters__\n\n- **ch**: The character to send. If a `str` is passed, it is encoded to\n`bytes` using utf-8 encoding.\n\n\n## start(self)\n\nTurns on sending mode, so that the SR Box starts to send output.\nThe SR Box must be in sending mode when you call\n[srbox.get_button_press].\n\n\n\n\n## stop(self)\n\nTurns off sending mode, so that the SR Box stops giving output.\n\n\n\n\n</div>\n\n": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __srbox__\n\nSi vous insérez le plugin srbox au début de votre expérience, une\ninstance de SRBOX fait automatiquement partie de l'objet d'expérimentation\net\npeut être accessible dans un élément de script en ligne sous SRBOX.\n\n__Note importante 1 :__\n\nSi vous ne spécifiez pas de périphérique, le plugin essayera de détecter automatiquement\nle\nport SR Box. Cependant, sur certains systèmes, cela fige l'expérience, il\nest donc préférable de spécifier explicitement un périphérique.\n\n__Note importante 2 :__\n\nVous\ndevez appeler [srbox.start] pour mettre la SR Box en mode envoi,\navant\nd'appeler [srbox.get_button_press] pour collecter une pression de bouton.\n\n__Exemple :__\n~~~ .python\nt0 = clock.time()\nsrbox.start()\nbutton, t1 = srbox.get_button_press(allowed_buttons=[1, 2],\n                                    require_state_change=True)\nif button == 1:\n    response_time = t1 - t0\nprint(f'Le bouton 1 a été pressé en {response_time} ms !')\nsrbox.stop()\n~~~\n<notranslate>[TOC]</notranslate>\n\n## get_button_press(allowed_buttons=None, timeout=None, require_state_change=False)\n\nCollecte une pression de bouton de la SR Box.\n\n\n__Paramètres__\n\n- **allowed_buttons**: Une liste de boutons acceptés ou `None` pour accepter tous\nles boutons. Les boutons valides sont des entiers de 1 à 8.\n- **timeout**: Une valeur d'expiration en millisecondes ou `None` pour aucune expiration.\n- **require_state_change    Indique si un bouton déjà pressé doit être accepté**: (False), ou si seulement un changement d'état de non pressé à pressé\nest accepté (True).\n\n__Renvoie__\n\n- Un tuple `(button_list, timestamp)`. `button_list` est `None` si aucun\nbouton n'a été pressé (c'est-à-dire si un délai d'expiration est survenu).\n\n\n## send(ch)\n\nEnvoie un seul caractère à la SR Box. Envoyez '`' pour éteindre toutes\nles lumières, 'a' pour allumer la lumière 1, 'b' pour allumer la lumière 2, 'c' pour les lumières\n1 et 2 allumées, etc.\n\n\n__Paramètres__\n\n- **ch**: Le caractère à envoyer. Si une `str` est passée, elle est codée en\n`bytes` en utilisant l'encodage utf-8.\n\n\n## start(self)\n\nActive le mode d'envoi, de sorte que la SR Box commence à envoyer des sorties.\nLa SR Box doit être en mode d'envoi lorsque vous appelez\n[srbox.get_button_press].\n\n\n\n\n## stop(self)\n\nDésactive le mode d'envoi, de sorte que la SR Box cesse de fournir des sorties.\n\n\n\n\n</div>"
  },
  "### change_experiment\n\nFired in: [general_properties.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/widgets/general_properties.py)\n\n```python\nextension_manager.fire(u'change_experiment')\n```\n\n### change_item\n\nFired in: [sequence.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/sequence.py)\n\n```python\nextension_manager.fire(u'change_item', name=self.name)\n```\n\nFired in: [qtitem.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/qtitem.py)\n\n```python\nextension_manager.fire(u'change_item', name=self.name)\n```\n\nFired in: [loop.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/loop.py)\n\n```python\nextension_manager.fire(u'change_item', name=self.name)\n```\n\n### close\n\nFired in: [qtopensesame.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/qtopensesame.py)\n\n```python\nextension_manager.fire(u'close')\n```\n\n### delete_item\n\nFired in: [qtitem_store.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/misc/qtitem_store.py)\n\n```python\nextension_manager.fire(u'delete_item', name=name)\n```\n\n### heartbeat\n\nFired in: [multiprocess_runner.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/runners/multiprocess_runner.py)\n\n```python\nextension_manager.fire(u'heartbeat')\n```\n\n### ide_jump_to_line\n\nFired in: [SymbolSelector.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/SymbolSelector/SymbolSelector.py)\n\n```python\nextension_manager.fire('ide_jump_to_line', lineno=lineno)\n```\n\nFired in: [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('ide_jump_to_line', lineno=line_number)\n```\n\n### ide_new_file\n\nFired in: [JupyterNotebook.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/JupyterNotebook/JupyterNotebook.py)\n\n```python\nextension_manager.fire(u'ide_new_file', source=code, ext=ext)\n```\n\n### ide_save_current_file\n\nFired in: [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('ide_save_current_file')\n```\n\n### image_annotations_detect\n\nFired in: [JupyterNotebook.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/JupyterNotebook/JupyterNotebook.py)\n\n```python\nextension_manager.fire(u'image_annotations_detect', code=code)\n```\n\n### jupyter_exception_occurred\n\nFired in: [transparent_jupyter_widget.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/JupyterConsole/jupyter_tabwidget/transparent_jupyter_widget.py)\n\n```python\nextension_manager.fire('jupyter_exception_occurred')\n```\n\n### jupyter_execute_finished\n\nFired in: [transparent_jupyter_widget.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/JupyterConsole/jupyter_tabwidget/transparent_jupyter_widget.py)\n\n```python\nextension_manager.fire('jupyter_execute_finished')\n```\n\n### jupyter_execute_result_text\n\nFired in: [transparent_jupyter_widget.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/JupyterConsole/jupyter_tabwidget/transparent_jupyter_widget.py)\n\n```python\nextension_manager.fire('jupyter_execute_result_text', text=text)\n```\n\n### jupyter_execute_start\n\nFired in: [transparent_jupyter_widget.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/JupyterConsole/jupyter_tabwidget/transparent_jupyter_widget.py)\n\n```python\nextension_manager.fire('jupyter_execute_start')\n```\n\n### jupyter_interrupt\n\nFired in: [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire(u'jupyter_interrupt')\n```\n\n### jupyter_restart": {
    "fr": "### change_experiment\n\nDéclenché dans : [general_properties.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/widgets/general_properties.py)\n\n```python\nextension_manager.fire(u'change_experiment')\n```\n\n### change_item\n\nDéclenché dans : [sequence.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/sequence.py)\n\n```python\nextension_manager.fire(u'change_item', name=self.name)\n```\n\nDéclenché dans : [qtitem.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/qtitem.py)\n\n```python\nextension_manager.fire(u'change_item', name=self.name)\n```\n\nDéclenché dans : [loop.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/loop.py)\n\n```python\nextension_manager.fire(u'change_item', name=self.name)\n```\n\n### close\n\nDéclenché dans : [qtopensesame.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/qtopensesame.py)\n\n```python\nextension_manager.fire(u'close')\n```\n\n### delete_item\n\nDéclenché dans : [qtitem_store.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/misc/qtitem_store.py)\n\n```python\nextension_manager.fire(u'delete_item', name=name)\n```\n\n### heartbeat\n\nDéclenché dans : [multiprocess_runner.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/runners/multiprocess_runner.py)\n\n```python\nextension_manager.fire(u'heartbeat')\n```\n\n### ide_jump_to_line\n\nDéclenché dans : [SymbolSelector.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/SymbolSelector/SymbolSelector.py)\n\n```python\nextension_manager.fire('ide_jump_to_line', lineno=lineno)\n```\n\nDéclenché dans : [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('ide_jump_to_line', lineno=line_number)\n```\n\n### ide_new_file\n\nDéclenché dans : [JupyterNotebook.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/JupyterNotebook/JupyterNotebook.py)\n\n```python\nextension_manager.fire(u'ide_new_file', source=code, ext=ext)\n```\n\n### ide_save_current_file\n\nDéclenché dans : [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('ide_save_current_file')\n```\n\n### image_annotations_detect\n\nDéclenché dans : [JupyterNotebook.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/JupyterNotebook/JupyterNotebook.py)\n\n```python\nextension_manager.fire(u'image_annotations_detect', code=code)\n```\n\n### jupyter_exception_occurred\n\nDéclenché dans : [transparent_jupyter_widget.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/JupyterConsole/jupyter_tabwidget/transparent_jupyter_widget.py)\n\n```python\nextension_manager.fire('jupyter_exception_occurred')\n```\n\n### jupyter_execute_finished\n\nDéclenché dans : [transparent_jupyter_widget.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/JupyterConsole/jupyter_tabwidget/transparent_jupyter_widget.py)\n\n```python\nextension_manager.fire('jupyter_execute_finished')\n```\n\n### jupyter_execute_result_text\n\nDéclenché dans : [transparent_jupyter_widget.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/JupyterConsole/jupyter_tabwidget/transparent_jupyter_widget.py)\n\n```python\nextension_manager.fire('jupyter_execute_result_text', text=text)\n```\n\n### jupyter_execute_start\n\nDéclenché dans : [transparent_jupyter_widget.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/JupyterConsole/jupyter_tabwidget/transparent_jupyter_widget.py)\n\n```python\nextension_manager.fire('jupyter_execute_start')\n```\n\n### jupyter_interrupt\n\nDéclenché dans : [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire(u'jupyter_interrupt')\n```\n\n### jupyter_restart"
  },
  "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __var__\n\n__New in 4.0.0__: As of OpenSesame 4.0, all experimental variables are\nalso available in the Python workspace. This means that you therefore \ndon't need the `var` object anymore.\n\nThe `var` object provides access to experimental variables.\nExperimental variables are the variables that live in the GUI, and are\ncommonly set as independent variables in the LOOP item, referred\nto using\nthe square-bracket (`[my_variable]`) notation, and logged by\nthe LOGGER\nitem.\n\nA `var` object is created automatically when the experiment starts.\nIn addition to the functions listed below, the following semantics are\nsupported:\n\n__Example__:\n\n~~~ .python\n# Set an experimental variable\nvar.my_variable = u'my_value'\n# Get an experimental variable\nprint(u'Subject nr = %d' % var.subject_nr)\n# Delete (unset) an experimental\nvariable\ndel var.my_variable\n# Check if an experimental variable exists\nif\nu'my_variable' in var:\n    print(u'my_variable exists!')\n# Loop through all\nexperimental variables\nfor var_name in var:\n        print(u'variable found:\n%s' % var_name)\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## clear(preserve=[])\n\n*New in 3.1.2*\n\nClears all experimentals variables.\n\n__Parameters__\n\n- **preserve**: A list of variable names that shouldn't be cleared.\n\n__Example__\n\n~~~ .python\nvar.clear()\n~~~\n\n\n\n## get(var, default=None, _eval=True, valid=None)\n\nGets an experimental variable.\n\n\n__Parameters__\n\n- **var**: The variable to retrieve.\n- **default**: A default value in case the variable doesn't exist, or `None` for\nno default value.\n- **_eval**: Determines whether the returned should be evaluated for variable\nreferences.\n- **valid**: A list of valid values, or `None` to allow all values.\n\n__Example__\n\n~~~ .python\nprint('my_variable = %s' % var.get(u'my_variable'))\n# Equivalent to:\nprint('my_variable = %s' % var.my_variable)\n# But if you want to pass keyword arguments you need to use `get()`:\nvar.get(u'my_variable', default=u'a_default_value')\n~~~\n\n\n\n## has(var)\n\nChecks if an experimental variable exists.\n\n\n__Parameters__\n\n- **var**: The variable to check.\n\n__Example__\n\n~~~ .python\nif var.has(u'my_variable'):\n        print(u'my_variable has been defined!')\n# Equivalent to:\nif u'my_variable' in var:\n        print(u'my_variable has been defined!')\n~~~\n\n\n\n## inspect(self)\n\nGenerates a description of all experimental variables, both alive\nand hypothetical.\n\n\n\n__Returns__\n\n- A dict where variable names are keys, and values are dicts with\nsource, value, and alive keys.\n\n\n## items(self)\n\nReturns a list of (variable_name, value) tuples. See `var.vars()`\nfor a note about the non-exhaustiveness of this function.\n\n\n\n__Returns__\n\n- A list of (variable_name, value) tuples.\n\n__Example__\n\n~~~ .python\nfor varname, value in var.items():\n        print(varname, value)\n~~~\n\n\n\n## set(var, val)\n\nSets and experimental variable.\n\n\n__Parameters__\n\n- **var**: The variable to assign.\n- **val**: The value to assign.\n\n__Example__\n\n~~~ .python\nvar.set(u'my_variable', u'my_value')\n# Equivalent to\nvar.my_variable = u'my_value'\n~~~\n\n\n\n## unset(var)\n\nDeletes a variable.\n\n\n__Parameters__\n\n- **var**: The variable to delete.\n\n__Example__\n\n~~~ .python\nvar.unset(u'my_variable')\n# Equivalent to:\ndel var.my_variable\n~~~\n\n\n\n## vars(self)\n\nReturns a list of experimental variables. Because experimental\nvariables can be stored in multiple places, this list may not be\nexhaustive. That is, `u'my_var' in var` may return `True`, while\nu'my_var' is not in the list of variables as returned by this function.\n\n\n\n__Returns__\n\n- A list of variable names.\n\n__Example__\n\n~~~ .python\nfor varname in var.vars():\n        print(varname)\n~~~\n\n\n\n</div>\n\n": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __var__\n\n__Nouveau en 4.0.0__: À partir d'OpenSesame 4.0, toutes les variables expérimentales sont\négalement disponibles dans l'espace de travail Python. Cela signifie que vous n'avez donc\nplus besoin de l'objet `var`.\n\nL'objet `var` fournit un accès aux variables expérimentales.\nLes variables expérimentales sont les variables qui se trouvent dans l'interface graphique et sont\ncommunément définies en tant que variables indépendantes dans l'élément LOOP, mentionnées\nen utilisant\nla notation des crochets (`[ma_variable]`), et enregistrées par\nl'élément LOGGER.\n\nUn objet `var` est automatiquement créé lorsque l'expérience commence.\nEn plus des fonctions listées ci-dessous, les sémantiques suivantes sont\nprises en charge :\n\n__Exemple__ :\n\n~~~ .python\n# Définir une variable expérimentale\nvar.ma_variable = u'ma_valeur'\n# Obtenir une variable expérimentale\nprint(u'Numéro du sujet = %d' % var.subject_nr)\n# Supprimer (définir) une variable expérimentale\ndel var.ma_variable\n# Vérifier si une variable expérimentale existe\nsi\nu'ma_variable' dans var:\n    print(u'ma_variable existe !')\n# Parcourir toutes les\nvariables expérimentales\npour var_name dans var:\n        print(u'variable trouvée :\n%s' % var_name)\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## clear(preserve=[])\n\n*Nouveau en 3.1.2*\n\nEfface toutes les variables expérimentales.\n\n__Paramètres__\n\n- **conserver**: Une liste des noms de variables qui ne doivent pas être effacés.\n\n__Exemple__\n\n~~~ .python\nvar.clear()\n~~~\n\n\n\n## get(var, default=None, _eval=True, valid=None)\n\nObtient une variable expérimentale.\n\n__Paramètres__\n\n- **var**: La variable à récupérer.\n- **default**: Une valeur par défaut si la variable n'existe pas, ou `None` pour\naucune valeur par défaut.\n- **_eval**: Détermine si la valeur retournée doit être évaluée pour les références de variable.\n- **valid**: Une liste de valeurs valides, ou `None` pour autoriser toutes les valeurs.\n\n__Exemple__\n\n~~~ .python\nprint('ma_variable = %s' % var.get(u'ma_variable'))\n# Équivalent à :\nprint('ma_variable = %s' % var.ma_variable)\n# Mais si vous voulez passer des arguments-clés, vous devez utiliser `get()` :\nvar.get(u'ma_variable', default=u'une_valeur_par_defaut')\n~~~\n\n\n\n## has(var)\n\nVérifie si une variable expérimentale existe.\n\n__Paramètres__\n\n- **var**: La variable à vérifier.\n\n__Exemple__\n\n~~~ .python\nif var.has(u'ma_variable'):\n        print(u'ma_variable a été définie !')\n# Équivalent à :\nif u'ma_variable' in var:\n        print(u'ma_variable a été définie !')\n~~~\n\n\n\n## inspect(self)\n\nGénère une description de toutes les variables expérimentales, à la fois vivantes\net hypothétiques.\n\n__Résultats__\n\n- Un dictionnaire où les noms de variables sont des clés, et les valeurs sont des dictionnaires avec\nsource, valeur, et clés vivantes.\n\n\n## items(self)\n\nRetourne une liste de tuples (nom_variable, valeur). Voir `var.vars()`\npour une note sur le caractère non exhaustif de cette fonction.\n\n__Résultats__\n\n- Une liste de tuples (nom_variable, valeur).\n\n__Exemple__\n\n~~~ .python\nfor nom_variable, valeur in var.items():\n        print(nom_variable, valeur)\n~~~\n\n\n\n## set(var, val)\n\nDéfinit une variable expérimentale.\n\n__Paramètres__\n\n- **var**: La variable à assigner.\n- **val**: La valeur à assigner.\n\n__Example__\n\n~~~ .python\nvar.set(u'ma_variable', u'ma_valeur')\n# Équivalent à\nvar.ma_variable = u'ma_valeur'\n~~~\n\n\n\n## unset(var)\n\nSupprime une variable.\n\n__Paramètres__\n\n- **var**: La variable à supprimer.\n\n__Exemple__\n\n~~~ .python\nvar.unset(u'ma_variable')\n# Équivalent à :\ndel var.ma_variable\n~~~\n\n\n\n## vars(self)\n\nRetourne une liste de variables expérimentales. Parce que les variables expérimentales\npeuvent être stockées à plusieurs endroits, cette liste peut ne pas être\nexhaustive. Autrement dit, `u'ma_var' in var` peut renvoyer `True`, tandis que\nu'ma_var' n'est pas dans la liste de variables renvoyées par cette fonction.\n\n__Résultats__\n\n- Une liste de noms de variables.\n\n__Exemple__\n\n~~~ .python\nfor nom_variable in var.vars():\n        print(nom_variable)\n~~~\n\n\n\n</div>"
  },
  "\n\n## reset\\_feedback()\nResets all feedback variables to their initial state.\n\n\n**Example**  \n```js\nreset_feedback()\n```\n<a name=\"set_subject_nr\"></a>\n\n## set\\_subject\\_nr(nr)\nSets the subject number and parity (even/ odd). This function is called\nautomatically when an experiment is started, so you only need to call it\nyourself if you overwrite the subject number that was specified when the\nexperiment was launched.\n\n\n\n| Param | Type | Description |\n| --- | --- | --- |\n| nr | <code>Number</code> | The subject number |\n\n**Example**  \n```js\nset_subject_nr(1)\nconsole.log('Subject nr = ' + vars.subject_nr)\nconsole.log('Subject parity = ' + vars.subject_parity)\n```\n<a name=\"sometimes\"></a>\n\n## sometimes([p])\nReturns true with a certain probability. (For more advanced randomization,\nuse the `random-ext` package, which is available as `random`.)\n\n\n\n| Param | Type | Default | Description |\n| --- | --- | --- | --- |\n| [p] | <code>Number</code> | <code>.5</code> | The probability of returning true |\n\n**Example**  \n```js\nif (sometimes()) {\n  console.log('Sometimes you win')\n} else {\n  console.log('Sometimes you lose')\n}\n```\n<a name=\"xy_from_polar\"></a>\n\n## xy\\_from\\_polar(rho, phi, [pole]) ⇒ <code>Array.&lt;Number&gt;</code>\nConverts polar coordinates (distance, angle) to Cartesian coordinates\n(x, y).\n\n\n**Returns**: <code>Array.&lt;Number&gt;</code> - An [x, y] array.  \n\n| Param | Type | Default | Description |\n| --- | --- | --- | --- |\n| rho | <code>Number</code> |  | The radial coordinate, also distance or eccentricity. |\n| phi | <code>Number</code> |  | The angular coordinate. This reflects a clockwise     rotation in degrees (i.e. not radians), where 0 is straight right. |\n| [pole] | <code>Array.&lt;Number&gt;</code> | <code>[0, 0]</code> | The reference point. |\n\n**Example**  \n```js\n// ECMA 5.1\nvar xy1 = xy_from_polar(100, 45)\nvar xy2 = xy_from_polar(100, -45)\nvar c = Canvas()\nc.line({sx: xy1[0], sy: xy1[1], ex: -xy1[0], ey: -xy1[1]})\nc.line({sx: xy2[0], sy: xy2[1], ex: -xy2[0], ey: -xy2[1]})\nc.show()\n// ECMA 6\nlet [x1, y1] = xy_from_polar(100, 45)\nlet [x2, y2] = xy_from_polar(100, -45)\nlet c = Canvas()\nc.line({sx: x1, sy: y1, ex: -x1, ey: -y1})\nc.line({sx: x2, sy: y2, ex: -x2, ey: -y2})\nc.show()\n```\n<a name=\"xy_to_polar\"></a>\n\n## xy\\_to\\_polar(x, y, [pole]) ⇒ <code>Array.&lt;Number&gt;</code>\nConverts Cartesian coordinates (x, y) to polar coordinates (distance,\nangle).\n\n\n**Returns**: <code>Array.&lt;Number&gt;</code> - An [rho, phi] array. Here, `rho` is the radial\n    coordinate, also distance or eccentricity. `phi` is the angular\n    coordinate in degrees (i.e. not radians), and reflects a\n    counterclockwise rotation, where 0 is straight right.  \n\n| Param | Type | Default | Description |\n| --- | --- | --- | --- |\n| x | <code>Number</code> |  | The X coordinate. |\n| y | <code>Number</code> |  | The Y coordinate |\n| [pole] | <code>Array.&lt;Number&gt;</code> | <code>[0, 0]</code> | The reference point. |\n\n**Example**  \n```js\n// ECMA 5.1 (browser + desktop)\nvar rho_phi = xy_to_polar(100, 100)\nvar rho = rho_phi[0]\nvar phi = rho_phi[1]\n// ECMA 6 (browser only)\nlet [rho, phi] = xy_to_polar(100, 100)\n```\n<a name=\"xy_distance\"></a>\n\n## xy\\_distance(x1, y1, x2, y2) ⇒ <code>Number</code>\nGives the distance between two points.\n\n\n**Returns**: <code>Number</code> - The distance between the two points.  \n\n| Param | Type | Description |\n| --- | --- | --- |\n| x1 | <code>Number</code> | The x coordinate of the first point. |\n| y1 | <code>Number</code> | The y coordinate of the first point. |\n| x2 | <code>Number</code> | The x coordinate of the second point. |\n| y2 | <code>Number</code> | The y coordinate of the second point. |\n\n<a name=\"xy_circle\"></a>\n\n## xy\\_circle(n, rho, [phi0], [pole]) ⇒ <code>Array.&lt;Array.&lt;Number&gt;&gt;</code>\nGenerates a list of points (x,y coordinates) in a circle. This can be\nused to draw stimuli in a circular arrangement.": {
    "fr": "## reset\\_feedback()\nRéinitialise toutes les variables de feedback à leur état initial.\n\n**Exemple**  \n```js\nreset_feedback()\n```\n<a name=\"set_subject_nr\"></a>\n\n## set\\_subject\\_nr(nr)\nDéfinit le numéro du sujet et sa parité (pair/ impair). Cette fonction est appelée\nautomatiquement lorsqu'une expérience est lancée. Vous n'avez donc besoin de l'appeler\nvous-même que si vous écrasez le numéro de sujet spécifié au lancement de l'expérience.\n\n| Param | Type | Description |\n| --- | --- | --- |\n| nr | <code>Number</code> | Le numéro du sujet |\n\n**Exemple**  \n```js\nset_subject_nr(1)\nconsole.log('Numéro de sujet = ' + vars.subject_nr)\nconsole.log('Parité du sujet = ' + vars.subject_parity)\n```\n<a name=\"sometimes\"></a>\n\n## sometimes([p])\nRenvoie vrai avec une certaine probabilité. (Pour une randomisation plus avancée,\nutilisez le package `random-ext`, disponible sous `random`.)\n\n| Param | Type | Default | Description |\n| --- | --- | --- | --- |\n| [p] | <code>Number</code> | <code>.5</code> | La probabilité de renvoyer vrai |\n\n**Exemple**  \n```js\nif (sometimes()) {\n  console.log('Parfois, vous gagnez')\n} else {\n  console.log('Parfois, vous perdez')\n}\n```\n<a name=\"xy_from_polar\"></a>\n\n## xy\\_from\\_polar(rho, phi, [pole]) ⇒ <code>Array.&lt;Number&gt;</code>\nConvertit des coordonnées polaires (distance, angle) en coordonnées cartésiennes\n(x, y).\n\n**Retour**: <code>Array.&lt;Number&gt;</code> - Un tableau [x, y].  \n\n| Param | Type | Default | Description |\n| --- | --- | --- | --- |\n| rho | <code>Number</code> |  | La coordonnée radiale, également distance ou excentricité. |\n| phi | <code>Number</code> |  | La coordonnée angulaire. Cela reflète une rotation     horaire en degrés (c'est-à-dire pas en radians), où 0 est tout droit à droite. |\n| [pole] | <code>Array.&lt;Number&gt;</code> | <code>[0, 0]</code> | Le point de référence. |\n\n**Exemple**  \n```js\n// ECMA 5.1\nvar xy1 = xy_from_polar(100, 45)\nvar xy2 = xy_from_polar(100, -45)\nvar c = Canvas()\nc.line({sx: xy1[0], sy: xy1[1], ex: -xy1[0], ey: -xy1[1]})\nc.line({sx: xy2[0], sy: xy2[1], ex: -xy2[0], ey: -xy2[1]})\nc.show()\n// ECMA 6\nlet [x1, y1] = xy_from_polar(100, 45)\nlet [x2, y2] = xy_from_polar(100, -45)\nlet c = Canvas()\nc.line({sx: x1, sy: y1, ex: -x1, ey: -y1})\nc.line({sx: x2, sy: y2, ex: -x2, ey: -y2})\nc.show()\n```\n<a name=\"xy_to_polar\"></a>\n\n## xy\\_to\\_polar(x, y, [pole]) ⇒ <code>Array.&lt;Number&gt;</code>\nConvertit des coordonnées cartésiennes (x, y) en coordonnées polaires (distance,\nangle).\n\n**Retour**: <code>Array.&lt;Number&gt;</code> - Un tableau [rho, phi]. Ici, `rho` est la coordonnée radiale,\n    également distance ou excentricité. `phi` est la coordonnée\n    angulaire en degrés (c'est-à-dire pas en radians) et reflète une\n    rotation anti-horaire, où 0 est tout droit à droite.  \n\n| Param | Type | Default | Description |\n| --- | --- | --- | --- |\n| x | <code>Number</code> |  | La coordonnée X. |\n| y | <code>Number</code> |  | La coordonnée Y |\n| [pole] | <code>Array.&lt;Number&gt;</code> | <code>[0, 0]</code> | Le point de référence. |\n\n**Exemple**  \n```js\n// ECMA 5.1 (navigateur + bureau)\nvar rho_phi = xy_to_polar(100, 100)\nvar rho = rho_phi[0]\nvar phi = rho_phi[1]\n// ECMA 6 (navigateur uniquement)\nlet [rho, phi] = xy_to_polar(100, 100)\n```\n<a name=\"xy_distance\"></a>\n\n## xy\\_distance(x1, y1, x2, y2) ⇒ <code>Number</code>\nDonne la distance entre deux points.\n\n**Retour**: <code>Number</code> - La distance entre les deux points.  \n\n| Param | Type | Description |\n| --- | --- | --- |\n| x1 | <code>Number</code> | La coordonnée x du premier point. |\n| y1 | <code>Number</code> | La coordonnée y du premier point. |\n| x2 | <code>Number</code> | La coordonnée x du deuxième point. |\n| y2 | <code>Number</code> | La coordonnée y du deuxième point. |\n\n<a name=\"xy_circle\"></a>\n\n## xy\\_circle(n, rho, [phi0], [pole]) ⇒ <code>Array.&lt;Array.&lt;Number&gt;&gt;</code>\nGénère une liste de points (coordonnées x,y) dans un cercle. Ceci peut être\nutilisé pour dessiner des stimuli dans un arrangement circulaire."
  },
  "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# class __Sampler__\n\nThe `Sampler` class provides functionality to play sound samples. You \ngenerally create a `Sampler` object with the `Sampler()` factory function, \nas described in the section [Creating a Sampler](#creating-a-sampler).\n\n__Example:__\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src, volume=.5)\nmy_sampler.play()\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## Things to know\n\n### Creating a Sampler\n\nYou generally create a `Sampler` with the `Sampler()` factory function, which\ntakes the full path to a sound file as the first argument.\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src)\n~~~\n\nOptionally, you can pass [Playback keywords](#playback-keywords) to `Sampler()`\nto set the default behavior:\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src, volume=.5)\n~~~\n\n### Sampling rate\n\nIf you find that your sample plays too slowly (low pitch) or too quickly (high\npitch), make sure that the sampling rate of your sample matches the sampling\nrate of the sampler back-end as specified under backend settings.\n\n### Supported file formats\n\nSound files in `.wav`, `.mp3`, and `.ogg` format are supported. If you need to\nconvert samples from a different format, you can use\n[Audacity](http://sourceforge.net/projects/audacity/).\n\n### Playback keywords\n\nFunctions that accept `**playback_args` take the following keyword arguments:\n\n- `volume` specifies a volume between `0.0` (silent) and `1.0` (maximum).\n- `pitch` specifies a pitch (or playback speed), where values > 1 indicate a\n  higher pitch, and values < 1 indicate a lower pitch.\n- `pan` specifies a panning, where values < 0 indicate panning to the left, and\n  values > 0 indicate panning to the right. Alternatively, you can set pan to\n  'left' or 'right' to play only a single channel.\n- `duration` specifies the duration of the sound in milliseconds, or is set to\n  `0` or `None` to play the full sound.\n- `fade_in` specifies the fade-in time (or attack) of the sound, or is set to\n  `0` or `None` to disable fade-in.\n- `block` indicates whether the experiment should block (`True`) during\n  playback or not (`False`).\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play(volume=.5, pan='left')\n~~~\n\nPlayback keywords only affect the current operation (except when passed to\n`Sampler()` when creating the object). To change the behavior for all\nsubsequent operations, set the playback properties directly:\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.volume = .5\nmy_sampler.pan = 'left'\nmy_sampler.play()\n~~~\n\nOr pass the playback keywords to `Sampler()` when creating the object:\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src, volume=.5, pan='left')\nmy_sampler.play()\n~~~\n\n## close_sound(experiment)\n\nCloses the mixer after the experiment is finished.\n\n\n__Parameters__\n\n- **experiment**: The experiment object.\n\n\n## init_sound(experiment)\n\nInitializes the pygame mixer before the experiment begins.\n\n\n__Parameters__\n\n- **experiment**: The experiment object.\n\n\n## is_playing(self)\n\nChecks if a sound is currently playing.\n\n\n\n__Returns__\n\n- True if a sound is playing, False if not.\n\n__Example__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play()\nsleep(100)\nif my_sampler.is_playing():\n        print('The sampler is still playing!')\n~~~\n\n\n\n## pause(self)\n\nPauses playback (if any).\n\n\n\n__Example__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play()\nsleep(100)\nmy_sampler.pause()\nsleep(100)\nmy_sampler.resume()\n~~~\n\n\n\n## play(\\*arglist, \\*\\*kwdict)\n\nPlays the sound.\n\n\n__Parameters__\n\n- **\\*\\*playback_args**: Optional [playback keywords](#playback-keywords) that will be used\nfor this call to `Sampler.play()`. This does not affect subsequent\noperations.\n\n__Example__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play(pitch=.5, block=True)\n~~~\n\n\n\n## resume(self)": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# classe __Sampler__\n\nLa classe `Sampler` fournit des fonctionnalités pour jouer des échantillons sonores. Vous \ncréez généralement un objet `Sampler` avec la fonction usine `Sampler()`, \ncomme décrit dans la section [Créer un Sampler](#creating-a-sampler).\n\n__Exemple :__\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src, volume=.5)\nmy_sampler.play()\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## Choses à savoir\n\n### Créer un Sampler\n\nVous créez généralement un `Sampler` avec la fonction usine `Sampler()`, qui\nprend le chemin complet vers un fichier sonore comme premier argument.\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src)\n~~~\n\nFacultativement, vous pouvez passer [Mots-clés de lecture](#playback-keywords) à `Sampler()`\npour définir le comportement par défaut :\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src, volume=.5)\n~~~\n\n### Taux d'échantillonnage\n\nSi vous trouvez que votre échantillon se lit trop lentement (tonalité basse) ou trop rapidement (tonalité élevée),\nassurez-vous que le taux d'échantillonnage de votre échantillon correspond au taux d'échantillonnage du backend de l'échantillonneur tel que spécifié dans les paramètres backend.\n\n### Formats de fichier pris en charge\n\nLes fichiers son au format `.wav`, `.mp3` et `.ogg` sont pris en charge. Si vous devez\nconvertir des échantillons à partir d'un autre format, vous pouvez utiliser\n[Audacity](http://sourceforge.net/projects/audacity/).\n\n### Mots-clés de lecture\n\nLes fonctions qui acceptent `**playback_args` prennent les arguments clés suivants :\n\n- `volume` spécifie un volume entre `0.0` (silencieux) et `1.0` (maximum).\n- `pitch` spécifie une hauteur (ou vitesse de lecture), où les valeurs > 1 indiquent une\n  hauteur plus élevée, et les valeurs < 1 indiquent une hauteur plus basse.\n- `pan` spécifie une panoramique, où les valeurs < 0 indiquent une panoramique vers la gauche, et\n  les valeurs > 0 indiquent une panoramique vers la droite. Alternativement, vous pouvez régler pan sur\n  'left' ou 'right' pour ne jouer qu'un seul canal.\n- `duration` spécifie la durée du son en millisecondes, ou est défini sur\n  `0` ou `None` pour jouer le son complet.\n- `fade_in` spécifie le temps de fondu d'entrée (ou d'attaque) du son, ou est défini sur\n  `0` ou `None` pour désactiver le fondu d'entrée.\n- `block` indique si l'expérience doit bloquer (`True`) pendant\n  la lecture ou pas (`False`).\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play(volume=.5, pan='left')\n~~~\n\nLes mots-clés de lecture n'affectent que l'opération en cours (sauf lorsqu'ils sont passés à\n`Sampler()` lors de la création de l'objet). Pour changer le comportement pour toutes les\nopérations ultérieures, définissez les propriétés de lecture directement :\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.volume = .5\nmy_sampler.pan = 'left'\nmy_sampler.play()\n~~~\n\nOu passez les mots-clés de lecture à `Sampler()` lors de la création de l'objet :\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src, volume=.5, pan='left')\nmy_sampler.play()\n~~~\n\n## close_sound(experiment)\n\nFerme le mixeur après la fin de l'expérience.\n\n\n__Paramètres__\n\n- **experiment**: L'objet expérimental.\n\n\n## init_sound(experiment)\n\nInitialise le mixeur pygame avant le début de l'expérience.\n\n\n__Paramètres__\n\n- **experiment**: L'objet expérimental.\n\n\n## is_playing(self)\n\nVérifie si un son est en cours de lecture.\n\n\n\n__Renvoie__\n\n- True si un son est en cours de lecture, False sinon.\n\n__Exemple__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play()\nsleep(100)\nif my_sampler.is_playing():\n        print('Le Sampler est toujours en cours de lecture!')\n~~~\n\n\n\n## pause(self)\n\nMet en pause la lecture (le cas échéant).\n\n\n\n__Exemple__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play()\nsleep(100)\nmy_sampler.pause()\nsleep(100)\nmy_sampler.resume()\n~~~\n\n\n\n## play(\\*arglist, \\*\\*kwdict)\n\nJoue le son.\n\n\n__Paramètres__\n\n- **\\*\\*playback_args**: Facultative [mots-clés de lecture](#playback-keywords) qui seront utilisés\npour cet appel à `Sampler.play()`. Cela n'affecte pas les opérations suivantes.\n\n__Exemple__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play(pitch=.5, block=True)\n~~~\n\n\n\n## resume(self)"
  },
  "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __clock__\n\nThe `clock` object offers basic time functions. A `clock` object is\ncreated automatically when the experiment starts.\n\n__Example__\n\n~~~ .python\n# Get the timestamp before and after sleeping for 1000 ms\nt0 = clock.time()\nclock.sleep(1000)\nt1 = clock.time()\ntime_passed = t1 - t0\nprint(f'This should be 1000: {time_passed}')\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## loop_for(ms, throttle=None, t0=None)\n\n*New in v3.2.0*\n\nAn iterator that loops for a fixed time.\n\n__Parameters__\n\n- **ms**: The number of milliseconds to loop for.\n- **throttle**: A period to sleep for in between each iteration.\n- **t0**: A starting time. If `None`, the starting time is the moment at\nwhich the iteration starts.\n\n__Returns__\n\n- \n\n__Example__\n\n~~~ .python\nfor ms in clock.loop_for(100, throttle=10):\n    print(ms)\n~~~\n\n\n\n## once_in_a_while(ms=1000)\n\n*New in v3.2.0*\n\nPeriodically returns `True`. This is mostly useful\nfor executing\ncode (e.g. within a `for` loop) that should only be\nexecuted once\nin a while.\n\n__Parameters__\n\n- **ms**: The minimum waiting period.\n\n__Returns__\n\n- `True` after (at least) the minimum waiting period has\npassed since\nthe last call to `Clock.once_in_a_while()`, or\n`False` otherwise.\n\n__Example__\n\n~~~ .python\nfor i in range(1000000):\n    if clock.once_in_a_while(ms=50):\n        # Execute this code only once every 50 ms\n        print(clock.time())\n~~~\n\n\n\n## sleep(ms)\n\nSleeps (pauses) for a period.\n\n\n__Parameters__\n\n- **ms**: The number of milliseconds to sleep for.\n\n__Example__\n\n~~~ .python\n# Create two canvas objects ...\nmy_canvas1 = Canvas()\nmy_canvas1.text('1')\nmy_canvas2 = Canvas()\nmy_canvas2.text('2')\n# ... and show them with 1 s in between\nmy_canvas1.show()\nclock.sleep(1000)\nmy_canvas2.show()\n~~~\n\n\n\n## time(self)\n\nGives a current timestamp in milliseconds. The absolute meaning of\nthe timestamp (i.e. when it was 0) depends on the backend.\n\n\n\n__Returns__\n\n- A timestamp.\n\n__Example__\n\n~~~ .python\nt = clock.time()\nprint(f'The current time is {t}')\n~~~\n\n\n\n</div>\n\n": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __horloge__\n\nL'objet `horloge` offre des fonctions de temps de base. Un objet `horloge` est\ncréé automatiquement lorsque l'expérience commence.\n\n__Exemple__\n\n~~~ .python\n# Obtenez le timestamp avant et après avoir dormi pendant 1000 ms\nt0 = horloge.temps()\nhorloge.dors(1000)\nt1 = horloge.temps()\ntemps_passé = t1 - t0\nprint(f'Ceci doit être égal à 1000 : {temps_passé}')\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## boucle_pour(ms, régulateur=None, t0=None)\n\n*Nouveau dans la v3.2.0*\n\nUn itérateur qui boucle pendant un temps fixe.\n\n__Paramètres__\n\n- **ms**: Le nombre de millisecondes à boucler.\n- **régulateur**: Une période de sommeil entre chaque itération.\n- **t0**: Un temps de départ. Si `None`, le temps de départ est le moment où \nl'itération commence.\n\n__Renvoie__\n\n-\n\n__Exemple__  \n\n~~~ .python\nfor ms in horloge.boucle_pour(100, régulateur=10):\n    print(ms)\n~~~\n\n\n## de_temps_en_temps(ms=1000)\n\n*Nouveau dans la v3.2.0*\n\nRenvoie périodiquement `Vrai`. Ceci est principalement utile\npour exécuter\ndu code (par exemple, dans une boucle `for`) qui ne devrait être\nexécuté que \nde temps en temps.\n\n__Paramètres__\n\n- **ms**: La période minimale d'attente.\n\n__Renvoie__\n\n- `Vrai` après (au moins) la période minimale d'attente depuis\nle dernier appel à `Horloge.de_temps_en_temps()`, ou\n`Faux` sinon.\n\n__Exemple__\n\n~~~ .python\nfor i in range(1000000):\n    if horloge.de_temps_en_temps(ms=50):\n        # Exécutez ce code seulement une fois toutes les 50 ms\n        print(horloge.temps())\n~~~\n\n\n\n## dors(ms)\n\nDort (fait une pause) pendant une période.\n\n\n__Paramètres__\n\n- **ms**: Le nombre de millisecondes pour dormir.\n\n__Exemple__\n\n~~~ .python\n# Créez deux objets canvas ...\nmon_canvas1 = Canvas()\nmon_canvas1.texte('1')\nmon_canvas2 = Canvas()\nmon_canvas2.texte('2')\n# ... Montrez-les avec un intervalle de 1 s\nmon_canvas1.montre()\nhorloge.dors(1000)\nmon_canvas2.montre()\n~~~\n\n\n\n## temps(self)\n\nDonne un horodatage actuel en millisecondes. La signification absolue de l'horodatage (c'est-à-dire quand il était à 0) dépend du backend.\n\n\n\n__Renvoie__\n\n- Un horodatage.\n\n__Exemple__\n\n~~~ .python\nt = horloge.temps()\nprint(f'Le temps actuel est {t}')\n~~~\n\n\n\n</div>"
  },
  "Resumes playback (if any).\n\n\n\n__Example__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play()\nsleep(100)\nmy_sampler.pause()\nsleep(100)\nmy_sampler.resume()\n~~~\n\n\n\n## set_config(\\*\\*cfg)\n\nUpdates the configurables.\n\n\n__Parameters__\n\n- **\\*\\*cfg**: The to-be-updated configurables.\n\n\n## stop(self)\n\nStops the currently playing sound (if any).\n\n\n\n__Example__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play()\nsleep(100)\nmy_sampler.stop()\n~~~\n\n\n\n## wait(self)\n\nBlocks until the sound has finished playing or returns right away\nif no sound is playing.\n\n\n\n__Example__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play()\nmy_sampler.wait()\nprint('The sampler is finished!')\n~~~\n\n\n\n</div>\n\n": {
    "fr": "Reprend la lecture (le cas échéant).\n\n\n\n__Exemple__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmon_sampler = Sampler(src)\nmon_sampler.play()\nsleep(100)\nmon_sampler.pause()\nsleep(100)\nmon_sampler.resume()\n~~~\n\n\n\n## set_config(\\*\\*cfg)\n\nMet à jour les éléments configurables.\n\n\n__Paramètres__\n\n- **\\*\\*cfg**: Les éléments configurables à mettre à jour.\n\n\n## stop(self)\n\nArrête le son en cours de lecture (le cas échéant).\n\n\n\n__Exemple__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmon_sampler = Sampler(src)\nmon_sampler.play()\nsleep(100)\nmon_sampler.stop()\n~~~\n\n\n\n## wait(self)\n\nBloque jusqu'à ce que le son ait fini de jouer ou renvoie immédiatement\nsi aucun son n'est en cours de lecture.\n\n\n\n__Exemple__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmon_sampler = Sampler(src)\nmon_sampler.play()\nmon_sampler.wait()\nprint(\"Le sampler est terminé !\")\n~~~\n\n\n\n</div>"
  },
  "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# class __Checkbox__\n\nThe `Checkbox` widget is a checkable box accompanied by a string of\ntext.\n\n__Example (OpenSesame script):__\n\n~~~\nwidget 0 0 1 1 checkbox\ngroup=\"group\" text=\"Option 1\"\nwidget 0 1 1 1 checkbox group=\"group\"\ntext=\"Option 2\"\n~~~\n\n__Example (Python):__\n\n~~~ .python\nform = Form()\ncheckbox1 = Checkbox(text='Option 1', group='group')\ncheckbox2 =\nCheckbox(text='Option 2', group='group')\nform.set_widget(checkbox1, (0,0))\nform.set_widget(checkbox2, (0,1))\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## coroutine(self)\n\nImplements the interaction. This can be overridden to implement\nmore complicated keyboard/ mouse interactions.\n\n\n\n\n## on_key_press(key)\n\nIs called whenever the widget is focused and the users enters a\nkey.\n\n\n__Parameters__\n\n- **key**: A key\n\n\n## on_mouse_click(pos)\n\nIs called whenever the user clicks on the widget. Toggles the state\nof the checkbox.\n\n\n__Parameters__\n\n- **pos**: An (x, y) coordinate tuple.\n\n\n## set_checked(checked=True)\n\nSets the checked status of the checkbox.\n\n\n__Parameters__\n\n- **checked**: The checked status.\n\n\n## set_rect(rect)\n\nSets the widget geometry.\n\n\n__Parameters__\n\n- **rect**: A (left, top, width, height) tuple.\n\n\n## set_var(val, var=None)\n\nSets an experimental variable.\n\n\n__Parameters__\n\n- **val**: A value.\n- **var**: A variable name, or `None` to use widget default.\n\n\n</div>\n\n": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# classe __Checkbox__\n\nLe widget `Checkbox` est une case à cocher accompagnée d'une chaîne de\ntexte.\n\n__Exemple (script OpenSesame) :__\n\n~~~\nwidget 0 0 1 1 checkbox\ngroup=\"group\" text=\"Option 1\"\nwidget 0 1 1 1 checkbox group=\"group\"\ntext=\"Option 2\"\n~~~\n\n__Exemple (Python) :__\n\n~~~ .python\nform = Form()\ncheckbox1 = Checkbox(text='Option 1', group='group')\ncheckbox2 =\nCheckbox(text='Option 2', group='group')\nform.set_widget(checkbox1, (0,0))\nform.set_widget(checkbox2, (0,1))\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## coroutine(self)\n\nImplémente l'interaction. Cela peut être modifié pour mettre en œuvre\ndes interactions clavier/souris plus compliquées.\n\n\n\n\n## on_key_press(key)\n\nEst appelé chaque fois que le widget est focalisé et que l'utilisateur entre une\ntouche.\n\n\n__Paramètres__\n\n- **key**: Une touche\n\n\n## on_mouse_click(pos)\n\nEst appelé chaque fois que l'utilisateur clique sur le widget. Bascule l'état\nde la case à cocher.\n\n\n__Paramètres__\n\n- **pos**: Un tuple de coordonnées (x, y).\n\n\n## set_checked(checked=True)\n\nDéfinit l'état coché de la case à cocher.\n\n\n__Paramètres__\n\n- **checked**: L'état coché.\n\n\n## set_rect(rect)\n\nDéfinit la géométrie du widget.\n\n\n__Paramètres__\n\n- **rect**: Un tuple (left, top, width, height).\n\n\n## set_var(val, var=None)\n\nDéfinit une variable expérimentale.\n\n\n__Paramètres__\n\n- **val**: Une valeur.\n- **var**: Un nom de variable ou `None` pour utiliser la valeur par défaut du widget.\n\n\n</div>"
  },
  "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __responses__\n\nThe `responses` object contains the history of the responses that were\ncollected during the experiment.\n\nA `responses` object is created automatically when the experiment starts.\n\nIn addition to the functions listed below, the following semantics are\nsupported:\n\n__Example__\n\n~~~ .python\n# Loop through all responses, where last-given responses come first\n# Each response has correct, response, response_time, item, and feedback\n# attributes.\nfor response in responses:\n    print(response.correct)\n# Print the two last-given respones\nprint('last_two responses:')\nprint(responses[:2])\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## add(response=None, correct=None, response_time=None, item=None, feedback=True)\n\nAdds a response.\n\n\n__Parameters__\n\n- **response    The response value, for example, 'space' for the spacebar, 0 for**: joystick button 0, etc.\n- **correct**: The correctness of the response.\n- **response_time**: The response_time.\n- **item**: The item that collected the response.\n- **feedback**: Indicates whether the response should be included in feedback on\naccuracy and average response time.\n\n__Example__\n\n~~~ .python\nresponses.add(response_time=500, correct=1, response='left')\n~~~\n\n\n\n## clear(self)\n\nClears all responses.\n\n\n\n__Example__\n\n~~~ .python\nresponses.clear()\n~~~\n\n\n\n## reset_feedback(self)\n\nSets the feedback status of all responses to False, so that only\nnew responses will be included in feedback.\n\n\n\n__Example__\n\n~~~ .python\nresponses.reset_feedback()\n~~~\n\n\n\n</div>\n\n": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __responses__\n\nL'objet `responses` contient l'historique des réponses qui ont été\ncollectées lors de l'expérience.\n\nUn objet `responses` est créé automatiquement lorsque l'expérience commence.\n\nEn plus des fonctions listées ci-dessous, les sémantiques suivantes sont\nprises en charge :\n\n__Exemple__\n\n~~~ .python\n# Parcourir toutes les réponses, où les dernières réponses données apparaissent en premier\n# Chaque réponse a des attributs corrects, réponse, temps_de_réponse, élément, et retour d'information.\nfor response in responses:\n    print(response.correct)\n# Imprimer les deux dernières réponses données\nprint('deux_dernières réponses :')\nprint(responses[:2])\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## add(response=None, correct=None, response_time=None, item=None, feedback=True)\n\nAjoute une réponse.\n\n\n__Paramètres__\n\n- **réponse**: La valeur de la réponse, par exemple, 'espace' pour la barre d'espace, 0 pour le bouton 0 du joystick, etc.\n- **correct**: La justesse de la réponse.\n- **response_time**: Le temps de réponse.\n- **item**: L'élément qui a collecté la réponse.\n- **feedback**: Indique si la réponse doit être incluse dans les commentaires sur\nla précision et le temps de réponse moyen.\n\n__Exemple__\n\n~~~ .python\nresponses.add(response_time=500, correct=1, response='gauche')\n~~~\n\n\n\n## clear(self)\n\nEfface toutes les réponses.\n\n\n\n__Exemple__\n\n~~~ .python\nresponses.clear()\n~~~\n\n\n\n## reset_feedback(self)\n\nMet l'état des commentaires de toutes les réponses à False, de sorte que seul\nles nouvelles réponses seront incluses dans les commentaires.\n\n\n\n__Exemple__\n\n~~~ .python\nresponses.reset_feedback()\n~~~\n\n\n\n</div>"
  },
  "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __log__\n\nThe `log` object provides data logging. A `log` object is created\nautomatically when the experiment starts.\n\n__Example__\n\n~~~ .python\n# Write one line of text\nlog.write('My custom log message')\n# Write all variables\nlog.write_vars()\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## close(self)\n\nCloses the current log.\n\n\n\n__Example__\n\n~~~ .python\nlog.close()\n~~~\n\n\n\n## open(path)\n\nOpens the current log. If a log was already open, it is closed\nautomatically, and re-opened.\n\n\n__Parameters__\n\n- **path**: The path to the current logfile. In most cases (unless) a custom\nlog back-end is used, this will be a filename.\n\n__Example__\n\n~~~ .python\n# Open a new log\nlog.open('/path/to/new/logfile.csv')\n~~~\n\n\n\n## write(msg, newline=True)\n\nWrite one message to the log.\n\n\n__Parameters__\n\n- **msg**: A text message. When using Python 2, this should be either\n`unicode` or a utf-8-encoded `str`. When using Python 3, this\nshould be either `str` or a utf-8-encoded `bytes`.\n- **newline**: Indicates whether a newline should be written after the message.\n\n__Example__\n\n~~~ .python\n# Write a single string of text\nlog.write(f'time = {clock.time()}')\n~~~\n\n\n\n## write_vars(var_list=None)\n\nWrites variables to the log.\n\n\n__Parameters__\n\n- **var_list**: A list of variable names to write, or None to write all variables\nthat exist in the experiment.\n\n__Example__\n\n~~~ .python\n# Write all variables to the logfile\nlog.write_vars()\n~~~\n\n\n\n</div>\n\n": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __log__\n\nL'objet `log` permet l'enregistrement des données. Un objet `log` est créé automatiquement lorsque l'expérience commence.\n\n__Exemple__\n\n~~~ .python\n# Écrire une ligne de texte\nlog.write('Mon message personnalisé')\n# Écrire toutes les variables\nlog.write_vars()\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## close(self)\n\nFerme le journal actuel.\n\n\n\n__Exemple__\n\n~~~ .python\nlog.close()\n~~~\n\n\n\n## open(path)\n\nOuvre le journal actuel. Si un journal était déjà ouvert, il est fermé\nautomatiquement et rouvert.\n\n\n__Paramètres__\n\n- **path**: Le chemin d'accès vers le journal actuel. Dans la plupart des cas (sauf) si un système d'enregistrement personnalisé est utilisé, ce sera un nom de fichier.\n\n__Exemple__\n\n~~~ .python\n# Ouvrir un nouveau journal\nlog.open('/path/to/new/logfile.csv')\n~~~\n\n\n\n## write(msg, newline=True)\n\nÉcrire un message dans le journal.\n\n\n__Paramètres__\n\n- **msg**: Un message texte. Lors de l'utilisation de Python 2, cela doit être soit\n  `unicode` ou un `str` encodé en utf-8. Lors de l'utilisation de Python 3, cela\n  doit être soit `str` ou `bytes` encodé en utf-8.\n- **newline**: Indique si un saut de ligne doit être écrit après le message.\n\n__Exemple__\n\n~~~ .python\n# Écrire une seule chaîne de texte\nlog.write(f'time = {clock.time()}')\n~~~\n\n\n\n## write_vars(var_list=None)\n\nÉcrit les variables dans le journal.\n\n\n__Paramètres__\n\n- **var_list**: Une liste de noms de variables à écrire, ou None pour écrire toutes les variables\n  qui existent dans l'expérience.\n\n__Exemple__\n\n~~~ .python\n# Écrire toutes les variables dans le fichier journal\nlog.write_vars()\n~~~\n\n\n\n</div>"
  },
  "Fired in: [console_bridge.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/misc/console_bridge.py)\n\n```python\nextension_manager.fire(u'jupyter_restart')\n```\n\nFired in: [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire(u'jupyter_restart')\n```\n\n### jupyter_run_code\n\nFired in: [menubar.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/opensesame_ide/menubar.py)\n\n```python\nextension_manager.fire('jupyter_run_code',\n                                                     code=command)\n```\n\n### jupyter_run_system_command\n\nFired in: [JupyterNotebook.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/JupyterNotebook/JupyterNotebook.py)\n\n```python\nextension_manager.fire('jupyter_run_system_command', cmd=cmd)\n```\n\n### jupyter_show_prompt\n\nFired in: [console_bridge.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/misc/console_bridge.py)\n\n```python\nextension_manager.fire(u'jupyter_show_prompt')\n```\n\n### jupyter_write\n\nFired in: [console_bridge.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/misc/console_bridge.py)\n\n```python\nextension_manager.fire(u'jupyter_write', msg=s)\n```\n\n### new_item\n\nFired in: [tree_overview.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/widgets/tree_overview.py)\n\n```python\nextension_manager.fire(u'new_item', name=item.name,\n\t\t\t\t_type=item.item_type)\n```\n\n### new_linked_copy\n\nFired in: [tree_overview.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/widgets/tree_overview.py)\n\n```python\nextension_manager.fire('new_linked_copy', name=item_name)\n```\n\n### notify\n\nFired in: [sequence.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/sequence.py)\n\n```python\nextension_manager.fire(u'notify',\n\t\t\t\t\tmessage=_(u'Sequence contains non-existing item: %s')\n```\n\nFired in: [qtitem.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/qtitem.py)\n\n```python\nextension_manager.fire(u'notify',\n\t\t\t\t\t\tmessage=_(u'\"%s\" is set to a variable or '\n\t\t\t\t\t\tu'unknown value and can only be edited through '\n\t\t\t\t\t\tu'the script.')\n```\n\nFired in: [qtitem.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/qtitem.py)\n\n```python\nextension_manager.fire(u'notify',\n\t\t\t\t\t\tmessage=_(u'\"%s\" is defined using '\n\t\t\t\t\t\t'variables and can only be edited through the '\n\t\t\t\t\t\t'script.')\n```\n\nFired in: [qtitem.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/qtitem.py)\n\n```python\nextension_manager.fire(u'notify',\n\t\t\t\t\t\tmessage=_(u'\"%s\" is defined using '\n\t\t\t\t\t\tu'variables or has an invalid value, and can only be '\n\t\t\t\t\t\tu'edited through the script.')\n```\n\nFired in: [logger.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/logger.py)\n\n```python\nextension_manager.fire(u'notify',\n\t\t\t\t\tmessage=_(u'You have multiple unlinked loggers. This can lead to messy log files.')\n```\n\nFired in: [sketchpad_widget.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/widgets/sketchpad_widget.py)\n\n```python\nextension_manager.fire(u'notify', message=notification,\n\t\t\t\tcategory=u'info')\n```\n\n### open_experiment\n\nFired in: [qtopensesame.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/qtopensesame.py)\n\n```python\nextension_manager.fire(u'open_experiment', path=path)\n```\n\n### open_item\n\nFired in: [qtitem.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/qtitem.py)\n\n```python\nextension_manager.fire(u'open_item', name=self.name)\n```\n\n### pause_experiment\n\nFired in: [base_runner.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/runners/base_runner.py)\n\n```python\nextension_manager.fire(u'pause_experiment')\n```\n\n### prepare_change_experiment": {
    "fr": "Déclenché dans : [console_bridge.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/misc/console_bridge.py)\n\n```python\nextension_manager.fire(u'jupyter_restart')\n```\n\nDéclenché dans : [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire(u'jupyter_restart')\n```\n\n### jupyter_run_code\n\nDéclenché dans : [menubar.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/opensesame_ide/menubar.py)\n\n```python\nextension_manager.fire('jupyter_run_code',\n                                                     code=command)\n```\n\n### jupyter_run_system_command\n\nDéclenché dans : [JupyterNotebook.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/JupyterNotebook/JupyterNotebook.py)\n\n```python\nextension_manager.fire('jupyter_run_system_command', cmd=cmd)\n```\n\n### jupyter_show_prompt\n\nDéclenché dans : [console_bridge.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/misc/console_bridge.py)\n\n```python\nextension_manager.fire(u'jupyter_show_prompt')\n```\n\n### jupyter_write\n\nDéclenché dans : [console_bridge.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/misc/console_bridge.py)\n\n```python\nextension_manager.fire(u'jupyter_write', msg=s)\n```\n\n### new_item\n\nDéclenché dans : [tree_overview.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/widgets/tree_overview.py)\n\n```python\nextension_manager.fire(u'new_item', name=item.name,\n\t\t\t\t_type=item.item_type)\n```\n\n### new_linked_copy\n\nDéclenché dans : [tree_overview.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/widgets/tree_overview.py)\n\n```python\nextension_manager.fire('new_linked_copy', name=item_name)\n```\n\n### notify\n\nDéclenché dans : [sequence.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/sequence.py)\n\n```python\nextension_manager.fire(u'notify',\n\t\t\t\t\tmessage=_(u'Sequence contains non-existing item: %s')\n```\n\nDéclenché dans : [qtitem.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/qtitem.py)\n\n```python\nextension_manager.fire(u'notify',\n\t\t\t\t\t\tmessage=_(u'\"%s\" is set to a variable or '\n\t\t\t\t\t\tu'unknown value and can only be edited through '\n\t\t\t\t\t\tu'the script.')\n```\n\nDéclenché dans : [qtitem.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/qtitem.py)\n\n```python\nextension_manager.fire(u'notify',\n\t\t\t\t\t\tmessage=_(u'\"%s\" is defined using '\n\t\t\t\t\t\t'variables and can only be edited through the '\n\t\t\t\t\t\t'script.')\n```\n\nDéclenché dans : [qtitem.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/qtitem.py)\n\n```python\nextension_manager.fire(u'notify',\n\t\t\t\t\t\tmessage=_(u'\"%s\" is defined using '\n\t\t\t\t\t\tu'variables or has an invalid value, and can only be '\n\t\t\t\t\t\tu'edited through the script.')\n```\n\nDéclenché dans : [logger.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/logger.py)\n\n```python\nextension_manager.fire(u'notify',\n\t\t\t\t\tmessage=_(u'You have multiple unlinked loggers. This can lead to messy log files.')\n```\n\nDéclenché dans : [sketchpad_widget.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/widgets/sketchpad_widget.py)\n\n```python\nextension_manager.fire(u'notify', message=notification,\n\t\t\t\tcategory=u'info')\n```\n\n### open_experiment\n\nDéclenché dans : [qtopensesame.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/qtopensesame.py)\n\n```python\nextension_manager.fire(u'open_experiment', path=path)\n```\n\n### open_item\n\nDéclenché dans : [qtitem.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/qtitem.py)\n\n```python\nextension_manager.fire(u'open_item', name=self.name)\n```\n\n### pause_experiment\n\nDéclenché dans : [base_runner.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/runners/base_runner.py)\n\n```python\nextension_manager.fire(u'pause_experiment')\n```\n\n### prepare_change_experiment"
  },
  "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __pool__\n\nThe `pool` object provides dict-like access to the file pool. When\nchecking whether a file is in the file pool, several folders are\nsearched.\nFor more details, see `pool.folders()`.\n\nA `pool` object is created\nautomatically when the experiment starts.\n\nIn addition to the functions\nlisted below, the following semantics are\nsupported:\n\n__Examples__\n\nBasic use:\n\n~~~ .python\n# Get the full path to a file in the file pool\nprint(f'The full path to img.png is {pool[\"img.png\"]}')\n# Check if a file is in the file pool\nif 'img.png' in pool:\n    print('img.png is in the file pool')\n# Delete a file from the file pool\ndel pool['img.png']\n# Walk through all files in the file pool. This retrieves the full paths.\nfor path in pool:\n    print(path)\n# Check the number of files in the file pool\nprint(f'There are {len(pool)} files in the file pool')\n~~~\n\nGet an image from the file pool and use a `Canvas` to show it.\n\n~~~ .python\nimage_path = pool['img.png']\nmy_canvas = Canvas()\nmy_canvas.image(image_path)\nmy_canvas.show()\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## add(path, new_name=None)\n\nCopies a file to the file pool.\n\n\n__Parameters__\n\n- **path**: The full path to the file on disk.\n- **new_name**: A new name for the file in the pool, or None to use the file's\noriginal name.\n\n__Example__\n\n~~~ .python\npool.add('/home/username/Pictures/my_ing.png')\n~~~\n\n\n\n## clean_up(self)\n\nRemoves the pool folder.\n\n\n\n\n## fallback_folder(self)\n\nThe full path to the fallback pool folder, which is the\n`__pool__` subfolder of the current experiment folder, or\n`None` if this folder does not exist. The fallback pool\nfolder is mostly useful in combination with a versioning\nsystem, such as git, because it allows you to save the\nexperiment as a plain-text file, even when having files\nin the file pool.\n\n\n\n__Returns__\n\n- \n\n__Example__\n\n~~~ .python\nif pool.fallback_folder() is not None:\n    print('There is a fallback pool folder!')\n~~~\n\n\n\n## files(self)\n\nReturns all files in the file pool.\n\n\n\n__Returns__\n\n- A list of full paths.\n\n__Example__\n\n~~~ .python\nfor path in pool.files():\n    print(path)\n# Equivalent to:\nfor path in pool:\n    print(path)\n~~~\n\n\n\n## folder(self)\n\nGives the full path to the (main) pool folder. This is typically a\ntemporary folder that is deleted when the experiment is finished.\n\n\n\n__Returns__\n\n- The full path to the main pool folder.\n\n__Example__\n\n~~~ .python\nprint(f'The pool folder is here: {pool.folder()}')\n~~~\n\n\n\n## folders(include_fallback_folder=True, include_experiment_path=False)\n\nGives a list of all folders that are searched when retrieving the\nfull path to a file. These are (in order):\n\n1. The file pool folder\nitself, as returned by `pool.folder()`.\n2. The folder of the current\nexperiment (if it exists)\n3. The fallback pool folder, as returned by\n`pool.fallback_folder()` (if it exists)\n\n__Parameters__\n\n- **include_fallback_folder**: Indicates whether the fallback pool folder should be included if it\nexists.\n- **include_experiment_path**: Indicates whether the experiment folder should be included if it\nexists.\n\n__Returns__\n\n- A list of all folders.\n\n__Example__\n\n~~~ .python\nprint('The following folders are searched for files:')\nfor folder in pool.folders():\n    print(folder)\n~~~\n\n\n\n## in_folder(path)\n\nChecks whether path is in the pool folder. This is different from\nthe `path in pool` syntax in that it only checks the main pool folder,\nand not the fallback pool folder and experiment folder.\n\n\n__Parameters__\n\n- **path**: A file basename to check.\n\n__Returns__\n\n- \n\n__Example__\n\n~~~ .python\nprint(pool.in_folder('cue.png'))\n~~~\n\n\n\n## rename(old_path, new_path)\n\nRenames a file in the pool folder.\n\n\n__Parameters__\n\n- **old_path**: The old file name.\n- **new_path**: The new file name.\n\n__Example__\n\n~~~ .python\npool.rename('my_old_img.png', 'my_new_img.png')\n~~~\n\n\n\n## size(self)\n\nGets the combined size in bytes of all files in the file pool.\n\n\n\n__Returns__\n\n- \n\n__Example__": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __pool__\n\nL'objet `pool` offre un accès de type dict au pool de fichiers. Lors\nde la vérification de la présence d'un fichier dans le pool de fichiers, plusieurs dossiers sont\nrecherchés.\nPour plus de détails, voir `pool.folders()`.\n\nUn objet `pool` est créé\nautomatiquement lorsque l'expérience démarre.\n\nEn plus des fonctions\nrépertoriées ci-dessous, les sémantiques suivantes sont\nprises en charge :\n\n__Exemples__\n\nUtilisation de base :\n\n~~~ .python\n# Obtenir le chemin complet d'un fichier dans le pool de fichiers\nprint(f'Le chemin complet du fichier img.png est {pool[\"img.png\"]}')\n# Vérifier si un fichier est dans le pool de fichiers\nif 'img.png' in pool:\n    print('img.png est dans le pool de fichiers')\n# Supprimer un fichier du pool de fichiers\ndel pool['img.png']\n# Parcourir tous les fichiers du pool de fichiers. Ceci récupère les chemins complets.\nfor path in pool:\n    print(path)\n# Vérifier le nombre de fichiers dans le pool de fichiers\nprint(f'Il y a {len(pool)} fichiers dans le pool de fichiers')\n~~~\n\nObtenir une image du pool de fichiers et utiliser un `Canvas` pour l'afficher.\n\n~~~ .python\nimage_path = pool['img.png']\nmon_canvas = Canvas()\nmon_canvas.image(image_path)\nmon_canvas.show()\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## add(path, new_name=None)\n\nCopie un fichier dans le pool de fichiers.\n\n__Paramètres__\n\n- **path**: Le chemin complet du fichier sur le disque.\n- **new_name**: Un nouveau nom pour le fichier dans le pool, ou None pour utiliser le nom original du fichier.\n\n__Exemple__\n\n~~~ .python\npool.add('/home/username/Pictures/my_img.png')\n~~~\n\n\n\n## clean_up(self)\n\nSupprime le dossier du pool.\n\n\n\n\n## fallback_folder(self)\n\nLe chemin complet du dossier de secours du pool, qui est le\nsous-dossier `__pool__` du dossier de l'expérience en cours, ou\n`None` si ce dossier n'existe pas. Le dossier de secours du pool\nest surtout utile en combinaison avec un système de versionnement\ntel que git, car il permet de sauvegarder l'expérience sous forme de fichier\ntexte brut, même lorsqu'il y a des fichiers\ndans le pool de fichiers.\n\n__Renvoie__\n\n-\n\n__Exemple__\n\n~~~ .python\nif pool.fallback_folder() is not None:\n    print('Il y a un dossier de pool de secours !')\n~~~\n\n\n\n## files(self)\n\nRenvoie tous les fichiers dans le pool de fichiers.\n\n__Renvoie__\n\n- Une liste de chemins complets.\n\n__Exemple__\n\n~~~ .python\nfor path in pool.files():\n    print(path)\n# Équivalent à :\nfor path in pool:\n    print(path)\n~~~\n\n\n\n## folder(self)\n\nDonne le chemin complet du dossier (principal) du pool. Il s'agit généralement d'un\ndossier temporaire qui est supprimé lorsque l'expérience est terminée.\n\n__Renvoie__\n\n- Le chemin complet du dossier principal du pool.\n\n__Exemple__\n\n~~~ .python\nprint(f'Le dossier du pool se trouve ici: {pool.folder()}')\n~~~\n\n\n\n## folders(include_fallback_folder=True, include_experiment_path=False)\n\nDonne une liste de tous les dossiers qui sont recherchés lors de la récupération du\nchemin complet d'un fichier. Ceux-ci sont (par ordre d'apparition) :\n\n1. Le dossier du pool de fichiers\nlui-même, tel que renvoyé par `pool.folder()`.\n2. Le dossier de l'expérience en cours (s'il existe)\n3. Le dossier de secours du pool, tel que renvoyé par\n`pool.fallback_folder()` (s'il existe)\n\n__Paramètres__\n\n- **include_fallback_folder**: Indique si le dossier de pool de secours doit être inclus s'il\nexiste.\n- **include_experiment_path**: Indique si le dossier de l'expérience doit être inclus s'il\nexiste.\n\n__Renvoie__\n\n- Une liste de tous les dossiers.\n\n__Exemple__\n\n~~~ .python\nprint('Les dossiers suivants sont recherchés pour les fichiers :')\nfor dossier in pool.folders():\n    print(dossier)\n~~~\n\n\n\n## in_folder(path)\n\nVérifie si le chemin est dans le dossier du pool. Ceci est différent de\nla syntaxe `path in pool` en ce sens qu'elle vérifie uniquement le dossier principal du pool,\net non pas le dossier de secours du pool et le dossier de l'expérience.\n\n__Paramètres__\n\n- **path**: Un nom de fichier de base à vérifier.\n\n__Renvoie__\n\n-\n\n__Exemple__\n\n~~~ .python\nprint(pool.in_folder('cue.png'))\n~~~\n\n\n\n## rename(old_path, new_path)\n\nRenomme un fichier dans le dossier du pool.\n\n__Paramètres__\n\n- **old_path**: L'ancien nom du fichier.\n- **new_path**: Le nouveau nom du fichier.\n\n__Exemple__\n\n~~~ .python\npool.rename('my_old_img.png', 'my_new_img.png')\n~~~\n\n\n\n## size(self)\n\nObtient la taille combinée en octets de tous les fichiers du pool de fichiers.\n\n__Renvoie__\n\n-\n\n__Exemple__"
  },
  "~~~ .python\nprint(f'The size of the file pool is {pool.size()} bytes')\n~~~\n\n\n\n</div>\n\n": {
    "fr": "~~~ .python\nprint(f'La taille du pool de fichiers est de {pool.size()} octets')\n~~~\n\n</div>"
  },
  "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# class __Canvas__\n\n{% set arg_max_width = \"The maximum width of the text in pixels, \" +\n\"before wrapping to a new line, or `None` to wrap at screen edge.\" %}\n\n{% set arg_bgmode = \"Specifies whether the background is the average of \" +\n\"col1 and col2 ('avg', corresponding to a typical Gabor patch), or \" + \n\"equal to col2 ('col2'), useful for blending into the background. Note: \" +\n\"this parameter is ignored by the psycho backend, which uses increasing \" + \n\"transparency for the background.\" %}\n\n{% set arg_style = \"Optional [style keywords](#style-keywords) that \" + \n\"specify the style of the current drawing operation. This does not \" + \n\"affect subsequent drawing operations.\" %}\n\n{% set arg_center = \"A bool indicating whether the coordinates reflect \" + \n\"the center (`True`) or top-left (`False`) of the text.\" %}\n\nThe `Canvas` class is used to present visual stimuli. You generally create a\n`Canvas` object with the `Canvas()` factory function, as described in the section\n[Creating a Canvas](#creating-a-canvas).\n\n__Example__:\n\n~~~ .python\n# Create and show a canvas with a central fixation dot\nmy_canvas = Canvas()\nmy_canvas.fixdot()\nmy_canvas.show()\n~~~\n\n__Example__:\n\nYou can also add `Canvas` elements as objects. See also the section on [Naming,\naccessing, and modifying elements](#naming-accessing-and-modifying-elements).\n\n~~~ .python\n# Create a canvas with a fixation dot and a rectangle\nmy_canvas = Canvas()\nmy_canvas['my_fixdot'] = FixDot()\nmy_canvas.show()\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## Things to know\n\n### Creating a Canvas\n\nYou generally create a `Canvas` with the `Canvas()` factory function:\n\n~~~ .python\nmy_canvas = Canvas()\n~~~\n\nOptionally, you can pass [Style keywords](#style-keywords) to `Canvas()` to set\nthe default style:\n\n~~~ .python\nmy_canvas = Canvas(color='green')\nmy_canvas.fixdot() # Will be green\n~~~\n\n### Style keywords\n\nAll functions that accept `**style_args` take the following keyword arguments:\n\n- `color` specifies the foreground color. For valid color specifications, see\n  [colors](#colors).\n- `background_color` specifies the background color. For valid color\n  specifications, see [colors](#colors).\n- `fill` indicates whether rectangles, circles, polygons, and ellipses are\n  filled (`True`), or drawn as an outline (`False`).\n- `penwidth` indicates a penwidth in pixels and should be `int` or `float`.\n- `html` indicates whether HTML-tags are interpreted, and should be `True` or\n  `False`.\n- `font_family` is the name of a font family, such as 'sans'.\n- `font_size` is a font size in pixels.\n- `font_italic` indicates whether text should italics, and should be `True` or\n  `False`.\n- `font_bold` indicates whether text should bold, and should be `True` or\n  `False`.\n- `font_underline` indicates whether text should underlined, and should be\n  `True` or `False`.\n\n~~~ .python\n# Draw a green fixation dot\nmy_canvas = Canvas()\nmy_canvas.fixdot(color='green')\nmy_canvas.show()\n~~~\n\nStyle keywords only affect the current drawing operation (except when passed to\n`Canvas()` while creating the `Canvas`). To change the style for all subsequent\ndrawing operations, set style properties, such as `canvas.color`, directly:\n\n~~~ .python\n# Draw a red cross with a 2px penwidth\nmy_canvas = Canvas()\nmy_canvas.color = 'red'\nmy_canvas.penwidth = 2\nmy_canvas.line(-10, -10, 10, 10)\nmy_canvas.line(-10, 10, 10, -10)\nmy_canvas.show()\n~~~\n\nOr pass the style properties to `Canvas()`:\n\n~~~ .python\n# Draw a red cross with a 2px penwidth\nmy_canvas = Canvas(color='red', penwidth=2)\nmy_canvas.line(-10, -10, 10, 10)\nmy_canvas.line(-10, 10, 10, -10)\nmy_canvas.show()\n~~~\n\n### Colors\n\nYou can specify colors in the following ways. This includes CSS3-type color\nspecifications, but also supports some extra specifications, such as CIE l* a*\nb* color space.\n\n__Version note:__ The `hsv`, `hsl`, and `lab` color spaces are new in v3.3.0.": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# classe __Canvas__\n\n{% set arg_max_width = \"La largeur maximale du texte en pixels, \" +\n\"avant de passer à une nouvelle ligne, ou `None` pour ajuster à la bordure de l'écran.\" %}\n\n{% set arg_bgmode = \"Spécifie si l'arrière-plan est la moyenne de \" +\n\"col1 et col2 ('avg', correspondant à un patch de Gabor typique), ou \" + \n\"égal à col2 ('col2'), utile pour se fondre dans l'arrière-plan. Remarque: \" +\n\"ce paramètre est ignoré par le backend psycho, qui utilise une augmentation \" + \n\"de la transparence pour l'arrière-plan.\" %}\n\n{% set arg_style = \"Mots-clés de [style optionnels](#style-keywords) qui \" + \n\"spécifient le style de l'opération de dessin en cours. Cela n'affecte pas \" + \n\"les opérations de dessin ultérieures.\" %}\n\n{% set arg_center = \"Un booléen indiquant si les coordonnées reflètent \" + \n\"le centre (`True`) ou haut-gauche (`False`) du texte.\" %}\n\nLa classe `Canvas` est utilisée pour présenter des stimuli visuels. Vous créez généralement un\nobjet `Canvas` avec la fonction de fabrique `Canvas()`, comme décrit dans la section\n[Création d'un Canvas](#creating-a-canvas).\n\n__Exemple__ :\n\n~~~ .python\n# Créer et afficher un canvas avec un point de fixation central\nmy_canvas = Canvas()\nmy_canvas.fixdot()\nmy_canvas.show()\n~~~\n\n__Exemple__ :\n\nVous pouvez également ajouter des éléments `Canvas` en tant qu'objets. Voir aussi la section sur [Nommer,\naccéder et modifier les éléments](#naming-accessing-and-modifying-elements).\n\n~~~ .python\n# Créer un canvas avec un point de fixation et un rectangle\nmy_canvas = Canvas()\nmy_canvas['my_fixdot'] = FixDot()\nmy_canvas.show()\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## Choses à savoir\n\n### Création d'un Canvas\n\nVous créez généralement un `Canvas` avec la fonction de fabrique `Canvas()` :\n\n~~~ .python\nmy_canvas = Canvas()\n~~~\n\nFacultativement, vous pouvez passer des [mots-clés de style](#style-keywords) à `Canvas()` pour définir\nle style par défaut :\n\n~~~ .python\nmy_canvas = Canvas(color='green')\nmy_canvas.fixdot() # Sera vert\n~~~\n\n### Mots-clés de style\n\nToutes les fonctions qui acceptent `**style_args` prennent les arguments de mot-clé suivants:\n\n- `color` spécifie la couleur de l'avant-plan. Pour les spécifications de couleur valides, voir\n  [couleurs](#colors).\n- `background_color` spécifie la couleur de l'arrière-plan. Pour les spécifications de couleur valides, voir [couleurs](#colors).\n- `fill` indique si les rectangles, cercles, polygones et ellipses sont\n  remplis (`True`) ou dessinés sous forme de contour (`False`).\n- `penwidth` indique une largeur de crayon en pixels et doit être `int` ou `float`.\n- `html` indique si les balises HTML sont interprétées et doit être `True` ou\n  `False`.\n- `font_family` est le nom d'une famille de polices, tel que 'sans'.\n- `font_size` est une taille de police en pixels.\n- `font_italic` indique si le texte doit être en italique et doit être `True` ou\n  `False`.\n- `font_bold` indique si le texte doit être en gras et doit être `True` ou\n  `False`.\n- `font_underline` indique si le texte doit être souligné et doit être\n  `True` ou `False`.\n\n~~~ .python\n# Dessiner un point de fixation vert\nmy_canvas = Canvas()\nmy_canvas.fixdot(color='green')\nmy_canvas.show()\n~~~\n\nLes mots-clés de style n'affectent que l'opération de dessin en cours (sauf lorsqu'ils sont passés à\n`Canvas()` lors de la création du `Canvas`). Pour changer le style pour toutes les opérations de dessin ultérieures, définissez directement les propriétés de style, telles que `canvas.color` :\n\n~~~ .python\n# Dessiner une croix rouge avec une largeur de crayon de 2px\nmy_canvas = Canvas()\nmy_canvas.color = 'red'\nmy_canvas.penwidth = 2\nmy_canvas.line(-10, -10, 10, 10)\nmy_canvas.line(-10, 10, 10, -10)\nmy_canvas.show()\n~~~\n\nOu passez les propriétés de style à `Canvas()` :\n\n~~~ .python\n# Dessiner une croix rouge avec une largeur de crayon de 2px\nmy_canvas = Canvas(color='red', penwidth=2)\nmy_canvas.line(-10, -10, 10, 10)\nmy_canvas.line(-10, 10, 10, -10)\nmy_canvas.show()\n~~~\n\n### Couleurs\n\nVous pouvez spécifier des couleurs de différentes manières. Cela inclut les spécifications de couleur de type CSS3, mais prend également en charge des spécifications supplémentaires, telles que l'espace colorimétrique CIE l* a* b*.\n\n__Note de version :__ Les espaces de couleur `hsv`, `hsl` et `lab` sont nouveaux dans la version 3.3.0."
  },
  "<div class=\"ClassDoc YAMLDoc\" id=\"eyetracker\" markdown=\"1\">\n\n# class __eyetracker__\n\nA generic Python library for eye tracking.\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-calibrate\" markdown=\"1\">\n\n## function __eyetracker\\.calibrate__\\(\\)\n\nCalibrates the eye tracking system. The actual behavior of this\nfunction depends on the type of eye tracker and is described below.\n\n__EyeLink:__\n\nThis function will activate the camera-setup screen, which allows\nyou to adjust the camera, and peform a calibration/ validation\nprocedure. Pressing 'q' will exit the setup routine. Pressing\n'escape' will first trigger a confirmation dialog and then, upon\nconfirmation, raises an Exception.\n\n__EyeTribe:__\n\nActivates a simple calibration routine.\n\n__Returns:__\n\nReturns True if calibration succeeded, or False if not; in\naddition a calibration log is added to the log file and some\nproperties are updated (i.e. the thresholds for detection\nalgorithms).\n\n- Type: bool\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-close\" markdown=\"1\">\n\n## function __eyetracker\\.close__\\(\\)\n\nNeatly closes connection to tracker. Saves data and sets\n`self.connected` to False.\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-connected\" markdown=\"1\">\n\n## function __eyetracker\\.connected__\\(\\)\n\nChecks if the tracker is connected.\n\n__Returns:__\n\nTrue if connection is established, False if not; sets\n`self.connected` to the same value.\n\n- Type: bool\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-draw_calibration_target\" markdown=\"1\">\n\n## function __eyetracker\\.draw\\_calibration\\_target__\\(x, y\\)\n\nDraws a calibration target.\n\n__Arguments:__\n\n- `x` -- The X coordinate\n\t- Type: int\n- `y` -- The Y coordinate\n\t- Type: int\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-draw_drift_correction_target\" markdown=\"1\">\n\n## function __eyetracker\\.draw\\_drift\\_correction\\_target__\\(x, y\\)\n\nDraws a drift-correction target.\n\n__Arguments:__\n\n- `x` -- The X coordinate\n\t- Type: int\n- `y` -- The Y coordinate\n\t- Type: int\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-drift_correction\" markdown=\"1\">\n\n## function __eyetracker\\.drift\\_correction__\\(pos=None, fix\\_triggered=False\\)\n\nPerforms a drift-correction procedure. The exact behavior of this\nfunction on the type of eye tracker and is described below. Because\ndrift correction may fail, you will generally call this function in\na loop.\n\n__EyeLink:__\n\nPressing 'q' during drift-correction will activate the camera-setup\nscreen. From there, pressing 'q' again will cause drift correction\nto fail immediately. Pressing 'escape' will give the option to abort\nthe experiment, in which case an Exception is raised.\n\n__Keywords:__\n\n- `pos` -- (x, y) position of the fixation dot or None for a central fixation.\n\t- Type: tuple, NoneType\n\t- Default: None\n- `fix_triggered` -- Boolean indicating if drift check should be performed based on gaze position (True) or on spacepress (False).\n\t- Type: bool\n\t- Default: False\n\n__Returns:__\n\nA boolean indicating if drift check is ok (True) or not (False).\n\n- Type: bool\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-fix_triggered_drift_correction\" markdown=\"1\">\n\n## function __eyetracker\\.fix\\_triggered\\_drift\\_correction__\\(pos=None, min\\_samples=30, max\\_dev=60, reset\\_threshold=10\\)\n\nPerforms a fixation triggered drift correction by collecting\na number of samples and calculating the average distance from the\nfixation position\n\n__Keywords:__\n\n- `pos` -- (x, y) position of the fixation dot or None for a central fixation.\n\t- Type: tuple, NoneType\n\t- Default: None\n- `min_samples` -- The minimal amount of samples after which an average deviation is calculated.\n\t- Type: int\n\t- Default: 30\n- `max_dev` -- The maximal deviation from fixation in pixels.\n\t- Type: int\n\t- Default: 60\n- `reset_threshold` -- If the horizontal or vertical distance in pixels between two consecutive samples is larger than this threshold, the sample collection is reset.\n\t- Type: int\n\t- Default: 10": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" id=\"eyetracker\" markdown=\"1\">\n\n# classe __eyetracker__\n\nUne bibliothèque Python générique pour le suivi du regard.\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-calibrate\" markdown=\"1\">\n\n## fonction __eyetracker\\.calibrate__\\(\\)\n\nCalibre le système de suivi du regard. Le comportement réel de cette\nfonction dépend du type de suivi du regard et est décrit ci-dessous.\n\n__EyeLink:__\n\nCette fonction active l'écran de configuration de la caméra, qui permet\nd'ajuster la caméra et d'effectuer une procédure de calibration/validation.\nAppuyer sur 'q' quittera la routine de configuration. Appuyer\nsur 'échap' déclenchera d'abord une boîte de dialogue de confirmation, puis, après\nconfirmation, lève une exception.\n\n__EyeTribe:__\n\nActive une routine de calibration simple.\n\n__Retourne:__\n\nRenvoie Vrai si la calibration a réussi, ou Faux si ce n'est pas le cas; en\nplus, un journal de calibration est ajouté au fichier journal et certaines\npropriétés sont mises à jour (c'est-à-dire les seuils pour la détection\nalgorithmes).\n\n- Type : bool\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-close\" markdown=\"1\">\n\n## fonction __eyetracker\\.close__\\(\\)\n\nFerme soigneusement la connexion au tracker. Sauvegarde les données et définit\n`self.connected` à Faux.\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-connected\" markdown=\"1\">\n\n## function __eyetracker\\.connected__\\(\\)\n\nVérifie si le suivi est connecté.\n\n__Retourne:__\n\nVrai si la connexion est établie, Faux si ce n'est pas le cas; définit\n`self.connected` à la même valeur.\n\n- Type : bool\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-draw_calibration_target\" markdown=\"1\">\n\n## function __eyetracker\\.draw\\_calibration\\_target__\\(x, y\\)\n\nDessine une cible de calibration.\n\n__Arguments:__\n\n- `x` -- La coordonnée X\n\t- Type : int\n- `y` -- La coordonnée Y\n\t- Type : int\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-draw_drift_correction_target\" markdown=\"1\">\n\n## function __eyetracker\\.draw\\_drift\\_correction\\_target__\\(x, y\\)\n\nDessine une cible de correction de dérive.\n\n__Arguments:__\n\n- `x` -- La coordonnée X\n\t- Type : int\n- `y` -- La coordonnée Y\n\t- Type : int\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-drift_correction\" markdown=\"1\">\n\n## function __eyetracker\\.drift\\_correction__\\(pos=None, fix\\_triggered=False\\)\n\nEffectue une procédure de correction de dérive. Le comportement exact de cette\nfonction dépend du type de suivi du regard et est décrit ci-dessous. Parce que\nla correction de dérive peut échouer, vous appellerez généralement cette fonction dans\nune boucle.\n\n__EyeLink:__\n\nAppuyer sur 'q' pendant la correction de dérive activera l'écran de configuration de la caméra. À partir de là, appuyer sur 'q' à nouveau entraînera l'échec immédiat de la correction de dérive. Appuyer sur 'échap' donnera la possibilité d'interrompre l'expérience, auquel cas une exception est levée.\n\n__Mots-clés:__\n\n- `pos` -- Position (x, y) du point de fixation ou None pour une fixation centrale.\n\t- Type : tuple, NoneType\n\t- Par défaut : None\n- `fix_triggered` -- Booléen indiquant si la vérification de la dérive doit être effectuée en fonction de la position du regard (Vrai) ou sur l'espace pressé (Faux).\n\t- Type : bool\n\t- Par défaut : Faux\n\n__Retourne:__\n\nUn booléen indiquant si la vérification de la dérive est correcte (Vrai) ou non (Faux).\n\n- Type : bool\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-fix_triggered_drift_correction\" markdown=\"1\">\n\n## function __eyetracker\\.fix\\_triggered\\_drift\\_correction__\\(pos=None, min\\_samples=30, max\\_dev=60, reset\\_threshold=10\\)\n\nEffectue une correction de dérive déclenchée par la fixation en collectant\nun certain nombre d'échantillons et en calculant la distance moyenne par rapport à la\nposition de fixation\n\n__Mots-clés:__\n\n- `pos` -- Position (x, y) du point de fixation ou None pour une fixation centrale.\n\t- Type : tuple, NoneType\n\t- Par défaut : None\n- `min_samples` -- Le nombre minimal d'échantillons après lequel une déviation moyenne est calculée.\n\t- Type : int\n\t- Par défaut : 30\n- `max_dev` -- La déviation maximale par rapport à la fixation en pixels.\n\t- Type : int\n\t- Par défaut : 60\n- `reset_threshold` -- Si la distance horizontale ou verticale en pixels entre deux échantillons consécutifs est supérieure à ce seuil, la collecte d'échantillons est réinitialisée.\n\t- Type : int\n\t- Par défaut : 10"
  },
  "\n**Returns**: <code>Array.&lt;Array.&lt;Number&gt;&gt;</code> - An array of [x,y] coordinate arrays.  \n\n| Param | Type | Default | Description |\n| --- | --- | --- | --- |\n| n | <code>Number</code> |  | The number of x,y coordinates to generate. |\n| rho | <code>Number</code> |  | The radial coordinate, also distance or eccentricity,     of the first point. |\n| [phi0] | <code>Number</code> | <code>0</code> | The angular coordinate for the first coordinate.     This is a counterclockwise rotation in degrees (i.e. not radians),     where 0 is straight right. |\n| [pole] | <code>Array.&lt;Number&gt;</code> | <code>[0, 0]</code> | The reference point. |\n\n**Example**  \n```js\n// Draw 8 rectangles around a central fixation dot\n// ECMA 5.1 (browser + desktop)\nvar c = Canvas()\nc.fixdot()\nvar points = xy_circle(8, 100)\nfor (var i in points) {\n  var x = points[i][0]\n  var y = points[i][1]\n  c.rect({x: x - 10, y: y - 10, w: 20, h: 20})\n}\nc.show()\n// ECMA 6 (browser only)\nlet c = Canvas()\nc.fixdot()\nfor (let [x, y] of xy_circle(8, 100)) {\n  c.rect({x: x - 10, y: y - 10, w: 20, h: 20})\n}\nc.show()\n```\n<a name=\"xy_grid\"></a>\n\n## xy\\_grid(n, spacing, [pole]) ⇒ <code>Array.&lt;Array.&lt;Number&gt;&gt;</code>\nGenerates a list of points (x,y coordinates) in a grid. This can be used\nto draw stimuli in a grid arrangement.\n\n\n**Returns**: <code>Array.&lt;Array.&lt;Number&gt;&gt;</code> - An array of [x,y] coordinate arrays.  \n\n| Param | Type | Default | Description |\n| --- | --- | --- | --- |\n| n | <code>Number</code> \\| <code>Array.&lt;Number&gt;</code> |  | A number that indicates the number of     columns and rows, so that `n=2` indicates a 2x2 grid, or a [n_col,     n_row] array, so that `n=[2,3]` indicates a 2x3 grid. |\n| spacing | <code>Number</code> \\| <code>Array.&lt;Number&gt;</code> |  | A numeric value that indicates the     spacing between cells, or a [col_spacing, row_spacing] array. |\n| [pole] | <code>Array.&lt;Number&gt;</code> | <code>[0, 0]</code> | The reference point. |\n\n**Example**  \n```js\n// Draw a 4x4 grid of rectangles\n// ECMA 5 (desktop + browser)\nvar c = Canvas()\nc.fixdot()\nvar points = xy_grid(4, 100)\nfor (var i in points) {\n  var x = points[i][0]\n  var y = points[i][1]\n  c.rect({x: x - 10, y: y - 10, w: 20, h: 20})\n}\nc.show()\n// ECMA 6 (browser only)\nlet c = Canvas()\nc.fixdot()\nfor (let [x, y] of xy_grid(4, 100)) {\n  c.rect({x: x-10, y: y-10, w: 20, h: 20})\n}\nc.show()\n```\n<a name=\"xy_random\"></a>\n\n## xy\\_random(n, width, height, [min_dist], [pole]) ⇒ <code>Array.&lt;Array.&lt;Number&gt;&gt;</code>\nGenerates a list of random points (x,y coordinates) with a minimum\nspacing between each pair of points. This function will throw an error\nwhen the coordinate list cannot be generated, typically because there are\ntoo many points, the min_dist is set too high, or the width or height are\nset too low.\n\n\n**Returns**: <code>Array.&lt;Array.&lt;Number&gt;&gt;</code> - An array of [x,y] coordinate arrays.  \n\n| Param | Type | Default | Description |\n| --- | --- | --- | --- |\n| n | <code>Number</code> |  | The number of points to generate. |\n| width | <code>Number</code> |  | The width of the field with random points. |\n| height | <code>Number</code> |  | The height of the field with random points. |\n| [min_dist] | <code>Number</code> | <code>0</code> | The minimum distance between each point. |\n| [pole] | <code>Array.&lt;Number&gt;</code> | <code>[0, 0]</code> | The reference point. |\n\n**Example**  \n```js\n// Draw a 50 rectangles in a random grid\n// ECMA 5 (desktop + browser)\nvar c = Canvas()\nc.fixdot()\nvar points = xy_random(50, 500, 500, 40)\nfor (var i in points) {\n  var x = points[i][0]\n  var y = points[i][1]\n  c.rect({x: x - 10, y: y - 10, w: 20, h: 20})\n}\nc.show()   \n// ECMA 6 (browser only)\nlet c = Canvas()\nc.fixdot()\nfor (let [x, y] of xy_random(50, 500, 500, 40)) {\n  c.rect({x: x-10, y: y-10, w: 20, h: 20})\n}\nc.show()\n```\n": {
    "fr": "**Renvoie**: <code>Array.&lt;Array.&lt;Number&gt;&gt;</code> - Un tableau de tableaux de coordonnées [x,y].  \n\n| Param | Type | Par défaut | Description |\n| --- | --- | --- | --- |\n| n | <code>Nombre</code> |  | Le nombre de coordonnées x,y à générer. |\n| rho | <code>Nombre</code> |  | La coordonnée radiale, également distance ou excentricité,     du premier point. |\n| [phi0] | <code>Nombre</code> | <code>0</code> | La coordonnée angulaire pour la première coordonnée.     Il s'agit d'une rotation antihoraire en degrés (c'est-à-dire pas en radians),     où 0 est tout droit à droite. |\n| [pole] | <code>Array.&lt;Nombre&gt;</code> | <code>[0, 0]</code> | Le point de référence. |\n\n**Exemple**  \n```js\n// Dessinez 8 rectangles autour d'un point de fixation central\n// ECMA 5.1 (navigateur + bureau)\nvar c = Canvas()\nc.fixdot()\nvar points = xy_circle(8, 100)\nfor (var i in points) {\n  var x = points[i][0]\n  var y = points[i][1]\n  c.rect({x: x - 10, y: y - 10, w: 20, h: 20})\n}\nc.show()\n// ECMA 6 (navigateur uniquement)\nlet c = Canvas()\nc.fixdot()\nfor (let [x, y] of xy_circle(8, 100)) {\n  c.rect({x: x - 10, y: y - 10, w: 20, h: 20})\n}\nc.show()\n```\n<a name=\"xy_grid\"></a>\n\n## xy\\_grid(n, espacement, [pole]) ⇒ <code>Array.&lt;Array.&lt;Number&gt;&gt;</code>\nGénère une liste de points (coordonnées x,y) dans une grille. Ceci peut être utilisé\npour dessiner des stimuli dans un arrangement en grille.\n\n\n**Renvoie**: <code>Array.&lt;Array.&lt;Number&gt;&gt;</code> - Un tableau de tableaux de coordonnées [x,y].  \n\n| Param | Type | Par défaut | Description |\n| --- | --- | --- | --- |\n| n | <code>Nombre</code> \\| <code>Array.&lt;Number&gt;</code> |  | Un nombre qui indique le nombre de     colonnes et de rangées, de sorte que `n=2` indique une grille 2x2, ou un tableau [n_col,     n_row], de sorte que `n=[2,3]` indique une grille 2x3. |\n| espacement | <code>Nombre</code> \\| <code>Array.&lt;Number&gt;</code> |  | Une valeur numérique qui indique l'     espacement entre les cellules, ou un tableau [col_spacing, row_spacing]. |\n| [pole] | <code>Array.&lt;Number&gt;</code> | <code>[0, 0]</code> | Le point de référence. |\n\n**Exemple**  \n```js\n// Dessinez une grille 4x4 de rectangles\n// ECMA 5 (bureau + navigateur)\nvar c = Canvas()\nc.fixdot()\nvar points = xy_grid(4, 100)\nfor (var i in points) {\n  var x = points[i][0]\n  var y = points[i][1]\n  c.rect({x: x - 10, y: y - 10, w: 20, h: 20})\n}\nc.show()\n// ECMA 6 (navigateur uniquement)\nlet c = Canvas()\nc.fixdot()\nfor (let [x, y] of xy_grid(4, 100)) {\n  c.rect({x: x-10, y: y-10, w: 20, h: 20})\n}\nc.show()\n```\n<a name=\"xy_random\"></a>\n\n## xy\\_random(n, largeur, hauteur, [min_dist], [pole]) ⇒ <code>Array.&lt;Array.&lt;Number&gt;&gt;</code>\nGénère une liste de points aléatoires (coordonnées x,y) avec un minimum\nespacement entre chaque paire de points. Cette fonction générera une erreur\nlorsque la liste des coordonnées ne peut pas être générée, généralement parce qu'il y a\ntrop de points, le min_dist est trop élevé, ou la largeur ou la hauteur sont\ntrop bas.\n\n\n**Renvoie**: <code>Array.&lt;Array.&lt;Number&gt;&gt;</code> - Un tableau de tableaux de coordonnées [x,y].  \n\n| Param | Type | Par défaut | Description |\n| --- | --- | --- | --- |\n| n | <code>Nombre</code> |  | Le nombre de points à générer. |\n| largeur | <code>Nombre</code> |  | La largeur du champ avec des points aléatoires. |\n| hauteur | <code>Nombre</code> |  | La hauteur du champ avec des points aléatoires. |\n| [min_dist] | <code>Nombre</code> | <code>0</code> | La distance minimale entre chaque point. |\n| [pole] | <code>Array.&lt;Number&gt;</code> | <code>[0, 0]</code> | Le point de référence. |\n\n**Exemple**  \n```js\n// Dessinez 50 rectangles dans une grille aléatoire\n// ECMA 5 (bureau + navigateur)\nvar c = Canvas()\nc.fixdot()\nvar points = xy_random(50, 500, 500, 40)\nfor (var i in points) {\n  var x = points[i][0]\n  var y = points[i][1]\n  c.rect({x: x - 10, y: y - 10, w: 20, h: 20})\n}\nc.show()   \n// ECMA 6 (navigateur uniquement)\nlet c = Canvas()\nc.fixdot()\nfor (let [x, y] of xy_random(50, 500, 500, 40)) {\n  c.rect({x: x-10, y: y-10, w: 20, h: 20})\n}\nc.show()\n```"
  },
  "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# class __Keyboard__\n\nThe `Keyboard` class is used to collect keyboard responses. You generally create\na `Keyboard` object with the `Keyboard()` factory function, as described in the\nsection [Creating a Keyboard](#creating-a-keyboard).\n\n__Example__\n\n~~~ .python\n# Wait for a 'z' or 'x' key with a timeout of 3000 ms\nmy_keyboard = Keyboard(keylist=['z', 'x'], timeout=3000)\nstart_time = clock.time()\nkey, end_time = my_keyboard.get_key()\nresponse = key\nresponse_time = end_time - start_time\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## Things to know\n\n### Creating a Keyboard\n\nYou generally create a `Keyboard` with the `Keyboard()` factory function:\n\n~~~ .python\nmy_keyboard = Keyboard()\n~~~\n\nOptionally, you can pass [Response keywords](#response-keywords) to `Keyboard()`\nto set the default behavior:\n\n~~~ .python\nmy_keyboard = Keyboard(timeout=2000)\n~~~\n\n### Key names\n\n- Key names may differ between backends.\n- Keys can be identified either by character or name, and are case-insentive.\n  For example:\n  - The key 'a' is represented by 'a' and 'A'\n  - The up arrow is represented by 'up' and 'UP'\n  - The '/' key is represented by '/', 'slash', and 'SLASH'\n  - The spacebar is represented by 'space' and 'SPACE'\n- To find out the name of key, you can:\n  - Click on the 'list available keys' button of the KEYBOARD_RESPONSE item.\n  - Collect a key press with a KEYBOARD_RESPONSE item, and display the key name\n    through a FEEDBACK item with the text 'You pressed [response]' in it.\n\n### Response keywords\n\nFunctions that accept `**resp_args` take the following keyword arguments:\n\n- `timeout` specifies a timeout value in milliseconds, or is set to `None` to\n  disable the timeout.\n- `keylist` specifies a list of keys that are accepted, or is set to `None`\n  accept all keys.\n\n~~~ .python\n# Get a left or right arrow press with a timeout of 3000 ms\nmy_keyboard = Keyboard()\nkey, time = my_keyboard.get_key(keylist=[u'left', u'right'], timeout=3000)\n~~~\n\nResponse keywords only affect the current operation (except when passed to\n`Keyboard()`). To change the behavior for all subsequent\noperations, set the response properties directly:\n\n~~~ .python\n# Get two key A or B presses with a 5000 ms timeout\nmy_keyboard = Keyboard()\nmy_keyboard.keylist = [u'a', u'b']\nmy_keyboard.timeout = 5000\nkey1, time1 = my_keyboard.get_key()\nkey2, time2 = my_keyboard.get_key()\n~~~\n\nOr pass the response options to [keyboard.__init__][__init__]:\n\n~~~ .python\n# Get two key A or B presses with a 5000 ms timeout\nmy_keyboard = Keyboard(keylist=[u'a', u'b'], timeout=5000)\nkey1, time1 = my_keyboard.get_key()\nkey2, time2 = my_keyboard.get_key()\n~~~\n\n## flush(self)\n\nClears all pending keyboard input, not limited to the keyboard.\n\n\n\n__Returns__\n\n- True if a key had been pressed (i.e., if there was something to\nflush) and False otherwise.\n\n\n## get_key(\\*arglist, \\*\\*kwdict)\n\nCollects a single key press.\n\n\n__Parameters__\n\n- **\\*\\*resp_args**: Optional [response keywords](#response-keywords) (`timeout` and\n`keylist`) that will be used for this call to `Keyboard.get_key()`.\nThis does not affect subsequent operations.\n\n__Returns__\n\n- A `(key, timestamp)` tuple. `key` is None if a timeout occurs.\n\n__Example__\n\n~~~ .python\nmy_keyboard = Keyboard()\nresponse, timestamp = my_keyboard.get_key(timeout=5000)\nif response is None:\n        print(u'A timeout occurred!')\n~~~\n\n\n\n## get_key_release(\\*arglist, \\*\\*kwdict)\n\n*New in v3.2.0*\n\nCollects a single key release.\n\n*Important:* This\nfunction currently assumes a QWERTY keyboard\nlayout (unlike\n`Keyboard.get_key()`). This means that the returned\n`key` may be\nincorrect on non-QWERTY keyboard layouts. In addition,\nthis function is\nnot implemented for the *psycho* backend.\n\n__Parameters__\n\n- **\\*\\*resp_args**: Optional [response keywords](#response-keywords) (`timeout` and\n`keylist`) that will be used for this call to\n`Keyboard.get_key_release()`. This does not affect subsequent\noperations.\n\n__Returns__": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# classe __Keyboard__\n\nLa classe `Keyboard` est utilisée pour collecter les réponses au clavier. Vous créez généralement\nun objet `Keyboard` avec la fonction usine `Keyboard()`, comme décrit dans la section [Créer un clavier](#creating-a-keyboard).\n\n__Exemple__\n\n~~~ .python\n# Attendre une touche 'z' ou 'x' avec un délai d'attente de 3000 ms\nmy_keyboard = Keyboard(keylist=['z', 'x'], timeout=3000)\nstart_time = clock.time()\nkey, end_time = my_keyboard.get_key()\nresponse = key\nresponse_time = end_time - start_time\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## Choses à savoir\n\n### Créer un clavier\n\nVous créez généralement un `Keyboard` avec la fonction usine `Keyboard()`:\n\n~~~ .python\nmy_keyboard = Keyboard()\n~~~\n\nFacultativement, vous pouvez passer des [Mots-clés de réponse](#response-keywords) à `Keyboard()`\npour définir le comportement par défaut:\n\n~~~ .python\nmy_keyboard = Keyboard(timeout=2000)\n~~~\n\n### Noms de touches\n\n- Les noms de touches peuvent varier entre les interfaces.\n- Les touches peuvent être identifiées soit par caractère soit par nom, et ne sont pas sensibles à la casse.\n  Par exemple :\n  - La touche 'a' est représenté par 'a' et 'A'\n  - La flèche vers le haut est représentée par 'up' et 'UP'\n  - La touche '/' est représentée par '/', 'slash', et 'SLASH'\n  - La barre d'espace est représentée par 'space' et 'SPACE'\n- Pour connaître le nom d'une touche, vous pouvez :\n  - Cliquer sur le bouton \"lister les touches disponibles\" de l'élément KEYBOARD_RESPONSE.\n  - Collecter une pression de touche avec un élément KEYBOARD_RESPONSE, et afficher le nom de la touche\n    à travers un élément FEEDBACK avec le texte 'Vous avez appuyé sur [response]' dedans.\n\n### Mots-clés de réponse\n\nLes fonctions qui acceptent `**resp_args` prennent les arguments de mots-clés suivants :\n\n- `timeout` spécifie une valeur de délai d'attente en millisecondes ou est défini sur `None` pour\n  désactiver le délai d'attente.\n- `keylist` spécifie une liste de touches acceptées, ou est défini sur `None`\n  pour accepter toutes les touches.\n\n~~~ .python\n# Obtenir une pression de la flèche gauche ou droite avec un délai d'attente de 3000 ms\nmy_keyboard = Keyboard()\nkey, time = my_keyboard.get_key(keylist=[u'left', u'right'], timeout=3000)\n~~~\n\nLes mots-clés de réponse n'affectent que l'opération en cours (sauf lorsqu'ils sont passés à\n`Keyboard()`). Pour changer le comportement pour toutes les opérations ultérieures, définissez directement les propriétés de la réponse :\n\n~~~ .python\n# Obtenir deux pressions de touche A ou B avec un délai d'attente de 5000 ms\nmy_keyboard = Keyboard()\nmy_keyboard.keylist = [u'a', u'b']\nmy_keyboard.timeout = 5000\nkey1, time1 = my_keyboard.get_key()\nkey2, time2 = my_keyboard.get_key()\n~~~\n\nOu passez les options de réponse à [keyboard.__init__][__init__]:\n\n~~~ .python\n# Obtenir deux pressions de touche A ou B avec un délai d'attente de 5000 ms\nmy_keyboard = Keyboard(keylist=[u'a', u'b'], timeout=5000)\nkey1, time1 = my_keyboard.get_key()\nkey2, time2 = my_keyboard.get_key()\n~~~\n\n## flush(self)\n\nEfface toute entrée clavier en attente, sans se limiter au clavier.\n\n__Renvoie__\n\n- True si une touche a été appuyée (c'est-à-dire s'il y avait quelque chose à\nvider) et False sinon.\n\n## get_key(\\*arglist, \\*\\*kwdict)\n\nCollecte une seule pression de touche.\n\n__Paramètres__\n\n- **\\*\\*resp_args**: Facultatif [mots-clés de réponse](#response-keywords) (`timeout` et\n`keylist`) qui seront utilisés pour cet appel à `Keyboard.get_key()`.\nCela n'affecte pas les opérations ultérieures.\n\n__Renvoie__\n\n- Un tuple `(key, timestamp)`. `key` est None si un délai d'attente se produit.\n\n__Exemple__\n\n~~~ .python\nmy_keyboard = Keyboard()\nresponse, timestamp = my_keyboard.get_key(timeout=5000)\nif response is None:\n        print(u'Un délai d\\'attente s\\'est produit!')\n~~~\n\n\n\n## get_key_release(\\*arglist, \\*\\*kwdict)\n\n*Nouveau dans v3.2.0*\n\nCollecte une seule libération de touche.\n\n*Important:* Cette\nfonction suppose actuellement une disposition de clavier QWERTY\ncontrairement à\n`Keyboard.get_key()`. Cela signifie que la touche retournée\npeut être\nincorrecte sur les dispositions de clavier non-QWERTY. De plus, cette fonction n'est\npas implémentée pour le backend *psycho*.\n\n__Paramètres__\n\n- **\\*\\*resp_args**: Facultatif [mots-clés de réponse](#response-keywords) (`timeout` et\n`keylist`) qui seront utilisés pour cet appel à\n`Keyboard.get_key_release()`. Cela n'affecte pas les opérations ultérieures.\n\n__Renvoie__"
  },
  "- A `(key, timestamp)` tuple. `key` is None if a timeout occurs.\n\n__Example__\n\n~~~ .python\nmy_keyboard = Keyboard()\nresponse, timestamp = my_keyboard.get_key_release(timeout=5000)\nif response is None:\n        print(u'A timeout occurred!')\n~~~\n\n\n\n## get_mods(self)\n\nReturns a list of keyboard moderators (e.g., shift, alt, etc.) that\nare currently pressed.\n\n\n\n__Returns__\n\n- A list of keyboard moderators. An empty list is returned if no\nmoderators are pressed.\n\n__Example__\n\n~~~ .python\nmy_keyboard = Keyboard()\nmoderators = my_keyboard.get_mods()\nif u'shift' in moderators:\n        print(u'The shift-key is down!')\n~~~\n\n\n\n## show_virtual_keyboard(visible=True)\n\nShows or hides a virtual keyboard if this is supported by the\nback-end. This function is only necessary if you want the virtual\nkeyboard to remain visible while collecting multicharacter\nresponses. Otherwise, `Keyboard.get_key()` will implicitly show and\nhide the keyboard for a single-character response.\n\nThis function does nothing for back-ends that do not support virtual\nkeyboards.\n\n__Parameters__\n\n- **visible**: True if the keyboard should be shown, False otherwise.\n\n__Example__\n\n~~~ .python\nmy_keyboard = Keyboard()\nmy_keyboard.show_virtual_keyboard(True)\nresponse1, timestamp2 = my_keyboard.get_key()\nresponse2, timestamp2 = my_keyboard.get_key()\nmy_keyboard.show_virtual_keyboard(False)\n~~~\n\n\n\n## synonyms(key)\n\nGives a list of synonyms for a key, either codes or names. Synonyms\ninclude all variables as types and as Unicode strings (if applicable).\n\n\n\n__Returns__\n\n- A list of synonyms\n\n\n## valid_keys(self)\n\nTries to guess which key names are accepted by the back-end. For\ninternal use.\n\n\n\n__Returns__\n\n- A list of valid key names.\n\n\n</div>\n\n": {
    "fr": "- Un tuple `(key, timestamp)`. `key` est None si un délai d'attente se produit.\n\n__Exemple__\n\n~~~ .python\nmy_keyboard = Keyboard()\nresponse, timestamp = my_keyboard.get_key_release(timeout=5000)\nif response is None:\n        print(u'Un délai d'attente est survenu!')\n~~~\n\n\n\n## get_mods(self)\n\nRenvoie une liste des modificateurs de clavier (par exemple, shift, alt, etc.) qui\nsont actuellement enfoncés.\n\n\n\n__Retourne__\n\n- Une liste de modificateurs de clavier. Une liste vide est renvoyée si aucune\n  modificateur n'est enfoncé.\n\n__Exemple__\n\n~~~ .python\nmy_keyboard = Keyboard()\nmoderateurs = my_keyboard.get_mods()\nif u'shift' in moderateurs:\n        print(u'La touche majuscule est enfoncée!')\n~~~\n\n\n\n## show_virtual_keyboard(visible=True)\n\nAffiche ou masque un clavier virtuel si cela est pris en charge par l'arrière-plan. Cette fonction est uniquement nécessaire si vous souhaitez que le clavier virtuel reste visible lors de la collecte de réponses multicharactères. Sinon, `Keyboard.get_key()` montrera et masquera implicitement le clavier pour une réponse à un seul caractère.\n\nCette fonction ne fait rien pour les back-ends qui ne prennent pas en charge les claviers virtuels.\n\n__Paramètres__\n\n- **visible**: True si le clavier doit être affiché, False sinon.\n\n__Exemple__\n\n~~~ .python\nmy_keyboard = Keyboard()\nmy_keyboard.show_virtual_keyboard(True)\nresponse1, timestamp1 = my_keyboard.get_key()\nresponse2, timestamp2 = my_keyboard.get_key()\nmy_keyboard.show_virtual_keyboard(False)\n~~~\n\n\n\n## synonyms(key)\n\nDonne une liste de synonymes pour une clé, soit des codes ou des noms. Les synonymes\nincluent toutes les variables en tant que types et en tant que chaînes Unicode (le cas échéant).\n\n\n\n__Retourne__\n\n- Une liste de synonymes\n\n\n## valid_keys(self)\n\nTente de deviner quels noms de clés sont acceptés par l'arrière-plan. Pour\nusage interne.\n\n\n\n__Retourne__\n\n- Une liste de noms de clés valides.\n\n\n</div>"
  },
  "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __joystick__\n\nIf you insert the JOYSTICK plugin at the start of your experiment, a\nJOYSTICK object automatically becomes part of the experiment object\nand can be used within an INLINE_SCRIPT item as `joystick`.\n\n{% set arg_joybuttonlist = \"A list of buttons that are accepted or \" +\n\"`None` to accept all buttons.\" %}\n{% set arg_timeout = \"A timeout value in milliseconds or `None` for no \" +\n\"timeout.\" %}\n\n<notranslate>[TOC]</notranslate>\n\n## flush(self)\n\nClears all pending input, not limited to the joystick.\n\n\n\n__Returns__\n\n- True if joyinput was pending (i.e., if there was something to\nflush) and False otherwise.\n\n\n## get_joyaxes(timeout=None)\n\nWaits for joystick axes movement.\n\n\n__Parameters__\n\n- **timeout**: A timeout value in milliseconds or `None` to use default timeout.\n\n__Returns__\n\n- A `(position, timestamp)` tuple. `position` is `None` if a timeout\noccurs. Otherwise, `position` is an `(x, y, z)` tuple.\n\n\n## get_joyballs(timeout=None)\n\nWaits for joystick trackball movement.\n\n\n__Parameters__\n\n- **timeout**: A timeout value in milliseconds or `None` to use default timeout.\n\n__Returns__\n\n- A `(position, timestamp)` tuple. The position is `None` if a\ntimeout occurs.\n\n\n## get_joybutton(joybuttonlist=None, timeout=None)\n\nCollects joystick button input.\n\n\n__Parameters__\n\n- **joybuttonlist**: A list of buttons that are accepted or `None` to default\njoybuttonlist.\n- **timeout**: A timeout value in milliseconds or `None` to use default timeout.\n\n__Returns__\n\n- A (joybutton, timestamp) tuple. The joybutton is `None` if a\ntimeout occurs.\n\n\n## get_joyhats(timeout=None)\n\nWaits for joystick hat movement.\n\n\n__Parameters__\n\n- **timeout**: A timeout value in milliseconds or `None` to use default timeout.\n\n__Returns__\n\n- A `(position, timestamp)` tuple. `position` is `None` if a timeout\noccurs. Otherwise, `position` is an `(x, y)` tuple.\n\n\n## get_joyinput(joybuttonlist=None, timeout=None)\n\nWaits for any joystick input (buttons, axes, hats or balls).\n\n\n__Parameters__\n\n- **joybuttonlist**: A list of buttons that are accepted or `None` to default\njoybuttonlist.\n- **timeout**: A timeout value in milliseconds or `None` to use default timeout.\n\n__Returns__\n\n- A (event, value, timestamp) tuple. The value is `None` if a timeout\noccurs. `event` is one of `None`, 'joybuttonpress',\n'joyballmotion', 'joyaxismotion', or 'joyhatmotion'\n\n\n## input_options(self)\n\nGenerates a list with the number of available buttons, axes, balls\nand hats.\n\n\n\n__Returns__\n\n- A list with number of inputs as: [buttons, axes, balls,\nhats].\n\n\n## set_joybuttonlist(joybuttonlist=None)\n\nSets a list of accepted buttons.\n\n\n__Parameters__\n\n- **joybuttonlist**: {{arg_joybuttonlist}}\n\n\n## set_timeout(timeout=None)\n\nSets a timeout.\n\n\n__Parameters__\n\n- **timeout**: {{arg_timeout}}\n\n\n</div>\n\n": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __joystick__\n\nSi vous insérez le plugin JOYSTICK au début de votre expérience, un\nobjet JOYSTICK fait automatiquement partie de l'objet expérience\net peut être utilisé dans un élément INLINE_SCRIPT sous le nom `joystick`.\n\n{% set arg_joybuttonlist = \"Une liste de boutons acceptés ou \" +\n\"`None` pour accepter tous les boutons.\" %}\n{% set arg_timeout = \"Une valeur de délai d'attente en millisecondes ou `None` pour ne pas avoir \" +\n\"de délai d'attente.\" %}\n\n<notranslate>[TOC]</notranslate>\n\n## flush(self)\n\nEfface toutes les entrées en attente, sans se limiter au joystick.\n\n\n\n__Renvoie__\n\n- True si l'entrée joyinput était en attente (c'est-à-dire s'il y avait quelque chose à\nvider) et False sinon.\n\n\n## get_joyaxes(timeout=None)\n\nAttend le mouvement des axes du joystick.\n\n\n__Paramètres__\n\n- **timeout**: Une valeur de délai d'attente en millisecondes ou `None` pour utiliser le délai d'attente par défaut.\n\n__Renvoie__\n\n- Un tuple `(position, timestamp)`. `position` est `None` si un délai d'attente\nse produit. Sinon, `position` est un tuple `(x, y, z)`.\n\n\n## get_joyballs(timeout=None)\n\nAttend le mouvement des boules de commande du joystick.\n\n\n__Paramètres__\n\n- **timeout**: Une valeur de délai d'attente en millisecondes ou `None` pour utiliser le délai d'attente par défaut.\n\n__Renvoie__\n\n- Un tuple `(position, timestamp)`. La position est `None` si un\ndélai d'attente se produit.\n\n\n## get_joybutton(joybuttonlist=None, timeout=None)\n\nCollecte les entrées des boutons du joystick.\n\n\n__Paramètres__\n\n- **joybuttonlist**: Une liste de boutons acceptés ou `None` pour la liste joybutton par défaut.\n- **timeout**: Une valeur de délai d'attente en millisecondes ou `None` pour utiliser le délai d'attente par défaut.\n\n__Renvoie__\n\n- Un tuple (joybutton, timestamp). Le joybutton est `None` si un\ndélai d'attente se produit.\n\n\n## get_joyhats(timeout=None)\n\nAttend le mouvement des chapeaux du joystick.\n\n\n__Paramètres__\n\n- **timeout**: Une valeur de délai d'attente en millisecondes ou `None` pour utiliser le délai d'attente par défaut.\n\n__Renvoie__\n\n- Un tuple `(position, timestamp)`. `position` est `None` si un délai d'attente\nse produit. Sinon, `position` est un tuple `(x, y)`.\n\n\n## get_joyinput(joybuttonlist=None, timeout=None)\n\nAttend n'importe quelle entrée de joystick (boutons, axes, chapeaux ou boules).\n\n\n__Paramètres__\n\n- **joybuttonlist**: Une liste de boutons acceptés ou `None` pour la liste joybutton par défaut.\n- **timeout**: Une valeur de délai d'attente en millisecondes ou `None` pour utiliser le délai d'attente par défaut.\n\n__Renvoie__\n\n- Un tuple (event, value, timestamp). La valeur est `None` si un délai d'attente\nse produit. `event` est l'un des `None`, 'joybuttonpress',\n'joyballmotion', 'joyaxismotion' ou 'joyhatmotion'\n\n\n## input_options(self)\n\nGénère une liste avec le nombre de boutons, axes, boules\net chapeaux disponibles.\n\n\n\n__Renvoie__\n\n- Une liste avec le nombre d'entrées comme suit : [boutons, axes, boules,\nchapeaux].\n\n\n## set_joybuttonlist(joybuttonlist=None)\n\nDéfinit une liste de boutons acceptés.\n\n\n__Paramètres__\n\n- **joybuttonlist**: {{arg_joybuttonlist}}\n\n\n## set_timeout(timeout=None)\n\nDéfinit un délai d'attente.\n\n\n__Paramètres__\n\n- **timeout**: {{arg_timeout}}\n\n\n</div>"
  },
  "Fired in: [general_properties.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/widgets/general_properties.py)\n\n```python\nextension_manager.fire(u'prepare_change_experiment')\n```\n\n### prepare_delete_item\n\nFired in: [qtitem_store.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/misc/qtitem_store.py)\n\n```python\nextension_manager.fire(u'prepare_delete_item', name=name)\n```\n\n### prepare_open_item\n\nFired in: [qtitem.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/qtitem.py)\n\n```python\nextension_manager.fire(u'prepare_open_item', name=self.name)\n```\n\n### prepare_purge_unused_items\n\nFired in: [unused_widget.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/widgets/unused_widget.py)\n\n```python\nextension_manager.fire(u'prepare_purge_unused_items')\n```\n\n### prepare_regenerate\n\nFired in: [qtopensesame.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/qtopensesame.py)\n\n```python\nextension_manager.fire(u'prepare_regenerate')\n```\n\n### prepare_rename_item\n\nFired in: [qtitem_store.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/misc/qtitem_store.py)\n\n```python\nextension_manager.fire(u'prepare_rename_item', from_name=from_name,\n\t\t\tto_name=to_name)\n```\n\n### purge_unused_items\n\nFired in: [unused_widget.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/widgets/unused_widget.py)\n\n```python\nextension_manager.fire(u'purge_unused_items')\n```\n\n### pyqode_clear_breakpoints\n\nFired in: [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_clear_breakpoints')\n```\n\n### pyqode_resume_auto_backend_restart\n\nFired in: [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_resume_auto_backend_restart')\n```\n\nFired in: [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_resume_auto_backend_restart')\n```\n\nFired in: [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_resume_auto_backend_restart')\n```\n\nFired in: [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_resume_auto_backend_restart')\n```\n\n### pyqode_select_indentation_mode\n\nFired in: [menubar.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/opensesame_ide/menubar.py)\n\n```python\nextension_manager.fire('pyqode_select_indentation_mode')\n```\n\n### pyqode_suspend_auto_backend_restart\n\nFired in: [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_suspend_auto_backend_restart')\n```\n\nFired in: [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_suspend_auto_backend_restart')\n```\n\nFired in: [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_suspend_auto_backend_restart')\n```\n\nFired in: [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_suspend_auto_backend_restart')\n```\n\n### regenerate\n\nFired in: [qtopensesame.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/qtopensesame.py)\n\n```python\nextension_manager.fire(u'regenerate')\n```": {
    "fr": "Déclenché dans : [general_properties.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/widgets/general_properties.py)\n\n```python\nextension_manager.fire(u'prepare_change_experiment')\n```\n\n### prepare_delete_item\n\nDéclenché dans : [qtitem_store.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/misc/qtitem_store.py)\n\n```python\nextension_manager.fire(u'prepare_delete_item', name=name)\n```\n\n### prepare_open_item\n\nDéclenché dans : [qtitem.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/qtitem.py)\n\n```python\nextension_manager.fire(u'prepare_open_item', name=self.name)\n```\n\n### prepare_purge_unused_items\n\nDéclenché dans : [unused_widget.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/widgets/unused_widget.py)\n\n```python\nextension_manager.fire(u'prepare_purge_unused_items')\n```\n\n### prepare_regenerate\n\nDéclenché dans : [qtopensesame.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/qtopensesame.py)\n\n```python\nextension_manager.fire(u'prepare_regenerate')\n```\n\n### prepare_rename_item\n\nDéclenché dans : [qtitem_store.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/misc/qtitem_store.py)\n\n```python\nextension_manager.fire(u'prepare_rename_item', from_name=from_name,\n\t\t\tto_name=to_name)\n```\n\n### purge_unused_items\n\nDéclenché dans : [unused_widget.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/widgets/unused_widget.py)\n\n```python\nextension_manager.fire(u'purge_unused_items')\n```\n\n### pyqode_clear_breakpoints\n\nDéclenché dans : [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_clear_breakpoints')\n```\n\n### pyqode_resume_auto_backend_restart\n\nDéclenché dans : [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_resume_auto_backend_restart')\n```\n\nDéclenché dans : [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_resume_auto_backend_restart')\n```\n\nDéclenché dans : [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_resume_auto_backend_restart')\n```\n\nDéclenché dans : [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_resume_auto_backend_restart')\n```\n\n### pyqode_select_indentation_mode\n\nDéclenché dans : [menubar.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/opensesame_ide/menubar.py)\n\n```python\nextension_manager.fire('pyqode_select_indentation_mode')\n```\n\n### pyqode_suspend_auto_backend_restart\n\nDéclenché dans : [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_suspend_auto_backend_restart')\n```\n\nDéclenché dans : [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_suspend_auto_backend_restart')\n```\n\nDéclenché dans : [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_suspend_auto_backend_restart')\n```\n\nDéclenché dans : [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('pyqode_suspend_auto_backend_restart')\n```\n\n### regenerate\n\nDéclenché dans : [qtopensesame.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/qtopensesame.py)\n\n```python\nextension_manager.fire(u'regenerate')\n```"
  },
  "__Returns:__\n\nA boolean indicating if drift check is ok (True) or not (False).\n\n- Type: bool\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-get_eyetracker_clock_async\" markdown=\"1\">\n\n## function __eyetracker\\.get\\_eyetracker\\_clock\\_async__\\(\\)\n\nReturns the difference between tracker time and PyGaze time, which can be used to synchronize timing\n\n__Returns:__\n\nThe difference between eyetracker time and PyGaze time.\n\n- Type: int, float\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-log\" markdown=\"1\">\n\n## function __eyetracker\\.log__\\(msg\\)\n\nWrites a message to the log file.\n\n__Arguments:__\n\n- `msg` -- A message.\n\t- Type: str, unicode\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-log_var\" markdown=\"1\">\n\n## function __eyetracker\\.log\\_var__\\(var, val\\)\n\nWrites a variable's name and value to the log file\n\n__Arguments:__\n\n- `var` -- A variable name.\n\t- Type: str, unicode\n- `val` -- A variable value\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-pupil_size\" markdown=\"1\">\n\n## function __eyetracker\\.pupil\\_size__\\(\\)\n\nReturns the newest pupil size sample; size may be measured as the diameter or the area of the pupil, depending on your setup (note that pupil size mostly is given in an arbitrary units).\n\n__Returns:__\n\nReturns pupil size for the eye that is currently being tracked (as specified by self.eye_used) or -1 when no data is obtainable.\n\n- Type: int, float\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-sample\" markdown=\"1\">\n\n## function __eyetracker\\.sample__\\(\\)\n\nReturns newest available gaze position.\n\n__Returns:__\n\nAn (x,y) tuple or a (-1,-1) on an error.\n\n- Type: tuple\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-send_command\" markdown=\"1\">\n\n## function __eyetracker\\.send\\_command__\\(cmd\\)\n\nDirectly sends a command to the eye tracker (not supported for all brands; might produce a warning message if your setup does not support direct commands).\n\n__Arguments:__\n\n- `cmd` -- The command to be sent to the eye tracker.\n\t- Type: str, unicode\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-set_detection_type\" markdown=\"1\">\n\n## function __eyetracker\\.set\\_detection\\_type__\\(eventdetection\\)\n\nSet the event detection type to either PyGaze algorithms, or\nnative algorithms as provided by the manufacturer (only if\navailable: detection type will default to PyGaze if no native\nfunctions are available)\n\n__Arguments:__\n\n- `eventdetection` -- A string indicating which detection type\nshould be employed: either 'pygaze' for\nPyGaze event detection algorithms or\n'native' for manufacturers algorithms (only\nif available; will default to 'pygaze' if no\nnative event detection is available)\n\t- Type: str, unicode\n\n__Returns:__\n\nDetection type for saccades, fixations and blinks in a tuple, e.g. ('pygaze','native','native') when 'native' was passed, but native detection was not available for saccade detection.\n\n- Type: tuple\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-set_draw_calibration_target_func\" markdown=\"1\">\n\n## function __eyetracker\\.set\\_draw\\_calibration\\_target\\_func__\\(func\\)\n\nSpecifies a custom function to draw the calibration target. This will function will override the default [draw_calibration_target].\n\n__Arguments:__\n\n- `func` -- The function to draw a calibration target. This function should accept two parameters, for the x and y coordinate of the target.\n\t- Type: function\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-set_draw_drift_correction_target_func\" markdown=\"1\">\n\n## function __eyetracker\\.set\\_draw\\_drift\\_correction\\_target\\_func__\\(func\\)\n\nSpecifies a custom function to draw the drift-correction target. This function will override the default [draw_drift_correction_target].\n\n__Arguments:__\n\n- `func` -- The function to draw a drift-correction target. This function should accept two parameters, for the x and y coordinate of the target.\n\t- Type: function\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-set_eye_used\" markdown=\"1\">": {
    "fr": "__Renvoie :__\n\nUn booléen indiquant si la vérification de dérive est correcte (True) ou non (False).\n\n- Type : bool\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-get_eyetracker_clock_async\" markdown=\"1\">\n\n## fonction __eyetracker\\.get\\_eyetracker\\_clock\\_async__\\(\\)\n\nRenvoie la différence entre l'heure du suiveur et l'heure de PyGaze, qui peut être utilisée pour synchroniser le temps\n\n__Renvoie :__\n\nLa différence entre l'heure du suiveur de regard et l'heure de PyGaze.\n\n- Type : int, float\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-log\" markdown=\"1\">\n\n## fonction __eyetracker\\.log__\\(msg\\)\n\nÉcrit un message dans le fichier de journal.\n\n__Arguments :__\n\n- `msg` -- Un message.\n\t- Type : str, unicode\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-log_var\" markdown=\"1\">\n\n## fonction __eyetracker\\.log\\_var__\\(var, val\\)\n\nÉcrit le nom et la valeur d'une variable dans le fichier de journal\n\n__Arguments :__\n\n- `var` -- Un nom de variable.\n\t- Type : str, unicode\n- `val` -- Une valeur de variable\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-pupil_size\" markdown=\"1\">\n\n## fonction __eyetracker\\.pupil\\_size__\\(\\)\n\nRenvoie la taille de la pupille la plus récente ; la taille peut être mesurée comme le diamètre ou la surface de la pupille, selon votre configuration (notez que la taille de la pupille est généralement donnée en unités arbitraires).\n\n__Renvoie :__\n\nRenvoie la taille de la pupille pour l'œil qui est actuellement suivi (tel que spécifié par self.eye_used) ou -1 lorsque aucune donnée n'est obtenable.\n\n- Type : int, float\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-sample\" markdown=\"1\">\n\n## fonction __eyetracker\\.sample__\\(\\)\n\nRenvoie la position du regard la plus récente disponible.\n\n__Renvoie :__\n\nUn tuple (x, y) ou un (-1, -1) en cas d'erreur.\n\n- Type : tuple\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-send_command\" markdown=\"1\">\n\n## fonction __eyetracker\\.send\\_command__\\(cmd\\)\n\nEnvoie directement une commande au suiveur de regard (non pris en charge pour toutes les marques ; peut produire un message d'avertissement si votre configuration ne prend pas en charge les commandes directes).\n\n__Arguments :__\n\n- `cmd` -- La commande à envoyer au suiveur de regard.\n\t- Type : str, unicode\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-set_detection_type\" markdown=\"1\">\n\n## fonction __eyetracker\\.set\\_detection\\_type__\\(eventdetection\\)\n\nDéfinit le type de détection des événements sur les algorithmes PyGaze, ou\nles algorithmes natifs fournis par le fabricant (seulement si\ndisponible : le type de détection sera par défaut PyGaze si aucune fonction native\nn'est disponible)\n\n__Arguments :__\n\n- `eventdetection` -- Une chaîne indiquant quel type de détection\ndoit être utilisé : soit 'pygaze' pour\nles algorithmes de détection d'événements PyGaze ou\n'native' pour les algorithmes du fabricant (seulement\nsi disponible ; par défaut à 'pygaze' si aucune\ndétection d'événements native n'est disponible)\n\t- Type : str, unicode\n\n__Renvoie :__\n\nType de détection pour les saccades, les fixations et les clignotements dans un tuple, par exemple ('pygaze','native','native') lorsque 'native' a été passé, mais la détection native n'était pas disponible pour la détection de saccade.\n\n- Type : tuple\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-set_draw_calibration_target_func\" markdown=\"1\">\n\n## fonction __eyetracker\\.set\\_draw\\_calibration\\_target\\_func__\\(func\\)\n\nSpécifie une fonction personnalisée pour dessiner la cible de calibration. Cette fonction remplacera la fonction par défaut [draw_calibration_target].\n\n__Arguments :__\n\n- `func` -- La fonction pour dessiner une cible de calibration. Cette fonction doit accepter deux paramètres, pour les coordonnées x et y de la cible.\n\t- Type : fonction\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-set_draw_drift_correction_target_func\" markdown=\"1\">\n\n## fonction __eyetracker\\.set\\_draw\\_drift\\_correction\\_target\\_func__\\(func\\)\n\nSpécifie une fonction personnalisée pour dessiner la cible de correction de dérive. Cette fonction remplacera la fonction par défaut [draw_drift_correction_target].\n\n__Arguments :__\n\n- `func` -- La fonction pour dessiner une cible de correction de dérive. Cette fonction doit accepter deux paramètres, pour les coordonnées x et y de la cible.\n\t- Type : fonction\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-set_eye_used\" markdown=\"1\">"
  },
  "The `Canvas` class is used to present visual stimuli. You generally\ncreate a `Canvas` object with the `Canvas()` factory function. Because\n`Canvas()` is a function, you do *not* need to use `new` when calling it.\nThe JavaScript `Canvas` class mimicks the corresponding Python `Canvas`\nclass.\n\n__Style keywords__ can be passed to all functions that accept `styleArgs`.\nStyle keywords can also be set as properties of the `Canvas` object. For an\noverview of style keywords, see the\n[Python `Canvas` documentation](%url:manual/python/canvas%).\n\n__Important:__ JavaScript doesn't support named parameters (or: keywords).\nTherefore, parameters are passed an `Object` with named properties and\ndefault values. Like so:\n\n```js\nvar myCanvas = Canvas()\n// (correct) pass parameters as an Object ...\nmyCanvas.fixdot({color: 'red'})\n// (incorrect) ... and *not* as named parameters\n// myCanvas.fixdot(color='red')\nmyCanvas.show()\n```\n\n<notranslate>[TOC]</notranslate>\n\n<a name=\"Canvas.arrow\"></a>\n\n### Canvas.arrow(obj)\nDraws an arrow. An arrow is a polygon consisting of 7 vertices, with an\narrowhead pointing at (ex, ey).\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.sx | <code>Number</code> | <code>0</code> | \n| obj.sy | <code>Number</code> | <code>0</code> | \n| obj.ex | <code>Number</code> | <code>50</code> | \n| obj.ey | <code>Number</code> | <code>0</code> | \n| obj.body_length | <code>Number</code> | <code>0.8</code> | \n| obj.body_width | <code>Number</code> | <code>0.5</code> | \n| obj.head_width | <code>Number</code> | <code>30</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nvar w = vars.width / 2\nvar h = vars.height / 2\n// Important: parameters are passed as an Object\nmyCanvas.arrow({sx: 0, sy: 0, w: w, h: h, head_width:100, body_length:0.5})\n```\n<a name=\"Canvas.clear\"></a>\n\n### Canvas.clear([styleArgs])\nClears the canvas with the current background color. Note that it is\n\t generally faster to use a different canvas for each experimental\n\t display than to use a single canvas and repeatedly clear and redraw\n\t it.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| [styleArgs] | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.fixdot({color: 'green'})\nmyCanvas.show()\n// do something\nmyCanvas.clear()\nmyCanvas.fixdot({color: 'red'})\nmyCanvas.show()\n```\n<a name=\"Canvas.circle\"></a>\n\n### Canvas.circle(obj)\nDraws a circle.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| obj.r | <code>Number</code> | <code>50</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.circle({x: 100, y: 100, r: 50, fill: true, color:'red'})\n```\n<a name=\"Canvas.ellipse\"></a>\n\n### Canvas.ellipse(obj)\nDraws an ellipse.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>-50</code> | \n| obj.y | <code>Number</code> | <code>-25</code> | \n| obj.w | <code>Number</code> | <code>100</code> | \n| obj.h | <code>Number</code> | <code>50</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.ellipse({x: -10, y: -10, w: 20, h: 20, fill:true})\n```\n<a name=\"Canvas.fixdot\"></a>\n\n### Canvas.fixdot(obj)\nDraws a fixation dot. The default style is medium-open.": {
    "fr": "La classe `Canvas` est utilisée pour présenter des stimuli visuels. Vous créez généralement un objet `Canvas` avec la fonction de fabrique `Canvas()`. Comme `Canvas()` est une fonction, vous n'avez *pas* besoin d'utiliser `new` lors de son appel.\nLa classe JavaScript `Canvas` imite la classe Python `Canvas` correspondante.\n\n__Les mots-clés de style__ peuvent être passés à toutes les fonctions qui acceptent `styleArgs`.\nLes mots-clés de style peuvent également être définis comme propriétés de l'objet `Canvas`. Pour un\naperçu des mots-clés de style, voir la [documentation Python `Canvas`](%url:manual/python/canvas/).\n\n__Important :__ JavaScript ne prend pas en charge les paramètres nommés (ou : les mots-clés).\nPar conséquent, les paramètres sont passés via un `Object` avec des propriétés nommées et\ndes valeurs par défaut. Comme ceci :\n\n```js\nvar myCanvas = Canvas()\n// (correct) passez des paramètres comme un Object ...\nmyCanvas.fixdot({color: 'red'})\n// (incorrect) ... et *non* comme des paramètres nommés\n// myCanvas.fixdot(color='red')\nmyCanvas.show()\n```\n\n<notranslate>[TOC]</notranslate>\n\n<a name=\"Canvas.arrow\"></a>\n\n### Canvas.arrow(obj)\nDessine une flèche. Une flèche est un polygone composé de 7 sommets, avec une\npointe de flèche pointant vers (ex, ey).\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.sx | <code>Number</code> | <code>0</code> | \n| obj.sy | <code>Number</code> | <code>0</code> | \n| obj.ex | <code>Number</code> | <code>50</code> | \n| obj.ey | <code>Number</code> | <code>0</code> | \n| obj.body_length | <code>Number</code> | <code>0.8</code> | \n| obj.body_width | <code>Number</code> | <code>0.5</code> | \n| obj.head_width | <code>Number</code> | <code>30</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Exemple**  \n```js\nvar myCanvas = Canvas()\nvar w = vars.width / 2\nvar h = vars.height / 2\n// Important : les paramètres sont passés comme un Object\nmyCanvas.arrow({sx: 0, sy: 0, w: w, h: h, head_width:100, body_length:0.5})\n```\n<a name=\"Canvas.clear\"></a>\n\n### Canvas.clear([styleArgs])\nEfface le canevas avec la couleur d'arrière-plan actuelle. Notez qu'il est\n\t généralement plus rapide d'utiliser un canevas différent pour chaque affichage expérimental\n\t plutôt que d'utiliser un seul canevas et de le effacer et le redessiner\n\t à plusieurs reprises.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| [styleArgs] | <code>Object</code> | <code>{}</code> | \n\n**Exemple**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.fixdot({color: 'green'})\nmyCanvas.show()\n// faire quelque chose\nmyCanvas.clear()\nmyCanvas.fixdot({color: 'red'})\nmyCanvas.show()\n```\n<a name=\"Canvas.circle\"></a>\n\n### Canvas.circle(obj)\nDessine un cercle.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| obj.r | <code>Number</code> | <code>50</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Exemple**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.circle({x: 100, y: 100, r: 50, fill: true, color:'red'})\n```\n<a name=\"Canvas.ellipse\"></a>\n\n### Canvas.ellipse(obj)\nDessine une ellipse.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>-50</code> | \n| obj.y | <code>Number</code> | <code>-25</code> | \n| obj.w | <code>Number</code> | <code>100</code> | \n| obj.h | <code>Number</code> | <code>50</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Exemple**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.ellipse({x: -10, y: -10, w: 20, h: 20, fill:true})\n```\n<a name=\"Canvas.fixdot\"></a>\n\n### Canvas.fixdot(obj)\nDessine un point de fixation. Le style par défaut est moyen-ouvert."
  },
  "- __Color names:__ 'red', 'black', etc. A full list of valid color names can be\n  found [here](http://www.w3.org/TR/SVG11/types.html#ColorKeywords).\n- __Seven-character hexadecimal strings:__ `#FF0000`, `#000000`, etc. Here,\n  values range from `00` to `FF`, so that `#FF0000` is bright red.\n- __Four-character hexadecimal strings:__ `#F00`, `#000`, etc. Here, values\n  range from '0' to 'F' so that `#F00` is bright red.\n- __RGB strings:__ `rgb(255,0,0)`, `rgb(0,0,0)`, etc. Here, values range from\n  0 to 255 so that `rgb(255,0,0)` is bright red.\n- __RGB percentage strings:__ `rgb(100%,0%,0%)`, `rgb(0%,0%,0%)`, etc. Here,\n  values range from 0% to 100% so that `rgb(100%,0%,0%)` is bright red.\n- __RGB tuples:__ `(255, 0, 0)`, `(0, 0 ,0)`, etc. Here, values range from `0`\n  to `255` so that `(255,0,0)' is bright red.\n- __HSV strings:__ `hsv(120, 100%, 100%)`. In the [HSV](https://en.wikipedia.org/\n  wiki/HSL_and_HSV) color space, the hue parameter is an angle from 0 to 359,\n  and the saturation and value parameters are percentages from 0% to 100%.\n- __HSL strings:__ `hsl(120, 100%, 50%)`. In the [HSL](https://en.wikipedia.org/\n  wiki/HSL_and_HSV) color space, the hue parameter is an angle from 0 to 359,\n  and the saturation and lightness parameters are percentages from 0% to 100%.\n- __LAB strings:__ `lab(53, -20, 0)`. In the [CIELAB](https://en.wikipedia.org/\n  wiki/CIELAB_color_space) color space, the parameters reflect lightness (`l*`),\n  green-red axis (`a*`, negative is green), and blue-yellow axis (`b*`, negative\n  is blue). This uses the D65 white point and the sRGB transfer function, as\n  implemented [here](https://www.psychopy.org/_modules/psychopy/tools/\n  colorspacetools.html).\n- __Luminance values:__  `255`, `0`, etc. Here, values range from `0` to `255`\n  so that `255` is white.\n\n~~~ .python\n# Various ways to specify green\nmy_canvas.fixdot(color='green')  # Dark green\nmy_canvas.fixdot(color='#00ff00')\nmy_canvas.fixdot(color='#0f0')\nmy_canvas.fixdot(color='rgb(0, 255, 0)')\nmy_canvas.fixdot(color='rgb(0%, 100%, 0%)')\nmy_canvas.fixdot(color='hsl(100, 100%, 50%)')\nmy_canvas.fixdot(color='hsv(0, 100%, 100%)')\nmy_canvas.fixdot(color='lab(53, -20, 0)')  # Dark green\nmy_canvas.fixdot(color=(0, 255, 0))  # Specify a luminance value (white)\n~~~\n\n### Naming, accessing, and modifying elements\n\nAs of OpenSesame 3.2, the `Canvas` supports an object-based interface that allows\nyou to name elements, and to access and modify elements individually, without\nhaving to redraw the entire `Canvas`.\n\nFor example, the following will first add a red `Line` element to a `Canvas`\nand show it, then change the color of the line to green and show it again,\nand then finally delete the line and show the canvas again (which is now blank).\nThe name of the element (`my_line`) is used to refer to the element for all the\noperations.\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas['my_line'] = Line(-100, -100, 100, 100, color='red')\nmy_canvas.show()\nclock.sleep(1000)\nmy_canvas['my_line'].color = 'green'\nmy_canvas.show()\nclock.sleep(1000)\ndel my_canvas['my_line']\nmy_canvas.show()\n~~~\n\nYou can also add an element without explicitly providing a name for it. In that\ncase, a name is generated automatically (e.g. `stim0`).\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas += FixDot()\nmy_canvas.show()\n~~~\n\nIf you add a list of elements, they will be automatically grouped together, and\nyou can refer to the entire group by name.\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas['my_cross'] = [    Line(-100, 0, 100, 0),    Line(0, -100, 0, 100)]\nmy_canvas.show()\n~~~\n\nTo check whether a particular `x,y` coordinate falls within the bounding\nrectangle of an element, you can use `in`:\n\n~~~ .python\nmy_mouse = Mouse(visible=True)\nmy_canvas = Canvas()\nmy_canvas['rect'] = Rect(-100, -100, 200, 200)\nmy_canvas.show()\nbutton, (x, y), time = my_mouse.get_click()\nif (x, y) in my_canvas['rect']:\n    print('Clicked in rectangle')\nelse:\n    print('Clicked outside of rectangle')\n~~~": {
    "fr": "- __Noms de couleurs :__ 'red', 'black', etc. Une liste complète des noms de couleurs valides peut être\n  trouvée [ici](http://www.w3.org/TR/SVG11/types.html#ColorKeywords).\n- __Chaines hexadécimales de sept caractères :__ `#FF0000`, `#000000`, etc. Ici,\n  les valeurs vont de `00` à `FF`, de sorte que `#FF0000` est rouge vif.\n- __Chaines hexadécimales de quatre caractères :__ `#F00`, `#000`, etc. Ici, les valeurs\n  vont de '0' à 'F' de sorte que `#F00` est rouge vif.\n- __Chaînes RGB :__ `rgb(255,0,0)`, `rgb(0,0,0)`, etc. Ici, les valeurs vont de\n  0 à 255 pour que `rgb(255,0,0)` soit rouge vif.\n- __Chaînes en pourcentage RGB :__ `rgb(100%,0%,0%)`, `rgb(0%,0%,0%)`, etc. Ici,\n  les valeurs vont de 0% à 100% de sorte que `rgb(100%,0%,0%)` soit rouge vif.\n- __Tuples RGB :__ `(255, 0, 0)`, `(0, 0 ,0)`, etc. Ici, les valeurs vont de `0`\n  à `255` pour que `(255,0,0)` soit rouge vif.\n- __Chaînes HSV :__ `hsv(120, 100%, 100%)`. Dans l'espace couleur [HSV](https://en.wikipedia.org/\n  wiki/HSL_and_HSV), le paramètre de teinte est un angle de 0 à 359,\n  et les paramètres de saturation et de valeur sont des pourcentages de 0% à 100%.\n- __Chaînes HSL :__ `hsl(120, 100%, 50%)`. Dans l'espace couleur [HSL](https://en.wikipedia.org/\n  wiki/HSL_and_HSV), le paramètre de teinte est un angle de 0 à 359,\n  et les paramètres de saturation et de luminosité sont des pourcentages de 0% à 100%.\n- __Chaînes LAB :__ `lab(53, -20, 0)`. Dans l'espace couleur [CIELAB](https://en.wikipedia.org/\n  wiki/CIELAB_color_space), les paramètres reflètent la luminosité (`l*`),\n  l'axe vert-rouge (`a*`, négatif est vert) et l'axe bleu-jaune (`b*`, négatif\n  est bleu). Ceci utilise le point blanc D65 et la fonction de transfert sRGB, comme\n  mis en œuvre [ici](https://www.psychopy.org/_modules/psychopy/tools/\n  colorspacetools.html).\n- __Valeurs de luminance :__  `255`, `0`, etc. Ici, les valeurs vont de `0` à `255`\n  pour que `255` soit blanc.\n\n~~~ .python\n# Différentes façons de spécifier le vert\nmy_canvas.fixdot(color='green')  # Vert foncé\nmy_canvas.fixdot(color='#00ff00')\nmy_canvas.fixdot(color='#0f0')\nmy_canvas.fixdot(color='rgb(0, 255, 0)')\nmy_canvas.fixdot(color='rgb(0%, 100%, 0%)')\nmy_canvas.fixdot(color='hsl(100, 100%, 50%)')\nmy_canvas.fixdot(color='hsv(0, 100%, 100%)')\nmy_canvas.fixdot(color='lab(53, -20, 0)')  # Vert foncé\nmy_canvas.fixdot(color=(0, 255, 0))  # Spécifier une valeur de luminance (blanc)\n~~~\n\n### Nommer, accéder et modifier les éléments\n\nÀ partir d'OpenSesame 3.2, le `Canvas` prend en charge une interface orientée objet qui permet\nde nommer les éléments, et d'accéder et de modifier les éléments individuellement, sans\navoir à redessiner l'ensemble du `Canvas`.\n\nPar exemple, la suite ajoutera d'abord un élément `Line` rouge à un `Canvas`\net l'affichera, puis changera la couleur de la ligne en vert et l'affichera à nouveau,\net enfin supprimera la ligne et montrera à nouveau le canevas (qui est maintenant vide).\nLe nom de l'élément (`my_line`) est utilisé pour se référer à l'élément pour toutes les\nopérations.\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas['my_line'] = Line(-100, -100, 100, 100, color='red')\nmy_canvas.show()\nclock.sleep(1000)\nmy_canvas['my_line'].color = 'green'\nmy_canvas.show()\nclock.sleep(1000)\ndel my_canvas['my_line']\nmy_canvas.show()\n~~~\n\nVous pouvez également ajouter un élément sans fournir explicitement de nom pour celui-ci. Dans ce\ncas, un nom est généré automatiquement (par exemple `stim0`).\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas += FixDot()\nmy_canvas.show()\n~~~\n\nSi vous ajoutez une liste d'éléments, ils seront automatiquement regroupés ensemble, et\nvous pouvez vous référer au groupe entier par son nom.\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas['my_cross'] = [    Line(-100, 0, 100, 0),    Line(0, -100, 0, 100)]\nmy_canvas.show()\n~~~\n\nPour vérifier si une coordonnée `x,y` particulière se trouve dans le rectangle englobant\nd'un élément, vous pouvez utiliser `in`:\n\n~~~ .python\nmy_mouse = Mouse(visible=True)\nmy_canvas = Canvas()\nmy_canvas['rect'] = Rect(-100, -100, 200, 200)\nmy_canvas.show()\nbutton, (x, y), time = my_mouse.get_click()\nif (x, y) in my_canvas['rect']:\n    print('Clicked in rectangle')\nelse:\n    print('Clicked outside of rectangle')\n~~~"
  },
  "Fired in: [qtopensesame.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/qtopensesame.py)\n\n```python\nextension_manager.fire(u'regenerate')\n```\n\n### register_editor\n\nFired in: [qtplugin.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/qtplugin.py)\n\n```python\nextension_manager.fire(u'register_editor', editor=editor)\n```\n\n### rename_item\n\nFired in: [qtitem_store.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/misc/qtitem_store.py)\n\n```python\nextension_manager.fire(u'rename_item', from_name=from_name,\n\t\t\tto_name=to_name)\n```\n\n### resume_experiment\n\nFired in: [base_runner.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/runners/base_runner.py)\n\n```python\nextension_manager.fire(u'resume_experiment')\n```\n\n### run_experiment_canceled\n\nFired in: [base_runner.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/runners/base_runner.py)\n\n```python\nextension_manager.fire('run_experiment_canceled')\n```\n\n### save_experiment\n\nFired in: [qtopensesame.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/qtopensesame.py)\n\n```python\nextension_manager.fire(u'save_experiment', path=self.current_path)\n```\n\n### startup\n\nFired in: [qtopensesame.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/qtopensesame.py)\n\n```python\nextension_manager.fire(u'startup')\n```\n\n### unregister_editor\n\nFired in: [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('unregister_editor', editor=editor)\n```\n\n": {
    "fr": "Déclenché dans : [qtopensesame.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/qtopensesame.py)\n\n```python\nextension_manager.fire(u'regenerate')\n```\n\n### register_editor\n\nDéclenché dans : [qtplugin.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/items/qtplugin.py)\n\n```python\nextension_manager.fire(u'register_editor', editor=editor)\n```\n\n### rename_item\n\nDéclenché dans : [qtitem_store.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/misc/qtitem_store.py)\n\n```python\nextension_manager.fire(u'rename_item', from_name=from_name,\n\t\t\tto_name=to_name)\n```\n\n### resume_experiment\n\nDéclenché dans : [base_runner.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/runners/base_runner.py)\n\n```python\nextension_manager.fire(u'resume_experiment')\n```\n\n### run_experiment_canceled\n\nDéclenché dans : [base_runner.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/runners/base_runner.py)\n\n```python\nextension_manager.fire('run_experiment_canceled')\n```\n\n### save_experiment\n\nDéclenché dans : [qtopensesame.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/qtopensesame.py)\n\n```python\nextension_manager.fire(u'save_experiment', path=self.current_path)\n```\n\n### startup\n\nDéclenché dans : [qtopensesame.py](https://github.com/open-cogsci/OpenSesame/blob/master/libqtopensesame/qtopensesame.py)\n\n```python\nextension_manager.fire(u'startup')\n```\n\n### unregister_editor\n\nDéclenché dans : [OpenSesameIDE.py](https://github.com/open-cogsci/rapunzel/blob/master/opensesame_extensions/OpenSesameIDE/OpenSesameIDE.py)\n\n```python\nextension_manager.fire('unregister_editor', editor=editor)\n```"
  },
  "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# class __Mouse__\n\nThe `Mouse` class is used to collect mouse input. You generally create a\n`Mouse` object with the `Mouse()` factory function, as described in the\nsection [Creating a Mouse](#creating-a-mouse).\n\n__Example__\n\n~~~ .python\n# Draw a 'fixation-dot mouse cursor' until a button is clicked\nmy_mouse = Mouse()\nmy_canvas = Canvas()\nwhile True:\n    button, position, timestamp = my_mouse.get_click(timeout=20)\n    if button is not None:\n        break\n    (x,y), time = my_mouse.get_pos()\n    my_canvas.clear()\n    my_canvas.fixdot(x, y)\n    my_canvas.show()\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## Things to know\n\n### Creating a Mouse\n\nYou generally create a `Mouse` with the `Mouse()` factory function:\n\n~~~ .python\nmy_mouse = Mouse()\n~~~\n\nOptionally, you can pass [Response keywords](#response-keywords) to `Mouse()`\nto set the default behavior:\n\n~~~ .python\nmy_mouse = Mouse(timeout=2000)\n~~~\n\n### Coordinates\n\n- When *Uniform coordinates* is set to 'yes', coordinates are relative to the\n  center of the display. That is, (0,0) is the center. This is the default as\n  of OpenSesame 3.0.0.\n- When *Uniform coordinates* is set to 'no', coordinates are relative to the\n  top-left of the display. That is, (0,0) is the top-left. This was the default\n  in OpenSesame 2.9.X and earlier.\n\n### Button numbers\n\nMouse buttons are numbered as follows:\n\n1. Left button\n2. Middle button\n3. Right button\n4. Scroll up\n5. Scroll down\n\n### Touch screens\n\nWhen working with a touch screen, a touch is registered as button 1\n(left button).\n\n### Response keywords\n\nFunctions that accept `**resp_args` take the following keyword arguments:\n\n- `timeout` specifies a timeout value in milliseconds, or is set to `None` to\n  disable the timeout.\n- `buttonlist` specifies a list of buttons that are accepted, or is set to\n  `None` accept all buttons.\n- `visible` indicates whether the mouse cursor becomes visible when a click is\n  collected (`True` or `False`). To immediately change cursor visibility, use\n  `Mouse.show_cursor()`.\n\n~~~ .python\n# Get a left or right button press with a timeout of 3000 ms\nmy_mouse = Mouse()\nbutton, time = my_mouse.get_click(buttonlist=[1,3], timeout=3000)\n~~~\n\nResponse keywords only affect the current operation (except when passed to\n`Mouse()` when creating the object). To change the behavior for all subsequent\noperations, set the response properties directly:\n\n~~~ .python\n# Get two left or right presses with a 5000 ms timeout\nmy_mouse = Mouse()\nmy_mouse.buttonlist = [1,3]\nmy_mouse.timeout = 5000\nbutton1, time1 = my_mouse.get_click()\nbutton2, time2 = my_mouse.get_click()\n~~~\n\nOr pass the response keywords to `Mouse()` when creating the object:\n\n~~~ .python\n# Get two left or right presses with a 5000 ms timeout\nmy_mouse = Mouse(buttonlist=[1,3], timeout=5000)\nbutton1, time1 = my_mouse.get_click()\nbutton2, time2 = my_mouse.get_click()\n~~~\n\n## flush(self)\n\nClears all pending input, not limited to the mouse.\n\n\n\n__Returns__\n\n- True if a button had been clicked (i.e., if there was something to\nflush) and False otherwise.\n\n__Example__\n\n~~~ .python\nmy_mouse = Mouse()\nmy_mouse.flush()\nbutton, position, timestamp = my_mouse.get_click()\n~~~\n\n\n\n## get_click(\\*arglist, \\*\\*kwdict)\n\nCollects a mouse click.\n\n\n__Parameters__\n\n- **\\*\\*resp_args**: Optional [response keywords](#response-keywords) that will be used\nfor this call to `Mouse.get_click()`. This does not affect\nsubsequent operations.\n\n__Returns__\n\n- A (button, position, timestamp) tuple. The button and position are\n`None` if a timeout occurs. Position is an (x, y) tuple in screen\ncoordinates.\n\n__Example__\n\n~~~ .python\nmy_mouse = Mouse()\nbutton, (x, y), timestamp = my_mouse.get_click(timeout=5000)\nif button is None:\n        print('A timeout occurred!')\n~~~\n\n\n\n## get_click_release(\\*arglist, \\*\\*kwdict)\n\n*New in v3.2.0*\n\nCollects a mouse-click release.\n\n*Important:* This\nfunction is currently not implemented for the\n*psycho* backend.\n\n__Parameters__": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# classe __Mouse__\n\nLa classe `Mouse` est utilisée pour collecter les entrées de la souris. Vous créez généralement un\nobjet `Mouse` avec la fonction usine `Mouse()`, comme décrit dans la section [Créer une souris](#creer-une-souris).\n\n__Exemple__\n\n~~~ .python\n# Dessinez un 'curseur mouse fixation-dot' jusqu'à ce qu'un bouton soit cliqué\nma_souris = Mouse()\nmon_canvas = Canvas()\nwhile True:\n    bouton, position, horodatage = ma_souris.get_click(timeout=20)\n    if bouton is not None:\n        break\n    (x,y), temps = ma_souris.get_pos()\n    mon_canvas.clear()\n    mon_canvas.fixdot(x, y)\n    mon_canvas.show()\n~~~\n\n<notranslate>[TOC]</notranslate>\n\n## Choses à savoir\n\n### Créer une souris\n\nVous créez généralement une `Mouse` avec la fonction usine `Mouse()`:\n\n~~~ .python\nma_souris = Mouse()\n~~~\n\nFacultativement, vous pouvez passer les mots-clés [Response](#response-keywords) à `Mouse()`\npour définir le comportement par défaut:\n\n~~~ .python\nma_souris = Mouse(timeout=2000)\n~~~\n\n### Coordonnées\n\n- Lorsque *Coordonnées uniformes* est réglé sur 'oui', les coordonnées sont relatives au\n  centre de l'affichage. C'est-à-dire, (0,0) est le centre. Ceci est la valeur par défaut à partir d'OpenSesame 3.0.0.\n- Lorsque *Coordonnées uniformes* est réglé sur 'non', les coordonnées sont relatives à\n  haut-gauche de l'affichage. C'est-à-dire, (0,0) est en haut à gauche. C'était la valeur par défaut dans OpenSesame 2.9.X et versions antérieures.\n\n### Numéros de boutons\n\nLes boutons de la souris sont numérotés comme suit:\n\n1. Bouton gauche\n2. Bouton du milieu\n3. Bouton droit\n4. Défilement vers le haut\n5. Défilement vers le bas\n\n### Écrans tactiles\n\nLors de l'utilisation d'un écran tactile, un toucher est enregistré en tant que bouton 1\n(bouton gauche).\n\n### Mots-clés de réponse\n\nLes fonctions qui acceptent `**resp_args` prennent les arguments de mots-clés suivants :\n\n- `timeout` spécifie une valeur de délai en millisecondes ou est défini sur `None` pour\n  désactiver le délai.\n- `buttonlist` spécifie une liste de boutons qui sont acceptés ou est défini sur\n  `None` accepter tous les boutons.\n- `visible` indique si le curseur de la souris devient visible lorsqu'un clic est\n  collecté (`True` ou `False`). Pour modifier immédiatement la visibilité du curseur, utilisez\n  `Mouse.show_cursor()`.\n\n~~~ .python\n# Obtenir un appui sur le bouton gauche ou droit avec un délai de 3000 ms\nma_souris = Mouse()\nbouton, heure = ma_souris.get_click(buttonlist=[1,3], timeout=3000)\n~~~\n\nLes mots-clés de réponse n'affectent que l'opération en cours (sauf lorsqu'ils sont passés à\n`Mouse()` lors de la création de l'objet). Pour modifier le comportement pour toutes les opérations ultérieures, définissez les propriétés de réponse directement:\n\n~~~ .python\n# Obtenir deux pressions gauche ou droite avec un délai de 5000 ms\nma_souris = Mouse()\nma_souris.buttonlist = [1,3]\nma_souris.timeout = 5000\nbouton1, temps1 = ma_souris.get_click()\nbouton2, temps2 = ma_souris.get_click()\n~~~\n\nOu passez les mots-clés de réponse à `Mouse()` lors de la création de l'objet:\n\n~~~ .python\n# Obtenir deux pressions gauche ou droite avec un délai de 5000 ms\nma_souris = Mouse(buttonlist=[1,3], timeout=5000)\nbouton1, temps1 = ma_souris.get_click()\nbouton2, temps2 = ma_souris.get_click()\n~~~\n\n## flush(self)\n\nEfface toutes les entrées en attente, sans se limiter à la souris.\n\n__Retourne__\n\n- True si un bouton a été cliqué (c'est-à-dire s'il y avait quelque chose à\nvider) et False sinon.\n\n__Exemple__\n\n~~~ .python\nma_souris = Mouse()\nma_souris.flush()\nbouton, position, horodatage = ma_souris.get_click()\n~~~\n\n## get_click(\\*arglist, \\*\\*kwdict)\n\nCollecte un clic de souris.\n\n__Paramètres__\n\n- **\\*\\*resp_args** : facultatif [mot-clé de réponse](#response-keywords) qui sera utilisé\npour cet appel à `Mouse.get_click()`. Cela n'affecte pas\nles opérations ultérieures.\n\n__Retourne__\n\n- Un tuple (bouton, position, horodatage). Le bouton et la position sont\n`None` si un délai se produit. La position est un tuple (x, y) en coordonnées d'écran.\n\n__Exemple__\n\n~~~ .python\nma_souris = Mouse()\nbouton, (x, y), horodatage = ma_souris.get_click(timeout=5000)\nif bouton is None:\n        print(\"Un délai d'attente s'est produit!\")\n~~~\n\n## get_click_release(\\*arglist, \\*\\*kwdict)\n\n*Nouveau dans v3.2.0*\n\nCollecte la libération d'un clic de souris.\n\n*Important:* ce\nfonction n'est actuellement pas implémentée pour le\nbackend *psycho*.\n\n__Paramètres__"
  },
  "~~~ .yaml\nname: opensesame_3.2.7-py2.7-win32-2\nchannels:\n- cogsci\n- conda-forge\n- defaults\ndependencies:\n- anaconda-client=1.6.3=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.5=py27_0\n- bleach=1.5.0=py27_0\n- bzip2=1.0.6=vc9_3\n- certifi=2016.2.28=py27_0\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.1.2=py_0\n- qscintilla2=2.9.3=py27_vc9_0\n- requests-oauthlib=0.6.2=py_0\n- webcolors=1.5=py27_0\n- colorama=0.3.9=py27_0\n- configparser=3.5.0=py27_0\n- decorator=4.1.2=py27_0\n- entrypoints=0.2.3=py27_0\n- enum34=1.1.6=py27_0\n- freetype=2.5.5=vc9_2\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- html5lib=0.999=py27_0\n- icu=57.1=vc9_0\n- ipykernel=4.6.1=py27_0\n- ipython=5.3.0=py27_0\n- ipython_genutils=0.2.0=py27_0\n- ipywidgets=6.0.0=py27_0\n- jinja2=2.9.6=py27_0\n- jpeg=9b=vc9_0\n- jsonschema=2.6.0=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=5.1.0=py27_0\n- jupyter_console=5.2.0=py27_0\n- jupyter_core=4.3.0=py27_0\n- libpng=1.6.30=vc9_1\n- libtiff=4.0.6=vc9_3\n- markdown=2.6.9=py27_0\n- markupsafe=1.0=py27_0\n- mistune=0.7.4=py27_0\n- mkl=2017.0.3=0\n- nbconvert=5.2.1=py27_0\n- nbformat=4.4.0=py27_0\n- notebook=5.0.0=py27_0\n- numpy=1.13.1=py27_0\n- olefile=0.44=py27_0\n- openssl=1.0.2l=vc9_0\n- pandocfilters=1.4.2=py27_0\n- path.py=10.3.1=py27_0\n- pathlib2=2.3.0=py27_0\n- pickleshare=0.7.4=py27_0\n- pillow=4.2.1=py27_0\n- pip=9.0.1=py27_1\n- prompt_toolkit=1.0.15=py27_0\n- pyflakes=1.6.0=py27_0\n- pygments=2.2.0=py27_0\n- pyopengl=3.1.1a1=np113py27_0\n- pyopengl-accelerate=3.1.1a1=np113py27_0\n- pyqt=5.6.0=py27_2\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.13=1\n- python-dateutil=2.6.1=py27_0\n- pytz=2017.2=py27_0\n- pyyaml=3.12=py27_0\n- pyzmq=16.0.2=py27_0\n- qt=5.6.2=vc9_6\n- qtawesome=0.4.4=py27_0\n- qtconsole=4.3.1=py27_0\n- qtpy=1.3.1=py27_0\n- requests=2.14.2=py27_0\n- scandir=1.5=py27_0\n- scipy=0.19.1=np113py27_0\n- setuptools=36.4.0=py27_1\n- shapely=1.6.2=py27_0 # Added in 3.2.5\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.18=py27_0\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.5.0.1=py27_0\n- testpath=0.3.1=py27_0\n- tornado=4.5.2=py27_0\n- traitlets=4.3.2=py27_0\n- vc=9=0\n- vs2008_runtime=9.00.30729.5054=0\n- wcwidth=0.1.7=py27_0\n- wheel=0.29.0=py27_0\n- widgetsnbextension=3.0.2=py27_0\n- win_unicode_console=0.5=py27_0\n- wincertstore=0.2=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.11=vc9_0\n- ffmpeg=3.4.1\n- pip:\n  - arrow==0.7.0\n  - backports-abc==0.5\n  - backports.shutil-get-terminal-size==1.0.0\n  - backports.ssl-match-hostname==3.5.0.1\n  - cffi==1.11.2\n  - configobj==5.0.6\n  - et-xmlfile==1.0.1\n  - expyriment-0.9.1b2_11_gc100ee8-py2-none-any.whl\n  - fastnumbers==2.0.2\n  - future==0.16.0\n  - humanize==0.5.1\n  - imageio==2.2.0\n  - ipython-genutils==0.2.0\n  - jdcal==1.3\n  - json-tricks==3.11.0\n  - jupyter-client==5.1.0\n  - jupyter-console==5.2.0\n  - jupyter-core==4.3.0\n  - mediadecoder==0.1.5\n  - moviepy==0.2.3.2\n  - oauthlib==1.1.2\n  - openpyxl==2.4.9\n  - opensesame-extension-osf==1.1.1\n  - opensesame_extension_osweb==1.3.0.1 # Updated in 3.2.7\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-plugin-psychopy==0.5.0\n  - opensesame-windows-launcher==0.4.2 # Updated in 3.2.2\n  - prettytable==0.7.2\n  - prompt-toolkit==1.0.15\n  - psychopy==1.85.3\n  - pyaudio==0.2.11\n  - pycparser==2.18\n  - pygame==1.9.3\n  - pyglet==1.3.0\n  - python-bidi==0.4.0\n  - python-datamatrix==0.9.14 # Updated in 3.2.7\n  - python-fileinspector==1.0.2\n  - python-opensesame==3.2.7 # Updated in 3.2.6\n  - python-pseudorandom==0.2.2\n  - python-pygaze==0.6.0a25 # Updated in 3.2.2\n  - python-qdatamatrix==0.1.18\n  - python-qnotifications==2.0.3 # Updated in 3.2.6\n  - python-qosf==1.2.3 # Updated in 3.2.3\n  - python-qprogedit==4.1.0 # Updated in 3.2.7\n  - python-qtpip==0.2.0 # Updated in 3.2.6\n  - js2py==0.60 # New in 3.2.7\n  - requests-oauthlib==0.6.2\n  - sounddevice==0.3.9\n  - tqdm==4.19.5\n  - webcolors==1.5\n  - win-unicode-console==0.5\n  - yolk3k==0.9\n~~~\n": {
    "fr": "~~~ .yaml\nname: opensesame_3.2.7-py2.7-win32-2\nchannels:\n- cogsci\n- conda-forge\n- defaults\ndependencies:\n- anaconda-client=1.6.3=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.5=py27_0\n- bleach=1.5.0=py27_0\n- bzip2=1.0.6=vc9_3\n- certifi=2016.2.28=py27_0\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.1.2=py_0\n- qscintilla2=2.9.3=py27_vc9_0\n- requests-oauthlib=0.6.2=py_0\n- webcolors=1.5=py27_0\n- colorama=0.3.9=py27_0\n- configparser=3.5.0=py27_0\n- decorator=4.1.2=py27_0\n- entrypoints=0.2.3=py27_0\n- enum34=1.1.6=py27_0\n- freetype=2.5.5=vc9_2\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- html5lib=0.999=py27_0\n- icu=57.1=vc9_0\n- ipykernel=4.6.1=py27_0\n- ipython=5.3.0=py27_0\n- ipython_genutils=0.2.0=py27_0\n- ipywidgets=6.0.0=py27_0\n- jinja2=2.9.6=py27_0\n- jpeg=9b=vc9_0\n- jsonschema=2.6.0=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=5.1.0=py27_0\n- jupyter_console=5.2.0=py27_0\n- jupyter_core=4.3.0=py27_0\n- libpng=1.6.30=vc9_1\n- libtiff=4.0.6=vc9_3\n- markdown=2.6.9=py27_0\n- markupsafe=1.0=py27_0\n- mistune=0.7.4=py27_0\n- mkl=2017.0.3=0\n- nbconvert=5.2.1=py27_0\n- nbformat=4.4.0=py27_0\n- notebook=5.0.0=py27_0\n- numpy=1.13.1=py27_0\n- olefile=0.44=py27_0\n- openssl=1.0.2l=vc9_0\n- pandocfilters=1.4.2=py27_0\n- path.py=10.3.1=py27_0\n- pathlib2=2.3.0=py27_0\n- pickleshare=0.7.4=py27_0\n- pillow=4.2.1=py27_0\n- pip=9.0.1=py27_1\n- prompt_toolkit=1.0.15=py27_0\n- pyflakes=1.6.0=py27_0\n- pygments=2.2.0=py27_0\n- pyopengl=3.1.1a1=np113py27_0\n- pyopengl-accelerate=3.1.1a1=np113py27_0\n- pyqt=5.6.0=py27_2\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.13=1\n- python-dateutil=2.6.1=py27_0\n- pytz=2017.2=py27_0\n- pyyaml=3.12=py27_0\n- pyzmq=16.0.2=py27_0\n- qt=5.6.2=vc9_6\n- qtawesome=0.4.4=py27_0\n- qtconsole=4.3.1=py27_0\n- qtpy=1.3.1=py27_0\n- requests=2.14.2=py27_0\n- scandir=1.5=py27_0\n- scipy=0.19.1=np113py27_0\n- setuptools=36.4.0=py27_1\n- shapely=1.6.2=py27_0 # Ajouté dans 3.2.5\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.18=py27_0\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.5.0.1=py27_0\n- testpath=0.3.1=py27_0\n- tornado=4.5.2=py27_0\n- traitlets=4.3.2=py27_0\n- vc=9=0\n- vs2008_runtime=9.00.30729.5054=0\n- wcwidth=0.1.7=py27_0\n- wheel=0.29.0=py27_0\n- widgetsnbextension=3.0.2=py27_0\n- win_unicode_console=0.5=py27_0\n- wincertstore=0.2=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.11=vc9_0\n- ffmpeg=3.4.1\n- pip:\n  - arrow==0.7.0\n  - backports-abc==0.5\n  - backports.shutil-get-terminal-size==1.0.0\n  - backports.ssl-match-hostname==3.5.0.1\n  - cffi==1.11.2\n  - configobj==5.0.6\n  - et-xmlfile==1.0.1\n  - expyriment-0.9.1b2_11_gc100ee8-py2-none-any.whl\n  - fastnumbers==2.0.2\n  - future==0.16.0\n  - humanize==0.5.1\n  - imageio==2.2.0\n  - ipython-genutils==0.2.0\n  - jdcal==1.3\n  - json-tricks==3.11.0\n  - jupyter-client==5.1.0\n  - jupyter-console==5.2.0\n  - jupyter-core==4.3.0\n  - mediadecoder==0.1.5\n  - moviepy==0.2.3.2\n  - oauthlib==1.1.2\n  - openpyxl==2.4.9\n  - opensesame-extension-osf==1.1.1\n  - opensesame_extension_osweb==1.3.0.1 # Mis à jour dans 3.2.7\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-plugin-psychopy==0.5.0\n  - opensesame-windows-launcher==0.4.2 # Mis à jour dans 3.2.2\n  - prettytable==0.7.2\n  - prompt-toolkit==1.0.15\n  - psychopy==1.85.3\n  - pyaudio==0.2.11\n  - pycparser==2.18\n  - pygame==1.9.3\n  - pyglet==1.3.0\n  - python-bidi==0.4.0\n  - python-datamatrix==0.9.14 # Mis à jour dans 3.2.7\n  - python-fileinspector==1.0.2\n  - python-opensesame==3.2.7 # Mis à jour dans 3.2.6\n  - python-pseudorandom==0.2.2\n  - python-pygaze==0.6.0a25 # Mis à jour dans 3.2.2\n  - python-qdatamatrix==0.1.18\n  - python-qnotifications==2.0.3 # Mis à jour dans 3.2.6\n  - python-qosf==1.2.3 # Mis à jour dans 3.2.3\n  - python-qprogedit==4.1.0 # Mis à jour dans 3.2.7\n  - python-qtpip==0.2.0 # Mis à jour dans 3.2.6\n  - js2py==0.60 # Nouveau dans 3.2.7\n  - requests-oauthlib==0.6.2\n  - sounddevice==0.3.9\n  - tqdm==4.19.5\n  - webcolors==1.5\n  - win-unicode-console==0.5\n  - yolk3k==0.9\n~~~"
  },
  "Release notes for 3.1.8": {
    "fr": "Notes de version pour 3.1.8"
  },
  "## function __eyetracker\\.set\\_eye\\_used__\\(\\)\n\nLogs the `eye_used` variable, based on which eye was specified (if both eyes are being tracked, the left eye is used). Does not return anything.\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-start_recording\" markdown=\"1\">\n\n## function __eyetracker\\.start\\_recording__\\(\\)\n\nStarts recording. Sets `self.recording` to `True` when recording is successfully started.\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-status_msg\" markdown=\"1\">\n\n## function __eyetracker\\.status\\_msg__\\(msg\\)\n\nSends a status message to the eye tracker, which is displayed in the tracker's GUI (only available for EyeLink setups).\n\n__Arguments:__\n\n- `msg` -- A string that is to be displayed on the experimenter PC,\ne.g.: \"current trial: %d\" % trialnr.\n\t- Type: str, unicode\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-stop_recording\" markdown=\"1\">\n\n## function __eyetracker\\.stop\\_recording__\\(\\)\n\nStops recording. Sets `self.recording` to `False` when recording is successfully stopped.\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_blink_end\" markdown=\"1\">\n\n## function __eyetracker\\.wait\\_for\\_blink\\_end__\\(\\)\n\nWaits for a blink end and returns the blink ending time.\nDetection based on Dalmaijer et al. (2013) if EVENTDETECTION is set\nto 'pygaze', or using native detection functions if EVENTDETECTION\nis set to 'native' (NOTE: not every system has native functionality;\nwill fall back to ;pygaze' if 'native' is not available!)\n\n__Returns:__\n\nBlink ending time in milliseconds, as measured from experiment begin time.\n\n- Type: int, float\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_blink_start\" markdown=\"1\">\n\n## function __eyetracker\\.wait\\_for\\_blink\\_start__\\(\\)\n\nWaits for a blink start and returns the blink starting time.\nDetection based on Dalmaijer et al. (2013) if EVENTDETECTION is set\nto 'pygaze', or using native detection functions if EVENTDETECTION\nis set to 'native' (NOTE: not every system has native functionality;\nwill fall back to ;pygaze' if 'native' is not available!)\n\n__Returns:__\n\nBlink starting time in milliseconds, as measured from experiment begin time\n\n- Type: int, float\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_event\" markdown=\"1\">\n\n## function __eyetracker\\.wait\\_for\\_event__\\(event\\)\n\nWaits for an event.\n\n__Arguments:__\n\n- `event` -- An integer event code, one of the following:\n\n- 3 = STARTBLINK\n- 4 = ENDBLINK\n- 5 = STARTSACC\n- 6 = ENDSACC\n- 7 = STARTFIX\n- 8 = ENDFIX\n\t- Type: int\n\n__Returns:__\n\nA `self.wait_for_*` method is called, depending on the specified event; the return value of corresponding method is returned.\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_fixation_end\" markdown=\"1\">\n\n## function __eyetracker\\.wait\\_for\\_fixation\\_end__\\(\\)\n\nReturns time and gaze position when a fixation has ended;\nfunction assumes that a 'fixation' has ended when a deviation of\nmore than self.pxfixtresh from the initial fixation position has\nbeen detected (self.pxfixtresh is created in self.calibration,\nbased on self.fixtresh, a property defined in self.__init__).\nDetection based on Dalmaijer et al. (2013) if EVENTDETECTION is set\nto 'pygaze', or using native detection functions if EVENTDETECTION\nis set to 'native' (NOTE: not every system has native functionality;\nwill fall back to ;pygaze' if 'native' is not available!)\n\n__Returns:__\n\nA `time, gazepos` tuple. Time is the end time in milliseconds (from expstart), gazepos is a (x,y) gaze position tuple of the position from which the fixation was initiated.\n\n- Type: tuple\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_fixation_start\" markdown=\"1\">\n\n## function __eyetracker\\.wait\\_for\\_fixation\\_start__\\(\\)": {
    "fr": "## fonction __eyetracker.set_eye_used__()\n\nEnregistre la variable `eye_used`, selon l'œil spécifié (si les deux yeux sont suivis, l'œil gauche est utilisé). Ne retourne rien.\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-start_recording\" markdown=\"1\">\n\n## fonction __eyetracker.start_recording__()\n\nDémarre l'enregistrement. Définit `self.recording` sur `True` lorsque l'enregistrement est démarré avec succès.\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-status_msg\" markdown=\"1\">\n\n## fonction __eyetracker.status_msg__(msg)\n\nEnvoie un message d'état à l'eye tracker, qui est affiché dans l'interface graphique du traceur (uniquement disponible pour les configurations EyeLink).\n\n__Arguments :__\n\n- `msg` -- Une chaîne de caractères à afficher sur le PC de l'expérimentateur,\npar exemple : \"essai en cours : %d\" % trialnr.\n  - Type : str, unicode\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-stop_recording\" markdown=\"1\">\n\n## fonction __eyetracker.stop_recording__()\n\nArrête l'enregistrement. Définit `self.recording` sur `False` lorsque l'enregistrement est arrêté avec succès.\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_blink_end\" markdown=\"1\">\n\n## fonction __eyetracker.wait_for_blink_end__()\n\nAttend la fin d'un clignement et renvoie le temps de fin du clignement.\nDétection basée sur Dalmaijer et al. (2013) si EVENTDETECTION est défini\nsur 'pygaze', ou à l'aide de fonctions de détection natives si EVENTDETECTION\nest défini sur 'native' (NOTE : tous les systèmes n'ont pas de fonctionnalité native ;\nretournera à ;pygaze' si 'native' n'est pas disponible !)\n\n__Renvoie :__\n\nTemps de fin du clignement en millisecondes, mesuré depuis le début de l'expérience.\n\n- Type : int, float\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_blink_start\" markdown=\"1\">\n\n## fonction __eyetracker.wait_for_blink_start__()\n\nAttend le début d'un clignement et renvoie le temps de début du clignement.\nDétection basée sur Dalmaijer et al. (2013) si EVENTDETECTION est défini\nsur 'pygaze', ou à l'aide de fonctions de détection natives si EVENTDETECTION\nest défini sur 'native' (NOTE : tous les systèmes n'ont pas de fonctionnalité native ;\nretournera à ;pygaze' si 'native' n'est pas disponible !)\n\n__Renvoie :__\n\nTemps de début du clignement en millisecondes, mesuré depuis le début de l'expérience\n\n- Type : int, float\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_event\" markdown=\"1\">\n\n## fonction __eyetracker.wait_for_event__(event)\n\nAttend un événement.\n\n__Arguments :__\n\n- `event` -- Un code d'événement entier, l'un des suivants :\n\n- 3 = STARTBLINK\n- 4 = ENDBLINK\n- 5 = STARTSACC\n- 6 = ENDSACC\n- 7 = STARTFIX\n- 8 = ENDFIX\n  - Type : int\n\n__Renvoie :__\n\nUne méthode `self.wait_for_*` est appelée, en fonction de l'événement spécifié ; la valeur de retour de la méthode correspondante est renvoyée.\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_fixation_end\" markdown=\"1\">\n\n## fonction __eyetracker.wait_for_fixation_end__()\n\nRenvoie le temps et la position du regard lorsqu'une fixation s'est terminée ;\nla fonction suppose qu'une \"fixation\" est terminée lorsqu'un écart de\nplus de self.pxfixtresh par rapport à la position de fixation initiale a\nété détecté (self.pxfixtresh est créé dans la calibration de soi-même,\nbasée sur self.fixtresh, une propriété définie dans self.__init__).\nDétection basée sur Dalmaijer et al. (2013) si EVENTDETECTION est défini\nsur 'pygaze', ou à l'aide de fonctions de détection natives si EVENTDETECTION\nest défini sur 'native' (NOTE : tous les systèmes n'ont pas de fonctionnalité native ;\nretournera à ;pygaze' si 'native' n'est pas disponible !)\n\n__Renvoie :__\n\nUn tuple `time, gazepos`. Le temps est le temps de fin en millisecondes (depuis le début de l'expérience), gazepos est un tuple de position du regard (x,y) de la position à partir de laquelle la fixation a été initiée.\n\n- Type : tuple\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_fixation_start\" markdown=\"1\">\n\n## fonction __eyetracker.wait_for_fixation_start__()"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.1.8 *Jazzy James* is the eight maintenance release in the 3.1 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.1 series.\n\nIf you are upgrading from OpenSesame 3.0 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n## Credits\n\nThanks to:\n\n- Jarik den Hartog (%-- github: {user: JdenHartog} --%) for his code contributions\n- Ronald Sprouse (%-- github: {user: rsprouse} --%) for his code contributions\n- Eduard Ort (%-- github: {user: eort} --%) for his code contributions\n- Daniel Schreij (%-- github: {user: dschreij} --%) for his work on the Mac OS package\n\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.1.8\n- %-- github: { repo: \"smathot/opensesame\", issue: 552 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 550 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 549 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 546 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 544 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 533 } --%\n\ndatamatrix:\n\n- Updated to 0.6.3\n\nqdatamatrix:\n\n- Updated to 0.1.16\n\n\n## Packages (Windows Python 2.7 package)\n\n\n### Detailed package information": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.1.8 *Jazzy James* est la huitième version de maintenance de la série 3.1. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.1.\n\nSi vous passez d'OpenSesame 3.0 ou d'une version antérieure, veuillez consulter la liste des changements importants :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Jarik den Hartog (%-- github: {user: JdenHartog} --%) pour ses contributions au code\n- Ronald Sprouse (%-- github: {user: rsprouse} --%) pour ses contributions au code\n- Eduard Ort (%-- github: {user: eort} --%) pour ses contributions au code\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour son travail sur le package Mac OS\n\n\n## Corrections de bugs et améliorations\n\nopensesame :\n\n- Mis à jour vers 3.1.8\n- %-- github: { repo: \"smathot/opensesame\", issue: 552 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 550 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 549 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 546 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 544 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 533 } --%\n\ndatamatrix :\n\n- Mis à jour vers 0.6.3\n\nqdatamatrix :\n\n- Mis à jour vers 0.1.16\n\n\n## Packages (package Windows Python 2.7)\n\n### Informations détaillées sur les packages"
  },
  "You can also get a list of the names of all elements that contain an `x,y`\ncoordinate, using the `Canvas.elements_at()` function, documented below.\n\n## arrow(sx, sy, ex, ey, body_length=0.8, body_width=0.5, head_width=30, \\*\\*style_args)\n\nDraws an arrow. An arrow is a polygon consisting of 7 vertices,\nwith an arrowhead pointing at (ex, ey).\n\n\n__Parameters__\n\n- **sx**: The X coordinate of the arrow's base.\n- **sy**: The Y coordinate of the arrow's base.\n- **ex**: The X coordinate of the arrow's tip.\n- **ey**: The Y coordinate of the arrow's tip..\n- **body_length**: Proportional length of the arrow body relative to the full arrow\n[0-1].\n- **body_width**: Proportional width (thickness) of the arrow body relative to the\nfull arrow [0-1].\n- **head_width**: Width (thickness) of the arrow head in pixels.\n\n\n## circle(x, y, r, \\*\\*style_args)\n\nDraws a circle.\n\n\n__Parameters__\n\n- **x**: The center X coordinate of the circle.\n- **y**: The center Y coordinate of the circle.\n- **r**: The radius of the circle.\n- **\\*\\*style_args**: {{arg_style}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Function interface\nmy_canvas.circle(100, 100, 50, fill=True, color='red')\n# Element interface\nmy_canvas['my_circle'] = Circle(100, 100, 50, fill=True, color='red')\n~~~\n\n\n\n## clear(\\*arglist, \\*\\*kwdict)\n\nClears the canvas with the current background color. Note that it\nis generally faster to use a different canvas for each experimental\ndisplay than to use a single canvas and repeatedly clear and redraw it.\n\n\n__Parameters__\n\n- **\\*\\*style_args**: {{arg_style}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot(color='green')\nmy_canvas.show()\nclock.sleep(1000)\nmy_canvas.clear()\nmy_canvas.fixdot(color='red')\nmy_canvas.show()\n~~~\n\n\n\n## copy(canvas)\n\nTurns the current `Canvas` into a copy of the passed `Canvas`.\n\n__Warning:__\n\nCopying `Canvas` objects can result in unpredictable behavior. In many\ncases, a better solution is to recreate multiple `Canvas` objects from\nscratch, and/ or to use the element interface to update `Canvas`\nelements individually.\n\n__Parameters__\n\n- **canvas**: The `Canvas` to copy.\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot(x=100, color='green')\nmy_copied_canvas = Canvas()\nmy_copied_canvas.copy(my_canvas)\nmy_copied_canvas.fixdot(x=200, color=\"blue\")\nmy_copied_canvas.show()\n~~~\n\n\n\n## elements_at(x, y)\n\n*New in v3.2.0*\n\nGets the names of elements that contain a\nparticular `x, y`\ncoordinate.\n\n__Parameters__\n\n- **x**: An X coordinate.\n- **y**: A Y coordinate.\n\n__Returns__\n\n- A `list` of element names that contain the coordinate `x, y`.\n\n__Example__\n\n~~~ .python\n# Create and show a canvas with two partly overlapping rectangles\nmy_canvas = Canvas()\nmy_canvas['right_rect'] = Rect(x=-200, y=-100, w=200, h=200, color='red')\nmy_canvas['left_rect'] = Rect(x=-100, y=-100, w=200, h=200, color='green')\nmy_canvas.show()\n# Collect a mouse click and print the names of the elements that\n# contain the clicked point\nmy_mouse = Mouse(visible=True)\nbutton, pos, time = my_mouse.get_click()\nif pos is not None:\n    x, y = pos\n    print('Clicked on elements: %s' % my_canvas.elements_at(x, y))\n~~~\n\n\n\n## ellipse(x, y, w, h, \\*\\*style_args)\n\nDraws an ellipse.\n\n\n__Parameters__\n\n- **x**: The left X coordinate.\n- **y**: The top Y coordinate.\n- **w**: The width.\n- **h**: The height.\n- **\\*\\*style_args**: {{arg_style}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Function interface\nmy_canvas.ellipse(-10, -10, 20, 20, fill=True)\n# Element interface\nmy_canvas['my_ellipse'] = Ellipse(-10, -10, 20, 20, fill=True)\n~~~\n\n\n\n## fixdot(x=None, y=None, style='default', \\*\\*style_args)\n\nDraws a fixation dot. The default style is medium-open.": {
    "fr": "Vous pouvez également obtenir une liste des noms de tous les éléments qui contiennent une coordonnée `x, y`\nen utilisant la fonction `Canvas.elements_at()`, documentée ci-dessous.\n\n## arrow(sx, sy, ex, ey, body_length=0.8, body_width=0.5, head_width=30, \\*\\*style_args)\n\nDessine une flèche. Une flèche est un polygone composé de 7 sommets,\navec une pointe de flèche pointant vers (ex, ey).\n\n__Paramètres__\n\n- **sx**: La coordonnée X de la base de la flèche.\n- **sy**: La coordonnée Y de la base de la flèche.\n- **ex**: La coordonnée X de la pointe de la flèche.\n- **ey**: La coordonnée Y de la pointe de la flèche.\n- **body_length**: Longueur proportionnelle du corps de la flèche par rapport à la flèche entière\n[0-1].\n- **body_width**: Largeur (épaisseur) proportionnelle du corps de la flèche par rapport à la\nflèche entière [0-1].\n- **head_width**: Largeur (épaisseur) de la tête de la flèche en pixels.\n\n\n## circle(x, y, r, \\*\\*style_args)\n\nDessine un cercle.\n\n__Paramètres__\n\n- **x**: La coordonnée X du centre du cercle.\n- **y**: La coordonnée Y du centre du cercle.\n- **r**: Le rayon du cercle.\n- **\\*\\*style_args**: {{arg_style}}\n\n__Exemple__\n\n~~~ .python\nmy_canvas = Canvas()\n# Interface de fonction\nmy_canvas.circle(100, 100, 50, fill=True, color='red')\n# Interface d'élément\nmy_canvas['my_circle'] = Circle(100, 100, 50, fill=True, color='red')\n~~~\n\n\n\n## clear(\\*arglist, \\*\\*kwdict)\n\nEfface le canevas avec la couleur d'arrière-plan actuelle. Notez que cela\nest généralement plus rapide d'utiliser un canevas différent pour chaque affichage expérimental que d'utiliser un seul canevas et de le vider et le redessiner à plusieurs reprises.\n\n__Paramètres__\n\n- **\\*\\*style_args**: {{arg_style}}\n\n__Exemple__\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot(color='green')\nmy_canvas.show()\nclock.sleep(1000)\nmy_canvas.clear()\nmy_canvas.fixdot(color='red')\nmy_canvas.show()\n~~~\n\n\n\n## copy(canvas)\n\nTransforme le `Canvas` actuel en une copie du `Canvas` passé.\n\n__Avertissement :__\n\nCopier des objets `Canvas` peut entraîner un comportement imprévisible. Dans de nombreux\ncas, une meilleure solution consiste à recréer plusieurs objets `Canvas` à partir de\nzéro, et / ou à utiliser l'interface d'élément pour mettre à jour les éléments `Canvas`\nindividuellement.\n\n__Paramètres__\n\n- **canvas**: Le `Canvas` à copier.\n\n__Exemple__\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot(x=100, color='green')\nmy_copied_canvas = Canvas()\nmy_copied_canvas.copy(my_canvas)\nmy_copied_canvas.fixdot(x=200, color=\"blue\")\nmy_copied_canvas.show()\n~~~\n\n\n\n\n\n## elements_at(x, y)\n\n* Nouveau dans v3.2.0 *\n\nObtient les noms des éléments qui contiennent une\ncoordonnée `x, y` particulière.\n\n__Paramètres__\n\n- **x**: Une coordonnée X.\n- **y**: Une coordonnée Y.\n\n__Renvoie__\n\n- Une `list` de noms d'éléments qui contiennent la coordonnée `x, y`.\n\n__Exemple__\n\n~~~ .python\n# Créez et affichez un canevas avec deux rectangles partiellement superposés\nmy_canvas = Canvas()\nmy_canvas['right_rect'] = Rect(x=-200, y=-100, w=200, h=200, color='red')\nmy_canvas['left_rect'] = Rect(x=-100, y=-100, w=200, h=200, color='green')\nmy_canvas.show()\n# Collectez un clic de souris et imprimez les noms des éléments qui\n# contiennent le point cliqué\nmy_mouse = Mouse(visible=True)\nbutton, pos, time = my_mouse.get_click()\nif pos is not None:\n    x, y = pos\n    print('Cliqué sur les éléments: %s' % my_canvas.elements_at(x, y))\n~~~\n\n\n\n## ellipse(x, y, w, h, \\*\\*style_args)\n\nDessine une ellipse.\n\n__Paramètres__\n\n- **x**: La coordonnée X gauche.\n- **y**: La coordonnée Y supérieure.\n- **w**: La largeur.\n- **h**: La hauteur.\n- **\\*\\*style_args**: {{arg_style}}\n\n__Exemple__\n\n~~~ .python\nmy_canvas = Canvas()\n# Interface de fonction\nmy_canvas.ellipse(-10, -10, 20, 20, fill=True)\n# Interface d'élément\nmy_canvas['my_ellipse'] = Ellipse(-10, -10, 20, 20, fill=True)\n~~~\n\n\n\n## fixdot(x=None, y=None, style='default', \\*\\*style_args)\n\nDessine un point de fixation. Le style par défaut est medium-open."
  },
  "- **\\*\\*resp_args**: Optional [response keywords](#response-keywords) that will be used\nfor this call to `Mouse.get_click_release()`. This does not affect\nsubsequent operations.\n\n__Returns__\n\n- A (button, position, timestamp) tuple. The button and position are\n`None` if a timeout occurs. Position is an (x, y) tuple in screen\ncoordinates.\n\n__Example__\n\n~~~ .python\nmy_mouse = Mouse()\nbutton, (x, y), timestamp = my_mouse.get_click_release(timeout=5000)\nif button is None:\n        print('A timeout occurred!')\n~~~\n\n\n\n## get_pos(self)\n\nReturns the current position of the cursor.\n\n\n\n__Returns__\n\n- A (position, timestamp) tuple.\n\n__Example__\n\n~~~ .python\nmy_mouse = Mouse()\n(x, y), timestamp = my_mouse.get_pos()\nprint('The cursor was at (%d, %d)' % (x, y))\n~~~\n\n\n\n## get_pressed(self)\n\nReturns the current state of the mouse buttons. A True value means\nthe button is currently being pressed.\n\n\n\n__Returns__\n\n- A (button1, button2, button3) tuple of boolean values.\n\n__Example__\n\n~~~ .python\nmy_mouse = Mouse()\nbuttons = my_mouse.get_pressed()\nb1, b2, b3 = buttons\nprint('Currently pressed mouse buttons: (%d,%d,%d)' % (b1,b2,b3))\n~~~\n\n\n\n## set_pos(pos=(0, 0))\n\nSets the position of the mouse cursor.\n\n__Warning:__ `set_pos()` is\nunreliable and will silently fail on\nsome systems.\n\n__Parameters__\n\n- **pos**: An (x,y) tuple for the new mouse coordinates.\n\n__Example__\n\n~~~ .python\nmy_mouse = Mouse()\nmy_mouse.set_pos(pos=(0,0))\n~~~\n\n\n\n## show_cursor(show=True)\n\nImmediately changes the visibility of the mouse cursor.\n\n__Note:__\nIn most cases, you will want to use the `visible`\nkeyword, which\nchanges the visibility during response collection,\nthat is, while\n`mouse.get_click()` is called. Calling \n`show_cursor()` will not\nimplicitly change the value of `visible`, \nwhich can lead to the\nsomewhat unintuitive behavior that the cursor\nis hidden as soon as\n`get_click()` is called.\n\n__Parameters__\n\n- **show**: Indicates whether the cursor is shown (True) or hidden (False).\n\n\n## synonyms(button)\n\nGives a list of synonyms for a mouse button. For example, 1 and\n'left_button' are synonyms.\n\n\n__Parameters__\n\n- **button**: A button value.\n\n__Returns__\n\n- A list of synonyms.\n\n\n</div>\n\n": {
    "fr": "- **\\*\\*resp_args**: Facultatif [mots-clés de réponse](#response-keywords) qui seront utilisés\npour cet appel à `Mouse.get_click_release()`. Cela n'affecte pas\nles opérations ultérieures.\n\n__Renvoie__\n\n- Un tuple (bouton, position, horodatage). Le bouton et la position sont\n`None` en cas de dépassement du temps imparti. La position est un tuple (x, y) en\ncoordonnées de l'écran.\n\n__Exemple__\n\n~~~ .python\nmy_mouse = Mouse()\nbutton, (x, y), timestamp = my_mouse.get_click_release(timeout=5000)\nif button is None:\n        print(\"Un dépassement de temps s'est produit !\")\n~~~\n\n## get_pos(self)\n\nRenvoie la position actuelle du curseur.\n\n__Renvoie__\n\n- Un tuple (position, horodatage).\n\n__Exemple__\n\n~~~ .python\nmy_mouse = Mouse()\n(x, y), timestamp = my_mouse.get_pos()\nprint(\"Le curseur était à (%d, %d)\" % (x, y))\n~~~\n\n## get_pressed(self)\n\nRenvoie l'état actuel des boutons de la souris. Une valeur True signifie\nque le bouton est actuellement enfoncé.\n\n__Renvoie__\n\n- Un tuple (button1, button2, button3) de valeurs booléennes.\n\n__Exemple__\n\n~~~ .python\nmy_mouse = Mouse()\nbuttons = my_mouse.get_pressed()\nb1, b2, b3 = buttons\nprint(\"Boutons de souris enfoncés actuellement : (%d,%d,%d)\" % (b1,b2,b3))\n~~~\n\n## set_pos(pos=(0, 0))\n\nDéfinit la position du curseur de la souris.\n\n__Attention :__ `set_pos()` est\npeu fiable et échouera silencieusement sur\ncertains systèmes.\n\n__Paramètres__\n\n- **pos**: Un tuple (x,y) pour les nouvelles coordonnées de la souris.\n\n__Exemple__\n\n~~~ .python\nmy_mouse = Mouse()\nmy_mouse.set_pos(pos=(0,0))\n~~~\n\n## show_cursor(show=True)\n\nChange immédiatement la visibilité du curseur de la souris.\n\n__Note :__\nDans la plupart des cas, vous préférerez utiliser le mot-clé `visible`,\nqui\nmodifie la visibilité lors de la collecte des réponses,\nc'est-à-dire\npendant l'appel à `mouse.get_click()`. Appeler\n`show_cursor()` ne\nchangera pas implicitement la valeur de `visible`,\nce qui peut entraîner\nun comportement quelque peu contre-intuitif où le curseur\nest caché dès que\n`get_click()` est appelé.\n\n__Paramètres__\n\n- **show**: Indique si le curseur est affiché (True) ou masqué (False).\n\n## synonyms(button)\n\nDonne une liste de synonymes pour un bouton de souris. Par exemple, 1 et\n'left_button' sont des synonymes.\n\n__Paramètres__\n\n- **button**: Une valeur de bouton.\n\n__Renvoie__\n\n- Une liste de synonymes.\n\n</div>"
  },
  "- 'large-filled' is a filled circle with a 16px radius.\n- 'medium-filled' is a filled circle with an 8px radius.\n- 'small-filled' is a filled circle with a 4px radius.\n- 'large-open' is a filled circle with a 16px radius and a 2px hole.\n- 'medium-open' is a filled circle with an 8px radius and a 2px hole.\n- 'small-open' is a filled circle with a 4px radius and a 2px hole.\n- 'large-cross' is 16px cross.\n- 'medium-cross' is an 8px cross.\n- 'small-cross' is a 4px cross.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| obj.style | <code>String</code> | <code>&#x27;default&#x27;</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.fixdot()\n```\n<a name=\"Canvas.gabor\"></a>\n\n### Canvas.gabor(obj)\nDraws a gabor patch.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| obj.orient | <code>Number</code> | <code>0</code> | \n| obj.freq | <code>Number</code> | <code>.1</code> | \n| obj.env | <code>String</code> | <code>&#x27;gaussian&#x27;</code> | \n| obj.size | <code>Number</code> | <code>96</code> | \n| obj.stdev | <code>Number</code> | <code>12</code> | \n| obj.phase | <code>Number</code> | <code>0</code> | \n| obj.col1 | <code>String</code> | <code>&#x27;white&#x27;</code> | \n| obj.col2 | <code>String</code> | <code>&#x27;black&#x27;</code> | \n| obj.bgmode | <code>String</code> | <code>&#x27;avg&#x27;</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.gabor({x: 100, y: 100, orient: 45, freq: .05})\n```\n<a name=\"Canvas.image\"></a>\n\n### Canvas.image(obj)\nDraws an image from a file in the file pool.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.fname | <code>String</code> |  | \n| obj.center | <code>Boolean</code> | <code>true</code> | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| obj.scale | <code>Number</code> | <code>1</code> | \n| obj.rotation | <code>Number</code> | <code>0</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.image({fname: 'image_in_pool.png'})\n```\n<a name=\"Canvas.line\"></a>\n\n### Canvas.line(obj)\nDraws a line.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.sx | <code>Number</code> | <code>0</code> | \n| obj.sy | <code>Number</code> | <code>0</code> | \n| obj.ex | <code>Number</code> | <code>50</code> | \n| obj.ey | <code>Number</code> | <code>0</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nvar ex = vars.width / 2\nvar ey = vars.height / 2\nmyCanvas.line({sx: 0, sy: 0, ex: ex, ey: ey})\n```\n<a name=\"Canvas.noise_patch\"></a>\n\n### Canvas.noise\\_patch(obj)\nDraws a patch of noise, with an envelope.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| obj.env | <code>String</code> | <code>&#x27;gaussian&#x27;</code> | \n| obj.size | <code>Number</code> | <code>96</code> | \n| obj.stdev | <code>Number</code> | <code>12</code> | \n| obj.col1 | <code>String</code> | <code>&#x27;white&#x27;</code> | \n| obj.col2 | <code>String</code> | <code>&#x27;black&#x27;</code> | \n| obj.bgmode | <code>String</code> | <code>&#x27;avg&#x27;</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.noise_patch({x: 100, y: 100, env: 'circular'})\n```\n<a name=\"Canvas.polygon\"></a>": {
    "fr": "- 'large-filled' est un cercle rempli avec un rayon de 16px.\n- 'medium-filled' est un cercle rempli avec un rayon de 8px.\n- 'small-filled' est un cercle rempli avec un rayon de 4px.\n- 'large-open' est un cercle rempli avec un rayon de 16px et un trou de 2px.\n- 'medium-open' est un cercle rempli avec un rayon de 8px et un trou de 2px.\n- 'small-open' est un cercle rempli avec un rayon de 4px et un trou de 2px.\n- 'large-cross' est une croix de 16px.\n- 'medium-cross' est une croix de 8px.\n- 'small-cross' est une croix de 4px.\n\n\n\n| Param | Type | Par défaut |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| obj.style | <code>String</code> | <code>&#x27;default&#x27;</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Exemple**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.fixdot()\n```\n<a name=\"Canvas.gabor\"></a>\n\n### Canvas.gabor(obj)\nDessine un patch Gabor.\n\n\n\n| Param | Type | Par défaut |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| obj.orient | <code>Number</code> | <code>0</code> | \n| obj.freq | <code>Number</code> | <code>.1</code> | \n| obj.env | <code>String</code> | <code>&#x27;gaussian&#x27;</code> | \n| obj.size | <code>Number</code> | <code>96</code> | \n| obj.stdev | <code>Number</code> | <code>12</code> | \n| obj.phase | <code>Number</code> | <code>0</code> | \n| obj.col1 | <code>String</code> | <code>&#x27;white&#x27;</code> | \n| obj.col2 | <code>String</code> | <code>&#x27;black&#x27;</code> | \n| obj.bgmode | <code>String</code> | <code>&#x27;avg&#x27;</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Exemple**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.gabor({x: 100, y: 100, orient: 45, freq: .05})\n```\n<a name=\"Canvas.image\"></a>\n\n### Canvas.image(obj)\nDessine une image à partir d'un fichier dans le pool de fichiers.\n\n\n\n| Param | Type | Par défaut |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.fname | <code>String</code> |  | \n| obj.center | <code>Boolean</code> | <code>true</code> | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| obj.scale | <code>Number</code> | <code>1</code> | \n| obj.rotation | <code>Number</code> | <code>0</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Exemple**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.image({fname: 'image_in_pool.png'})\n```\n<a name=\"Canvas.line\"></a>\n\n### Canvas.line(obj)\nDessine une ligne.\n\n\n\n| Param | Type | Par défaut |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.sx | <code>Number</code> | <code>0</code> | \n| obj.sy | <code>Number</code> | <code>0</code> | \n| obj.ex | <code>Number</code> | <code>50</code> | \n| obj.ey | <code>Number</code> | <code>0</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Exemple**  \n```js\nvar myCanvas = Canvas()\nvar ex = vars.width / 2\nvar ey = vars.height / 2\nmyCanvas.line({sx: 0, sy: 0, ex: ex, ey: ey})\n```\n<a name=\"Canvas.noise_patch\"></a>\n\n### Canvas.noise\\_patch(obj)\nDessine un patch de bruit, avec une enveloppe.\n\n\n\n| Param | Type | Par défaut |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| obj.env | <code>String</code> | <code>&#x27;gaussian&#x27;</code> | \n| obj.size | <code>Number</code> | <code>96</code> | \n| obj.stdev | <code>Number</code> | <code>12</code> | \n| obj.col1 | <code>String</code> | <code>&#x27;white&#x27;</code> | \n| obj.col2 | <code>String</code> | <code>&#x27;black&#x27;</code> | \n| obj.bgmode | <code>String</code> | <code>&#x27;avg&#x27;</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Exemple**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.noise_patch({x: 100, y: 100, env: 'circular'})\n```\n<a name=\"Canvas.polygon\"></a>"
  },
  "Returns starting time and position when a fixation is started;\nfunction assumes a 'fixation' has started when gaze position\nremains reasonably stable (i.e. when most deviant samples are\nwithin self.pxfixtresh) for five samples in a row (self.pxfixtresh\nis created in self.calibration, based on self.fixtresh, a property\ndefined in self.__init__).\nDetection based on Dalmaijer et al. (2013) if EVENTDETECTION is set\nto 'pygaze', or using native detection functions if EVENTDETECTION\nis set to 'native' (NOTE: not every system has native functionality;\nwill fall back to ;pygaze' if 'native' is not available!)\n\n__Returns:__\n\nA `time, gazepos` tuple. Time is the starting time in milliseconds (from expstart), gazepos is a (x,y) gaze position tuple of the position from which the fixation was initiated.\n\n- Type: tuple\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_saccade_end\" markdown=\"1\">\n\n## function __eyetracker\\.wait\\_for\\_saccade\\_end__\\(\\)\n\nReturns ending time, starting and end position when a saccade is\nended; based on Dalmaijer et al. (2013) online saccade detection\nalgorithm if EVENTDETECTION is set to 'pygaze', or using native\ndetection functions if EVENTDETECTION is set to 'native' (NOTE: not\nevery system has native functionality; will fall back to ;pygaze'\nif 'native' is not available!)\n\n__Returns:__\n\nAn `endtime, startpos, endpos` tuple. Endtime in milliseconds (from expbegintime); startpos and endpos are (x,y) gaze position tuples.\n\n- Type: tuple\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_saccade_start\" markdown=\"1\">\n\n## function __eyetracker\\.wait\\_for\\_saccade\\_start__\\(\\)\n\nReturns starting time and starting position when a saccade is\nstarted; based on Dalmaijer et al. (2013) online saccade detection\nalgorithm if EVENTDETECTION is set to 'pygaze', or using native\ndetection functions if EVENTDETECTION is set to 'native' (NOTE: not\nevery system has native functionality; will fall back to ;pygaze'\nif 'native' is not available!)\n\n__Returns:__\n\nAn `endtime, startpos` tuple. Endtime in milliseconds (from expbegintime); startpos is an (x,y) gaze position tuple.\n\n- Type: tuple\n\n</div>\n\n</div>\n\n": {
    "fr": "Renvoie l'heure de début et la position lorsqu'une fixation est commencée ;\nla fonction suppose qu'une \"fixation\" a commencé lorsque la position du regard\nreste raisonnablement stable (c'est-à-dire lorsque la plupart des échantillons déviants sont\nà l'intérieur de self.pxfixtresh) pendant cinq échantillons d'affilée (self.pxfixtresh\nest créé dans self.calibration, basé sur self.fixtresh, une propriété\ndéfinie dans self.__init__).\nDétection basée sur Dalmaijer et al. (2013) si EVENTDETECTION est défini\nà 'pygaze', ou en utilisant des fonctions de détection natives si EVENTDETECTION\nest défini sur 'native' (NOTE : tous les systèmes n'ont pas de fonctionnalité native ;\nretournera à 'pygaze' si 'native' n'est pas disponible!)\n\n__Renvoie :__\n\nUn tuple `time, gazepos`. Time est l'heure de début en millisecondes (à partir de expstart), gazepos est un tuple de position (x,y) du regard à partir duquel la fixation a été initiée.\n\n- Type: tuple\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_saccade_end\" markdown=\"1\">\n\n## fonction __eyetracker\\.wait\\_for\\_saccade\\_end__\\(\\)\n\nRenvoie l'heure de fin, la position de départ et la position de fin lorsqu'une saccade est\nterminée ; basée sur l'algorithme de détection de saccades en ligne de Dalmaijer et al. (2013) si EVENTDETECTION est défini à 'pygaze', ou en utilisant des\nfonctions de détection natives si EVENTDETECTION est défini sur 'native' (NOTE: pas\ntous les systèmes ont une fonctionnalité native ; retournera à 'pygaze'\nsi 'native' n'est pas disponible !)\n\n__Renvoie :__\n\nUn tuple `endtime, startpos, endpos`. Endtime en millisecondes (à partir de expbegintime) ; startpos et endpos sont des tuples de position (x,y) du regard.\n\n- Type: tuple\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_saccade_start\" markdown=\"1\">\n\n## fonction __eyetracker\\.wait\\_for\\_saccade\\_start__\\(\\)\n\nRenvoie l'heure de début et la position de départ lorsqu'une saccade est\ncommencée ; basée sur l'algorithme de détection de saccades en ligne de Dalmaijer et al. (2013) si EVENTDETECTION est défini à 'pygaze', ou en utilisant des\nfonctions de détection natives si EVENTDETECTION est défini sur 'native' (NOTE: pas\ntous les systèmes ont une fonctionnalité native ; retournera à 'pygaze'\nsi 'native' n'est pas disponible !)\n\n__Renvoie :__\n\nUn tuple `endtime, startpos`. Endtime en millisecondes (à partir de expbegintime) ; startpos est un tuple de position (x,y) du regard.\n\n- Type: tuple\n\n</div>\n\n</div>\n\n"
  },
  "### Canvas.polygon(obj)\nDraws a polygon that defined by a list of vertices. I.e. a shape of\npoints connected by lines.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.vertices | <code>Array.&lt;Array.&lt;Number&gt;&gt;</code> |  | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nvar n1 = [0,0]\nvar n2 = [100, 100]\nvar n3 = [0, 100]\nmyCanvas.polygon({vertices: [n1, n2, n3]})\n```\n<a name=\"Canvas.rect\"></a>\n\n### Canvas.rect(obj)\nDraws a rectangle.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>-50</code> | \n| obj.y | <code>Number</code> | <code>-25</code> | \n| obj.w | <code>Number</code> | <code>100</code> | \n| obj.h | <code>Number</code> | <code>50</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.rect({x: -10, y: -10, w: 20, h: 20, fill:true})\n```\n<a name=\"Canvas.show\"></a>\n\n### Canvas.show() ⇒ <code>Number</code>\nShows, or 'flips', the canvas on the screen.\n\n\n**Returns**: <code>Number</code> - A timestamp of the time at which the canvas appeared on\n    the screen.  \n<a name=\"Canvas.text\"></a>\n\n### Canvas.text(obj)\nDraws text.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.text | <code>String</code> |  | \n| obj.center | <code>Boolean</code> | <code>true</code> | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.text({text: 'Some text'})\n```\n": {
    "fr": "### Canvas.polygon(obj)\nDessine un polygone défini par une liste de sommets. C'est-à-dire une forme\nde points reliés par des lignes.\n\n| Param | Type | Valeur par défaut |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.vertices | <code>Array.&lt;Array.&lt;Number&gt;&gt;</code> |  | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Exemple**  \n```js\nvar myCanvas = Canvas()\nvar n1 = [0,0]\nvar n2 = [100, 100]\nvar n3 = [0, 100]\nmyCanvas.polygon({vertices: [n1, n2, n3]})\n```\n<a name=\"Canvas.rect\"></a>\n\n### Canvas.rect(obj)\nDessine un rectangle.\n\n| Param | Type | Valeur par défaut |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>-50</code> | \n| obj.y | <code>Number</code> | <code>-25</code> | \n| obj.w | <code>Number</code> | <code>100</code> | \n| obj.h | <code>Number</code> | <code>50</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Exemple**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.rect({x: -10, y: -10, w: 20, h: 20, fill:true})\n```\n<a name=\"Canvas.show\"></a>\n\n### Canvas.show() ⇒ <code>Number</code>\nAffiche, ou 'retourne', le canevas à l'écran.\n\n**Renvoie**: <code>Number</code> - Un horodatage du moment où le canevas est apparu sur\n    l'écran.\n<a name=\"Canvas.text\"></a>\n\n### Canvas.text(obj)\nDessine du texte.\n\n| Param | Type | Valeur par défaut |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.text | <code>String</code> |  | \n| obj.center | <code>Boolean</code> | <code>true</code> | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Exemple**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.text({text: 'Du texte'})\n```"
  },
  "- 'large-\nfilled' is a filled circle with a 16px radius.\n- 'medium-filled' is a\nfilled circle with an 8px radius.\n- 'small-filled' is a filled circle\nwith a 4px radius.\n- 'large-open' is a filled circle with a 16px radius\nand a 2px hole.\n- 'medium-open' is a filled circle with an 8px radius\nand a 2px hole.\n- 'small-open' is a filled circle with a 4px radius and\na 2px hole.\n- 'large-cross' is 16px cross.\n- 'medium-cross' is an 8px\ncross.\n- 'small-cross' is a 4px cross.\n\n__Parameters__\n\n- **x**: The X coordinate of the dot center, or None to draw a horizontally\ncentered dot.\n- **y**: The Y coordinate of the dot center, or None to draw a vertically\ncentered dot.\n- **style**: The fixation-dot style. One of: default, large-filled,\nmedium-\nfilled, small-filled, large-open, medium-open,\nsmall-open, large-\ncross, medium-cross, or small-cross.\ndefault equals medium-open.\n- **\\*\\*style_args**: {{arg_style}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Function interface\nmy_canvas.fixdot()\n# Element interface\nmy_canvas['my_fixdot'] = FixDot()\n~~~\n\n\n\n## gabor(x, y, orient, freq, env='gaussian', size=96, stdev=12, phase=0, col1='white', col2='black', bgmode='avg')\n\nDraws a Gabor patch. Note: The exact rendering of the Gabor patch\ndepends on the back-end.\n\n\n__Parameters__\n\n- **x**: The center X coordinate.\n- **y**: The center Y coordinate.\n- **orient**: Orientation in degrees [0 .. 360]. This refers to a\nclockwise rotation from a vertical.\n- **freq**: Frequency in cycles/px of the sinusoid.\n- **env**: The envelope that determines the shape of the patch. Can be\n\"gaussian\", \"linear\", \"circular\", or \"rectangular\".\n- **size**: A size in pixels.\n- **stdev**: Standard deviation in pixels of the gaussian. Only applicable to\ngaussian envelopes.\n- **phase**: Phase of the sinusoid [0.0 .. 1.0].\n- **col1**: A color for the peaks.\n- **col2**: A color for the troughs. Note: The psycho back-end\nignores this\nparameter and always uses the inverse of\n`col1` for the throughs.\n- **bgmode**: {{arg_bgmode}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Function interface\nmy_canvas.gabor(100, 100, 45, .05)\n# Element interface\nmy_canvas['my_gabor'] = Gabor(100, 100, 45, .05)\n~~~\n\n\n\n## image(fname, center=True, x=None, y=None, scale=None, rotation=None)\n\nDraws an image from file. This function does not look in the file\npool, but takes an absolute path.\n\n\n__Parameters__\n\n- **fname**: The filename of the image. When using Python 2, this should be\neither `unicode` or a utf-8-encoded `str`. When using Python 3,\nthis should be either `str` or a utf-8-encoded `bytes`.\n- **center**: A bool indicating whether coordinates indicate the center (True) or\ntop-left (False).\n- **x**: The X coordinate, or `None` to draw a horizontally centered image.\n- **y**: The Y coordinate, or `None` to draw a vertically centered image.\n- **scale**: The scaling factor of the image. `None` or 1 indicate the original\nsize. 2.0 indicates a 200% zoom, etc.\n- **rotation**: The rotation of the image `None` or 0 indicate the original\nrotation. Positive values indicate a clockwise rotation in degrees.\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Determine the absolute path:\npath = exp.pool['image_in_pool.png']\n# Function interface\nmy_canvas.image(path)\n# Element interface\nmy_canvas['my_image'] = Image(path)\n~~~\n\n\n\n## line(sx, sy, ex, ey, \\*\\*style_args)\n\nDraws a line.\n\n\n__Parameters__\n\n- **sx**: The left X coordinate.\n- **sy**: The top Y coordinate.\n- **ex**: The right X coordinate.\n- **ey**: The bottom Y coordinate.\n- **\\*\\*style_args**: {{arg_style}}\n\n\n## lower_to_bottom(element)\n\nLowers an element to the bottom, so that it is drawn first; that\nis, it becomes the background.\n\n\n__Parameters__\n\n- **element**: A SKETCHPAD element, or its name.\n\n\n## noise_patch(x, y, env='gaussian', size=96, stdev=12, col1='white', col2='black', bgmode='avg')\n\nDraws a patch of noise, with an envelope. The exact rendering of\nthe noise patch depends on the back-end.\n\n\n__Parameters__": {
    "fr": "- 'large-filled' est un cercle rempli avec un rayon de 16px.\n- 'medium-filled' est un\ncercle rempli avec un rayon de 8px.\n- 'small-filled' est un cercle rempli\navec un rayon de 4px.\n- 'large-open' est un cercle rempli avec un rayon de 16px\net un trou de 2px.\n- 'medium-open' est un cercle rempli avec un rayon de 8px\net un trou de 2px.\n- 'small-open' est un cercle rempli avec un rayon de 4px et\nun trou de 2px.\n- 'large-cross' est une croix de 16px.\n- 'medium-cross' est une croix de 8px\n- 'small-cross' est une croix de 4px.\n\n__Paramètres__\n\n- **x**: La coordonnée X du centre du point, ou None pour dessiner un point horizontalement\ncentré.\n- **y**: La coordonnée Y du centre du point, ou None pour dessiner un point verticalement\ncentré.\n- **style**: Le style du point de fixation. L'un des éléments suivants: default, large-filled,\nmedium-\nfilled, small-filled, large-open, medium-open,\nsmall-open, large-\ncross, medium-cross, ou small-cross.\ndefault égale medium-open.\n- **\\*\\*style_args**: {{arg_style}}\n\n__Exemple__\n\n~~~ .python\nmy_canvas = Canvas()\n# Interface de fonction\nmy_canvas.fixdot()\n# Interface d'élément\nmy_canvas['my_fixdot'] = FixDot()\n~~~\n\n\n\n## gabor(x, y, orient, freq, env='gaussian', size=96, stdev=12, phase=0, col1='white', col2='black', bgmode='avg')\n\nDessine un patch Gabor. Note: Le rendu exact du patch Gabor\ndépend du back-end.\n\n\n__Paramètres__\n\n- **x**: La coordonnée X du centre.\n- **y**: La coordonnée Y du centre.\n- **orient**: Orientation en degrés [0 .. 360]. Cela fait référence à une\nrotation horaire à partir d'une verticale.\n- **freq**: Fréquence en cycles/px du sinus.\n- **env**: L'enveloppe qui détermine la forme du patch. Peut être\n\"gaussian\", \"linear\", \"circular\" ou \"rectangular\".\n- **size**: Une taille en pixels.\n- **stdev**: Écart type en pixels du gaussien. Applicable uniquement aux\nenveloppes gaussiennes.\n- **phase**: Phase du sinus [0.0 .. 1.0].\n- **col1**: Une couleur pour les pics.\n- **col2**: Une couleur pour les creux. Note : Le back-end psycho\nignore cette\nparamètre et utilise toujours l'inverse de\n`col1` pour les creux.\n- **bgmode**: {{arg_bgmode}}\n\n__Exemple__\n\n~~~ .python\nmy_canvas = Canvas()\n# Interface de fonction\nmy_canvas.gabor(100, 100, 45, .05)\n# Interface d'élément\nmy_canvas['my_gabor'] = Gabor(100, 100, 45, .05)\n~~~\n\n\n\n## image(fname, center=True, x=None, y=None, scale=None, rotation=None)\n\nDessine une image à partir d'un fichier. Cette fonction ne cherche pas dans le fichier\npool, mais prend un chemin absolu.\n\n\n__Paramètres__\n\n- **fname**: Le nom de fichier de l'image. Lors de l'utilisation de Python 2, cela doit être\nsoit `unicode` soit un `str` encodé en utf-8. Lors de l'utilisation de Python 3,\ncela doit être soit `str` soit un `bytes` encodé en utf-8.\n- **center**: Un booléen indiquant si les coordonnées indiquent le centre (True) ou\nhaut-gauche (False).\n- **x**: La coordonnée X ou `None` pour dessiner une image horizontalement centrée.\n- **y**: La coordonnée Y ou `None` pour dessiner une image verticalement centrée.\n- **scale**: Le facteur d'échelle de l'image. `None` ou 1 indiquent la taille originale.\n2.0 indique un zoom de 200%, etc.\n- **rotation**: La rotation de l'image. `None` ou 0 indiquent la rotation originale.\nLes valeurs positives indiquent une rotation horaire en degrés.\n\n__Exemple__\n\n~~~ .python\nmy_canvas = Canvas()\n# Déterminer le chemin absolu :\npath = exp.pool['image_in_pool.png']\n# Interface de fonction\nmy_canvas.image(path)\n# Interface d'élément\nmy_canvas['my_image'] = Image(path)\n~~~\n\n\n\n## line(sx, sy, ex, ey, \\*\\*style_args)\n\nDessine une ligne.\n\n\n__Paramètres__\n\n- **sx**: La coordonnée X gauche.\n- **sy**: La coordonnée Y supérieure.\n- **ex**: La coordonnée X droite.\n- **ey**: La coordonnée Y inférieure.\n- **\\*\\*style_args**: {{arg_style}}\n\n\n## lower_to_bottom(element)\n\nAbaisse un élément vers le bas, de sorte qu'il soit dessiné en premier; c'est\nà dire qu'il devient l'arrière-plan.\n\n\n__Paramètres__\n\n- **element**: Un élément SKETCHPAD, ou son nom.\n\n\n## noise_patch(x, y, env='gaussian', size=96, stdev=12, col1='white', col2='black', bgmode='avg')\n\nDessine un patch de bruit, avec une enveloppe. Le rendu exact du\npatch de bruit dépend du back-end.\n\n\n__Paramètres__"
  },
  "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n## Canvas(auto_prepare=True, \\*\\*style_args)\n\nA factory function that creates a new `Canvas` object. For a\ndescription of possible keywords, see:\n\n- %link:manual/python/canvas%\n\n\n__Returns__\n\n- A `Canvas` object.\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas(color=u'red', penwidth=2)\nmy_canvas.line(-10, -10, 10, 10)\nmy_canvas.line(-10, 10, 10, -10)\nmy_canvas.show()\n~~~\n\n\n\n## Experiment(osexp_path=None, log_path='defaultlog.csv', fullscreen=False, subject_nr=0, \\*\\*kwargs)\n\nA factory function that creates a new `Experiment` object. This is only\nuseful when implementing an experiment entirely through a Python script,\nrather than through the user interface.\n\n\n__Parameters__\n\n- **osexp_path**: If a path to an `.osexp` file is specified, this file is opened and\ncan be run directly by calling `Experiment.run()`. If no experiment\nfile is specified, an empty experiment is initialized.\n- **log_path**: \n- **fullscreen**: \n- **subject_nr**: \n- **kwargs**: Optional keyword arguments that are interpreted as experimental\nvariables. The main use of this is to specify the backend through\nthe `canvas_backend` keyword.\n\n__Returns__\n\n- An (exp, win, clock, log) tuple corresponding to the Experiment,\nwindow handle (backend-specific), Clock, and Log objects.\n\n__Example__\n\nTo implement an experiment fully programatically:\n\n~~~ .python\nfrom libopensesame.python_workspace_api import (\n    Experiment, Canvas, Text, Keyboard)\nexp, win, clock, log = Experiment(canvas_backend='legacy')\nc = Canvas()\nc += Text('Press any key')\nc.show()\nkb = Keyboard()\nkb.get_key()\nexp.end()\n~~~\n\nTo load an experiment file and run it:\n\n~~~ .python\nfrom libopensesame.python_workspace_api import Experiment\nexp, win, clock, log = Experiment(osexp_path='my_experiment.osexp',\n                                  subject_nr=2)\nexp.run()\n~~~\n\n\n\n## Form(\\*args, \\*\\*kwargs)\n\nA factory function that creates a new `Form` object. For a\ndescription\nof possible keywords, see:\n\n- %link:manual/forms/widgets%\n\n\n__Returns__\n\n- A `Form` object.\n\n__Example__\n\n~~~ .python\nform = Form()\nlabel = Label(text='label')\nbutton = Button(text='Ok')\nform.set_widget(label, (0,0))\nform.set_widget(button, (0,1))\nform._exec()\n~~~\n\n\n\n## Keyboard(\\*\\*resp_args)\n\nA factory function that creates a new `Keyboard` object. For a\ndescription of possible keywords, see:\n\n- %link:manual/python/keyboard%\n\n\n__Returns__\n\n- A `Keyboard` object.\n\n__Example__\n\n~~~ .python\nmy_keyboard = Keyboard(keylist=[u'a', u'b'], timeout=5000)\nkey, time = my_keyboard.get_key()\n~~~\n\n\n\n## Mouse(\\*\\*resp_args)\n\nA factory function that creates a new `Mouse` object. For a\ndescription\nof possible keywords, see:\n\n- %link:manual/python/mouse%\n\n\n__Returns__\n\n- A `mouse` object.\n\n__Example__\n\n~~~ .python\nmy_mouse = Mouse(keylist=[1,3], timeout=5000)\nbutton, time = my_mouse.get_button()\n~~~\n\n\n\n## Sampler(src, \\*\\*playback_args)\n\nA factory function that creates a new `Sampler` object. For a\ndescription of possible keywords, see:\n\n- %link:manual/python/sampler%\n\n\n__Returns__\n\n- A SAMPLER object.\n\n__Example__\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src, volume=.5, pan='left')\nmy_sampler.play()\n~~~\n\n\n\n## Synth(osc='sine', freq=440, length=100, attack=0, decay=5)\n\nA factory function that synthesizes a sound and returns it as a\n`Sampler` object.\n\n\n__Parameters__\n\n- **osc**: Oscillator, can be \"sine\", \"saw\", \"square\" or \"white_noise\".\n- **freq**: Frequency, either an integer value (value in hertz) or a string (\"A1\",\n\"eb2\", etc.).\n- **length**: The length of the sound in milliseconds.\n- **attack**: The attack (fade-in) time in milliseconds.\n- **decay**: The decay (fade-out) time in milliseconds.\n\n__Returns__\n\n- A SAMPLER object.\n\n__Example__\n\n~~~ .python\nmy_sampler = Synth(freq=u'b2', length=500)\n~~~\n\n\n\n## copy_sketchpad(name)\n\nReturns a copy of a `sketchpad`'s canvas.\n\n\n__Parameters__\n\n- **name**: The name of the `sketchpad`.\n\n__Returns__\n\n- A copy of the `sketchpad`'s canvas.\n\n__Example__": {
    "fr": "<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n## Canvas(auto_prepare=True, \\*\\*style_args)\n\nUne fonction d'usine qui crée un nouvel objet `Canvas`. Pour une\ndescription des mots-clés possibles, voir :\n\n- %link:manual/python/canvas%\n\n\n__Renvoie__\n\n- Un objet `Canvas`.\n\n__Exemple__\n\n~~~ .python\nmy_canvas = Canvas(color=u'red', penwidth=2)\nmy_canvas.line(-10, -10, 10, 10)\nmy_canvas.line(-10, 10, 10, -10)\nmy_canvas.show()\n~~~\n\n\n\n## Experiment(osexp_path=None, log_path='defaultlog.csv', fullscreen=False, subject_nr=0, \\*\\*kwargs)\n\nUne fonction d'usine qui crée un nouvel objet `Experiment`. Ceci est seulement\nutile lorsqu'on implémente une expérience entièrement à travers un script Python,\nplutôt que par l'interface utilisateur.\n\n\n__Paramètres__\n\n- **osexp_path** : Si un chemin vers un fichier `.osexp` est spécifié, ce fichier est ouvert et\npeut être exécuté directement en appelant `Experiment.run()`. Si aucun fichier d'expérience\nn'est spécifié, une expérience vide est initialisée.\n- **log_path** : \n- **fullscreen** : \n- **subject_nr** : \n- **kwargs**: Arguments clés optionnels qui sont interprétés comme des variables expérimentales.\nL'usage principal de ceci est de spécifier le backend à travers\nle mot-clé `canvas_backend`.\n\n__Renvoie__\n\n- Un tuple (exp, win, clock, log) correspondant aux objets Experiment,\ngestionnaire de fenêtre (spécifique au backend), Clock et Log.\n\n__Exemple__\n\nPour implémenter une expérience entièrement de manière programmatique :\n\n~~~ .python\nfrom libopensesame.python_workspace_api import (\n    Experiment, Canvas, Text, Keyboard)\nexp, win, clock, log = Experiment(canvas_backend='legacy')\nc = Canvas()\nc += Text('Press any key')\nc.show()\nkb = Keyboard()\nkb.get_key()\nexp.end()\n~~~\n\nPour charger un fichier d'expérience et l'exécuter :\n\n~~~ .python\nfrom libopensesame.python_workspace_api import Experiment\nexp, win, clock, log = Experiment(osexp_path='my_experiment.osexp',\n                                  subject_nr=2)\nexp.run()\n~~~\n\n\n\n## Form(\\*args, \\*\\*kwargs)\n\nUne fonction d'usine qui crée un nouvel objet `Form`. Pour une\ndescription\ndes mots-clés possibles, voir :\n\n- %link:manual/forms/widgets%\n\n\n__Renvoie__\n\n- Un objet `Form`.\n\n__Exemple__\n\n~~~ .python\nform = Form()\nlabel = Label(text='label')\nbutton = Button(text='Ok')\nform.set_widget(label, (0,0))\nform.set_widget(button, (0,1))\nform._exec()\n~~~\n\n\n\n## Keyboard(\\*\\*resp_args)\n\nUne fonction d'usine qui crée un nouvel objet `Keyboard`. Pour une\ndescription des mots-clés possibles, voir :\n\n- %link:manual/python/keyboard%\n\n\n__Renvoie__\n\n- Un objet `Keyboard`.\n\n__Exemple__\n\n~~~ .python\nmy_keyboard = Keyboard(keylist=[u'a', u'b'], timeout=5000)\nkey, time = my_keyboard.get_key()\n~~~\n\n\n\n## Mouse(\\*\\*resp_args)\n\nUne fonction d'usine qui crée un nouvel objet `Mouse`. Pour une\ndescription\ndes mots-clés possibles, voir :\n\n- %link:manual/python/mouse%\n\n\n__Renvoie__\n\n- Un objet `mouse`.\n\n__Exemple__\n\n~~~ .python\nmy_mouse = Mouse(keylist=[1,3], timeout=5000)\nbutton, time = my_mouse.get_button()\n~~~\n\n\n\n## Sampler(src, \\*\\*playback_args)\n\nUne fonction d'usine qui crée un nouvel objet `Sampler`. Pour une\ndescription des mots-clés possibles, voir :\n\n- %link:manual/python/sampler%\n\n\n__Renvoie__\n\n- Un objet SAMPLER.\n\n__Exemple__\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src, volume=.5, pan='left')\nmy_sampler.play()\n~~~\n\n\n\n## Synth(osc='sine', freq=440, length=100, attack=0, decay=5)\n\nUne fonction d'usine qui synthétise un son et le retourne sous forme d'\nobjet `Sampler`.\n\n\n__Paramètres__\n\n- **osc** : Oscillateur, peut être \"sine\", \"saw\", \"square\" ou \"white_noise\".\n- **freq** : Fréquence, soit une valeur entière (valeur en hertz) ou une chaîne (\"A1\",\n\"eb2\", etc.).\n- **length** : La durée du son en millisecondes.\n- **attack** : Le temps d'attaque (fade-in) en millisecondes.\n- **decay** : Le temps de décroissance (fade-out) en millisecondes.\n\n__Renvoie__\n\n- Un objet SAMPLER.\n\n__Exemple__\n\n~~~ .python\nmy_sampler = Synth(freq=u'b2', length=500)\n~~~\n\n\n\n## copy_sketchpad(name)\n\nRenvoie une copie du canvas d'un `sketchpad`.\n\n\n__Paramètres__\n\n- **name** : Le nom du `sketchpad`.\n\n__Renvoie__\n\n- Une copie du canvas du `sketchpad`.\n\n__Exemple__"
  },
  "~~~ .yaml\nname: opensesame_3.1.8-py2.7-win32-1\nchannels:\n- cogsci\n- defaults\ndependencies:\n- python==2.7.12\n- anaconda-client=1.4.0=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.4=py27_0\n- bzip2=1.0.6=vc9_3\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.0.3=py_0\n- psychopy=1.82.01=py27_0\n- pygame=1.9.2a0=py27_0\n# - pyglet=1.2.4=py27_0 # As of 3.1.8 installed through pip so that we can pip update it\n- python-datamatrix=0.6.3=py_0 # updated in 3.1.8\n- python-fileinspector=1.0.2=py_0 # updated in 3.1.3\n- python-opensesame=3.1.8=py_0 # updated in 3.1.8\n- python-pseudorandom=0.2.2=py27_0\n- python-pygaze=0.6.0a21=py_0 # Updated in 3.1.3\n- python-qdatamatrix=0.1.16=py_0 # updated in 3.1.8\n- python-qnotifications=1.1.1=py_0 # updated in 3.1.3\n- python-qosf=1.2.2=py_0 # updated in 3.1.7\n- python-qprogedit=4.0.11=py_0 # updated in 3.1.7\n- qscintilla2=2.9.1=py27_vc9_0\n- requests-oauthlib=0.6.1=py_0\n- webcolors=1.5=py27_0\n- configparser=3.5.0b2=py27_1\n- decorator=4.0.10=py27_0\n- entrypoints=0.2.2=py27_0\n- freetype=2.5.5=vc9_1\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- ipykernel=4.3.1=py27_0\n- ipython=4.2.0=py27_0\n- ipython_genutils=0.1.0=py27_0\n- ipywidgets=4.1.1=py27_0\n- jinja2=2.8=py27_1\n- jpeg=8d=vc9_0\n- jsonschema=2.5.1=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=4.3.0=py27_0\n- jupyter_console=4.1.1=py27_0\n- jupyter_core=4.1.0=py27_0\n- libpng=1.6.22=vc9_0\n- libtiff=4.0.6=vc9_2\n- markdown=2.6.6=py27_0\n- markupsafe=0.23=py27_2\n- mistune=0.7.2=py27_0\n- mkl=11.3.3=1\n- nbconvert=4.2.0=py27_0\n- nbformat=4.0.1=py27_0\n- notebook=4.2.1=py27_0\n- numpy=1.11.1=py27_0\n- openssl=1.0.2h=vc9_0\n- path.py=8.2.1=py27_0\n- pickleshare=0.5=py27_0\n- pillow=3.2.0=py27_1\n- pip=8.1.2=py27_0\n- pyflakes=1.2.3=py27_0\n- pygments=2.1.3=py27_0\n- pyopengl=3.1.1a1=np111py27_0\n- pyopengl-accelerate=3.1.1a1=np111py27_0\n- pyqt=4.11.4=py27_6\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.12=0\n- python-dateutil=2.5.3=py27_0\n- pytz=2016.4=py27_0\n- pyyaml=3.11=py27_4\n- pyzmq=15.2.0=py27_0\n- qt=4.8.7=vc9_8\n- qtawesome=0.3.3=py27_0\n- qtconsole=4.2.1=py27_0\n- qtpy=1.0.2=py27_0\n- requests=2.10.0=py27_0\n- scipy=0.17.1=np111py27_1\n- setuptools=23.0.0=py27_0\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.16.9=py27_2\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.4.0.2=py27_1\n- tornado=4.3=py27_1\n- traitlets=4.2.1=py27_0\n- vs2008_runtime=9.00.30729.1=2\n- wheel=0.29.0=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.8=vc9_3\n- pip:\n  - pyglet==1.2.4\n  - cffi==1.7.0\n  - expyriment==0.8.0 # Upgrade manually to 0.8.1.opensesame2\n  - imageio==1.5\n  - mediadecoder==0.1.5\n  - moviepy==0.2.2.11  \n  - opensesame-extension-osf==1.1.1 # Updated in 3.1.7\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-windows-launcher==0.4.1\n  - pycparser==2.14\n  - python-bidi==0.4.0\n  - sounddevice==0.3.3\n  - tqdm==4.7.6\n  - pyaudio==0.2.9 # Added in 3.1.3\n  - openpyxl==2.4.0 # Added in 3.1.3\n  - fastnumbers==1.0.0 # Added in 3.1.5\n  - prettytable==0.7.2 # Added in 3.1.5\nprefix: opensesame_3.1.8-py2.7-win32-1\n~~~\n": {
    "fr": "~~~ .yaml\nname: opensesame_3.1.8-py2.7-win32-1\nchannels:\n- cogsci\n- defaults\ndependencies:\n- python==2.7.12\n- anaconda-client=1.4.0=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.4=py27_0\n- bzip2=1.0.6=vc9_3\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.0.3=py_0\n- psychopy=1.82.01=py27_0\n- pygame=1.9.2a0=py27_0\n# - pyglet=1.2.4=py27_0 # As of 3.1.8 installed through pip so that we can pip update it\n- python-datamatrix=0.6.3=py_0 # updated in 3.1.8\n- python-fileinspector=1.0.2=py_0 # updated in 3.1.3\n- python-opensesame=3.1.8=py_0 # updated in 3.1.8\n- python-pseudorandom=0.2.2=py27_0\n- python-pygaze=0.6.0a21=py_0 # Updated in 3.1.3\n- python-qdatamatrix=0.1.16=py_0 # updated in 3.1.8\n- python-qnotifications=1.1.1=py_0 # updated in 3.1.3\n- python-qosf=1.2.2=py_0 # updated in 3.1.7\n- python-qprogedit=4.0.11=py_0 # updated in 3.1.7\n- qscintilla2=2.9.1=py27_vc9_0\n- requests-oauthlib=0.6.1=py_0\n- webcolors=1.5=py27_0\n- configparser=3.5.0b2=py27_1\n- decorator=4.0.10=py27_0\n- entrypoints=0.2.2=py27_0\n- freetype=2.5.5=vc9_1\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- ipykernel=4.3.1=py27_0\n- ipython=4.2.0=py27_0\n- ipython_genutils=0.1.0=py27_0\n- ipywidgets=4.1.1=py27_0\n- jinja2=2.8=py27_1\n- jpeg=8d=vc9_0\n- jsonschema=2.5.1=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=4.3.0=py27_0\n- jupyter_console=4.1.1=py27_0\n- jupyter_core=4.1.0=py27_0\n- libpng=1.6.22=vc9_0\n- libtiff=4.0.6=vc9_2\n- markdown=2.6.6=py27_0\n- markupsafe=0.23=py27_2\n- mistune=0.7.2=py27_0\n- mkl=11.3.3=1\n- nbconvert=4.2.0=py27_0\n- nbformat=4.0.1=py27_0\n- notebook=4.2.1=py27_0\n- numpy=1.11.1=py27_0\n- openssl=1.0.2h=vc9_0\n- path.py=8.2.1=py27_0\n- pickleshare=0.5=py27_0\n- pillow=3.2.0=py27_1\n- pip=8.1.2=py27_0\n- pyflakes=1.2.3=py27_0\n- pygments=2.1.3=py27_0\n- pyopengl=3.1.1a1=np111py27_0\n- pyopengl-accelerate=3.1.1a1=np111py27_0\n- pyqt=4.11.4=py27_6\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.12=0\n- python-dateutil=2.5.3=py27_0\n- pytz=2016.4=py27_0\n- pyyaml=3.11=py27_4\n- pyzmq=15.2.0=py27_0\n- qt=4.8.7=vc9_8\n- qtawesome=0.3.3=py27_0\n- qtconsole=4.2.1=py27_0\n- qtpy=1.0.2=py27_0\n- requests=2.10.0=py27_0\n- scipy=0.17.1=np111py27_1\n- setuptools=23.0.0=py27_0\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.16.9=py27_2\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.4.0.2=py27_1\n- tornado=4.3=py27_1\n- traitlets=4.2.1=py27_0\n- vs2008_runtime=9.00.30729.1=2\n- wheel=0.29.0=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.8=vc9_3\n- pip:\n  - pyglet==1.2.4\n  - cffi==1.7.0\n  - expyriment==0.8.0 # Upgrade manually to 0.8.1.opensesame2\n  - imageio==1.5\n  - mediadecoder==0.1.5\n  - moviepy==0.2.2.11  \n  - opensesame-extension-osf==1.1.1 # Updated in 3.1.7\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-windows-launcher==0.4.1\n  - pycparser==2.14\n  - python-bidi==0.4.0\n  - sounddevice==0.3.3\n  - tqdm==4.7.6\n  - pyaudio==0.2.9 # Added in 3.1.3\n  - openpyxl==2.4.0 # Added in 3.1.3\n  - fastnumbers==1.0.0 # Added in 3.1.5\n  - prettytable==0.7.2 # Added in 3.1.5\nprefix: opensesame_3.1.8-py2.7-win32-1\n~~~\n"
  },
  "- **x**: The center X coordinate.\n- **y**: The center Y coordinate.\n- **env**: The envelope that determines the shape of the patch. Can be\n\"gaussian\", \"linear\", \"circular\", or \"rectangular\".\n- **size**: A size in pixels.\n- **stdev**: Standard deviation in pixels of the gaussian. Only applicable to\ngaussian envelopes.\n- **col1**: The first color.\n- **col2**: The second color. Note: The psycho back-end ignores this\nparameter\nand always uses the inverse of `col1`.\n- **bgmode**: {{arg_bgmode}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Function interface\nmy_canvas.noise_patch(100, 100, env='circular')\n# Element interface\nmy_canvas['my_noise_patch'] = NoisePatch(100, 100, env='circular')\n~~~\n\n\n\n## polygon(vertices, \\*\\*style_args)\n\nDraws a polygon that defined by a list of vertices. I.e. a shape of\npoints connected by lines.\n\n\n__Parameters__\n\n- **vertices**: A list of tuples, where each tuple corresponds to a vertex. For\nexample, [(100,100), (200,100), (100,200)] will draw a triangle.\n- **\\*\\*style_args**: {{arg_style}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\nn1 = 0,0\nn2 = 100, 100\nn3 = 0, 100\n# Function interface\nmy_canvas.polygon([n1, n2, n3])\n# Element interface\nmy_canvas['my_polygon'] = Polygon([n1, n2, n3])\n~~~\n\n\n\n## prepare(self)\n\nFinishes pending canvas operations (if any), so that a subsequent\ncall to [canvas.show] is extra fast. It's only necessary to call this\nfunction if you have disabled `auto_prepare` when initializing the\n`Canvas`.\n\n\n\n\n## raise_to_top(element)\n\nRaises an element to the top, so that it is drawn last; that is, it\nbecomes the foreground.\n\n\n__Parameters__\n\n- **element**: A SKETCHPAD element, or its name.\n\n\n## rect(x, y, w, h, \\*\\*style_args)\n\nDraws a rectangle.\n\n\n__Parameters__\n\n- **x**: The left X coordinate.\n- **y**: The top Y coordinate.\n- **w**: The width.\n- **h**: The height.\n- **\\*\\*style_args**: {{arg_style}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Function interface\nmy_canvas.rect(-10, -10, 20, 20, fill=True)\n# Element interface\nmy_canvas['my_rect'] = Rect(-10, -10, 20, 20, fill=True)\n~~~\n\n\n\n## rename_element(old_name, new_name)\n\nRenames an element.\n\n\n\n\n## show(self)\n\nShows, or 'flips', the canvas on the screen.\n\n\n\n__Returns__\n\n- A timestamp of the time at which the canvas actually appeared on\nthe screen, or a best guess if precise temporal information is not\navailable. For more information about timing, see </misc/timing>.\nDepending on the back-end the timestamp is an `int` or a `float`.\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\nt = my_canvas.show()\nexp.set('time_fixdot', t)\n~~~\n\n\n\n## text(text, center=True, x=None, y=None, max_width=None, \\*\\*style_args)\n\nDraws text.\n\n\n__Parameters__\n\n- **text**: A string of text. When using Python 2, this should be either\n`unicode` or a utf-8-encoded `str`. When using Python 3, this\nshould be either `str` or a utf-8-encoded `bytes`.\n- **center**: {{arg_center}}\n- **x**: The X coordinate, or None to draw horizontally centered text.\n- **y**: The Y coordinate, or None to draw vertically centered text.\n- **max_width**: {{arg_max_width}}\n- **\\*\\*style_args**: {{arg_style}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Function interface\nmy_canvas.text('Some text with <b>boldface</b> and <i>italics</i>')\n# Element interface\nmy_canvas['my_text'] = Text('Some text with <b>boldface</b> and <i>italics</i>')\n~~~\n\n\n\n## text_size(text, center=True, max_width=None, \\*\\*style_args)\n\nDetermines the size of a text string in pixels.\n\n\n__Parameters__\n\n- **text**: A string of text.\n- **center**: {{arg_center}}\n- **max_width**: {{arg_max_width}}\n- **\\*\\*style_args**: {{arg_style}}\n\n__Returns__\n\n- A (width, height) tuple containing the dimensions of the text\nstring.\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\nw, h = my_canvas.text_size('Some text')\n~~~\n\n\n\n</div>\n\n": {
    "fr": "- **x**: Coordonnée X centrale.\n- **y**: Coordonnée Y centrale.\n- **env**: L'enveloppe qui détermine la forme du patch. Peut être\n\"gaussian\", \"linéaire\", \"circulaire\" ou \"rectangulaire\".\n- **size**: Une taille en pixels.\n- **stdev**: Écart type en pixels du gaussien. Applicable uniquement aux\nenveloppes gaussiennes.\n- **col1**: La première couleur.\n- **col2**: La deuxième couleur. Remarque: Le back-end psycho ignore ce\nparamètre\net utilise toujours l'inverse de `col1`.\n- **bgmode**: {{arg_bgmode}}\n\n__Exemple__\n\n~~~ .python\nmy_canvas = Canvas()\n# Interface fonction\nmy_canvas.noise_patch(100, 100, env='circulaire')\n# Interface élément\nmy_canvas['my_noise_patch'] = NoisePatch(100, 100, env='circulaire')\n~~~\n\n\n\n## polygon(sommets, \\*\\*style_args)\n\nDessine un polygone défini par une liste de sommets. C'est-à-dire une forme de\npoints reliés par des lignes.\n\n\n__Paramètres__\n\n- **sommets**: Une liste de tuples, où chaque tuple correspond à un sommet. Par\nexemple, [(100,100), (200,100), (100,200)] dessinera un triangle.\n- **\\*\\*style_args**: {{arg_style}}\n\n__Exemple__\n\n~~~ .python\nmy_canvas = Canvas()\nn1 = 0,0\nn2 = 100, 100\nn3 = 0, 100\n# Interface fonction\nmy_canvas.polygon([n1, n2, n3])\n# Interface élément\nmy_canvas['my_polygon'] = Polygon([n1, n2, n3])\n~~~\n\n\n\n## prepare(self)\n\nTermine les opérations de canevas en attente (le cas échéant), de sorte qu'un\nappel ultérieur à [canvas.show] soit extrêmement rapide. Il est seulement nécessaire d'appeler cette\nfonction si vous avez désactivé `auto_prepare` lors de l'initialisation du\n`Canvas`.\n\n\n\n\n## raise_to_top(element)\n\nPlace un élément au premier plan, de sorte qu'il soit dessiné en dernier ; c'est-à-dire, il\ndevient le premier plan.\n\n\n__Paramètres__\n\n- **element**: Un élément SKETCHPAD ou son nom.\n\n\n## rect(x, y, w, h, \\*\\*style_args)\n\nDessine un rectangle.\n\n\n__Paramètres__\n\n- **x**: Coordonnée X gauche.\n- **y**: Coordonnée Y supérieure.\n- **w**: La largeur.\n- **h**: La hauteur.\n- **\\*\\*style_args**: {{arg_style}}\n\n__Exemple__\n\n~~~ .python\nmy_canvas = Canvas()\n# Interface fonction\nmy_canvas.rect(-10, -10, 20, 20, fill=True)\n# Interface élément\nmy_canvas['my_rect'] = Rect(-10, -10, 20, 20, fill=True)\n~~~\n\n\n\n## rename_element(old_name, new_name)\n\nRenomme un élément.\n\n\n\n\n## show(self)\n\nAffiche ou 'bascule' le canvas à l'écran.\n\n\n\n__Retour__\n\n- Un horodatage du moment où le canevas est réellement apparu sur\nl'écran, ou une meilleure estimation si des informations temporelles précises ne sont pas\ndisponibles. Pour plus d'informations sur le timing, voir </misc/timing>.\nEn fonction du back-end, l'horodatage est un `int` ou un `float`.\n\n__Exemple__\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\nt = my_canvas.show()\nexp.set('time_fixdot', t)\n~~~\n\n\n\n## text(texte, center=True, x=None, y=None, max_width=None, \\*\\*style_args)\n\nDessine du texte.\n\n\n__Paramètres__\n\n- **texte**: Une chaîne de texte. Lors de l'utilisation de Python 2, cela devrait être soit\n`unicode` ou une chaîne `str` encodée en utf-8. Lors de l'utilisation de Python 3, cela\ndevrait être soit `str` ou des `bytes` encodées en utf-8.\n- **center**: {{arg_center}}\n- **x**: La coordonnée X, ou None pour dessiner le texte centré horizontalement.\n- **y**: La coordonnée Y, ou None pour dessiner le texte centré verticalement.\n- **max_width**: {{arg_max_width}}\n- **\\*\\*style_args**: {{arg_style}}\n\n__Exemple__\n\n~~~ .python\nmy_canvas = Canvas()\n# Interface fonction\nmy_canvas.text('Du texte en <b>gras</b> et en <i>italique</i>')\n# Interface élément\nmy_canvas['my_text'] = Text('Du texte en <b>gras</b> et en <i>italique</i>')\n~~~\n\n\n\n## text_size(texte, center=True, max_width=None, \\*\\*style_args)\n\nDétermine la taille d'une chaîne de texte en pixels.\n\n\n__Paramètres__\n\n- **texte**: Une chaîne de texte.\n- **center**: {{arg_center}}\n- **max_width**: {{arg_max_width}}\n- **\\*\\*style_args**: {{arg_style}}\n\n__Retour__\n\n- Un tuple (largeur, hauteur) contenant les dimensions de la chaîne de texte\n.\n\n__Exemple__\n\n~~~ .python\nmy_canvas = Canvas()\nw, h = my_canvas.text_size('Du texte')\n~~~\n\n\n\n</div>"
  },
  "~~~ .python\nmy_canvas = copy_sketchpad('my_sketchpad')\nmy_canvas.show()\n~~~\n\n\n\n## pause()\n\nPauses the experiment.\n\n\n\n\n## register_cleanup_function(fnc)\n\nRegisters a clean-up function, which is executed when the experiment\nends. Clean-up functions are executed at the very end, after the display,\nsound device, and log file have been closed. Clean-up functions are also\nexecuted when the experiment crashes.\n\n\n\n__Example__\n\n~~~ .python\ndef my_cleanup_function():\n        print(u'The experiment is finished!')\nregister_cleanup_function(my_cleanup_function)\n~~~\n\n\n\n## reset_feedback()\n\nResets all feedback variables to their initial state.\n\n\n\n__Example__\n\n~~~ .python\nreset_feedback()\n~~~\n\n\n\n## set_subject_nr(nr)\n\nSets the subject number and parity (even/ odd). This function is called\nautomatically when an experiment is started, so you only need to call it\nyourself if you overwrite the subject number that was specified when the\nexperiment was launched.\n\n\n__Parameters__\n\n- **nr**: The subject nr.\n\n__Example__\n\n~~~ .python\nset_subject_nr(1)\nprint('Subject nr = %d' % var.subject_nr)\nprint('Subject parity = %s' % var.subject_parity)\n~~~\n\n\n\n## sometimes(p=0.5)\n\nReturns True with a certain probability. (For more advanced\nrandomization, use the Python `random` module.)\n\n\n__Parameters__\n\n- **p**: The probability of returning True.\n\n__Returns__\n\n- True or False\n\n__Example__\n\n~~~ .python\nif sometimes():\n        print('Sometimes you win')\nelse:\n        print('Sometimes you loose')\n~~~\n\n\n\n## xy_circle(n, rho, phi0=0, pole=(0, 0))\n\nGenerates a list of points (x,y coordinates) in a circle. This can be\nused to draw stimuli in a circular arrangement.\n\n\n__Parameters__\n\n- **n**: The number of x,y coordinates to generate.\n- **rho**: The radial coordinate, also distance or eccentricity, of the first\npoint.\n- **phi0**: The angular coordinate for the first coordinate. This is a\ncounterclockwise rotation in degrees (i.e. not radians), where 0 is\nstraight right.\n- **pole**: The refence point.\n\n__Returns__\n\n- A list of (x,y) coordinate tuples.\n\n__Example__\n\n~~~ .python\n# Draw 8 rectangles around a central fixation dot\nc = Canvas()\nc.fixdot()\nfor x, y in xy_circle(8, 100):\n        c.rect(x-10, y-10, 20, 20)\nc.show()\n~~~\n\n\n\n## xy_distance(x1, y1, x2, y2)\n\nGives the distance between two points.\n\n\n__Parameters__\n\n- **x1**: The x coordinate of the first point.\n- **y1**: The y coordinate of the first point.\n- **x2**: The x coordinate of the second point.\n- **y2**: The y coordinate of the second point.\n\n__Returns__\n\n- The distance between the two points.\n\n\n## xy_from_polar(rho, phi, pole=(0, 0))\n\nConverts polar coordinates (distance, angle) to Cartesian coordinates\n(x, y).\n\n\n__Parameters__\n\n- **rho**: The radial coordinate, also distance or eccentricity.\n- **phi**: The angular coordinate. This reflects a clockwise rotation in degrees\n(i.e. not radians), where 0 is straight right.\n- **pole**: The refence point.\n\n__Returns__\n\n- An (x, y) coordinate tuple.\n\n__Example__\n\n~~~ .python\n# Draw a cross\nx1, y1 = xy_from_polar(100, 45)\nx2, y2 = xy_from_polar(100, -45)\nc = Canvas()\nc.line(x1, y1, -x1, -y1)\nc.line(x2, y2, -x2, -y2)\nc.show()\n~~~\n\n\n\n## xy_grid(n, spacing, pole=(0, 0))\n\nGenerates a list of points (x,y coordinates) in a grid. This can be\nused to draw stimuli in a grid arrangement.\n\n\n__Parameters__\n\n- **n**: An `int` that indicates the number of columns and rows, so that `n=2`\nindicates a 2x2 grid, or a (n_col, n_row) `tuple`, so that `n=(2,3)`\nindicates a 2x3 grid.\n- **spacing**: A numeric value that indicates the spacing between cells, or a\n(col_spacing, row_spacing) tuple.\n- **pole**: The refence point.\n\n__Returns__\n\n- A list of (x,y) coordinate tuples.\n\n__Example__\n\n~~~ .python\n# Draw a 4x4 grid of rectangles\nc = Canvas()\nc.fixdot()\nfor x, y in xy_grid(4, 100):\n        c.rect(x-10, y-10, 20, 20)\nc.show()\n~~~\n\n\n\n## xy_random(n, width, height, min_dist=0, pole=(0, 0))": {
    "fr": "~~~ .python\nmy_canvas = copy_sketchpad('mon_sketchpad')\nmy_canvas.show()\n~~~\n\n## pause()\n\nMet l'expérience en pause.\n\n## register_cleanup_function(fnc)\n\nEnregistre une fonction de nettoyage, qui est exécutée lorsque l'expérience se termine. Les fonctions de nettoyage sont exécutées à la toute fin, après la fermeture de l'affichage, du dispositif sonore et du fichier de journal. Les fonctions de nettoyage sont également exécutées lorsque l'expérience échoue.\n\n__Exemple__\n\n~~~ .python\ndef ma_fonction_de_nettoyage():\n        print(u\"L'expérience est terminée!\")\nregister_cleanup_function(ma_fonction_de_nettoyage)\n~~~\n\n## reset_feedback()\n\nRéinitialise toutes les variables de feedback à leur état initial.\n\n__Exemple__\n\n~~~ .python\nreset_feedback()\n~~~\n\n## set_subject_nr(nr)\n\nDéfinit le numéro de participant et la parité (pair/impair). Cette fonction est appelée automatiquement lorsqu'une expérience est lancée, vous n'avez donc besoin de l'appeler vous-même que si vous écrivez par-dessus le numéro de participant qui a été spécifié lors du lancement de l'expérience.\n\n__Paramètres__\n\n- **nr**: Le numéro de participant.\n\n__Exemple__\n\n~~~ .python\nset_subject_nr(1)\nprint('Numéro de participant = %d' % var.subject_nr)\nprint('Parité = %s' % var.subject_parity)\n~~~\n\n## sometimes(p=0.5)\n\nRetourne True avec une certaine probabilité. (Pour une randomisation plus avancée, utilisez le module `random` de Python.)\n\n__Paramètres__\n\n- **p**: La probabilité de retourner True.\n\n__Retourne__\n\n- True ou False\n\n__Exemple__\n\n~~~ .python\nif sometimes():\n        print('Parfois tu gagnes')\nelse:\n        print('Parfois tu perds')\n~~~\n\n## xy_circle(n, rho, phi0=0, pole=(0, 0))\n\nGénère une liste de points (coordonnées x,y) dans un cercle. Ceci peut être utilisé pour dessiner des stimuli dans un arrangement circulaire.\n\n__Paramètres__\n\n- **n**: Le nombre de coordonnées x,y à générer.\n- **rho**: La coordonnée radiale, aussi appelée distance ou excentricité, du premier point.\n- **phi0**: La coordonnée angulaire pour la première coordonnée. Il s'agit d'une rotation antihoraire en degrés (et non en radians), où 0 est à droite.\n- **pole**: Le point de référence.\n\n__Retourne__\n\n- Une liste de tuples de coordonnées (x,y).\n\n__Exemple__\n\n~~~ .python\n# Dessiner 8 rectangles autour d'un point de fixation central\nc = Canvas()\nc.fixdot()\nfor x, y in xy_circle(8, 100):\n        c.rect(x-10, y-10, 20, 20)\nc.show()\n~~~\n\n## xy_distance(x1, y1, x2, y2)\n\nIndique la distance entre deux points.\n\n__Paramètres__\n\n- **x1**: La coordonnée x du premier point.\n- **y1**: La coordonnée y du premier point.\n- **x2**: La coordonnée x du second point.\n- **y2**: La coordonnée y du second point.\n\n__Retourne__\n\n- La distance entre les deux points.\n\n## xy_from_polar(rho, phi, pole=(0, 0))\n\nConvertit les coordonnées polaires (distance, angle) en coordonnées cartésiennes (x, y).\n\n__Paramètres__\n\n- **rho**: La coordonnée radiale, c'est-à-dire la distance ou l'excentricité.\n- **phi**: La coordonnée angulaire. Elle reflète une rotation dans le sens des aiguilles d'une montre en degrés (c'est-à-dire pas en radians), où 0 est droit devant.\n- **pole**: Le point de référence.\n\n__Retourne__\n\n- Un tuple de coordonnées (x, y).\n\n__Exemple__\n\n~~~ .python\n# Dessiner une croix\nx1, y1 = xy_from_polar(100, 45)\nx2, y2 = xy_from_polar(100, -45)\nc = Canvas()\nc.line(x1, y1, -x1, -y1)\nc.line(x2, y2, -x2, -y2)\nc.show()\n~~~\n\n## xy_grid(n, spacing, pole=(0, 0))\n\nGénère une liste de points (coordonnées x,y) dans une grille. Ceci peut être utilisé pour dessiner des stimuli dans un arrangement en grille.\n\n__Paramètres__\n\n- **n**: Un `int` qui indique le nombre de colonnes et de lignes, de sorte que `n=2` indique une grille 2x2, ou un tuple (n_col, n_row), de sorte que `n=(2,3)` indique une grille 2x3.\n- **spacing**: Une valeur numérique indiquant l'espacement entre les cellules, ou un tuple (col_spacing, row_spacing).\n- **pole**: Le point de référence.\n\n__Retourne__\n\n- Une liste de tuples de coordonnées (x,y).\n\n__Exemple__\n\n~~~ .python\n# Dessiner une grille 4x4 de rectangles\nc = Canvas()\nc.fixdot()\nfor x, y in xy_grid(4, 100):\n        c.rect(x-10, y-10, 20, 20)\nc.show()\n~~~\n\n## xy_random(n, width, height, min_dist=0, pole=(0, 0))"
  },
  "Generates a list of random points (x,y coordinates) with a minimum\nspacing between each pair of points. This function will raise an\nException when the coordinate list cannot be generated,  typically because\nthere are too many points, the min_dist is set too high, or the width or\nheight are set too low.\n\n\n__Parameters__\n\n- **n**: The number of points to generate.\n- **width**: The width of the field with random points.\n- **height**: The height of the field with random points.\n- **min_dist**: The minimum distance between each point.\n- **pole**: The refence point.\n\n__Returns__\n\n- A list of (x,y) coordinate tuples.\n\n__Example__\n\n~~~ .python\n# Draw a 50 rectangles in a random grid\nc = Canvas()\nc.fixdot()\nfor x, y in xy_random(50, 500, 500, min_dist=40):\n        c.rect(x-10, y-10, 20, 20)\nc.show()\n~~~\n\n\n\n## xy_to_polar(x, y, pole=(0, 0))\n\nConverts Cartesian coordinates (x, y) to polar coordinates (distance,\nangle).\n\n\n__Parameters__\n\n- **x**: The X coordinate.\n- **y**: The Y coordinate.\n- **pole**: The refence point.\n\n__Returns__\n\n- An (rho, phi) coordinate tuple. Here, `rho` is the radial coordinate,\nalso distance or eccentricity. `phi` is the angular coordinate in\ndegrees (i.e. not radians), and reflects a counterclockwise rotation,\nwhere 0 is straight right.\n\n__Example__\n\n~~~ .python\nrho, phi = xy_to_polar(100, 100)\n~~~\n\n\n\n</div>\n\n": {
    "fr": "Génère une liste de points aléatoires (coordonnées x, y) avec un espacement minimum\nentre chaque paire de points. Cette fonction générera une exception si la liste des coordonnées ne peut pas être générée, généralement parce qu'il y a trop de points, la min_dist est trop élevée, ou la largeur ou la hauteur sont trop faibles.\n\n\n__Paramètres__\n\n- **n** : Le nombre de points à générer.\n- **width** : La largeur du champ avec des points aléatoires.\n- **height** : La hauteur du champ avec des points aléatoires.\n- **min_dist** : La distance minimale entre chaque point.\n- **pole** : Le point de référence.\n\n__Renvoie__\n\n- Une liste de tuples de coordonnées (x, y).\n\n__Exemple__\n\n~~~ .python\n# Dessiner 50 rectangles dans une grille aléatoire\nc = Canvas()\nc.fixdot()\nfor x, y in xy_random(50, 500, 500, min_dist=40):\n        c.rect(x-10, y-10, 20, 20)\nc.show()\n~~~\n\n\n\n## xy_to_polar(x, y, pole=(0, 0))\n\nConvertit les coordonnées cartésiennes (x, y) en coordonnées polaires (distance,\nangle).\n\n\n__Paramètres__\n\n- **x** : La coordonnée X.\n- **y** : La coordonnée Y.\n- **pole** : Le point de référence.\n\n__Renvoie__\n\n- Un tuple de coordonnées (rho, phi). Ici, `rho` est la coordonnée radiale,\naussi distance ou excentricité. `phi` est la coordonnée angulaire en\ndegrés (c'est-à-dire pas en radians), et reflète une rotation antihoraire,\noù 0 est tout droit à droite.\n\n__Exemple__\n\n~~~ .python\nrho, phi = xy_to_polar(100, 100)\n~~~\n\n\n\n</div>"
  },
  "\nOpenSesame is a program to create experiments for psychology, neuroscience, and experimental economics. The latest $status$ version is $version$ *$codename$*, released on $release-date$ ([release notes](http://osdoc.cogsci.nl/$branch$/notes/$notes$)).\n\n<div class=\"btn-group\" role=\"group\" aria-label=\"...\">\n  <a role=\"button\" class=\"btn btn-success\" href=\"%url:download%\">\n\t\t<span class=\"glyphicon glyphicon-download\" aria-hidden=\"true\"></span>\n\t\tDownload\n\t </a>\n  <a role=\"button\" class=\"btn btn-success\" href=\"%url:beginner%\">\n  <span class=\"glyphicon glyphicon-education\" aria-hidden=\"true\"></span>\n  \tTutorial\n  </a>\n  <a role=\"button\" class=\"btn btn-success\" href=\"https://professional.cogsci.nl/\">\n  <span class=\"glyphicon glyphicon-comment\" aria-hidden=\"true\"></span>\n  Get support</a>\n</div>\n\n## Features\n\n- __A user-friendly interface__ — a modern, professional, and easy-to-use graphical [interface](%link:manual/interface%)\n- __Online experiments__ — run your experiment in a browser with [OSWeb](%link:manual/osweb/workflow%)\n- __Python__ — add the power of [Python](%link:manual/python/about%) to your experiment\n- __JavaScript__ — add the power of [JavaScript](%link:manual/python/about%) to your experiment\n- __Use your devices__ — use your [eye tracker](%link:pygaze%), [button box](%link:buttonbox%), [EEG equipment](%link:parallel%), and more.\n- __Free__ — released under the GPL3\n- __Crossplatform__ — Windows, Mac OS, and Linux\n\n## Citations\n\n<notranslate>\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nMathôt, S., & March, J. (2022). Conducting linguistic experiments online with OpenSesame and OSWeb. *Language Learning*. doi:10.1111/lang.12509\n<br /><small>[Related preprint (not identical to published manuscript)](https://doi.org/10.31234/osf.io/wnryc)</small>\n</notranslate>\n": {
    "fr": "OpenSesame est un programme pour créer des expériences en psychologie, neurosciences et économie expérimentale. La dernière version $status$ est la $version$ *$codename$*, publiée le $release-date$ ([notes de version](http://osdoc.cogsci.nl/$branch$/notes/$notes$)).\n\n<div class=\"btn-group\" role=\"group\" aria-label=\"...\">\n  <a role=\"button\" class=\"btn btn-success\" href=\"%url:download%\">\n\t\t<span class=\"glyphicon glyphicon-download\" aria-hidden=\"true\"></span>\n\t\tTélécharger\n\t </a>\n  <a role=\"button\" class=\"btn btn-success\" href=\"%url:beginner%\">\n  <span class=\"glyphicon glyphicon-education\" aria-hidden=\"true\"></span>\n  \tTutoriel\n  </a>\n  <a role=\"button\" class=\"btn btn-success\" href=\"https://professional.cogsci.nl/\">\n  <span class=\"glyphicon glyphicon-comment\" aria-hidden=\"true\"></span>\n  Obtenir de l'aide</a>\n</div>\n\n## Fonctionnalités\n\n- __Une interface conviviale__ — une [interface](%link:manual/interface%) graphique moderne, professionnelle et facile à utiliser\n- __Expériences en ligne__ — exécutez votre expérience dans un navigateur avec [OSWeb](%link:manual/osweb/workflow%)\n- __Python__ — ajoutez la puissance de [Python](%link:manual/python/about%) à votre expérience\n- __JavaScript__ — ajoutez la puissance de [JavaScript](%link:manual/python/about%) à votre expérience\n- __Utilisez vos appareils__ — utilisez votre [eye tracker](%link:pygaze%), [boîtier de boutons](%link:buttonbox%), [équipement EEG](%link:parallel%), et plus encore.\n- __Gratuit__ — publié sous licence GPL3\n- __Multiplateforme__ — Windows, Mac OS et Linux\n\n## Citations\n\n<notranslate>\nMathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: Un générateur d'expériences open-source et graphique pour les sciences sociales. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nMathôt, S., & March, J. (2022). Réalisation d'expériences linguistiques en ligne avec OpenSesame et OSWeb. *Language Learning*. doi:10.1111/lang.12509\n<br /><small>[Prépublication liée (non identique au manuscrit publié)](https://doi.org/10.31234/osf.io/wnryc)</small>\n</notranslate>"
  },
  "Release notes for 3.1.7": {
    "fr": "Notes de version pour 3.1.7"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About this update\n\nOpenSesame 3.1.7 *Jazzy James* is the seventh maintenance release in the 3.1 series. It contains bug fixes and minor improvements, and should be a pleasant and safe upgrade for everyone who is using the 3.1 series.\n\nIf you are upgrading from OpenSesame 3.0 or earlier, please see the list of important changes:\n\n- %link:important-changes-3%\n\n## Credits\n\nThanks to:\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) for the Mac OS package, and his code contributions\n- Jarik den Hartog (%-- github: {user: JdenHartog} --%) for his code contributions\n- %-- github: {user: juliencegarra} --% for his code contributions\n\n## Bug fixes and improvements\n\nopensesame:\n\n- Updated to 3.1.7\n- %-- github: { repo: \"smathot/opensesame\", issue: 495 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 509 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 511 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 513 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 514 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 515 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 516 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 517 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 519 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 520 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 521 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 524 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 525 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 526 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 528 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 529 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 530 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 531 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 534 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 535 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 536 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 538 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 539 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 540 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 541 } --%\n\nqprogedit:\n\n- Updated to 4.0.11\n\ndatamatrix:\n\n- Updated to 0.4.15\n\nqdatamatrix:\n\n- Updated to 0.1.15\n\nqosf:\n\n- Updated to 1.2.2\n\nopensesame-extension-osf\n\n- Updated to 1.1.1\n\n\n## Packages (Windows Python 2.7 package)\n\n\n### Detailed package information": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de cette mise à jour\n\nOpenSesame 3.1.7 *Jazzy James* est la septième version de maintenance de la série 3.1. Elle contient des corrections de bugs et des améliorations mineures, et devrait être une mise à niveau agréable et sûre pour tous ceux qui utilisent la série 3.1.\n\nSi vous mettez à niveau depuis OpenSesame 3.0 ou une version antérieure, veuillez consulter la liste des modifications importantes :\n\n- %link:important-changes-3%\n\n## Crédits\n\nMerci à :\n\n- Daniel Schreij (%-- github: {user: dschreij} --%) pour le paquet Mac OS, et ses contributions de code\n- Jarik den Hartog (%-- github: {user: JdenHartog} --%) pour ses contributions de code\n- %-- github: {user: juliencegarra} --% pour ses contributions de code\n\n## Corrections de bugs et améliorations\n\nopensesame :\n\n- Mis à jour pour la version 3.1.7\n- %-- github: { repo: \"smathot/opensesame\", issue: 495 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 509 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 511 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 513 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 514 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 515 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 516 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 517 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 519 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 520 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 521 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 524 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 525 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 526 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 528 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 529 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 530 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 531 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 534 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 535 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 536 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 538 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 539 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 540 } --%\n- %-- github: { repo: \"smathot/opensesame\", issue: 541 } --%\n\nqprogedit :\n\n- Mis à jour pour la version 4.0.11\n\ndatamatrix :\n\n- Mis à jour pour la version 0.4.15\n\nqdatamatrix :\n\n- Mis à jour pour la version 0.1.15\n\nqosf :\n\n- Mis à jour pour la version 1.2.2\n\nopensesame-extension-osf\n\n- Mis à jour pour la version 1.1.1\n\n## Paquets (Paquet Windows Python 2.7)\n\n### Informations détaillées sur les paquets"
  },
  "~~~ .yaml\nname: opensesame_3.1.7-py2.7-win32-1\nchannels:\n- cogsci\n- defaults\ndependencies:\n- python==2.7.12\n- anaconda-client=1.4.0=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.4=py27_0\n- bzip2=1.0.6=vc9_3\n- clyent=1.2.2=py27_0\n- arrow=0.7.0=py_0\n- humanize=0.5.1=py_0\n- oauthlib=1.0.3=py_0\n- psychopy=1.82.01=py27_0\n- pygame=1.9.2a0=py27_0\n- pyglet=1.2.4=py27_0\n- python-datamatrix=0.4.15=py_0 # updated in 3.1.7\n- python-fileinspector=1.0.2=py_0 # updated in 3.1.3\n- python-opensesame=3.1.7=py_0 # updated in 3.1.7\n- python-pseudorandom=0.2.2=py27_0\n- python-pygaze=0.6.0a21=py_0 # Updated in 3.1.3\n- python-qdatamatrix=0.1.15=py_0 # updated in 3.1.7\n- python-qnotifications=1.1.1=py_0 # updated in 3.1.3\n- python-qosf=1.2.2=py_0 # updated in 3.1.7\n- python-qprogedit=4.0.11=py_0 # updated in 3.1.7\n- qscintilla2=2.9.1=py27_vc9_0\n- requests-oauthlib=0.6.1=py_0\n- webcolors=1.5=py27_0\n- configparser=3.5.0b2=py27_1\n- decorator=4.0.10=py27_0\n- entrypoints=0.2.2=py27_0\n- freetype=2.5.5=vc9_1\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- ipykernel=4.3.1=py27_0\n- ipython=4.2.0=py27_0\n- ipython_genutils=0.1.0=py27_0\n- ipywidgets=4.1.1=py27_0\n- jinja2=2.8=py27_1\n- jpeg=8d=vc9_0\n- jsonschema=2.5.1=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=4.3.0=py27_0\n- jupyter_console=4.1.1=py27_0\n- jupyter_core=4.1.0=py27_0\n- libpng=1.6.22=vc9_0\n- libtiff=4.0.6=vc9_2\n- markdown=2.6.6=py27_0\n- markupsafe=0.23=py27_2\n- mistune=0.7.2=py27_0\n- mkl=11.3.3=1\n- nbconvert=4.2.0=py27_0\n- nbformat=4.0.1=py27_0\n- notebook=4.2.1=py27_0\n- numpy=1.11.1=py27_0\n- openssl=1.0.2h=vc9_0\n- path.py=8.2.1=py27_0\n- pickleshare=0.5=py27_0\n- pillow=3.2.0=py27_1\n- pip=8.1.2=py27_0\n- pyflakes=1.2.3=py27_0\n- pygments=2.1.3=py27_0\n- pyopengl=3.1.1a1=np111py27_0\n- pyopengl-accelerate=3.1.1a1=np111py27_0\n- pyqt=4.11.4=py27_6\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.12=0\n- python-dateutil=2.5.3=py27_0\n- pytz=2016.4=py27_0\n- pyyaml=3.11=py27_4\n- pyzmq=15.2.0=py27_0\n- qt=4.8.7=vc9_8\n- qtawesome=0.3.3=py27_0\n- qtconsole=4.2.1=py27_0\n- qtpy=1.0.2=py27_0\n- requests=2.10.0=py27_0\n- scipy=0.17.1=np111py27_1\n- setuptools=23.0.0=py27_0\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.16.9=py27_2\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.4.0.2=py27_1\n- tornado=4.3=py27_1\n- traitlets=4.2.1=py27_0\n- vs2008_runtime=9.00.30729.1=2\n- wheel=0.29.0=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.8=vc9_3\n- pip:\n  - cffi==1.7.0\n  - expyriment==0.8.0 # Upgrade manually to 0.8.1.opensesame2\n  - imageio==1.5\n  - mediadecoder==0.1.5\n  - moviepy==0.2.2.11  \n  - opensesame-extension-osf==1.1.1 # Updated in 3.1.7\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-windows-launcher==0.4.1\n  - pycparser==2.14\n  - python-bidi==0.4.0\n  - sounddevice==0.3.3\n  - tqdm==4.7.6\n  - pyaudio==0.2.9 # Added in 3.1.3\n  - openpyxl==2.4.0 # Added in 3.1.3\n  - fastnumbers==1.0.0 # Added in 3.1.5\n  - prettytable==0.7.2 # Added in 3.1.5\nprefix: opensesame_3.1.7-py2.7-win32-1\n~~~\n": {
    "fr": "~~~ .yaml\nname: opensesame_3.1.7-py2.7-win32-1\nchannels:\n- cogsci\n- defaults\ndependencies:\n- python==2.7.12\n- anaconda-client=1.4.0=py27_0\n- backports=1.0=py27_0\n- backports_abc=0.4=py27_0\n- bzip2=1.0.6=vc9_3\n- clyent=1.2.2=py27_0\n- flèche=0.7.0=py_0\n- humaniser=0.5.1=py_0\n- oauthlib=1.0.3=py_0\n- psychopy=1.82.01=py27_0\n- pygame=1.9.2a0=py27_0\n- pyglet=1.2.4=py27_0\n- python-datamatrix=0.4.15=py_0 # mis à jour dans 3.1.7\n- python-fileinspector=1.0.2=py_0 # mis à jour dans 3.1.3\n- python-opensesame=3.1.7=py_0 # mis à jour dans 3.1.7\n- python-pseudorandom=0.2.2=py27_0\n- python-pygaze=0.6.0a21=py_0 # Mis à jour dans 3.1.3\n- python-qdatamatrix=0.1.15=py_0 # mis à jour dans 3.1.7\n- python-qnotifications=1.1.1=py_0 # mis à jour dans 3.1.3\n- python-qosf=1.2.2=py_0 # mis à jour dans 3.1.7\n- python-qprogedit=4.0.11=py_0 # mis à jour dans 3.1.7\n- qscintilla2=2.9.1=py27_vc9_0\n- requests-oauthlib=0.6.1=py_0\n- webcolors=1.5=py27_0\n- configparser=3.5.0b2=py27_1\n- décorateur=4.0.10=py27_0\n- entrypoints=0.2.2=py27_0\n- freetype=2.5.5=vc9_1\n- functools32=3.2.3.2=py27_0\n- get_terminal_size=1.0.0=py27_0\n- ipykernel=4.3.1=py27_0\n- ipython=4.2.0=py27_0\n- ipython_genutils=0.1.0=py27_0\n- ipywidgets=4.1.1=py27_0\n- jinja2=2.8=py27_1\n- jpeg=8d=vc9_0\n- jsonschema=2.5.1=py27_0\n- jupyter=1.0.0=py27_3\n- jupyter_client=4.3.0=py27_0\n- jupyter_console=4.1.1=py27_0\n- jupyter_core=4.1.0=py27_0\n- libpng=1.6.22=vc9_0\n- libtiff=4.0.6=vc9_2\n- markdown=2.6.6=py27_0\n- markupsafe=0.23=py27_2\n- mistune=0.7.2=py27_0\n- mkl=11.3.3=1\n- nbconvert=4.2.0=py27_0\n- nbformat=4.0.1=py27_0\n- notebook=4.2.1=py27_0\n- numpy=1.11.1=py27_0\n- openssl=1.0.2h=vc9_0\n- path.py=8.2.1=py27_0\n- pickleshare=0.5=py27_0\n- pillow=3.2.0=py27_1\n- pip=8.1.2=py27_0\n- pyflakes=1.2.3=py27_0\n- pygments=2.1.3=py27_0\n- pyopengl=3.1.1a1=np111py27_0\n- pyopengl-accelerate=3.1.1a1=np111py27_0\n- pyqt=4.11.4=py27_6\n- pyreadline=2.1=py27_0\n- pyserial=2.7=py27_0\n- python=2.7.12=0\n- python-dateutil=2.5.3=py27_0\n- pytz=2016.4=py27_0\n- pyyaml=3.11=py27_4\n- pyzmq=15.2.0=py27_0\n- qt=4.8.7=vc9_8\n- qtawesome=0.3.3=py27_0\n- qtconsole=4.2.1=py27_0\n- qtpy=1.0.2=py27_0\n- requests=2.10.0=py27_0\n- scipy=0.17.1=np111py27_1\n- setuptools=23.0.0=py27_0\n- simplegeneric=0.8.1=py27_1\n- singledispatch=3.4.0.3=py27_0\n- sip=4.16.9=py27_2\n- six=1.10.0=py27_0\n- sqlite=3.13.0=vc9_1\n- ssl_match_hostname=3.4.0.2=py27_1\n- tornado=4.3=py27_1\n- traitlets=4.2.1=py27_0\n- vs2008_runtime=9.00.30729.1=2\n- wheel=0.29.0=py27_0\n- yaml=0.1.6=0\n- zlib=1.2.8=vc9_3\n- pip:\n  - cffi==1.7.0\n  - expyriment==0.8.0 # Mise à niveau manuelle vers 0.8.1.opensesame2\n  - imageio==1.5\n  - mediadecoder==0.1.5\n  - moviepy==0.2.2.11  \n  - opensesame-extension-osf==1.1.1 # Mis à jour dans 3.1.7\n  - opensesame-plugin-media-player-mpy==0.1.6\n  - opensesame-windows-launcher==0.4.1\n  - pycparser==2.14\n  - python-bidi==0.4.0\n  - sounddevice==0.3.3\n  - tqdm==4.7.6\n  - pyaudio==0.2.9 # Ajouté dans 3.1.3\n  - openpyxl==2.4.0 # Ajouté dans 3.1.3\n  - fastnumbers==1.0.0 # Ajouté dans 3.1.5\n  - prettytable==0.7.2 # Ajouté dans 3.1.5\nprefix: opensesame_3.1.7-py2.7-win32-1\n~~~"
  },
  "Release notes for 2.9.1": {
    "fr": "Notes de version pour 2.9.1"
  },
  "OpenSesame 2.9.1 is the first maintenance release in the 2.9 series. If you are upgrading from 2.8.3 or earlier, please also read the [2.9.0 release notes].\n\n## Credits\n\nThanks to Timo Lüke for updating the German translation.\n\n## Changelog\n\n### Bugs fixed\n\n- Fix resetting font size and family in sketchpad (#284)\n- Fix rounding issue in canvas._gabor() (#283)\n- Better detection of Exception messages (#285)\n- Fix a race condition when dropping an item on a loop or sequence\n- Fix broken context menu in sketchpad when running a translation (#287)\n- Correctly parse variables in video_player plugin (#288)\n- Use new sketchpad-element icons also in 32x32 size\n- Fixed a bug when reducing and canceling the number of cycles in a loop\n- Fixed display of font style in sketchpad widget\n- Include PyQt4 plugins in Windows build\n\n### Improvements\n\n- Application-wide keyboard shortcuts for tab switching\n- Add close current tab action\n- Improved focus behavior\n\n### Translation updates\n\n- Update German translation (de_DE)\n\n### Windows packaging\n\n- Update included libraries. See `modules()` output below.\n- Includes a snapshot of PyGaze (0.5.0~opensesame-3)\n- Includes a slightly patched version of PsychoPy 1.80.05 that addresses an important issue with keypress timestamps. (Unchanged from 2.8.2.)\n\n~~~\nOpenSesame 2.9.1\nPython 2.7.6 (default, Nov 10 2013, 19:24:18) [MSC v.1500 32 bit (Intel)]\nOpenCV is not available\nOpenCV2 2.4.9\nQProgedit 2.0.5\nExpyriment 0.7.0 (Revision 7a6b73d; Python 2.7.6)\nNumPy 1.8.1\nPIL is available (version is unknown)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.5.0~opensesame3\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.1\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.4.1\nSciPy 0.14.0\n~~~\n\n[2.9.0 release notes]: /notes/2.9.0/\n": {
    "fr": "OpenSesame 2.9.1 est la première version de maintenance de la série 2.9. Si vous effectuez une mise à jour depuis la version 2.8.3 ou antérieure, veuillez également lire les [notes de version 2.9.0].\n\n## Crédits\n\nMerci à Timo Lüke pour la mise à jour de la traduction allemande.\n\n## Journal des modifications\n\n### Bugs corrigés\n\n- Correction de la réinitialisation de la taille et de la famille de police dans sketchpad (#284)\n- Correction d'un problème d'arrondi dans canvas._gabor() (#283)\n- Meilleure détection des messages d'exception (#285)\n- Correction d'une condition de compétition lors du dépôt d'un élément sur une boucle ou une séquence\n- Correction du menu contextuel cassé dans sketchpad lors de l'exécution d'une traduction (#287)\n- Analyse correcte des variables dans le plugin video_player (#288)\n- Utilisation de nouvelles icônes d'éléments sketchpad également en taille 32x32\n- Correction d'un bug lors de la réduction et de l'annulation du nombre de cycles dans une boucle\n- Affichage corrigé du style de police dans le widget sketchpad\n- Inclure les plugins PyQt4 dans la compilation Windows\n\n### Améliorations\n\n- Raccourcis clavier globaux pour le changement d'onglet\n- Ajouter une action pour fermer l'onglet actuel\n- Amélioration du comportement de la mise au point\n\n### Mises à jour des traductions\n\n- Mise à jour de la traduction allemande (de_DE)\n\n### Packaging Windows\n\n- Mise à jour des bibliothèques incluses. Voir la sortie de `modules()` ci-dessous.\n- Inclut un instantané de PyGaze (0.5.0~opensesame-3)\n- Inclut une version légèrement modifiée de PsychoPy 1.80.05 qui aborde un problème important avec les horodatages des touches. (Inchangé depuis 2.8.2.)\n\n~~~\nOpenSesame 2.9.1\nPython 2.7.6 (default, Nov 10 2013, 19:24:18) [MSC v.1500 32 bit (Intel)]\nOpenCV n'est pas disponible\nOpenCV2 2.4.9\nQProgedit 2.0.5\nExpyriment 0.7.0 (Révision 7a6b73d ; Python 2.7.6)\nNumPy 1.8.1\nPIL est disponible (version inconnue)\nPsychoPy 1.80.05-opensesame-1\nPyAudio 0.2.8\nPyGame 1.9.1release\nPyGaze 0.5.0~opensesame3\nPyglet 1.1.4\nPyOpenGL 3.1.0\nPyQt 4.11.1\nPySerial 2.7\npython-bidi 0.3.4\npython-markdown 2.4.1\nSciPy 0.14.0\n~~~\n\n[notes de version 2.9.0]: /notes/2.9.0/"
  },
  "Release notes for 2.9.5": {
    "fr": "Notes de version pour 2.9.5"
  },
  "Creating an extension": {
    "fr": "Créer une extension"
  },
  "<notranslate>[TOC]</notranslate>\n\n\n## What is an OpenSesame extension?\n\n*Extensions* add arbitrary functionality to the OpenSesame user interface. For example, an extension can add a new entry to the main toolbar or the menubar. (To add functionality that you can use in experiments, you need a [plugin](%url:plugin%).)\n\n\n## Relevant files\n\nOne or more extensions are put together in an extension package, which is always a subpackage of `opensesame_extensions` (which is itself a so-called implicit namespace package, but that's a technical detail that is not very important). Let's say that your extension package is called `example`, and that it contains a single extension (there can be more) called `example_extension`. This would correspond to the following file-and-folder structure:\n\n```\nopensesame_extensions/\n    example/\n        __init__.py               # can be empty but must exist\n        example_extension/\n            __init__.py           # contains extension information\n            example_extension.py  # contains extension class\n```\n\n\n## Extension information\n\nExtension information is defined in the `__init__.py` of the extension module, so in our example this is `opensesesame_extensions/example/example_extension/__init__.py`.\n\n```python\n\"\"\"A docstring with a description of the extension\"\"\"\n\n# A standard icon name\n# - <https://specifications.freedesktop.org/icon-naming-spec/icon-naming-spec-latest.html>\nicon = 'applications-accessories'\n# The label and the tooltip are used to create the default action, which is\n# insert into the menu and/ or toolbar (or neither)\nlabel = \"Example extension\"\ntooltip = \"Example tooltip\"\nmenu = {\n    \"index\": -1,\n    \"separator_before\": True,\n    \"separator_after\": True,\n    \"submenu\": \"Example\"\n}\ntoolbar = {\n    \"index\": -1,\n    \"separator_before\": True,\n    \"separator_after\": True\n}\n# Settings are perstistently stored in the cfg object\nsettings = {\n    \"example_setting\": \"example value\"\n}\n```\n\nAn extension can appear in the menu or main toolbar of OpenSesame. This requires that you define several fields in `__init__.py` as shown above:\n\n- The `label` is the text that will appear in the menu.\n- The `icon` is a [freedesktop-compliant icon name][icon-spec] that specifies the icon that will appear in the menu and/ or toolbar.\n- The `index` gives the position of the extension in the menu/ toolbar, and works like a `list` index. That is, negative values are relative to the last entry, where -1 puts your extension at the end.\n\nTo have your extension respond to menu/ toolbar activation, implement the `activate()` method as shown below in the extension code below.\n\n\n## Writing the extension code\n\nThe main extension code is placed in `[extension_name].py`. This file generally contains only a single class named `[ExtensionName].py`, that is, a class with the CamelCase equivalent of the plugin name, which inherits `libqtopensesame.extensions.BaseExtension`. So a basic (non-functional) extension class looks like this:\n\n~~~ .python\nfrom libopensesame.py3compat import *\nfrom libopensesame.oslogging import oslogger\nfrom libqtopensesame.extensions import BaseExtension\n\n\nclass ExampleExtension(BaseExtension):\n    \"\"\"An example extension that lists several common events. The class name\n    should be the CamelCase version of the folder_name and file_name. So in\n    this case both the extension folder (which is a Python package) and the\n    .py file (which is a Python module) are called example_extension, whereas\n    the class is called ExampleExtension.\n    \"\"\"\n\n    def activate(self):\n        oslogger.debug('example_extension extension activated')\n\n    def event_save_experiment(self, path):\n        oslogger.debug(f'Event fired: save_experiment(path={path})')\n\n    # See example_extension source code for more event listeners\n~~~\n\n\n## Listening for events": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## Qu'est-ce qu'une extension OpenSesame ?\n\nLes *Extensions* ajoutent des fonctionnalités arbitraires à l'interface utilisateur d'OpenSesame. Par exemple, une extension peut ajouter une nouvelle entrée dans la barre d'outils principale ou dans la barre des menus. (Pour ajouter des fonctionnalités que vous pouvez utiliser dans des expériences, vous avez besoin d'un [plugin](%url:plugin%).)\n\n## Fichiers pertinents\n\nUne ou plusieurs extensions sont regroupées dans un paquet d'extension, qui est toujours un sous-paquet de `opensesame_extensions` (qui est en lui-même un paquet de noms de domaine implicite, mais c'est un détail technique qui n'est pas très important). Disons que votre paquet d'extension s'appelle `example`, et qu'il contient une seule extension (il peut y en avoir plus) appelée `example_extension`. Ceci correspondrait à la structure de fichiers et de dossiers suivante:\n\n```\nopensesame_extensions/\n    example/\n        __init__.py               # peut être vide mais doit exister\n        example_extension/\n            __init__.py           # contient des informations sur l'extension\n            example_extension.py  # contient la classe d'extension\n```\n\n## Informations sur l'extension\n\nLes informations sur l'extension sont définies dans le fichier `__init__.py` du module d'extension, donc dans notre exemple, il s'agit de `opensesesame_extensions/example/example_extension/__init__.py`.\n\n```python\n\"\"\"Une chaîne de caractères décrivant l'extension\"\"\"\n\n# Un nom d'icône standard\n# - <https://specifications.freedesktop.org/icon-naming-spec/icon-naming-spec-latest.html>\nicon = 'applications-accessories'\n# Le label et l'info-bulle sont utilisés pour créer l'action par défaut, qui est\n# insérée dans le menu et/ ou la barre d'outils (ou aucun des deux)\nlabel = \"Exemple d'extension\"\ntooltip = \"Exemple d'info-bulle\"\nmenu = {\n    \"index\": -1,\n    \"separator_before\": True,\n    \"separator_after\": True,\n    \"submenu\": \"Exemple\"\n}\ntoolbar = {\n    \"index\": -1,\n    \"separator_before\": True,\n    \"separator_after\": True\n}\n# Les paramètres sont stockés de manière persistante dans l'objet cfg\nsettings = {\n    \"exemple_setting\": \"valeur exemple\"\n}\n```\n\nUne extension peut apparaître dans le menu ou la barre d'outils principale d'OpenSesame. Cela nécessite de définir plusieurs champs dans `__init__.py` comme indiqué ci-dessus :\n\n- Le `label` est le texte qui apparaîtra dans le menu.\n- L'`icon` est un [nom d'icône conforme à freedesktop][icon-spec] qui spécifie l'icône qui apparaîtra dans le menu et/ ou la barre d'outils.\n- L'`index` donne la position de l'extension dans le menu/ barre d'outils, et fonctionne comme un index `list`. C'est-à-dire que les valeurs négatives sont relatives à la dernière entrée, où -1 place votre extension à la fin.\n\nPour que votre extension réponde à l'activation du menu/ barre d'outils, implémentez la méthode `activate()` comme indiqué ci-dessous dans le code de l'extension ci-dessous.\n\n## Écrire le code de l'extension\n\nLe code principal de l'extension est placé dans `[extension_name].py`. Ce fichier contient généralement une seule classe nommée `[ExtensionName].py`, c'est-à-dire une classe avec l'équivalent CamelCase du nom du plugin, qui hérite de `libqtopensesame.extensions.BaseExtension`. Ainsi, une classe d'extension de base (non fonctionnelle) ressemble à ceci:\n\n~~~ .python\nfrom libopensesame.py3compat import *\nfrom libopensesame.oslogging import oslogger\nfrom libqtopensesame.extensions import BaseExtension\n\nclass ExampleExtension(BaseExtension):\n    \"\"\"Un exemple d'extension qui liste plusieurs événements communs. Le nom de la classe\n    doit être la version CamelCase du folder_name et du file_name. Donc, dans\n    ce cas, le dossier d'extension (qui est un paquet Python) et le\n    fichier .py (qui est un module Python) sont appelés example_extension, alors que\n    la classe est appelée ExampleExtension.\n    \"\"\"\n\n    def activate(self):\n        oslogger.debug(\"l'extension example_extension a été activée\")\n\n    def event_save_experiment(self, path):\n        oslogger.debug(f\"Événement déclenché: save_experiment(path={path})\")\n\n    # Voir le code source de example_extension pour plus d'écouteurs d'événements\n~~~\n\n## Écoute des événements"
  },
  "OpenSesame fires events whenever something important happens. For example, the `save_experiment` event is fired when an experiment is saved. To have your extension listen to an event, simply implement a method with the name `event_[event name]` as shown above.\n\nNote that some events take keyword arguments, such as `path` in the case of `save_experiment`. The keyword signature of your function must match the expected keyword signature. See the Event overview below for a full list of events and expected keywords.\n\n\n## Building a package and uploading to pypi\n\nBuilding an extensin package and uploading it to `pypi` works the same way as it does for plugins:\n\n- %link:plugin%\n- <https://github.com/open-cogsci/opensesame-extension-example>\n\n## Examples\n\nFor a working example, see:\n\n- <https://github.com/open-cogsci/opensesame-extension-example>\n\nOther examples can be found in the `opensesame_extensions` folder of the OpenSesame source code:\n\n- <https://github.com/open-cogsci/OpenSesame/tree/milgram/opensesame_extensions/core>\n\n[example]: https://github.com/open-cogsci/OpenSesame/tree/master/extensions/example\n[icon-spec]: http://standards.freedesktop.org/icon-naming-spec/icon-naming-spec-latest.html\n\n\n## Event overview\n\nThis overview lists all events that are fired somewhere in the code, and that your extenstion can therefore listen to by implementing the corresponding `event_[eventname]()` functions.\n\n<notranslate> include: include/events.md --%\n": {
    "fr": "OpenSesame déclenche des événements chaque fois que quelque chose d'important se produit. Par exemple, l'événement `save_experiment` est déclenché lorsqu'une expérience est enregistrée. Pour que votre extension écoute un événement, il suffit d'implémenter une méthode avec le nom `event_[nom de l'événement]` comme indiqué ci-dessus.\n\nNotez que certains événements prennent des arguments de mots-clés, comme `path` dans le cas de `save_experiment`. La signature de mots-clés de votre fonction doit correspondre à la signature de mots-clés attendue. Voir la vue d'ensemble des événements ci-dessous pour une liste complète des événements et des mots-clés attendus.\n\n## Créer un package et le télécharger sur pypi\n\nCréer un package d'extension et le télécharger sur `pypi` fonctionne de la même manière que pour les plugins :\n\n- %link:plugin%\n- <https://github.com/open-cogsci/opensesame-extension-example>\n\n## Exemples\n\nPour un exemple fonctionnel, voir :\n\n- <https://github.com/open-cogsci/opensesame-extension-example>\n\nD'autres exemples peuvent être trouvés dans le dossier `opensesame_extensions` du code source d'OpenSesame :\n\n- <https://github.com/open-cogsci/OpenSesame/tree/milgram/opensesame_extensions/core>\n\n[example]: https://github.com/open-cogsci/OpenSesame/tree/master/extensions/example\n[icon-spec]: http://standards.freedesktop.org/icon-naming-spec/icon-naming-spec-latest.html\n\n## Aperçu des événements\n\nCet aperçu répertorie tous les événements qui sont déclenchés quelque part dans le code et que votre extension peut donc écouter en implémentant les fonctions `event_[nomdelévénement]()` correspondantes.\n\n<notranslate> include: include/events.md --%"
  },
  "Installing packages, plugins, and extensions": {
    "fr": "Installer des paquets, plugins et extensions"
  },
  "\nThis page has moved to:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>\n": {
    "fr": "Cette page a été déplacée vers :\n\n- <https://rapunzel.cogsci.nl/manual/environment/>"
  },
  "Logging and reading data files": {
    "fr": "Enregistrement et lecture de fichiers de données"
  },
  "Always triple check whether your data has been logged correctly before running your experiment!\n{: .page-notification}\n\n<notranslate>[TOC]</notranslate>\n\n\n## Using the logger item\n\nOpenSesame will not log your data automatically. Instead, you need to insert a LOGGER item, typically at the end of your trial sequence.\n\n<notranslate>\nfigure:\n id: FigLogger\n source: logger.png\n caption: |\n  The LOGGER item.\n</notranslate>\n\nThe simplest way to use the LOGGER is by leaving the option 'Automatically log all variables' enabled. That way, all variables that OpenSesame knows about are written the log file, except for those that are explicitly excluded (see below).\n\nYou can explicitly *include* which variables you want to log. The main reason for doing so is when you find that some variables are missing (because OpenSesame did not automatically detect them), or if you have disabled the option 'Automatically log all variables', \n\nYou can also explicitly exclude certain variables from the log file. The main reason for doing so is to keep the log files clean by excluding variables that are generally not useful.\n\nIn general, you should create only one logger item, and reuse that LOGGER at different locations in your experiment if necessary (i.e. use linked copies of the same LOGGER item). If you create multiple LOGGERs (rather than using a single LOGGER multiple times), they will all write to the same log file, and the result will be a mess!\n\n## Using Python inline script\n\nYou can write to the log file using the `log` object:\n\n~~~ .python\nlog.write('This will be written to the log file!')\n~~~\n\nFor more information, see:\n\n- %link:log%\n\nYou should generally not write to the log file directly and use a LOGGER item at the same time; doing so will result in messy log files.\n\n## Format of the data files\n\nIf you have used the standard LOGGER item, data files are in the following format format (simply standard csv):\n\n- plain-text\n- comma-separated\n- double-quoted (literal double-quotes are escaped with backward slashes)\n- unix-style line endings\n- UTF-8 encoded\n- column names on the first row\n\n## Reading and processing data files\n\n### In Python with pandas or DataMatrix\n\nIn Python, you can use [pandas](http://pandas.pydata.org/) to read csv files.\n\n```python\nimport pandas\ndf = pandas.read_csv('subject-1.csv')\nprint(df)\n```\n\nOr [DataMatrix](https://datamatrix.cogsci.nl/):\n\n```python\nfrom datamatrix import io\ndm = io.readtxt('subject-1.csv')\nprint(dm)\n```\n\n### In R\n\nIn R, you can simply use the `read.csv()` function to read a single data file.\n\n~~~ .R\ndf = read.csv('subject-1.csv', encoding = 'UTF-8')\nhead(df)\n~~~\n\nIn addition, you can use the `read_opensesame()` function from the [readbulk](https://github.com/pascalkieslich/readbulk) package to easily read and merge multiple data files into one large data frame. The package is available on CRAN and can be installed via `install.packages('readbulk')`.\n\n~~~ .R\n# Read and merge all data files stored in the folder 'raw_data'\nlibrary(readbulk)\ndf = read_opensesame('raw_data')\n~~~\n\n### In JASP\n\n[JASP](http://jasp-stats.org/), an open-source statistics package, opens csv files straight away.\n\n### In LibreOffice Calc\n\nIf you open a csv file in LibreOffice Calc, you have to indicate the exact data format, as indicated in %FigLibreOffice. (The default settings are often correct.)\n\n<notranslate>\nfigure:\n source: libreoffice.png\n id: FigLibreOffice\n</notranslate>\n\n### In Microsoft Excel\n\nIn Microsoft Excel, you need to use the Text Import Wizard.\n\n### Merging multiple data files into one large file\n\nFor some purposes, such as using pivot tables, it may be convenient to merge all data files into one large file. With Python DataMatrix, you can do this with the following script:\n\n```python\nimport os\nfrom datamatrix import DataMatrix, io, operations as ops": {
    "fr": "Vérifiez toujours trois fois si vos données ont été correctement enregistrées avant d'exécuter votre expérience !\n{: .page-notification}\n\n<notranslate>[TOC]</notranslate>\n\n\n## Utilisation de l'élément LOGGER\n\nOpenSesame ne consignera pas automatiquement les données. Vous devez plutôt insérer un élément LOGGER, généralement à la fin de votre séquence d'essai.\n\n<notranslate>\nfigure:\n id: FigLogger\n source: logger.png\n caption: |\n  L'élément LOGGER.\n</notranslate>\n\nLa manière la plus simple d'utiliser LOGGER est de laisser l'option \"Enregistrer automatiquement toutes les variables\" activée. Ainsi, toutes les variables que OpenSesame connaît seront écrites dans le fichier journal, à l'exception de celles qui sont explicitement exclues (voir ci-dessous).\n\nVous pouvez explicitement *inclure* les variables que vous souhaitez consigner. La raison principale de le faire est lorsque certaines variables sont manquantes (parce que OpenSesame ne les a pas détectées automatiquement) ou si vous désactivez l'option \"Enregistrer automatiquement toutes les variables\".\n\nVous pouvez également explicitement exclure certaines variables du fichier journal. La raison principale de le faire est de garder les fichiers journaux propres en excluant les variables généralement non utiles.\n\nEn général, vous devez créer un seul élément LOGGER et réutiliser LOGGER à différents endroits de votre expérience si nécessaire (c'est-à-dire utiliser des copies liées du même élément LOGGER). Si vous créez plusieurs LOGGER (plutôt que d'utiliser un seul LOGGER plusieurs fois), ils écriront tous dans le même fichier journal, et le résultat sera un désordre!\n\n## Utilisation de script Python inline\n\nVous pouvez écrire dans le fichier journal en utilisant l'objet `log` :\n\n~~~ .python\nlog.write('Ceci sera écrit dans le fichier journal!')\n~~~\n\nPour plus d'informations, voir :\n\n- %link:log%\n\nEn règle générale, vous ne devez pas écrire directement dans le fichier journal et utiliser un élément LOGGER en même temps ; cela entraînera des fichiers journaux désordonnés.\n\n## Format des fichiers de données\n\nSi vous avez utilisé l'élément LOGGER standard, les fichiers de données sont au format suivant (simplement csv standard) :\n\n- texte brut\n- séparés par des virgules\n- entre guillemets doubles (les guillemets doubles littéraux sont échappés avec des barres obliques inverses)\n- fins de ligne de style Unix\n- encodé en UTF-8\n- noms de colonnes sur la première ligne\n\n## Lecture et traitement des fichiers de données\n\n### En Python avec pandas ou DataMatrix\n\nEn Python, vous pouvez utiliser [pandas](http://pandas.pydata.org/) pour lire les fichiers csv.\n\n```python\nimport pandas\ndf = pandas.read_csv('sujet-1.csv')\nprint(df)\n```\n\nOu [DataMatrix](https://datamatrix.cogsci.nl/):\n\n```python\nfrom datamatrix import io\ndm = io.readtxt('sujet-1.csv')\nprint(dm)\n```\n\n### En R\n\nEn R, vous pouvez simplement utiliser la fonction `read.csv()` pour lire un fichier de données unique.\n\n~~~ .R\ndf = read.csv('sujet-1.csv', encoding = 'UTF-8')\nhead(df)\n~~~\n\nDe plus, vous pouvez utiliser la fonction `read_opensesame()` du package [readbulk](https://github.com/pascalkieslich/readbulk) pour facilement lire et fusionner plusieurs fichiers de données en un seul grand dataframe. Le package est disponible sur CRAN et peut être installé via `install.packages('readbulk')`.\n\n~~~ .R\n# Lire et fusionner tous les fichiers de données stockés dans le dossier 'raw_data'\nlibrary(readbulk)\ndf = read_opensesame('raw_data')\n~~~\n\n### Dans JASP\n\n[JASP](http://jasp-stats.org/), un logiciel de statistiques open source, ouvre directement les fichiers csv.\n\n### Dans LibreOffice Calc\n\nSi vous ouvrez un fichier csv dans LibreOffice Calc, vous devez indiquer le format de données exact, comme indiqué dans %FigLibreOffice. (Les paramètres par défaut sont souvent corrects.)\n\n<notranslate>\nfigure:\n source: libreoffice.png\n id: FigLibreOffice\n</notranslate>\n\n### Dans Microsoft Excel\n\nDans Microsoft Excel, vous devez utiliser l'Assistant d'importation de texte.\n\n### Fusion de plusieurs fichiers de données en un seul grand fichier\n\nPour certaines utilisations, comme l'utilisation de tables croisées dynamiques, il peut être pratique de fusionner tous les fichiers de données en un seul grand fichier. Avec Python DataMatrix, vous pouvez le faire avec le script suivant :\n\n```python\nimport os\nfrom datamatrix import DataMatrix, io, operations as ops"
  },
  "# Change this to the folder that contains the .csv files\nSRC_FOLDER = 'student_data'\n# Change this to a list of column names that you want to keep\nCOLUMNS_TO_KEEP = [\n    'RT_search',\n    'load',\n    'memory_resp'\n]\n\n\ndm = DataMatrix()\nfor basename in os.listdir(SRC_FOLDER):\n    path = os.path.join(SRC_FOLDER, basename)\n    print('Reading {}'.format(path))\n    dm <<= ops.keep_only(io.readtxt(path), *COLUMNS_TO_KEEP)\nio.writetxt(dm, 'merged-data.csv')\n```\n\n\n## Logging in OSWeb\n\nWhen you run an experiment in a browser with OSWeb, logging works differently from when you run an experiment on the desktop.\n\nSpecifically, when you launch an OSWeb experiment directly from within OpenSesame, the log file is downloaded at the end of the experiment. This log file is in `.json` format. When you launch an OSWeb experiment from JATOS, there is no log file as such, but rather all data is sent to JATOS from where it can be downloaded.\n\nSee also:\n\n- %link:manual/osweb/workflow%\n\n\n\n[libreoffice]: http://www.libreoffice.org/\n[openoffice]: http://www.openoffice.org/\n[gnumeric]: http://projects.gnome.org/gnumeric/\n[log-func]: /python/inline-script/#inline_script.log\n[codecs]: http://docs.python.org/2/library/codecs.html\n[ppa]: https://launchpad.net/~smathot/+archive/cogscinl/\n": {
    "fr": "# Changez ceci pour le dossier contenant les fichiers .csv\nSRC_FOLDER = 'student_data'\n# Changez ceci en une liste de noms de colonnes que vous souhaitez conserver\nCOLUMNS_TO_KEEP = [\n    'RT_search',\n    'load',\n    'memory_resp'\n]\n\n\ndm = DataMatrix()\nfor basename in os.listdir(SRC_FOLDER):\n    path = os.path.join(SRC_FOLDER, basename)\n    print('Lecture de {}'.format(path))\n    dm <<= ops.keep_only(io.readtxt(path), *COLUMNS_TO_KEEP)\nio.writetxt(dm, 'donnees-fusionnees.csv')\n```\n\n\n## Enregistrement dans OSWeb\n\nLorsque vous exécutez une expérience dans un navigateur avec OSWeb, l'enregistrement fonctionne différemment de lorsque vous exécutez une expérience sur le bureau.\n\nPlus précisément, lorsque vous lancez une expérience OSWeb directement à partir de OpenSesame, le fichier journal est téléchargé à la fin de l'expérience. Ce fichier journal est au format `.json`. Lorsque vous lancez une expérience OSWeb à partir de JATOS, il n'y a pas de fichier journal à proprement parler, mais plutôt toutes les données sont envoyées à JATOS à partir duquel elles peuvent être téléchargées.\n\nVoir aussi :\n\n- %link:manuel/osweb/workflow%\n\n\n\n[libreoffice]: http://www.libreoffice.org/\n[openoffice]: http://www.openoffice.org/\n[gnumeric]: http://projects.gnome.org/gnumeric/\n[log-func]: /python/inline-script/#inline_script.log\n[codecs]: http://docs.python.org/2/library/codecs.html\n[ppa]: https://launchpad.net/~smathot/+archive/cogscinl/"
  },
  "The prepare-run strategy": {
    "fr": "La stratégie de préparation-exécution"
  },
  "<notranslate>[TOC]</notranslate>\n\n## About\n\nExperiments typically consist of short intervals ('trials') during which participants perceive stimuli and perform a task. Timing should be controlled during a trial, but some unpredictable variation in the duration of the interval between trials is acceptable. Therefore, a good strategy is to perform time-consuming tasks before a trial, and to keep the operations that are performed during a trial to a minimum.\n\nOpenSesame does this by calling each element from a SEQUENCE item twice. This is the *prepare-run strategy*:\n\n- During the Prepare phase, items are given the opportunity to prepare. For example, a SYNTH generates a sound (but doesn't play it); and a SKETCHPAD draws a canvas (but doesn't show it).\n- During the Run phase, items do as a little as possible. For example, a SYNTH plays back a previously prepared sound; and a SKETCHPAD shows a previously prepared canvas.\n\nThis reduces the risk of timing glitches. The prepare-run strategy is implemented at the level of SEQUENCE items, which typically contains the time-critical parts of an experiment. This means that before a SEQUENCE is started, there is some unpredictable temporal jitter.\n\n## Item-specific notes\n\n### loop items\n\nA LOOP item is not prepared in advance. It is important to take this into account when using a LOOP to implement time-critical parts. For example, you may be tempted to implement an RSVP stream using a LOOP item as follows:\n\n~~~text\nrsvp_loop item (4 cycles)\n- stimulus_item\n~~~\n\nIn this construction, *stimulus_item* will be prepared and run four times in alternation, like so:\n\n~~~text\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\n~~~\n\nTherefore, you need to verify that the preparation of *stimulus_item* does not cause any timing glitches.\n\n### sequence items\n\nAll items that are part of a SEQUENCE are prepared in advance. Therefore, the following construction ...\n\n~~~text\ntrial_sequence\n- fixation_sketchpad\n- target_sketchpad\n- keyboard_response\n- logger\n~~~\n\n... will be executed as follows ...\n\n~~~text\nprepare fixation_sketchpad\nprepare target_sketchpad\nprepare keyboard_response\nprepare logger\nrun fixation_sketchpad\nrun target_sketchpad\nrun keyboard_response\nrun logger\n~~~\n\n### sketchpad and feedback items\n\nSKETCHPAD and FEEDBACK items differ in when they are prepared. For SKETCHPADs preparation occurs during the Prepare phase; for FEEDBACK items, preparation occurs only during the Run phase.\n\nFor more information, see:\n\n- %link:manual/stimuli/visual%\n\n### synth and sampler items\n\nFor SYNTH and SAMPLER items, the sound is generated and preloaded during the Prepare phase.\n\n### inline_script items\n\nIn an INLINE_SCRIPT item, you can choose how you want to implement the run and prepare strategy. In general, it is good practice to adhere to the following guidelines:\n\n- Time-consuming, preparatory functionality goes in the Prepare phase. For example, creating canvas objects, and generating sounds.\n- A minimum amount of code is put in the run phase. For example, only showing a previously prepared canvas.\n\n### Other items and plugins\n\nIn general, items should follow the principle of performing as much as possible time-consuming preparation during the Prepare phase, and minimizing the Run phase. However, every plugin is implemented differently. If you are unsure about a specific case, please post a query on the forum.\n\n## Conditional expressions (run if, show if, break if, etc)\n\nIn SEQUENCE items, the 'Run if' condition is evaluated at the last moment, during the run phase. Therefore, you can use a condition like `correct == 0` which depends on the results of a KEYBOARD_RESPONSE item which has been called just before. It is important to take into account that the 'Run if' expression applies *only* to the run phase of an item—The prepare phase is *always* executed.": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos\n\nLes expériences sont généralement composées de courts intervalles ('trials') durant lesquels les participants perçoivent des stimuli et effectuent une tâche. Le temps doit être contrôlé pendant un trial, mais une certaine variation imprévisible de la durée de l'intervalle entre les trials est acceptable. Il est donc judicieux d'effectuer des tâches chronophages avant un trial et de réduire au minimum les opérations effectuées pendant un trial.\n\nOpenSesame fait cela en appelant chaque élément d'un élément SEQUENCE deux fois. Il s'agit de la *stratégie de préparation-exécution* :\n\n- Pendant la phase de préparation, les éléments ont l'opportunité de se préparer. Par exemple, un SYNTH génère un son (mais ne le joue pas) ; et un SKETCHPAD dessine un canevas (mais ne l'affiche pas).\n- Pendant la phase d'exécution, les éléments font le moins possible. Par exemple, un SYNTH lit un son préparé précédemment ; et un SKETCHPAD montre un canevas préparé précédemment.\n\nCela réduit le risque de problèmes de temporisation. La stratégie de préparation-exécution est mise en œuvre au niveau des éléments SEQUENCE, qui contiennent généralement les parties critiques en termes de temps d'une expérience. Cela signifie qu'avant qu'une SEQUENCE ne démarre, il y a une certaine gigue temporelle imprévisible.\n\n## Notes spécifiques aux éléments\n\n### éléments loop\n\nUn élément LOOP n'est pas préparé à l'avance. Il est important de prendre cela en compte lors de l'utilisation d'un LOOP pour mettre en œuvre des parties temporellement critiques. Par exemple, vous pouvez être tenté d'implémenter un flux RSVP à l'aide d'un élément LOOP comme suit :\n\n~~~text\nrsvp_loop item (4 cycles)\n- stimulus_item\n~~~\n\nDans cette construction, *stimulus_item* sera préparé et exécuté quatre fois en alternance, comme ceci :\n\n~~~text\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\n~~~\n\nIl est donc nécessaire de vérifier que la préparation de *stimulus_item* ne provoque pas de problèmes de temporisation.\n\n### éléments sequence\n\nTous les éléments faisant partie d'une SEQUENCE sont préparés à l'avance. Par conséquent, la construction suivante ...\n\n~~~text\ntrial_sequence\n- fixation_sketchpad\n- target_sketchpad\n- keyboard_response\n- logger\n~~~\n\n... sera exécutée comme suit ...\n\n~~~text\nprepare fixation_sketchpad\nprepare target_sketchpad\nprepare keyboard_response\nprepare logger\nrun fixation_sketchpad\nrun target_sketchpad\nrun keyboard_response\nrun logger\n~~~\n\n### éléments sketchpad et feedback\n\nLes éléments SKETCHPAD et FEEDBACK diffèrent dans leur préparation. Pour les SKETCHPAD, la préparation se fait lors de la phase de préparation ; pour les éléments FEEDBACK, la préparation ne se fait que lors de la phase d'exécution.\n\nPour plus d'informations, voir :\n\n- %link:manual/stimuli/visual%\n\n### éléments synth et sampler\n\nPour les éléments SYNTH et SAMPLER, le son est généré et préchargé pendant la phase de préparation.\n\n### éléments inline_script\n\nDans un élément INLINE_SCRIPT, vous pouvez choisir comment vous souhaitez implémenter la stratégie de préparation et d'exécution. En général, il est recommandé de suivre les directives suivantes :\n\n- Les fonctionnalités de préparation chronophages sont insérées dans la phase de préparation. Par exemple, créer des objets canevas et générer des sons.\n- Un minimum de code est placé dans la phase d'exécution. Par exemple, afficher uniquement un canevas préparé précédemment.\n\n### Autres éléments et plugins\n\nEn général, les éléments doivent suivre le principe visant à effectuer autant que possible une préparation chronophage lors de la phase de préparation et à minimiser la phase d'exécution. Cependant, chaque plugin est implémenté différemment. Si vous avez des doutes sur un cas spécifique, n'hésitez pas à poser une question sur le forum.\n\n## Expressions conditionnelles (run if, show if, break if, etc)\n\nDans les éléments SEQUENCE, la condition 'Run if' est évaluée au dernier moment, pendant la phase d'exécution. Ainsi, vous pouvez utiliser une condition comme `correct == 0`, qui dépend des résultats d'un élément KEYBOARD_RESPONSE qui a été appelé juste avant. Il est important de prendre en compte que l'expression 'Run if' s'applique *uniquement* à la phase d'exécution d'un élément - La phase de préparation est *toujours* exécutée."
  },
  "In COROUTINES items, the 'Run if' condition is evaluated during the Prepare phase. Therefore, the conditions cannot depend on events that occur during the execution of the COROUTINES.\n\nIn SKETCHPAD items, the 'Show if' condition is evaluated during the Prepare phase, when the canvas is constructed. In FEEDBACK items, the 'Show if' condition is evaluated during the Run phase (because the canvas is only constructed in the Run phase).\n": {
    "fr": "Dans les éléments COROUTINES, la condition 'Exécuter si' est évaluée pendant la phase de Préparation. Par conséquent, les conditions ne peuvent pas dépendre des événements qui se produisent pendant l'exécution des COROUTINES.\n\nDans les éléments SKETCHPAD, la condition 'Afficher si' est évaluée pendant la phase de Préparation, lorsque le canevas est construit. Dans les éléments FEEDBACK, la condition 'Afficher si' est évaluée pendant la phase d'Exécution (car le canevas n'est construit que durant la phase d'Exécution)."
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About runners\n\nThere are several technically different ways in which you can execute your experiment. Each of these corresponds to a *runner*. You can select a runner under Menu → Tools → Preferences → Runner.\n\nUnless you have a reason not to, you should use the *multiprocess* runner. However, if OpenSesame sometimes crashes, you can try whether selecting a different runner resolves this.\n\n\n## Available runners\n\n### Multiprocess\n\nThe *multiprocess* runner executes your experiment in a different process. The benefit of this approach is that your experiment can crash without bringing the user interface down with it. Another advantage of the *multiprocess* runner is that it allows the variable inspector to show your experimental variables while the experiment is running.\n\n### Inprocess\n\nThe *inprocess* runner executes the experiment in the same process as the user interface. The benefit of this approach is its simplicity. The downside is that the user interface may crash if the experiment crashes, and vice versa.\n\n### External\n\nThe *external* runner executes the experiment by launching opensesamerun as a separate application. The benefit of this approach is that your experiment can crash without bringing the user interface down with it.\n": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos des runners\n\nIl existe plusieurs façons techniquement différentes d'exécuter votre expérience. Chacune d'elles correspond à un *runner*. Vous pouvez sélectionner un runner dans Menu → Outils → Préférences → Runner.\n\nSauf si vous avez une raison de ne pas le faire, vous devriez utiliser le runner *multiprocess*. Cependant, si OpenSesame se bloque parfois, vous pouvez essayer de voir si la sélection d'un autre runner résout ce problème.\n\n## Runners disponibles\n\n### Multiprocess\n\nLe runner *multiprocess* exécute votre expérience dans un processus différent. Le principal avantage de cette méthode est que votre expérience peut se bloquer sans entraîner la fermeture de l'interface utilisateur. Un autre avantage du runner *multiprocess* est qu'il permet à l'inspecteur de variables d'afficher vos variables expérimentales pendant l'exécution de l'expérience.\n\n### Inprocess\n\nLe runner *inprocess* exécute l'expérience dans le même processus que l'interface utilisateur. L'avantage de cette méthode est sa simplicité. L'inconvénient est que l'interface utilisateur peut se bloquer si l'expérience se bloque, et vice versa.\n\n### Externe\n\nLe runner *externe* exécute l'expérience en lançant opensesamerun en tant qu'application distincte. Le principal avantage de cette méthode est que votre expérience peut se bloquer sans entraîner la fermeture de l'interface utilisateur."
  },
  "OpenSesameRun (no GUI)": {
    "fr": "OpenSesameRun (sans interface graphique)"
  },
  "## About\n\n`opensesamerun` is a simple tool that allows you to execute OpenSesame experiments with a minimal GUI, or directly, by specifying all necessary options via the command line. A minimal GUI will automatically appear if not all command line options have been specified, notably the experiment file, the subject number, and the log file.\n\n~~~\nUsage: opensesamerun [experiment] [options]\n\nOptions:\n  --version             show program's version number and exit\n  -h, --help            show this help message and exit\n\n  Subject and log file options:\n    -s SUBJECT, --subject=SUBJECT\n                        Subject number\n    -l LOGFILE, --logfile=LOGFILE\n                        Logfile\n\n  Display options:\n    -f, --fullscreen    Run fullscreen\n    -c, --custom_resolution\n                        Do not use the display resolution specified in the\n                        experiment file\n    -w WIDTH, --width=WIDTH\n                        Display width\n    -e HEIGHT, --height=HEIGHT\n                        Display height\n\n  Miscellaneous options:\n    -d, --debug         Print lots of debugging messages to the standard\n                        output\n    --stack             Print stack information\n\n  Miscellaneous options:\n    --pylink            Load PyLink before PyGame (necessary for using the\n                        Eyelink plug-ins in non-dummy mode)\n~~~\n\n## Example\n\nLet's say that you want to run the gaze cuing example experiment, for subject #1, and save the log file in your Documents folder (this example assumes Linux, but it works analogously on other platforms):\n\n~~~\nopensesamerun /usr/share/opensesame/examples/gaze_cuing.opensesame.tar.gz -s 1 -l /home/sebastiaan/Documents/subject1.tsv -f \n~~~\n\n\n## Alternative `libopensesame`\n\nYou can also start experiments without using the GUI through the `libopensesame` Python module:\n\n- %link:manual/python/nogui%\n": {
    "fr": "## À propos\n\n`opensesamerun` est un outil simple qui vous permet d'exécuter des expériences OpenSesame avec une interface graphique minimale, ou directement, en spécifiant toutes les options nécessaires via la ligne de commande. Une interface graphique minimale apparaîtra automatiquement si toutes les options de ligne de commande n'ont pas été spécifiées, notamment le fichier d'expérience, le numéro de sujet et le fichier journal.\n\n~~~\nUtilisation : opensesamerun [expérience] [options]\n\nOptions :\n  --version             afficher le numéro de version du programme et quitter\n  -h, --help            afficher ce message d'aide et quitter\n\n  Options de sujet et de fichier journal :\n    -s SUJET, --subject=SUJET\n                        Numéro de sujet\n    -l LOGFILE, --logfile=LOGFILE\n                        Fichier journal\n\n  Options d'affichage :\n    -f, --fullscreen    Exécuter en plein écran\n    -c, --custom_resolution\n                        Ne pas utiliser la résolution d'affichage spécifiée dans le\n                        fichier d'expérience\n    -w WIDTH, --width=WIDTH\n                        Largeur d'affichage\n    -e HEIGHT, --height=HEIGHT\n                        Hauteur d'affichage\n\n  Options diverses :\n    -d, --debug         Imprimer beaucoup de messages de débogage sur la sortie standard\n                        output\n    --stack             Imprimer des informations sur la pile\n\n  Options diverses :\n    --pylink            Charger PyLink avant PyGame (nécessaire pour utiliser le\n                        plug-ins Eyelink en mode non fictif)\n~~~\n\n## Exemple\n\nDisons que vous souhaitez exécuter l'expérience d'exemple de guidage du regard, pour le sujet n°1, et enregistrer le fichier journal dans votre dossier Documents (cet exemple suppose Linux, mais cela fonctionne de manière analogue sur d'autres plates-formes) :\n\n~~~\nopensesamerun /usr/share/opensesame/examples/gaze_cuing.opensesame.tar.gz -s 1 -l /home/sebastiaan/Documents/sujet1.tsv -f \n~~~\n\n\n## Alternative `libopensesame`\n\nVous pouvez également démarrer des expériences sans utiliser l'interface graphique grâce au module Python `libopensesame` :\n\n- %link:manuel/python/nogui%"
  },
  "Parallel port (EEG triggers)": {
    "fr": "Port parallèle (déclencheurs EEG)"
  },
  "In EEG/ ERP studies it is common to send triggers to mark the timestamp for significant events (e.g., the onset of a trial, presentation of a particular stimulus, etc.). Triggers are typically bytes that are sent via the parallel port to the EEG apparatus.\n\n<notranslate>[TOC]</notranslate>\n\n## Using the `parallel_port_trigger` plugin\n\nParallel_port_trigger is a third-party plugin, but has been reviewed by the OpenSesame team.\n{: .page-notification}\n\nTriggers can be sent with the `parallel_port_trigger` plugin which works under Linux and Windows.\n\nThe plugin has three input boxes:\n\n- The value ranges between 0-255 and specifies the trigger byte.\n- The duration (in ms) is the time that the trigger is on. Unless a 0 ms duration was specified, the trigger will be reset to 0 after this interval.\n- The port address has to be specified manually. This setting applies only to Windows and is ignored under Linux.\n\nYou can download the plugin from here:\n\n- <https://github.com/dev-jam/opensesame_plugin_parallel-port-trigger>\n\n<notranslate>\nfigure:\n id: FigScreenshot\n source: plugin-screenshot.png\n caption: |\n  A screenshot of the `parallel_port_trigger` plugin.\n</notranslate>\n\n## Using `dportio.dll` in a Python inline Script (Windows only)\n\nInstead of using the `parallel_port_trigger` plugin, it is also possible to send triggers with `dlportio.dll` through a Python inline script. This approach is Windows only. To do so, first add an INLINE_SCRIPT to the start of the experiment with the following code in the prepare phase:\n\n~~~ .python\ntry:\n\tfrom ctypes import windll\n\tglobal io\n\tio = windll.dlportio # requires dlportio.dll !!!\nexcept:\n\tprint('The parallel port couldn\\'t be opened')\n~~~\n\nThis will load `dlportio.dll` as a global object called `io`. Please note that failure will not crash the experiment, so make sure to check the debug window for error messages!\n\nNow use the following code in an INLINE_SCRIPT anywhere in the experiment to send a trigger:\n\n~~~ .python\nglobal io\ntrigger = 1\nport = 0x378\ntry:\n\tio.DlPortWritePortUchar(port, trigger)\nexcept:\n\tprint('Failed to send trigger!')\n~~~\n\nNote that this sends trigger 1 to port 0x378 (=888). Change these values according to your set-up.\n\n## Getting access to the parallel port\n\n### Linux\n\nIn Linux we use the `parport_pc` module (tested in Debian Wheezy) and we need to provide ourselves with permissions to do so. We can accomplish this by executing the following commands:\n\n\tsudo rmmod lp\n\tsudo rmmod parport_pc\n\tsudo modprobe parport_pc\n\tsudo adduser [user] lp\n\nHere, `[user]` should be replaced by your username. Next, logout and login, and you are ready to go!\n\n### Windows XP and Windows Vista (32 bit)\n\n1. Download the 32-bit DLPortIO driver from [here][win32-dll] and uncompress the zip archive.\n2. Go to `DriverLINX/drivers` folder and copy `dlportio.dll` and `dlportio.sys` to the `install` folder. This is the folder  where `install.exe` is located. Then run `install.exe`\n3. You need to copy `dlportio.dll` to the OpenSesame folder (that is, the same folder that contains `opensesame.exe`).\n\n### Windows 7 (32 and 64 bit)": {
    "fr": "Dans les études EEG/ERP, il est courant d'envoyer des déclencheurs pour marquer l'instant de certains événements significatifs (par exemple, le début d'un essai, la présentation d'un stimulus particulier, etc.). Les déclencheurs sont généralement des octets envoyés via le port parallèle vers l'appareil EEG.\n\n<notranslate>[TOC]</notranslate>\n\n## Utilisation du plugin `parallel_port_trigger`\n\nParallel_port_trigger est un plugin tiers, mais a été examiné par l'équipe OpenSesame.\n{: .page-notification}\n\nLes déclencheurs peuvent être envoyés avec le plugin `parallel_port_trigger` qui fonctionne sous Linux et Windows.\n\nLe plugin a trois zones de saisie :\n\n- La valeur varie entre 0 et 255 et spécifie l'octet du déclencheur.\n- La durée (en ms) est le temps pendant lequel le déclencheur est activé. À moins qu'une durée de 0 ms ne soit spécifiée, le déclencheur sera réinitialisé à 0 après cet intervalle.\n- L'adresse du port doit être spécifiée manuellement. Ce réglage s'applique uniquement à Windows et est ignoré sous Linux.\n\nVous pouvez télécharger le plugin depuis ici :\n\n- <https://github.com/dev-jam/opensesame_plugin_parallel-port-trigger>\n\n<notranslate>\nfigure:\n id: FigScreenshot\n source: plugin-screenshot.png\n caption: |\n  Une capture d'écran du plugin `parallel_port_trigger`.\n</notranslate>\n\n## Utilisation de `dportio.dll` dans un script Python inline (uniquement pour Windows)\n\nAu lieu d'utiliser le plugin `parallel_port_trigger`, il est également possible d'envoyer des déclencheurs avec `dlportio.dll` via un script Python inline. Cette approche est réservée à Windows. Pour ce faire, ajoutez d'abord un INLINE_SCRIPT au début de l'expérience avec le code suivant dans la phase de préparation :\n\n~~~ .python\ntry:\n\tfrom ctypes import windll\n\tglobal io\n\tio = windll.dlportio # requires dlportio.dll !!!\nexcept:\n\tprint('Le port parallèle n\\'a pas pu être ouvert')\n~~~\n\nCela chargera `dlportio.dll` en tant qu'objet global appelé `io`. Veuillez noter que l'échec ne provoquera pas de plantage de l'expérience, alors assurez-vous de vérifier la fenêtre de débogage pour les messages d'erreur !\n\nUtilisez maintenant le code suivant dans un INLINE_SCRIPT n'importe où dans l'expérience pour envoyer un déclencheur :\n\n~~~ .python\nglobal io\ntrigger = 1\nport = 0x378\ntry:\n\tio.DlPortWritePortUchar(port, trigger)\nexcept:\n\tprint('Échec de l\\'envoi du déclencheur!')\n~~~\n\nNotez que cela envoie le déclencheur 1 au port 0x378 (=888). Modifiez ces valeurs en fonction de votre configuration.\n\n## Obtenir l'accès au port parallèle\n\n### Linux\n\nDans Linux, nous utilisons le module `parport_pc` (testé sur Debian Wheezy) et nous devons nous donner les autorisations pour le faire. Nous pouvons y parvenir en exécutant les commandes suivantes :\n\n\tsudo rmmod lp\n\tsudo rmmod parport_pc\n\tsudo modprobe parport_pc\n\tsudo adduser [user] lp\n\nIci, `[user]` doit être remplacé par votre nom d'utilisateur. Ensuite, déconnectez-vous et reconnectez-vous, et vous êtes prêt à partir !\n\n### Windows XP et Windows Vista (32 bits)\n\n1. Téléchargez le pilote DLPortIO 32 bits [ici][win32-dll] et décompressez l'archive zip.\n2. Allez dans le dossier `DriverLINX/drivers` et copiez `dlportio.dll` et `dlportio.sys` dans le dossier `install`. C'est le dossier où se trouve `install.exe`. Ensuite, exécutez `install.exe`.\n3. Vous devez copier `dlportio.dll` dans le dossier OpenSesame (c'est-à-dire le même dossier qui contient `opensesame.exe`).\n\n### Windows 7 (32 et 64 bits)"
  },
  "1. Download the 32-bit or 64bit DLPortIO driver [here][win7-dll] and uncompress the zip archive.\n2. As Windows 7 has a strengthened security system (at least compared to XP) one cannot simply install the DLPortIO driver. This won't work as Windows 7 will block all attempts of installing a not-officially-signed (by Microsoft) driver. Good for the security of an average user -- bad for us. To bypass this restriction one has to use a little helper program called \"Digital Signature Enforcement Overrider\" (DSEO) which can be downloaded [here][dseo] (of course there are other possible ways to do this but this program is mentioned in the DLPortIO `readme.txt` and one does not have to dive deeper into MS Windows 7 architecture specialities).\n3. Start DSEO with administrator privileges (right click on `dseo13b.exe`, select \"run as administrator\"). Now the DSEO window pops up. It just presents a list of options which operation to run next.\n4. Choose the option \"sign driver/sys-file\" and press ok. Now another window appears where you have to type in the absolute path to the `DLPortIO.sys` file (only this one, not the dll!). Remember to escape spaces in the path if you have any (don't ask how long that took me) otherwise your files will not be found. Pressing ok will sign the sys-file.\n5. Back in the DSEO list choose \"enable test mode\" and press ok. Then choose \"exit\" and restart your PC. Windows 7 wrongly complains that DSEO might not be installed correctly -- just click on \"yes, the software is installed correctly\".\n6. After boot-up is completed you'll see that something like \"Windows 7 test mode built #number#\" is written on the desktop just above the clock in the starter-bar. That's necessary. You have to be in test mode to run this unofficially signed driver.\n7. Now run `DLPortIO_install.bat` with administrator privileges (in Windows Explorer, right click the file, ...). Answer \"yes\" if Windows warns you about registry changes.\n8. Reboot.\n9. Copy `DLPortIO.dll` to the Opensesame folder, that is, the same folder that contains `opensesame.exe`.\n\nSource: [Forum post by Absurd][post-3]\n\n## Recommendations\n\n- Start your experiment with a 'zero' trigger to make sure all the pins are set to zero.\n- It's recommended to use the [psycho] or [xpyriment] backends instead of the [legacy] backend (using PyGame) for time-critical experiments. This is because [psycho] and [xpyriment] takes the refresh rate of the monitor into account when returning timestamps, whereas [legacy] does not. For more information, see [miscellaneous/timing].\n- Send the trigger code right after (instead of just before) the presentation of your stimulus (assuming that it's the stimulus onset you want to mark). By doing so you'll make sure that the time stamp is as accurately as possible and will not suffer from a small random jitter due to your monitor's refresh rate. [Source: lvanderlinden][post-2]\n\n## Troubleshooting\n\nThere are a number of relevant forum topics in which trigger-related problems are discussed (and, for the most, solved!).\n\n- A post about ghost triggers, i.e. unwanted triggers that are mysteriously registered by the EEG apparatus: [link][post-2]\n- A post with elaborate installation instructions for DLPortIO on Windows 7 ([Source: absurd][post-3]).\n\nPlease don't hesitate to post questions on the forum, or to let us know of your experiences (good or bad).\n\n[win32-dll]: http://files.cogsci.nl/misc/dlportio.zip\n[win7-dll]: http://real.kiev.ua/avreal/download/#DLPORTIO_TABLE\n[dseo]: http://www.ngohq.com/home.php?page=dseo\n[post-2]: http://forum.cogsci.nl/index.php?p=/discussion/comment/780#Comment_780\n[post-3]: http://forum.cogsci.nl/index.php?p=/discussion/comment/745#Comment_745\n[miscellaneous/timing]: /miscellaneous/timing\n[legacy]: /backends/legacy\n[xpyriment]: /backends/xpyriment\n[psycho]: /backends/psycho\n": {
    "fr": "1. Téléchargez le pilote DLPortIO 32 bits ou 64 bits [ici][win7-dll] et décompressez l'archive zip.\n2. Comme Windows 7 dispose d'un système de sécurité renforcé (au moins par rapport à XP), on ne peut pas simplement installer le pilote DLPortIO. Cela ne fonctionnera pas car Windows 7 bloquera toutes les tentatives d'installation d'un pilote non officiellement signé (par Microsoft). Bon pour la sécurité d'un utilisateur moyen -- mauvais pour nous. Pour contourner cette restriction, il faut utiliser un petit programme d'aide appelé \"Digital Signature Enforcement Overrider\" (DSEO) qui peut être téléchargé [ici][dseo] (bien sûr, il existe d'autres moyens possibles de le faire, mais ce programme est mentionné dans le `readme.txt` de DLPortIO et il ne faut pas se plonger plus profondément dans les spécificités de l'architecture de MS Windows 7).\n3. Démarrez DSEO avec des privilèges d'administrateur (clic droit sur `dseo13b.exe`, sélectionnez \"exécuter en tant qu'administrateur\"). La fenêtre DSEO apparaît. Elle présente simplement une liste d'options pour choisir l'opération à effectuer ensuite.\n4. Choisissez l'option \"sign driver/sys-file\" et appuyez sur ok. Une autre fenêtre apparaît où vous devez taper le chemin absolu vers le fichier `DLPortIO.sys` (seulement celui-ci, pas le dll !). N'oubliez pas d'échapper les espaces dans le chemin si vous en avez (ne demandez pas combien de temps cela m'a pris) sinon vos fichiers ne seront pas trouvés. En appuyant sur ok, vous signerez le fichier sys.\n5. Retournez dans la liste DSEO, choisissez \"enable test mode\" et appuyez sur ok. Ensuite, choisissez \"exit\" et redémarrez votre PC. Windows 7 se plaint à tort que DSEO n'a peut-être pas été installé correctement -- cliquez simplement sur \"oui, le logiciel est installé correctement\".\n6. Une fois le démarrage terminé, vous verrez que quelque chose comme \"Windows 7 test mode built #number#\" est écrit sur le bureau, juste au-dessus de l'horloge dans la barre de démarrage. C'est nécessaire. Vous devez être en mode test pour exécuter ce pilote non officiellement signé.\n7. Exécutez maintenant `DLPortIO_install.bat` avec des privilèges d'administrateur (dans l'explorateur Windows, cliquez avec le bouton droit sur le fichier, ...). Répondez \"oui\" si Windows vous avertit des modifications de registre.\n8. Redémarrez.\n9. Copiez `DLPortIO.dll` dans le dossier Opensesame, c'est-à-dire le même dossier qui contient `opensesame.exe`.\n\nSource : [Forum post by Absurd][post-3]\n\n## Recommandations\n\n- Commencez votre expérience avec un déclencheur 'zéro' pour vous assurer que toutes les broches sont réglées sur zéro.\n- Il est recommandé d'utiliser les backends [psycho] ou [xpyriment] au lieu du backend [legacy] (utilisant PyGame) pour les expériences critiques en termes de temps. Cela est dû au fait que [psycho] et [xpyriment] tiennent compte de la fréquence de rafraîchissement du moniteur lorsqu'ils retournent des horodatages, alors que [legacy] ne le fait pas. Pour plus d'informations, consultez [miscellaneous/timing].\n- Envoyez le code de déclenchement juste après (au lieu de juste avant) la présentation de votre stimulus (en supposant que ce soit le début du stimulus que vous voulez marquer). En faisant cela, vous vous assurerez que le timestamp est aussi précis que possible et ne souffrira pas d'un léger jitter aléatoire dû à la fréquence de rafraîchissement de votre moniteur. [Source : lvanderlinden][post-2]\n\n## Dépannage\n\nIl existe plusieurs sujets de forum pertinents dans lesquels les problèmes liés aux déclencheurs sont discutés (et, pour la plupart, résolus !).\n\n- Un post sur les déclencheurs fantômes, c'est-à-dire les déclencheurs non désirés qui sont mystérieusement enregistrés par l'appareil EEG : [lien][post-2]\n- Un post avec des instructions d'installation détaillées pour DLPortIO sur Windows 7 ([Source : absurd][post-3]).\n\nN'hésitez pas à poser des questions sur le forum, ou à nous faire part de vos expériences (bonnes ou mauvaises).\n\n[win32-dll]: http://files.cogsci.nl/misc/dlportio.zip\n[win7-dll]: http://real.kiev.ua/avreal/download/#DLPORTIO_TABLE\n[dseo]: http://www.ngohq.com/home.php?page=dseo\n[post-2]: http://forum.cogsci.nl/index.php?p=/discussion/comment/780#Comment_780\n[post-3]: http://forum.cogsci.nl/index.php?p=/discussion/comment/745#Comment_745\n[miscellaneous/timing]: /miscellaneous/timing\n[legacy]: /backends/legacy\n[xpyriment]: /backends/xpyriment\n[psycho]: /backends/psycho"
  },
  "StimSync": {
    "fr": "StimSync"
  },
  "StimSync is an open-source open-hardware device for handling input (e.g., button presses) and output (e.g., triggers) in psychological and neuroscientific experiments. StimSync offers examples for use with OpenSesame.\n\nFor more information, see:\n\n- <http://www.mccauslandcenter.sc.edu/crnl/stimsync-0>\n": {
    "fr": "StimSync est un dispositif open-source et open-hardware pour gérer les entrées (par exemple, les pressions de boutons) et les sorties (par exemple, les déclencheurs) dans les expériences psychologiques et neuroscientifiques. StimSync propose des exemples d'utilisation avec OpenSesame.\n\nPour plus d'informations, consultez :\n\n- <http://www.mccauslandcenter.sc.edu/crnl/stimsync-0>"
  },
  "Oculus rift (virtual reality)": {
    "fr": "Oculus Rift (réalité virtuelle)"
  },
  "<iframe src=\"http://wl.figshare.com/articles/1394986/embed?show_title=1\" width=\"640\" height=\"861\" frameborder=\"0\"></iframe>\n\nHernández-Sande, A., Lorca, J. A. (2015): OpenSesame: An example of stimulus presentation in Virtual Reality headsets (Oculus Rift DK1). *Figshare*. doi:10.6084/m9.figshare.1394986\n": {
    "fr": "<iframe src=\"http://wl.figshare.com/articles/1394986/embed?show_title=1\" width=\"640\" height=\"861\" frameborder=\"0\"></iframe>\n\nHernández-Sande, A., Lorca, J. A. (2015): OpenSesame : Un exemple de présentation de stimulus dans des casques de réalité virtuelle (Oculus Rift DK1). *Figshare*. doi:10.6084/m9.figshare.1394986"
  },
  "Ambulatory Monitoring System (VU-AMS)": {
    "fr": "Système de Surveillance Ambulatoire (VU-AMS)"
  },
  "VU-AMS is a third-party plugin, and is not maintained by the OpenSesame team.\n{: .alert .alert-info}\n\n\nThe VU University Ambulatory Monitoring System (VU-AMS) is a device that can be used to measure a variety of factors related to heart rate, respiration, and body movement. The developers offer an OpenSesame template on their website.\n\nFor more information, see:\n\n- <http://www.vu-ams.nl> (product website)\n- <http://www.vu-ams.nl/support/downloads/extras/> (OpenSesame template)\n": {
    "fr": "VU-AMS est un plugin tiers et n'est pas maintenu par l'équipe OpenSesame.\n{: .alert .alert-info}\n\n\nLe système de surveillance ambulatoire de l'Université VU (VU-AMS) est un dispositif qui peut être utilisé pour mesurer divers facteurs liés à la fréquence cardiaque, la respiration et le mouvement du corps. Les développeurs proposent un modèle OpenSesame sur leur site Web.\n\nPour plus d'informations, voir:\n\n- <http://www.vu-ams.nl> (site du produit)\n- <http://www.vu-ams.nl/support/downloads/extras/> (modèle OpenSesame)"
  },
  "Emotiv EEG": {
    "fr": "Emotiv EEG"
  },
  "[Emotiv](https://emotiv.com/) is a low-cost EEG headset. Dimitrios Adamos (Neuroinformatics.GRoup of the Aristotle University of Thessaloniki) has written a tutorial for using the Emotiv with OpenSesame:\n\n- <http://neuroinformatics.gr/node/37>\n\n<notranslate>\nfigure:\n source: emotiv.png\n id: FigEmotiv\n caption: Emotiv is a low-cost EEG headset.\n</notranslate>\n": {
    "fr": "[Emotiv](https://emotiv.com/) est un casque EEG à faible coût. Dimitrios Adamos (Neuroinformatics.GRoup de l'Université Aristote de Thessalonique) a écrit un tutoriel pour utiliser l'Emotiv avec OpenSesame :\n\n- <http://neuroinformatics.gr/node/37>\n\n<notranslate>\nfigure:\n source: emotiv.png\n id: FigEmotiv\n caption: Emotiv est un casque EEG à faible coût.\n</notranslate>"
  },
  "Serial port": {
    "fr": "Port série"
  },
  "PySerial is an easy to use Python library for serial port communications, which is bundled with all OpenSesame packages. For more information, see:\n\n- <http://pyserial.sourceforge.net/>\n": {
    "fr": "PySerial est une bibliothèque Python facile à utiliser pour les communications sur port série, qui est incluse avec tous les packages OpenSesame. Pour plus d'informations, consultez :\n\n- <http://pyserial.sourceforge.net/>"
  },
  "Tobii": {
    "fr": "Tobii"
  },
  "PyGaze offers *experimental* support for Tobii eye trackers. The `tobii-research` package can be installed through `pip`, but at the time of writing it requires a specific version of Python—and *which* version of Python it requires varies from release to release. Therefore, the first step is to find out which version of Python you need. You can do that by visiting the `tobii-research` on PyPi and clicking on 'Download files':\n\n- <https://pypi.org/project/tobii-research/#files>\n\nFrom the file names, you can tell which version of Python you need; for example, the `cp310` in the name \n`tobii_research-1.10.2-cp310-cp310-win_amd64.whl` means that you need Python 3.10 (`cp` stands for C-Python).\n\nNext, install OpenSesame in a Python environment of the correct version (so Python 3.10 for version 1.10.2 of `tobii-research` as shown above). This most easily done using Anaconda, as described [here](%url:download%). Finally, install the `tobii-research` package into this Python environment.\n\n```\n!pip install tobii-research\n```\n\n\nFor more information, see:\n\n- %link:pygaze%\n- <https://rapunzel.cogsci.nl/manual/environment/>\n- <http://www.tobii.com/en/eye-tracking-research/global/>\n": {
    "fr": "PyGaze offre un support *expérimental* pour les eye-trackers Tobii. Le paquet `tobii-research` peut être installé via `pip`, mais au moment de l'écriture, il nécessite une version spécifique de Python—et *quelle* version de Python il requiert varie d'une version à l'autre. Par conséquent, la première étape consiste à déterminer quelle version de Python vous avez besoin. Vous pouvez le faire en visitant `tobii-research` sur PyPi et en cliquant sur \"Download files\":\n\n- <https://pypi.org/project/tobii-research/#files>\n\nÀ partir des noms de fichiers, vous pouvez déterminer quelle version de Python vous avez besoin; par exemple, le `cp310` dans le nom\n`tobii_research-1.10.2-cp310-cp310-win_amd64.whl` signifie que vous avez besoin de Python 3.10 (`cp` signifie C-Python).\n\nEnsuite, installez OpenSesame dans un environnement Python de la version correcte (donc Python 3.10 pour la version 1.10.2 de `tobii-research` comme indiqué ci-dessus). Ceci est plus facilement réalisé en utilisant Anaconda, comme décrit [ici](%url:download%). Enfin, installez le paquet `tobii-research` dans cet environnement Python.\n\n```\n!pip install tobii-research\n```\n\n\nPour plus d'informations, voir :\n\n- %link:pygaze%\n- <https://rapunzel.cogsci.nl/manual/environment/>\n- <http://www.tobii.com/en/eye-tracking-research/global/>"
  },
  "Eyelink": {
    "fr": "Eyelink"
  },
  "<notranslate>[TOC]</notranslate>\n\n## About EyeLink\n\nThe Eyelink series of eye trackers, produced by SR Research, are one of the most commonly used eye trackers in psychological research. SR Research provides Python bindings for the Eyelink (called PyLink), which are used by PyGaze. The license of PyLink is incompatible with the license used by OpenSesame. For that reason, PyLink is not included in the default distribution of OpenSesame, and needs to be installed separately.\n\n\n## SR Research forum\n\nYou will need to download some software from the SR Research forum. This is a closed forum, but you can register free of charge.\n\n- <https://www.sr-support.com/>\n\n\n## Windows\n\n### Installing the EyeLink Developers Kit\n\nThe Eyelink Developers Kit (sometimes called Display Software) provides the libraries that are required to communicate with the Eyelink PC. You can find it here:\n\n- <https://www.sr-support.com/thread-13.html>\n\nIf you extract the .zip, and then run the .exe installer, the EyeLink display will be installed in one of the following folders (depending on your version of Windows:\n\n```\nC:\\Program Files\\SR Research\\EyeLink\\\nC:\\Program Files (x86)\\SR Research\\EyeLink\n```\n\nIn this folder, there is a `libs` subfolder, which you need to add to the system Path (this may have been added to the path automatically, but check to make sure). You can do this by opening \"My Computer\", clicking on \"View system information\", opening the \"Advanced\" tab, clicking on \"Environment Variables\" and appending `;C:\\Program Files\\SR Research\\EyeLink\\libs` or (depending on your system) `;C:\\Program Files (x86)\\SR Research\\EyeLink\\libs` to the Path variable (under System variables).\n\n\n### Installing PyLink\n\nPyLink is the Python library for EyeLink support. PyLink is included with recent versions of the EyeLink display software (described above), and you can find it in one of the following folders (depending on your version of Windows):\n\n```\nC:\\Program Files\\SR Research\\EyeLink\\SampleExperiments\\Python\nC:\\Program Files (x86)\\SR Research\\EyeLink\\SampleExperiments\\Python\n```\n\nAlternatively, you can download Pylink from here:\n\n- <https://www.sr-support.com/thread-13.html>\n\nTo install PyLink in OpenSesame, simply copy the folder with the PyLink the OpenSesame program folder, or the `Lib\\site-packages` subfolder. In some cases, the `pylink` folder has a name such as `pylink27-amd64`, in which case you have to rename it to just `pylink`.\n\n__Important:__ The Python version of PyLink needs to match the Python version of your OpenSesame installation. In most cases, this means that you need PyLink for Python 3.7.\n\n\n## Ubuntu\n\nThe EyeLink display software can be installed directly from a repository. This also installs PyLink and various convenient tools, such ast the `edf2asc` converter.\n\n```bash\nsudo add-apt-repository \"deb http://download.sr-support.com/software SRResearch main\"\nsudo apt-get update\nsudo apt-get install eyelink-display-software\n```\n\nFor more information, please visit:\n\n- <https://www.sr-support.com/thread-13.html>\n\n\n## PyGaze\n\nAfter you have install the EyeLink display software and PyLink per the instructions above, you can use the EyeLink with PyGaze! See:\n\n- %link:pygaze%\n": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos d'EyeLink\n\nLa série d'eye-trackers EyeLink, produite par SR Research, est l'une des plus couramment utilisées dans la recherche en psychologie. SR Research fournit des liaisons Python pour l'EyeLink (appelées PyLink), qui sont utilisées par PyGaze. La licence de PyLink est incompatible avec celle utilisée par OpenSesame, c'est pourquoi PyLink n'est pas inclus dans la distribution par défaut d'OpenSesame et doit être installé séparément.\n\n\n## Forum SR Research\n\nVous devrez télécharger certains logiciels depuis le forum SR Research. Ce forum est un forum fermé, mais vous pouvez vous inscrire gratuitement.\n\n- <https://www.sr-support.com/>\n\n## Windows\n\n### Installer le Kit de développement EyeLink\n\nLe Kit de développement EyeLink (parfois appelé Display Software) fournit les bibliothèques nécessaires pour communiquer avec le PC EyeLink. Vous pouvez le trouver ici :\n\n- <https://www.sr-support.com/thread-13.html>\n\nSi vous extrayez le .zip, puis exécutez l'installateur .exe, le display EyeLink sera installé dans l'un des dossiers suivants (selon votre version de Windows) :\n\n```\nC:\\Program Files\\SR Research\\EyeLink\\\nC:\\Program Files (x86)\\SR Research\\EyeLink\n```\n\nDans ce dossier, il y a un sous-dossier `libs`, que vous devez ajouter au chemin système (cela a peut-être été ajouté automatiquement, mais vérifiez pour vous assurer). Vous pouvez le faire en ouvrant \"Mon ordinateur\", en cliquant sur \"Afficher les informations système\", en ouvrant l'onglet \"Avancé\", en cliquant sur \"Variables d'environnement\" et en ajoutant `;C:\\Program Files\\SR Research\\EyeLink\\libs` ou (selon votre système) `;C:\\Program Files (x86)\\SR Research\\EyeLink\\libs` à la variable Path (sous Variables système).\n\n### Installer PyLink\n\nPyLink est la bibliothèque Python pour le support EyeLink. PyLink est inclus dans les versions récentes du logiciel d'affichage EyeLink (décrit ci-dessus) et vous pouvez le trouver dans l'un des dossiers suivants (selon votre version de Windows) :\n\n```\nC:\\Program Files\\SR Research\\EyeLink\\SampleExperiments\\Python\nC:\\Program Files (x86)\\SR Research\\EyeLink\\SampleExperiments\\Python\n```\n\nSinon, vous pouvez télécharger Pylink ici :\n\n- <https://www.sr-support.com/thread-13.html>\n\nPour installer PyLink dans OpenSesame, il suffit de copier le dossier avec le PyLink dans le dossier du programme OpenSesame ou dans le sous-dossier `Lib\\site-packages`. Dans certains cas, le dossier `pylink` porte un nom tel que `pylink27-amd64`, auquel cas vous devez le renommer simplement `pylink`.\n\n__Important :__ La version Python de PyLink doit correspondre à la version Python de votre installation OpenSesame. Dans la plupart des cas, cela signifie que vous avez besoin de PyLink pour Python 3.7.\n\n\n## Ubuntu\n\nLe logiciel d'affichage EyeLink peut être installé directement à partir d'un référentiel. Cela installe également PyLink et divers outils pratiques, tels que le convertisseur `edf2asc`.\n\n```bash\nsudo add-apt-repository \"deb http://download.sr-support.com/software SRResearch main\"\nsudo apt-get update\nsudo apt-get install eyelink-display-software\n```\n\nPour plus d'informations, veuillez visiter :\n\n- <https://www.sr-support.com/thread-13.html>\n\n\n## PyGaze\n\nAprès avoir installé le logiciel d'affichage EyeLink et PyLink comme indiqué ci-dessus, vous pouvez utiliser EyeLink avec PyGaze ! Voir :\n\n- %link:pygaze%"
  },
  "SMI": {
    "fr": "SMI"
  },
  "PyGaze offers *experimental* support for SMI eye trackers. (SMI no longer exists as a company, but its eye trackers are still used in some labs.) For more information, see:\n\n- %link:pygaze%\n": {
    "fr": "PyGaze offre un support *expérimental* pour les eye-trackers SMI. (SMI n'existe plus en tant que société, mais ses eye-trackers sont toujours utilisés dans certains laboratoires.) Pour plus d'informations, consultez :\n\n- %link:pygaze%"
  },
  "WebGazer.js": {
    "fr": "WebGazer.js"
  },
  "Requires OSWeb v1.4.6.1\n{:.page-notification}\n\n<notranslate>[TOC]</notranslate>\n\n\n## About WebGazer\n\nWebGazer.js is an eye-tracking library written in JavaScript. You can include it with OSWeb to perform eye tracking in online experiments.\n\n- <https://webgazer.cs.brown.edu/>\n\n\n## Including WebGazer.js in the experiment\n\nWebGazer.js is not bundled with OSWeb by default. However, you can include it as an external library by entering a link to `webgazer.js` under External JavaScript libraries. Currently, a functional link is:\n\n```\nhttps://webgazer.cs.brown.edu/webgazer.js\n```\n\nSee also:\n\n- %link:manual/osweb/osweb%\n\n\n## Example experiment\n\nBelow you can download an example experiment that uses WebGazer.js. Participants are first asked to click on and look at a set of dots; this will cause WebGazer.js to automatically perform something akin to a calibration procedure. Next, the experiment shows a simple screen to test the accuracy of gaze-position recording. In general, fine-grained eye tracking is not feasible, but you can tell which quadrant of the screen a participant is looking at. To run this experiment, you need include WebGazer.js in the experiment, as described above. \n\n- %static:attachments/webgazer.osexp%\n\nYou can also launch the experiment directly in the browser:\n\n- <https://jatos.mindprobe.eu/publix/BowSAFY2VWl>\n": {
    "fr": "Nécessite OSWeb v1.4.6.1\n{:.page-notification}\n\n<notranslate>[TOC]</notranslate>\n\n\n## À propos de WebGazer\n\nWebGazer.js est une bibliothèque de suivi oculaire écrite en JavaScript. Vous pouvez l'inclure avec OSWeb pour effectuer un suivi oculaire dans des expériences en ligne.\n\n- <https://webgazer.cs.brown.edu/>\n\n\n## Inclure WebGazer.js dans l'expérience\n\nWebGazer.js n'est pas inclus par défaut avec OSWeb. Cependant, vous pouvez l'inclure en tant que bibliothèque externe en entrant un lien vers `webgazer.js` dans les bibliothèques JavaScript externes. Actuellement, un lien fonctionnel est :\n\n```\nhttps://webgazer.cs.brown.edu/webgazer.js\n```\n\nVoir aussi :\n\n- %link:manual/osweb/osweb%\n\n\n## Expérience exemple\n\nVous pouvez télécharger ci-dessous une expérience exemple qui utilise WebGazer.js. Les participants sont d'abord invités à cliquer sur et à regarder un ensemble de points ; cela amènera WebGazer.js à effectuer automatiquement quelque chose qui ressemble à une procédure d'étalonnage. Ensuite, l'expérience montre un écran simple pour tester la précision de l'enregistrement de la position du regard. En général, un suivi oculaire à grain fin n'est pas réalisable, mais vous pouvez dire dans quel quadrant de l'écran un participant regarde. Pour exécuter cette expérience, vous devez inclure WebGazer.js dans l'expérience, comme décrit ci-dessus.\n\n- %static:attachments/webgazer.osexp%\n\nVous pouvez également lancer l'expérience directement dans le navigateur :\n\n- <https://jatos.mindprobe.eu/publix/BowSAFY2VWl>"
  },
  "GazePoint / OpenGaze": {
    "fr": "GazePoint / OpenGaze"
  },
  "PyGaze offers *experimental* support for GazePoint eye trackers through the OpenGaze API as of OpenSesame 3.3.11. For more information, see:\n\n- %link:pygaze%\n- <https://www.gazept.com/>\n": {
    "fr": "PyGaze offre un soutien *expérimental* pour les eye-trackers GazePoint grâce à l'API OpenGaze à partir d'OpenSesame 3.3.11. Pour plus d'informations, consultez :\n\n- %link:pygaze%\n- <https://www.gazept.com/>"
  },
  "EyeLogic": {
    "fr": "LogiqueOculaire"
  },
  "PyGaze offers *experimental support* for EyeLogic eye trackers as of OpenSesame 3.3.11. For more information, see:\n\n- %link:pygaze%\n- <https://www.eyelogicsolutions.com/>\n": {
    "fr": "PyGaze offre un *support expérimental* pour les eye-trackers EyeLogic à partir d'OpenSesame 3.3.11. Pour plus d'informations, voir :\n\n- %link:pygaze%\n- <https://www.eyelogicsolutions.com/>"
  },
  "Mechanical Turk": {
    "fr": "Turc mécanique"
  },
  "\nThere is currently no information that is specific to running OSWeb experiments on Mechanical Turk. For general information about connecting JATOS to Mechanical Turk, see:\n\n- <http://www.jatos.org/Connect-to-Mechanical-Turk.html>\n": {
    "fr": "Il n'y a actuellement aucune information spécifique concernant l'exécution d'expériences OSWeb sur Mechanical Turk. Pour des informations générales sur la connexion de JATOS à Mechanical Turk, consultez :\n\n- <http://www.jatos.org/Connect-to-Mechanical-Turk.html>"
  },
  "Inline JavaScript": {
    "fr": "JavaScript en ligne"
  },
  "This page has moved to:\n\n- %link:manual/javascript/about%\n": {
    "fr": "Cette page a été déplacée vers :\n\n- %link:manual/javascript/about%"
  },
  "JATOS": {
    "fr": "JATOS"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## About JATOS\n\nJATOS is a system for managing online experiments. It allows you to create accounts for experimenters, upload experiments, and generate links that you can distribute to participants.\n\n- <https://www.jatos.org/>\n\n\n## Exporting your experiment to a JATOS study\n\n- In OpenSesame, open the OSWeb extension (Menu → Tools → OSWeb)\n- Click on 'Export experiment as JATOS study'\n- Save your experiment as a `.zip` file\n\n\n## Importing your experiment in JATOS\n\n- In JATOS, click on 'Import study' (%FigJatos2)\n- Select the `.zip` file that you have exported from OpenSesame\n- Once the file has been uploaded to the server, JATOS will ask you to confirm that you want to import the study\n- Click on 'Import' to confirm\n- The study now appears in the list of studies on the left-hand side (%FigJatos3)\n\n\n<notranslate>\nfigure:\n id: FigJatos2\n source: jatos-2.png\n caption: Click on 'Import study' and select the `.zip` file that you have exported with the OSWeb extension.\n</notranslate>\n\n\n<notranslate>\nfigure:\n id: FigJatos3\n source: jatos-3.png\n caption: Once the experiment has been successfully imported in JATOS, it appears in the list of experiments.\n</notranslate>\n\n\n## How can I get access to a JATOS server?\n\nThere is not a single JATOS server. Rather, different organizations and people have installed JATOS onto their own servers.\n\n\nFor testing purposes:\n\n- You can use the [JATOS test server](https://www.jatos.org/JATOS-Tryout-Server.html) (%FigJatos1). The JATOS test server is reset every night, so you cannot use it for data collection!\n\n\nFor data collection:\n\n- You can set up your own JATOS server, or use a JATOS server that is provided by your institution\n- Or you can also make use of <https://mindprobe.eu/>, a free JATOS server sponsored by ESCoP and OpenSesame.\n\n\n<notranslate>\nfigure:\n id: FigJatos1\n source: jatos-1.png\n caption: For testing purposes, you can use the JATOS test server.\n</notranslate>\n": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos de JATOS\n\nJATOS est un système de gestion d'expériences en ligne. Il vous permet de créer des comptes pour les expérimentateurs, de télécharger des expériences et de générer des liens que vous pouvez distribuer aux participants.\n\n- <https://www.jatos.org/>\n\n## Exporter votre expérience en tant qu'étude JATOS\n\n- Dans OpenSesame, ouvrez l'extension OSWeb (Menu → Outils → OSWeb)\n- Cliquez sur 'Exporter l'expérience comme étude JATOS'\n- Enregistrez votre expérience en tant que fichier `.zip`\n\n## Importer votre expérience dans JATOS\n\n- Dans JATOS, cliquez sur 'Importer une étude' (%FigJatos2)\n- Sélectionnez le fichier `.zip` que vous avez exporté depuis OpenSesame\n- Une fois le fichier téléchargé sur le serveur, JATOS vous demandera de confirmer que vous souhaitez importer l'étude\n- Cliquez sur 'Importer' pour confirmer\n- L'étude apparaît maintenant dans la liste des études sur le côté gauche (%FigJatos3)\n\n<notranslate>\nfigure:\n id: FigJatos2\n source: jatos-2.png\n caption: Cliquez sur 'Importer une étude' et sélectionnez le fichier `.zip` que vous avez exporté avec l'extension OSWeb.\n</notranslate>\n\n<notranslate>\nfigure:\n id: FigJatos3\n source: jatos-3.png\n caption: Une fois l'expérience importée avec succès dans JATOS, elle apparaît dans la liste des expériences.\n</notranslate>\n\n## Comment puis-je accéder à un serveur JATOS ?\n\nIl n'existe pas de serveur JATOS unique. En revanche, différentes organisations et personnes ont installé JATOS sur leurs propres serveurs.\n\nPour des tests :\n\n- Vous pouvez utiliser le [serveur de test JATOS](https://www.jatos.org/JATOS-Tryout-Server.html) (%FigJatos1). Le serveur de test JATOS est réinitialisé chaque nuit, vous ne pouvez donc pas l'utiliser pour la collecte de données !\n\nPour la collecte de données :\n\n- Vous pouvez configurer votre propre serveur JATOS, ou utiliser un serveur JATOS fourni par votre institution\n- Ou vous pouvez également utiliser <https://mindprobe.eu/>, un serveur JATOS gratuit parrainé par ESCoP et OpenSesame.\n\n<notranslate>\nfigure:\n id: FigJatos1\n source: jatos-1.png\n caption: Pour des tests, vous pouvez utiliser le serveur de test JATOS.\n</notranslate>"
  },
  "Downloading and converting data": {
    "fr": "Téléchargement et conversion des données"
  },
  "Once you have collected data with OSWeb through JATOS, you can download this data in JATOS by navigating to your experiment, clicking on Results, and then selecting Export Results → All (see %FigJatosExportResults).\n\n\n<notranslate>\nfigure:\n id: FigJatosExportResults\n source: jatos-export-results.png\n caption: Exporting results collecting with OSWeb through JATOS.\n</notranslate>\n\n\nYou will then download a file that has a name similar to `jatos_results_20190429113807.txt`. This file contains mostly JSON data, but may also contain fragments of data that render the file invalid as a regular JSON string. However, you can easily convert the data to a `.csv` or `.xlsx` file with 'Convert JATOS results to csv/ xlsx' option in the OSWeb extension.\n": {
    "fr": "Une fois que vous avez collecté des données avec OSWeb via JATOS, vous pouvez télécharger ces données dans JATOS en accédant à votre expérimentation, en cliquant sur Résultats, puis en sélectionnant Exporter Résultats → Tout (voir %FigJatosExportResults).\n\n<notranslate>\nfigure:\n id: FigJatosExportResults\n source: jatos-export-results.png\n caption: Exportation des résultats collectés avec OSWeb via JATOS.\n</notranslate>\n\nVous téléchargerez alors un fichier dont le nom ressemble à `jatos_results_20190429113807.txt`. Ce fichier contient principalement des données JSON, mais peut également contenir des fragments de données qui rendent le fichier invalide en tant que chaîne JSON régulière. Cependant, vous pouvez facilement convertir les données en un fichier `.csv` ou `.xlsx` avec l'option 'Convert JATOS results to csv/ xlsx' dans l'extension OSWeb."
  },
  "Running experiments online with OSWeb": {
    "fr": "Exécution d'expériences en ligne avec OSWeb"
  },
  "\n<notranslate>[TOC]</notranslate>\n\n\n## The workflow\n\nFor an introduction to the workflow, see also:\n\nMathôt, S., & March, J. (2022). Conducting linguistic experiments online with OpenSesame and OSWeb. *Language Learning*. doi:10.1111/lang.12509\n<br /><small>[Related preprint (not identical to published manuscript)](https://doi.org/10.31234/osf.io/wnryc)</small>\n\n\n### Developing your experiment\n\nFirst, you develop your experiment as you ordinarily would, using the OpenSesame desktop application. Not all functionality is available in online experiments. Notably, you cannot use Python INLINE_SCRIPT items, but have to use JavaScript INLINE_JAVASCRIPT items instead. During the development of your experiment, it is therefore important to check that your experiment is compatible with OSWeb.\n\n- %link:manual/osweb/osweb%\n- %link:manual/javascript/about%\n- %link:manual/osweb/questionnaires%\n\n\n### Uploading your experiment to JATOS\n\nOnce you have developed your experiment, you export it from OpenSesame and upload it to JATOS. JATOS is a web server that manages experiments: it allows you to generate links that you can distribute participants, and it stores data that has been collected.\n\nThere is not a single JATOS server. Rather, many institutions maintain their own JATOS server. In addition, <https://mindprobe.eu> is a free JATOS server, sponsored by ESCoP and OpenSesame.\n\n- %link:jatos%\n\n\n### Collecting data\n\nOne you have uploaded your experiment to JATOS, you can start collecting data. You can do this by manually sending links to participants, for example through email. Or you can use a platform for participant recruitment, such as Prolific, Mechanical Turk, or Sona Systems.\n\n- %link:prolific%\n- %link:mturk%\n- %link:sonasystems%\n\n\n## Tutorials\n\n- %link:tutorials/intermediate-javascript%\n- %link:wcst%\n": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## Le flux de travail\n\nPour une introduction au flux de travail, consultez également :\n\nMathôt, S., & March, J. (2022). Réaliser des expériences linguistiques en ligne avec OpenSesame et OSWeb. *Language Learning*. doi:10.1111/lang.12509\n<br /><small>[Pré-impression liée (non identique au manuscrit publié)](https://doi.org/10.31234/osf.io/wnryc)</small>\n\n### Développer votre expérience\n\nTout d'abord, vous développez votre expérience comme vous le feriez normalement, en utilisant l'application de bureau OpenSesame. Toutes les fonctionnalités ne sont pas disponibles dans les expériences en ligne. Notamment, vous ne pouvez pas utiliser d'éléments INLINE_SCRIPT en Python, mais vous devez utiliser des éléments INLINE_JAVASCRIPT en JavaScript à la place. Lors du développement de votre expérience, il est donc important de vérifier que votre expérience est compatible avec OSWeb.\n\n- %link:manual/osweb/osweb%\n- %link:manual/javascript/about%\n- %link:manual/osweb/questionnaires%\n\n### Télécharger votre expérience sur JATOS\n\nUne fois que vous avez développé votre expérience, vous l'exportez à partir d'OpenSesame et la téléchargez sur JATOS. JATOS est un serveur web qui gère les expériences : il vous permet de générer des liens que vous pouvez distribuer aux participants, et stocke les données collectées.\n\nIl n'y a pas de serveur JATOS unique. De nombreuses institutions ont plutôt leur propre serveur JATOS. De plus, <https://mindprobe.eu> est un serveur JATOS gratuit, parrainé par ESCoP et OpenSesame.\n\n- %link:jatos%\n\n### Collecte des données\n\nUne fois que vous avez téléchargé votre expérience sur JATOS, vous pouvez commencer à collecter des données. Vous pouvez le faire en envoyant manuellement des liens aux participants, par exemple par e-mail. Ou vous pouvez utiliser une plateforme de recrutement de participants, telle que Prolific, Mechanical Turk ou Sona Systems.\n\n- %link:prolific%\n- %link:mturk%\n- %link:sonasystems%\n\n## Tutoriels\n\n- %link:tutorials/intermediate-javascript%\n- %link:wcst%"
  },
  "Looping and independent variables": {
    "fr": "Bouclage et variables indépendantes"
  },
  "The LOOP item has two important functions:\n\n- It runs another item multiple times.\n- It is where you usually define your independent variables; that is, the variables that you manipulate in your experiment.\n\n<notranslate>[TOC]</notranslate>\n\n## The item to run\n\nA LOOP is always connected to a single other item: the item to run. You select the item to run in the box labeled \"Run\". In most cases, the item to run is a SEQUENCE, which runs multiple items sequentially.\n\nTwo common SEQUENCE-LOOP structures are:\n\n- If a SEQUENCE corresponds to a single trial (by convention called *trial_sequence*), then a LOOP that is connected to this sequence corresponds to multiple trials, or a block (by convention called *block_loop*).\n- If a SEQUENCE corresponds to a block of trials followed by a feedback display (by convention called *block_sequence*), then a loop that is connected to this sequence corresponds to multiple blocks, or a complete experimental session (by convention called *experimental_loop*).\n\n## Defining independent variables\n\nThe loop table is a powerful-yet-simple way to define independent variables. Every column in the table corresponds to a variable; every row corresponds to a cycle, that is, a level of the variable. For example, a simple loop with one variable (`animal`) that has two cycles (\"cat\" and \"dog\") looks like this:\n\nanimal |\n------ |\ncat    |\ndog    |\n\nThe loop has a few important options:\n\n*Repeat* indicates how often each cycle should be executed. In the example above, repeat is set to 2, which means that *trial_sequence* is called twice while the variable `animal` has the value \"cat\", and twice while `animal` has the value \"dog\" (so four times in total).\n\n*Order* indicates whether cycles should be executed sequentially or in random order. Randomization is complete, in the sense that the complete list of number-of-cycles × repeat trials is randomized.\n\n## Reading independent variables from file\n\nIf you want to read independent variables from file, rather than entering them into the loop table, you can do so as follows:\n\n- Set *Source* to *file*.\n- Select an Excel (`.xlsx`) or CSV (`.csv`) file in the *File* entry.\n\nThe source file follows the same conventions as the loop table; that is, each column corresponds to a variable, and each row corresponds to a cycle.\n\nCSV files are expected to be in the following format:\n\n- plain-text\n- comma-separated\n- double-quoted (literal double-quotes are escaped with backward slashes)\n- UTF-8 encoded\n\n## Breaking the loop\n\nIf you want to break the loop before all cycles have been executed, you can specify a break-if expression. This break-if expression follows the same syntax as other conditional expressions, as described on:\n\n- %link:manual/variables%\n\nFor example, the following break-if statement would break the loop as soon as a correct response is given:\n\n```python\n{correct} == 1\n```\n\nThe *Evaluate on first cycle* option indicates whether the break-if statement should be evaluated before the first cycle, in which case no cycles may be executed at all, or only before the second cycle, in which case at least one cycle is always executed. In some cases, the break-if statement will refer to a variable that is only defined after the first cycle, in which case you should disable the 'Evaluate on first cycle' option to avoid a 'Variable does not exist' error.\n\n## Generating a full-factorial design\n\nBy clicking on the *Full-factorial design* you open a wizard that allows you to easily generate a full-factorial design, that is, a design in which each combination of factors occurs.\n\n## Pseudorandomization\n\nYou can add constraints for pseudorandomization to the script of the loop item. This shuffles the rows, even if Order is set to sequential. (Currently, this is not possible through the GUI.)\n\nExample: Make sure that repetitions of the same word (given by the `word` variable) are separated by at least 4 cycles:\n\n```python\nconstrain word mindist=4\n```": {
    "fr": "L'élément LOOP a deux fonctions importantes :\n\n- Il exécute un autre élément plusieurs fois.\n- C'est là que vous définissez généralement vos variables indépendantes ; c'est-à-dire les variables que vous manipulez dans votre expérience.\n\n<notranslate>[TOC]</notranslate>\n\n## L'élément à exécuter\n\nUn LOOP est toujours connecté à un autre élément : l'élément à exécuter. Vous sélectionnez l'élément à exécuter dans la case étiquetée \"Exécuter\". Dans la plupart des cas, l'élément à exécuter est une SEQUENCE, qui exécute plusieurs éléments séquentiellement.\n\nDeux structures SEQUENCE-LOOP courantes sont :\n\n- Si une SEQUENCE correspond à un seul essai (par convention appelé *trial_sequence*), alors un LOOP connecté à cette séquence correspond à plusieurs essais, ou un bloc (par convention appelé *block_loop*).\n- Si une SEQUENCE correspond à un bloc d'essais suivis d'un affichage de feedback (par convention appelé *block_sequence*), alors un loop connecté à cette séquence correspond à plusieurs blocs, ou une session expérimentale complète (par convention appelée *experimental_loop*).\n\n## Définition des variables indépendantes\n\nLe tableau de loop est un moyen simple et puissant de définir des variables indépendantes. Chaque colonne du tableau correspond à une variable; chaque ligne correspond à un cycle, c'est-à-dire un niveau de la variable. Par exemple, une boucle simple avec une variable (`animal`) comportant deux cycles (\"chat\" et \"chien\") ressemble à ceci :\n\nanimal |\n------ |\nchat    |\nchien    |\n\nLe loop a quelques options importantes :\n\n*Répéter* indique combien de fois chaque cycle doit être exécuté. Dans l'exemple ci-dessus, répéter est réglé sur 2, ce qui signifie que *trial_sequence* est appelé deux fois alors que la variable `animal` a la valeur \"chat\", et deux fois alors que `animal` a la valeur \"chien\" (quatre fois en tout).\n\n*Ordre* indique si les cycles doivent être exécutés séquentiellement ou dans un ordre aléatoire. La randomisation est complète, dans le sens où la liste complète des essais nombre-de-cycles × répétition est randomisée.\n\n## Lecture des variables indépendantes à partir d'un fichier\n\nSi vous souhaitez lire des variables indépendantes à partir d'un fichier plutôt que de les entrer dans le tableau de loop, vous pouvez procéder comme suit :\n\n- Réglez *Source* sur *fichier*.\n- Sélectionnez un fichier Excel (`.xlsx`) ou CSV (`.csv`) dans l'entrée *Fichier*.\n\nLe fichier source suit les mêmes conventions que le tableau de loop ; c'est-à-dire que chaque colonne correspond à une variable et chaque ligne correspond à un cycle.\n\nLes fichiers CSV doivent être au format suivant :\n\n- texte brut\n- séparés par des virgules\n- entre guillemets doubles (les guillemets doubles littéraux sont échappés par des barres obliques inverses)\n- encodé en UTF-8\n\n## Interrompre la boucle\n\nSi vous souhaitez interrompre la boucle avant que tous les cycles aient été exécutés, vous pouvez spécifier une expression break-if. Cette expression break-if suit la même syntaxe que les autres expressions conditionnelles, telles que décrites sur :\n\n- %link:manual/variables%\n\nPar exemple, l'instruction break-if suivante interromprait la boucle dès qu'une réponse correcte est donnée :\n\n```python\n{correct} == 1\n```\n\nL'option *Évaluer au premier cycle* indique si l'instruction break-if doit être évaluée avant le premier cycle, auquel cas aucun cycle peut ne pas être exécuté du tout, ou seulement avant le deuxième cycle, auquel cas au moins un cycle est toujours exécuté. Dans certains cas, l'instruction break-if fera référence à une variable qui n'est définie qu'après le premier cycle, auquel cas vous devez désactiver l'option 'Évaluer au premier cycle' pour éviter une erreur 'Variable does not exist'.\n\n## Génération d'un plan factoriel complet\n\nEn cliquant sur le *Plan factoriel complet*, vous ouvrez un assistant qui vous permet de générer facilement un plan factoriel complet, c'est-à-dire un plan dans lequel chaque combinaison de facteurs se produit.\n\n## Pseudorandomisation\n\nVous pouvez ajouter des contraintes de pseudorandomisation au script de l'élément loop. Cela permet de mélanger les lignes, même si l'ordre est réglé sur séquentiel. (Actuellement, cela n'est pas possible via l'interface graphique.)\n\nExemple : Assurez-vous que les répétitions du même mot (donné par la variable `word`) sont séparées par au moins 4 cycles :\n\n```python\nconstrain word mindist=4\n```"
  },
  "Example: Make sure that the same word is not repeated:\n\n```python\nconstrain word maxrep=1\n```\n\n`constrain` commands must come *after* `setcycle` commands.\n\n## Advanced loop operations\n\nCommands for advanced loop operations must come *after* `constrain` and `setcycle` commands.\n\n### fullfactorial\n\nThe `fullfactorial` instruction treats the loop table as the input for a full-factorial design. For example, the following loop table:\n\ncue   | duration\n----- | --------\nleft  | 0\nright | 100\n      | 200\n\nWould result in:\n\ncue   | duration\n----- | --------\nleft  | 0\nleft  | 100\nleft  | 200\nright | 0\nright | 100\nright | 200\n\n### shuffle\n\n`shuffle` without argument randomizes the entire table. When a column name is specified (`shuffle cue`), only that column is randomized.\n\n### shuffle_horiz\n\n`shuffle_horiz` shuffles all columns horizontally. When multiple columns are specified, only those columns are shuffled horizontally.\n\nFor example, when `shuffle_horiz word1 word2` is applied to the following table:\n\nword1 | word2 | word3\n----- | ----- | -----\ncat   | dog   | bunny\ncat   | dog   | bunny\ncat   | dog   | bunny\n\nThe result could be (i.e. values are randomly swapped between `word1` and `word2`, but not `word3`):\n\nword1 | word2 | word3\n----- | ----- | -----\ndog   | cat   | bunny\ndog   | cat   | bunny\ncat   | dog   | bunny\n\n### slice\n\n`slice [from] [to]` selects a slice from the loop. It requires a start and an end index, where 0 is the first row, and negative values are counted from the end backwards. (Just like list slicing in Python, in other words.)\n\nFor example, when `slice 1 -1` is applied to the following table:\n\nword  |\n----- |\ncat   |\ndog   |\nbunny |\nhorse |\n\nThe result would be:\n\nword  |\n----- |\ndog   |\nbunny |\n\n### sort\n\n`sort [column]` sorts a single column, without changing any of the other columns.\n\n### sortby\n\n`sortby [column]` sorts the entire table by a single column.\n\n### reverse\n\n`reverse` reverses the order of the entire table. If a column name is specified (e.g. `reverse word`), only that column is reversed, without changing any of the other columns.\n\n### roll\n\n`roll [value]` rolls the entire table forward (for positive values) or backward (for negative values). If a column name is specified (e.g. `roll 1 word`), only that column is rolled, without changing any of the other columns.\n\nFor example, if `roll 1` is applied to the following table:\n\nword  |\n----- |\ncat   |\ndog   |\nbunny |\nhorse |\n\nThe result would be:\n\nword  |\n----- |\nhorse |\ncat   |\ndog   |\nbunny |\n\n### weight\n\n`weight [column]` repeats each row by a weighting value specified in a column.\n\nFor example, if `weight w` is applied to the following table:\n\nword  | w\n----- | -\ncat   | 0\ndog   | 0\nbunny | 2\nhorse | 1\n\nThe result would be:\n\nword  | w\n----- | -\nbunny | 2\nbunny | 2\nhorse | 1\n\n## Previewing the loop\n\nIf you have specified constraints, or have used advanced loop operations, then it is a good idea to check that the result is as expected. To do so, you can generate a preview of the loop table as it will be (or could be, in case of randomization) when you run the experiment.\n\nTo generate a preview, click on the *Preview* button.\n\n\n## Accessing the loop table in Python inline script\n\nThe original LOOP table, as you see it in the OpenSesame user interface, is a [`DataMatrix`](http://datamatrix.cogsci.nl/) object called `dm`, and is a property of the LOOP item.\n\nThis original LOOP table is usually transformed in various ways; for example, the order of the rows can be randomized, and rows can be repeated multiple times. The transformed LOOP is also a `DataMatrix` object, and is called `live_dm`. `live_dm` is created just before the loop is executed and is set to `None` when the loop is finished; that is, `live_dm` is only available during the *run* phase of the LOOP.\n\nFinally, the index of the current row is stored as the experimental variable `live_row`. That is, `live_row` indicates the currently active row of `live_dm`.": {
    "fr": "Exemple: Assurez-vous que le même mot n'est pas répété:\n\n```python\nconstrain word maxrep=1\n```\n\nLes commandes `constrain` doivent venir *après* les commandes `setcycle`.\n\n## Opérations avancées sur les boucles\n\nLes commandes pour les opérations avancées sur les boucles doivent venir *après* les commandes `constrain` et `setcycle`.\n\n### fullfactorial\n\nL'instruction `fullfactorial` traite la table de boucle comme l'entrée pour un plan factoriel complet. Par exemple, la table de boucle suivante:\n\ncue   | duration\n----- | --------\nleft  | 0\nright | 100\n      | 200\n\nDonnera comme résultat:\n\ncue   | duration\n----- | --------\nleft  | 0\nleft  | 100\nleft  | 200\nright | 0\nright | 100\nright | 200\n\n### shuffle\n\n`shuffle` sans argument mélange toute la table. Lorsqu'un nom de colonne est spécifié (`shuffle cue`), seule cette colonne est mélangée.\n\n### shuffle_horiz\n\n`shuffle_horiz` mélange toutes les colonnes horizontalement. Lorsque plusieurs colonnes sont spécifiées, seules ces colonnes sont mélangées horizontalement.\n\nPar exemple, lorsque `shuffle_horiz word1 word2` est appliqué à la table suivante :\n\nword1 | word2 | word3\n----- | ----- | -----\ncat   | dog   | bunny\ncat   | dog   | bunny\ncat   | dog   | bunny\n\nLe résultat pourrait être (c'est-à-dire que les valeurs sont échangées de manière aléatoire entre `word1` et `word2`, mais pas `word3`):\n\nword1 | word2 | word3\n----- | ----- | -----\ndog   | cat   | bunny\ndog   | cat   | bunny\ncat   | dog   | bunny\n\n### slice\n\n`slice [from] [to]` sélectionne une partie de la boucle. Il nécessite un indice de début et de fin, où 0 est la première ligne et les valeurs négatives sont comptées à partir de la fin vers l'arrière. (Comme dans le découpage de liste en Python, en d'autres termes.)\n\nPar exemple, lorsque `slice 1 -1` est appliqué à la table suivante :\n\nword  |\n----- |\ncat   |\ndog   |\nbunny |\nhorse |\n\nLe résultat serait:\n\nword  |\n----- |\ndog   |\nbunny |\n\n### sort\n\n`sort [column]` trie une seule colonne, sans modifier les autres colonnes.\n\n### sortby\n\n`sortby [column]` trie la table entière par une seule colonne.\n\n### reverse\n\n` reverse` inverse l'ordre de toute la table. Si un nom de colonne est spécifié (par exemple, `reverse word`), seule cette colonne est inversée, sans changer les autres colonnes.\n\n### roll\n\n` roll [value]` fait avancer (pour les valeurs positives) ou reculer (pour les valeurs négatives) toute la table. Si un nom de colonne est spécifié (par exemple, `roll 1 word`), seule cette colonne est décalée, sans changer les autres colonnes.\n\nPar exemple, si `roll 1` est appliqué à la table suivante :\n\nword  |\n----- |\ncat   |\ndog   |\nbunny |\nhorse |\n\nLe résultat serait:\n\nword  |\n----- |\nhorse |\ncat   |\ndog   |\nbunny |\n\n### weight\n\n` weight [column]` répète chaque ligne en fonction d'une valeur de pondération spécifiée dans une colonne.\n\nPar exemple, si `weight w` est appliqué à la table suivante :\n\nword  | w\n----- | -\ncat   | 0\ndog   | 0\nbunny | 2\nhorse | 1\n\nLe résultat serait:\n\nword  | w\n----- | -\nbunny | 2\nbunny | 2\nhorse | 1\n\n## Aperçu de la boucle\n\nSi vous avez spécifié des contraintes ou utilisé des opérations avancées sur les boucles, il est conseillé de vérifier que le résultat est celui attendu. Pour ce faire, vous pouvez générer un aperçu de la table de boucle telle qu'elle sera (ou pourrait être, en cas de randomisation) lorsque vous exécuterez l'expérience.\n\nPour générer un aperçu, cliquez sur le bouton *Aperçu*.\n\n## Accéder à la table de boucle dans un script Python en ligne\n\nLa table LOOP d'origine, telle que vous la voyez dans l'interface utilisateur d'OpenSesame, est un objet [`DataMatrix`](http://datamatrix.cogsci.nl/) appelé `dm`, et est une propriété de l'élément LOOP.\n\nCette table LOOP d'origine est généralement transformée de diverses manières ; par exemple, l'ordre des lignes peut être randomisé, et les lignes peuvent être répétées plusieurs fois. La LOOP transformée est également un objet `DataMatrix`, et s'appelle `live_dm`. `live_dm` est créé juste avant l'exécution de la boucle et est défini à `None` lorsque la boucle est terminée ; c'est-à-dire que `live_dm` est disponible uniquement pendant la phase *run* de la LOOP.\n\nEnfin, l'indice de la ligne courante est stocké dans la variable expérimentale `live_row`. C'est-à-dire que `live_row` indique la ligne active de `live_dm`."
  },
  "So let's say that we have a LOOP called *block_loop*. We could then access the LOOP table in a Python inline script as follows:\n\n~~~ .python\nprint('The original loop table:')\nprint(items['block_loop'].dm)\n\nprint('The transformed loop table:')\nprint(items['block_loop'].live_dm)\n\nprint('The current row:')\nprint(items['block_loop'].live_dm[var.live_row])\n~~~\n\nYou can even programatically define the LOOP table. You have to do this in the Prepare phase of an INLINE_SCRIPT that precedes the LOOP.\n\n```python\nfrom datamatrix import DataMatrix\n\nitems['block_loop'].dm = DataMatrix(length=4)\nitems['block_loop'].dm.cue_side = 'left', 'right', 'left', 'right'\nitems['block_loop'].dm.cue_validity = 'valid', 'valid', 'invalid', 'invalid'\n```\n\n`DataMatrix` objects are powerful structures for working with tabular data. For more information, see:\n\n- <https://pydatamatrix.eu/>\n": {
    "fr": "Alors, disons que nous avons une LOOP appelée *block_loop*. Nous pourrions alors accéder à la table LOOP dans un script Python en ligne comme suit :\n\n~~~ .python\nprint(\"La table originale de la boucle :\")\nprint(items['block_loop'].dm)\n\nprint(\"La table de boucle transformée :\")\nprint(items['block_loop'].live_dm)\n\nprint(\"La ligne actuelle :\")\nprint(items['block_loop'].live_dm[var.live_row])\n~~~\n\nVous pouvez même définir la table LOOP de manière programmatique. Vous devez le faire dans la phase de préparation d'un INLINE_SCRIPT qui précède la LOOP.\n\n```python\nfrom datamatrix import DataMatrix\n\nitems['block_loop'].dm = DataMatrix(length=4)\nitems['block_loop'].dm.cue_side = 'gauche', 'droite', 'gauche', 'droite'\nitems['block_loop'].dm.cue_validity = 'valide', 'valide', 'invalide', 'invalide'\n```\n\nLes objets `DataMatrix` sont des structures puissantes pour travailler avec des données tabulaires. Pour plus d'informations, consultez :\n\n- <https://pydatamatrix.eu/>"
  },
  "Doing things in sequence": {
    "fr": "Faire des choses en séquence"
  },
  "The SEQUENCE item has two important functions:\n\n- It runs multiple other items one after another.\n- It determines which items should, and which shouldn't, be run.\n\nSEQUENCEs are run from top to bottom; that is, the item at the top is run first. The order of a SEQUENCE is always sequential.\n\n## Run-if expressions\n\nYou can use run-if expressions to determine whether or not a particular item should be run. For example, if you want a display to be presented only if a participant has made an incorrect response, you can set the run-if expressions for that item to:\n\n```python\n{correct} == 0\n```\n\nIf you leave the run-if expressions empty or enter `True`, the item will always be run. Run-if expressions use the same syntax as other conditional expressions. For more information, see:\n\n- %link:manual/variables%\n\nRun-if expressions only affect which items are run, not which items are prepared. Phrased differently, the Prepare phase of all items in a SEQUENCE is always executed, regardless of the run-if expressions. See also:\n\n- %link:prepare-run%\n\n\n## Disabling items\n\nTo completely disable an item in a SEQUENCE, right-click on it and select 'Disable'. This is mostly useful during development of your experiment, for example to temporarily bypass the instructions.\n": {
    "fr": "L'élément SEQUENCE a deux fonctions importantes :\n\n- Il exécute plusieurs autres éléments l'un après l'autre.\n- Il détermine quels éléments doivent être exécutés et lesquels ne doivent pas l'être.\n\nLes SEQUENCEs sont exécutées de haut en bas ; c'est-à-dire que l'élément situé en haut est exécuté en premier. L'ordre d'une SEQUENCE est toujours séquentiel.\n\n## Expressions run-if\n\nVous pouvez utiliser des expressions run-if pour déterminer si un élément particulier doit être exécuté ou non. Par exemple, si vous souhaitez afficher un écran uniquement si un participant a donné une réponse incorrecte, vous pouvez définir les expressions run-if pour cet élément comme suit :\n\n```python\n{correct} == 0\n```\n\nSi vous laissez les expressions run-if vides ou saisissez `True`, l'élément sera toujours exécuté. Les expressions run-if utilisent la même syntaxe que les autres expressions conditionnelles. Pour plus d'informations, consultez :\n\n- %link:manuel/variables%\n\nLes expressions run-if n'affectent que les éléments exécutés, et non ceux qui sont préparés. Autrement dit, la phase de préparation de tous les éléments d'une SEQUENCE est toujours exécutée, indépendamment des expressions run-if. Voir également :\n\n- %link:prepare-run%\n\n\n## Désactiver les éléments\n\nPour désactiver complètement un élément dans une SEQUENCE, cliquez dessus avec le bouton droit de la souris et sélectionnez 'Disable' (Désactiver). Ceci est principalement utile lors du développement de votre expérience, par exemple pour contourner temporairement les instructions."
  },
  "Access experimental variables": {
    "fr": "Accéder aux variables expérimentales"
  },
  "%-- include: include/api/var.md --%\n": {
    "fr": "%-- inclure : include/api/var.md --%"
  },
  "Access the file pool": {
    "fr": "Accédez au pool de fichiers"
  },
  "%-- include: include/api/pool.md --%\n": {
    "fr": "%-- include: include/api/pool.md --%"
  },
  "%-- include: include/api/canvas.md --%\n": {
    "fr": "%-- inclure: include/api/canvas.md --%"
  },
  "Access items": {
    "fr": "Accéder aux éléments"
  },
  "%-- include: include/api/items.md --%\n": {
    "fr": "%-- include: include/api/items.md ---%"
  },
  "Clock functions": {
    "fr": "Fonctions d'horloge"
  },
  "%-- include: include/api/clock.md --%\n": {
    "fr": "%-- inclure: inclure/api/horloge.md --%"
  },
  "Sampler functions": {
    "fr": "Fonctions de l'échantillonneur"
  },
  "%-- include: include/api/sampler.md --%\n": {
    "fr": "%-- include: include/api/sampler.md --%"
  },
  "Access response history": {
    "fr": "Accéder à l'historique des réponses"
  },
  "%-- include: include/api/responses.md --%\n": {
    "fr": "%-- include: inclure/api/réponses.md --%"
  },
  "Log functions": {
    "fr": "Fonctions de journalisation"
  },
  "%-- include: include/api/log.md --%\n": {
    "fr": "%-- include: include/api/log.md --%"
  },
  "About Python": {
    "fr": "À propos de Python"
  },
  "In OpenSesame you can create complex experiments using only the graphical user interface (GUI). But you will sometimes encounter situations in which the functionality provided by the GUI is insufficient. In these cases you can add Python code to your experiment.\n\nPython is not supported in online experiments with OSWeb. If you need to run your experiment online, you have to use [JavaScript](%url:manual/javascript/about%) instead.\n\n<notranslate>[TOC]</notranslate>\n\n## Learning Python\n\nYou can find a set of basic tutorials and exercises to get you started with Python at <https://pythontutorials.eu/>.\n\n\n## Python in the OpenSesame GUI\n\n### A single Python workspace\n\nAll Python code is executed in a single Python workspace. This means that variables that have been defined in one INLINE_SCRIPT are accessible in all other INLINE_SCRIPTs, as well as in Python statements that are embedded in run-if statements and text strings. The same principle applies to modules: once `import`ed, they are available everywhere.\n\nFor example, you can simply construct the `Canvas` in one INLINE_SCRIPT ...\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\n~~~\n\n... and show it in another INLINE_SCRIPT ...\n\n~~~ .python\nmy_canvas.show()\n~~~\n\n### Inline_script items\n\nIn order to use Python code you need to add an INLINE_SCRIPT item to your experiment. You can do this by dragging the Python icon (the blue/yellow icon) from the item toolbar into the experiment sequence. After you have done this you will see something like %FigInlineScript.\n\n<notranslate>\nfigure:\n id: FigInlineScript\n source: inline-script.png\n caption: The INLINE_SCRIPT item.\n</notranslate>\n\nAs you can see, the INLINE_SCRIPT item consists of two tabs: one for the Prepare phase and one for the Run phase. The Prepare phase is executed first, to allow items to prepare for the time-critical run phase. It is good practice to construct `Canvas` objects, `Sampler` objects, etc. during the Prepare phase, so that they can be presented without delay during the Run phase. But this is only convention; you can execute arbitrary Python code during both phases.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Conditional (\"if\") expressions\n\nYou can use single-line Python expressions in conditional expressions. For example, you can use the following Python script as a run-if expression (see also %FigRunIf):\n\n~~~ .python\ncorrect == 1 and response_time < 1000\n~~~\n\n<notranslate>\nfigure:\n id: FigRunIf\n source: run-if.png\n caption: Using Python script in the run-if statement of a SEQUENCE item.\n</notranslate>\n\nFor more information about conditional (\"if\") expressions, see:\n\n- %link:manual/variables%\n\n\n### Python in text strings\n\nYou can embed Python statements in text strings using the `{...} syntax. This works for simple variable references, but also for single-line expressions. For example, you could the following text to a SKETCHPAD:\n\n```text\nThe resolution is {width} x {height} px, which is a total of {width * height} pixels\n```\n\nDepending on your experiment's resolution, this might evaluate to:\n\n```text\nThe resolution is 1024 x 768 px, which is a total of 786432 pixels\n```\n\nFor more information about variables and text, see:\n\n- %link:manual/variables%\n- %link:manual/stimuli/text%\n\n\n### The Jupyter console (debug window)\n\nOpenSesame reroutes the standard output to the console (or: debug window), which you can activate using Control + D or through the menu (Menu -> View -> Show debug window; see %FigDebugNormal). You can print to the console using `print()`.\n\n~~~ .python\nprint('This will appear in the debug window!')\n~~~\n\nThe console is also an interactive Python interpreter powered by [project Jupyter](https://jupyter.org).\n\n\n## Things to know\n\n### Common functions\n\nMany common functions are directly available in an INLINE_SCRIPT item, without the need to import anything. For example:": {
    "fr": "Dans OpenSesame, vous pouvez créer des expériences complexes en utilisant uniquement l'interface graphique (GUI). Cependant, vous rencontrerez parfois des situations dans lesquelles les fonctionnalités offertes par la GUI sont insuffisantes. Dans ces cas, vous pouvez ajouter du code Python à votre expérience.\n\nPython n'est pas pris en charge dans les expériences en ligne avec OSWeb. Si vous devez exécuter votre expérience en ligne, vous devez utiliser [JavaScript](%url:manual/javascript/about%) à la place.\n\n<notranslate>[TOC]</notranslate>\n\n## Apprendre Python\n\nVous pouvez trouver un ensemble de tutoriels et d'exercices de base pour commencer avec Python sur <https://pythontutorials.eu/>.\n\n## Python dans l'interface graphique d'OpenSesame\n\n### Un seul espace de travail Python\n\nTout le code Python est exécuté dans un seul espace de travail Python. Cela signifie que les variables définies dans un INLINE_SCRIPT sont accessibles dans tous les autres INLINE_SCRIPT, ainsi que dans les instructions Python intégrées dans les instructions run-if et les chaînes de texte. Le même principe s'applique aux modules : une fois `importé`, ils sont disponibles partout.\n\nPar exemple, vous pouvez simplement construire le `Canvas` dans un INLINE_SCRIPT...\n\n~~~ .python\nmon_canvas = Canvas()\nmon_canvas.fixdot()\n~~~\n\n... et le montrer dans un autre INLINE_SCRIPT ...\n\n~~~ .python\nmon_canvas.show()\n~~~\n\n### Éléments inline_script\n\nPour utiliser du code Python, vous devez ajouter un élément INLINE_SCRIPT à votre expérience. Vous pouvez le faire en faisant glisser l'icône Python (l'icône bleue/jaune) de la barre d'outils des éléments dans la séquence de l'expérience. Après avoir fait cela, vous verrez quelque chose comme %FigInlineScript.\n\n<notranslate>\nfigure:\n id: FigInlineScript\n source: inline-script.png\n caption: L'élément INLINE_SCRIPT.\n</notranslate>\n\nComme vous pouvez le voir, l'élément INLINE_SCRIPT se compose de deux onglets : un pour la phase de préparation et un pour la phase d'exécution. La phase de préparation est exécutée en premier, pour permettre aux éléments de se préparer pour la phase d'exécution sensible au temps. Il est recommandé de construire des objets `Canvas`, des objets `Sampler`, etc. pendant la phase de préparation, afin qu'ils puissent être présentés sans délai pendant la phase d'exécution. Mais il ne s'agit que d'une convention ; vous pouvez exécuter du code Python arbitraire pendant les deux phases.\n\nPour plus d'informations sur la stratégie de préparation-exécution, voir :\n\n- %link:prepare-run%\n\n### Expressions conditionnelles (\"if\")\n\nVous pouvez utiliser des expressions Python d'une seule ligne dans les expressions conditionnelles. Par exemple, vous pouvez utiliser le script Python suivant comme expression run-if (voir aussi %FigRunIf) :\n\n~~~ .python\ncorrect == 1 and response_time < 1000\n~~~\n\n<notranslate>\nfigure:\n id: FigRunIf\n source: run-if.png\n caption: Utilisation du script Python dans l'instruction run-if d'un élément SEQUENCE.\n</notranslate>\n\nPour plus d'informations sur les expressions conditionnelles (\"if\"), voir :\n\n- %link:manual/variables%\n\n### Python dans les chaînes de texte\n\nVous pouvez intégrer des instructions Python dans les chaînes de texte en utilisant la syntaxe {...}. Cela fonctionne pour les références de variables simples, mais aussi pour les expressions d'une seule ligne. Par exemple, vous pouvez ajouter le texte suivant à un SKETCHPAD :\n\n```text\nLa résolution est de {width} x {height} px, soit un total de {width * height} pixels\n```\n\nEn fonction de la résolution de votre expérience, cela pourrait donner :\n\n```text\nLa résolution est de 1024 x 768 px, soit un total de 786432 pixels\n```\n\nPour plus d'informations sur les variables et le texte, voir :\n\n- %link:manual/variables%\n- %link:manual/stimuli/text%\n\n### La console Jupyter (fenêtre de débogage)\n\nOpenSesame redirige la sortie standard vers la console (ou : fenêtre de débogage), que vous pouvez activer avec la touche Contrôle + D ou via le menu (Menu -> Affichage -> Afficher la fenêtre de débogage ; voir %FigDebugNormal). Vous pouvez imprimer sur la console en utilisant `print()`.\n\n~~~ .python\nprint('Ceci apparaîtra dans la fenêtre de débogage !')\n~~~\n\nLa console est également un interpréteur Python interactif alimenté par [projet Jupyter](https://jupyter.org).\n\n## Choses à savoir\n\n### Fonctions courantes\n\nDe nombreuses fonctions courantes sont directement disponibles dans un élément INLINE_SCRIPT, sans avoir besoin d'importer quoi que ce soit. Par exemple :"
  },
  "~~~ .python\n# `Canvas()` is a factory function that returns a `Canvas` object\nfixdot_canvas = Canvas()\nif sometimes(): # Sometimes the fixdot is green\n    fixdot_canvas.fixdot(color='green')\nelse: # Sometimes it is red\n    fixdot_canvas.fixdot(color='red')\nfixdot_canvas.show()\n~~~\n\nFor a list of common functions, see:\n\n- %link:manual/python/common%\n\n\n### The `var` object: Access to experimental variables\n\n__Version note__ As of OpenSesame 4.0, all experimental variables are available as globals. This means that you no longer need the `var` object.\n{:.page-notification}\n\nYou can access experimental variables through the `var` object:\n\n~~~ .python\n# Get an experimental variable\nprint('my_variable is: %s' % var.my_variable)\n# Set an experimental variable\nvar.my_variable = 'my_value'\n~~~\n\nA full overview of the `var` object can be found here:\n\n- %link:manual/python/var%\n\n\n### The `clock` object: Time functions\n\nBasic time functions are available through the `clock` object:\n\n~~~ .python\n# Get the current timestamp\nt = clock.time()\n# Wait for 1 s\nclock.sleep(1000)\n~~~\n\nA full overview of the `clock` object can be found here:\n\n- %link:manual/python/clock%\n\n\n### The `log` object: Data logging\n\nData logging is available through the `log` object:\n\n~~~ .python\n# Write one line of text\nlog.write('My custom log message')\n# Write all variables\nlog.write_vars()\n~~~\n\nA full overview of the `log` object can be found here:\n\n- %link:manual/python/log%\n\n\n### The `pool` object: Access to the file pool\n\nYou get the full path to a file in the file pool through the `pool` object:\n\n~~~ .python\n# Show an image from the file pool\npath = pool['img.png']\nmy_canvas = Canvas()\nmy_canvas.image(path)\nmy_canvas.show()\n~~~\n\nA full overview of the `pool` object can be found here:\n\n- %link:manual/python/pool%\n\n\n### The `responses` object: Access to participant responses\n\nThe `responses` object keeps track of all participant responses that have been collected during the experiment. For example, to list the correctness of all responses so far:\n\n~~~ .python\nfor response in responses:\n\tprint(response.correct)\n~~~\n\nA full overview of the `responses` object can be found here:\n\n- %link:manual/python/responses%\n\n\n### The `Canvas` class: Presenting visual stimuli\n\nThe `Canvas` class is used to present visual stimuli. For example, you can show a fixation dot as follows:\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\nmy_canvas.show()\n~~~\n\nA full overview of the `Canvas` class can be found here:\n\n- %link:manual/python/canvas%\n\n\n### The `Keyboard` class: Collecting key presses\n\nThe `Keyboard` class is used to collect key presses. For example, to collect a key press with a timeout of 1000 ms:\n\n~~~ .python\nmy_keyboard = Keyboard(timeout=1000)\nkey, time = my_keyboard.get_key()\n~~~\n\nA full overview of the `Keyboard` class can be found here:\n\n- %link:manual/python/keyboard%\n\n\n### The `Mouse` class: Collecting mouse clicks and screen touches\n\nThe `Mouse` class is used to collect mouse clicks and screen touches. (OpenSesame makes no distinction between the two.) For example, to collect a mouse click with a timeout of 1000 ms:\n\n~~~ .python\nmy_mouse = Mouse(timeout=1000)\nbutton, position, time = my_mouse.get_click()\n~~~\n\nA full overview of the `Mouse` class can be found here:\n\n- %link:manual/python/mouse%\n\n\n### The `Sampler` class: Sound playback\n\nThe `Sampler` class is used to play back sound samples. For example, to play back a simple beep:\n\n~~~ .python\nmy_sampler = Sampler()\nmy_sampler.play()\n~~~\n\nA full overview of the `Sampler` class can be found here:\n\n- %link:manual/python/sampler%\n\n\n## Alternative modules for display presentation, response collection, etc.\n\n\n### `psychopy`\n\nIf you are using the *psycho* backend, you can directly use the various [PsychoPy] modules. For more information, see:\n\n- %link:backends%\n\n\n### `expyriment`\n\nIf you are using the *xpyriment* backend, you can directly use the various [Expyriment] modules. For more information, see:\n\n- %link:backends%": {
    "fr": "~~~ .python\n# `Canvas()` est une fonction usine qui renvoie un objet `Canvas`\nfixdot_canvas = Canvas()\nif sometimes(): # Parfois, le fixdot est vert\n    fixdot_canvas.fixdot(color='green')\nelse: # Parfois, il est rouge\n    fixdot_canvas.fixdot(color='red')\nfixdot_canvas.show()\n~~~\n\nPour une liste des fonctions courantes, consultez :\n\n- %link:manual/python/common%\n\n\n### L'objet `var` : Accès aux variables expérimentales\n\n__Note de version__ Depuis OpenSesame 4.0, toutes les variables expérimentales sont disponibles en tant que variables globales. Cela signifie que vous n'avez plus besoin de l'objet `var`.\n{:.page-notification}\n\nVous pouvez accéder aux variables expérimentales via l'objet `var` :\n\n~~~ .python\n# Obtenir une variable expérimentale\nprint('my_variable est : %s' % var.my_variable)\n# Définir une variable expérimentale\nvar.my_variable = 'my_value'\n~~~\n\nUn aperçu complet de l'objet `var` se trouve ici :\n\n- %link:manual/python/var%\n\n\n### L'objet `clock` : Fonctions de temps\n\nLes fonctions de temps de base sont disponibles via l'objet `clock` :\n\n~~~ .python\n# Obtenir l'horodatage actuel\nt = clock.time()\n# Attendre pendant 1 s\nclock.sleep(1000)\n~~~\n\nUn aperçu complet de l'objet `clock` se trouve ici :\n\n- %link:manual/python/clock%\n\n\n### L'objet `log` : Enregistrement des données\n\nL'enregistrement des données est disponible via l'objet `log` :\n\n~~~ .python\n# Écrire une ligne de texte\nlog.write('Mon message de journal personnalisé')\n# Écrire toutes les variables\nlog.write_vars()\n~~~\n\nUn aperçu complet de l'objet `log` se trouve ici :\n\n- %link:manual/python/log%\n\n\n### L'objet `pool` : Accès au pool de fichiers\n\nVous obtenez le chemin complet d'un fichier dans le pool de fichiers via l'objet `pool` :\n\n~~~ .python\n# Afficher une image du pool de fichiers\npath = pool['img.png']\nmy_canvas = Canvas()\nmy_canvas.image(path)\nmy_canvas.show()\n~~~\n\nUn aperçu complet de l'objet `pool` se trouve ici :\n\n- %link:manual/python/pool%\n\n\n### L'objet `responses` : Accès aux réponses des participants\n\nL'objet `responses` suit toutes les réponses des participants qui ont été collectées pendant l'expérience. Par exemple, pour lister la justesse de toutes les réponses jusqu'à présent :\n\n~~~ .python\nfor response in responses:\n\tprint(response.correct)\n~~~\n\nUn aperçu complet de l'objet `responses` se trouve ici :\n\n- %link:manual/python/responses%\n\n\n### La classe `Canvas` : Présentation de stimuli visuels\n\nLa classe `Canvas` est utilisée pour présenter des stimuli visuels. Par exemple, vous pouvez afficher un point de fixation comme suit :\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\nmy_canvas.show()\n~~~\n\nUn aperçu complet de la classe `Canvas` se trouve ici :\n\n- %link:manual/python/canvas%\n\n\n### La classe `Keyboard` : Collecte des touches du clavier\n\nLa classe `Keyboard` est utilisée pour collecter les pressions sur les touches. Par exemple, pour collecter une pression de touche avec un délai d'expiration de 1000 ms :\n\n~~~ .python\nmy_keyboard = Keyboard(timeout=1000)\nkey, time = my_keyboard.get_key()\n~~~\n\nUn aperçu complet de la classe `Keyboard` se trouve ici :\n\n- %link:manual/python/keyboard%\n\n\n### La classe `Mouse` : Collecte des clics de souris et des écrans tactiles\n\nLa classe `Mouse` est utilisée pour collecter les clics de souris et les écrans tactiles. (OpenSesame ne fait pas de distinction entre les deux.) Par exemple, pour collecter un clic de souris avec un délai d'expiration de 1000 ms :\n\n~~~ .python\nmy_mouse = Mouse(timeout=1000)\nbutton, position, time = my_mouse.get_click()\n~~~\n\nUn aperçu complet de la classe `Mouse` se trouve ici :\n\n- %link:manual/python/mouse%\n\n\n### La classe `Sampler` : Lecture de sons\n\nLa classe `Sampler` est utilisée pour lire des échantillons sonores. Par exemple, pour lire un simple bip :\n\n~~~ .python\nmy_sampler = Sampler()\nmy_sampler.play()\n~~~\n\nUn aperçu complet de la classe `Sampler` se trouve ici :\n\n- %link:manual/python/sampler%\n\n\n## Modules alternatifs pour la présentation d'affichages, la collecte de réponses, etc.\n\n\n### `psychopy`\n\nSi vous utilisez le backend *psycho*, vous pouvez utiliser directement les différents modules [PsychoPy]. Pour plus d'informations, consultez :\n\n- %link:backends%\n\n\n### `expyriment`\n\nSi vous utilisez le backend *xpyriment*, vous pouvez utiliser directement les différents modules [Expyriment]. Pour plus d'informations, consultez :\n\n- %link:backends%"
  },
  "### `pygame`\n\nIf you are using the *legacy*, *droid*, or *xpyriment* (only with \"Use OpenGL\" set to \"no\") backend, you can directly use the various [PyGame] modules. For more information, see:\n\n- %link:backends%\n\n\n[python]: http://www.python.org/\n[backends]: /backends/about-backends\n[ipython]: http://ipython.org/\n[swaroop]: http://www.swaroopch.com/notes/Python\n[swaroop-direct]: http://www.ibiblio.org/swaroopch/byteofpython/files/120/byteofpython_120.pdf\n[downey]: http://www.greenteapress.com/thinkpython/\n[downey-direct]: http://www.greenteapress.com/thinkpython/thinkpython.pdf\n[opensesamerun]: /usage/opensesamerun/\n[psychopy]: http://www.psychopy.org/\n[expyriment]: http://www.expyriment.org/\n[pygame]: http://www.pygame.org/\n": {
    "fr": "### `pygame`\n\nSi vous utilisez le backend *legacy*, *droid*, ou *xpyriment* (uniquement avec \"Use OpenGL\" réglé sur \"non\"), vous pouvez utiliser directement les différents modules [PyGame]. Pour plus d'informations, consultez :\n\n- %link:backends%\n\n\n[python]: http://www.python.org/\n[backends]: /backends/about-backends\n[ipython]: http://ipython.org/\n[swaroop]: http://www.swaroopch.com/notes/Python\n[swaroop-direct]: http://www.ibiblio.org/swaroopch/byteofpython/files/120/byteofpython_120.pdf\n[downey]: http://www.greenteapress.com/thinkpython/\n[downey-direct]: http://www.greenteapress.com/thinkpython/thinkpython.pdf\n[opensesamerun]: /usage/opensesamerun/\n[psychopy]: http://www.psychopy.org/\n[expyriment]: http://www.expyriment.org/\n[pygame]: http://www.pygame.org/"
  },
  "Common functions": {
    "fr": "Fonctions communes"
  },
  "The following functions are available in INLINE_SCRIPT items:\n\n<notranslate>[TOC]</notranslate>\n\n<notranslate> include: include/api/python_workspace_api.md --%\n": {
    "fr": "Les fonctions suivantes sont disponibles dans les éléments INLINE_SCRIPT :\n\n<notranslate>[TOC]</notranslate>\n\n<notranslate> inclure : include/api/python_workspace_api.md --%"
  },
  "Keyboard functions": {
    "fr": "Fonctions du clavier"
  },
  "%-- include: include/api/keyboard.md --%\n": {
    "fr": "%-- include: include/api/clavier.md --%"
  },
  "Mouse functions": {
    "fr": "Fonctions de souris"
  },
  "%-- include: include/api/mouse.md --%\n": {
    "fr": "%-- include: include/api/souris.md --%"
  },
  "OpenSesame as a Python library (no GUI)": {
    "fr": "OpenSesame en tant que bibliothèque Python (pas d'interface graphique)"
  },
  "TODO\n": {
    "fr": "À FAIRE"
  },
  "Sound recording": {
    "fr": "Enregistrement sonore"
  },
  "<notranslate>[TOC]</notranslate>\n\n\n## Audio Low Latency plugins\n\nThe Audio Low Latency plugins, developed by Bob Rosbag, are the recommended way to record sound input. The main goal of this set of plugins is to play and record audio with minimal and predictable latencies to achieve a high accuracy and precision. The `PyAlsaAudio` package which uses the Linux ALSA audio system provided the best results within Python. `PortAudio` and `sounddevice` are cross-platform and work on both Windows as Linux.\n\nThe plugins are not installed by default, but can be installed through pip:\n\n```bash\npip install opensesame-plugin-audio-low-latency\n```\n\nSee also:\n\n- <https://pypi.org/project/opensesame-plugin-audio-low-latency/>\n\n\n## Sound recorder plugins\n\nThe sound recorder plugins, developed by Daniel Schreij, are no longer under active development and are therefore no longer recommended. More information about this set of plugins can be found on previous version of this page:\n\n- <https://osdoc.cogsci.nl/3.2/manual/response/soundrecording/>\n": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## Plugins Audio Low Latency\n\nLes plugins Audio Low Latency, développés par Bob Rosbag, sont la méthode recommandée pour enregistrer des entrées sonores. L'objectif principal de cet ensemble de plugins est de lire et d'enregistrer des sons avec des latences minimales et prévisibles pour atteindre une haute précision et exactitude. Le package `PyAlsaAudio`, qui utilise le système audio Linux ALSA, a donné les meilleurs résultats au sein de Python. `PortAudio` et `sounddevice` sont multiplateformes et fonctionnent aussi bien sur Windows que sur Linux.\n\nLes plugins ne sont pas installés par défaut, mais peuvent être installés via pip :\n\n```bash\npip install opensesame-plugin-audio-low-latency\n```\n\nVoir aussi :\n\n- <https://pypi.org/project/opensesame-plugin-audio-low-latency/>\n\n## Plugins enregistreur de son\n\nLes plugins enregistreur de son, développés par Daniel Schreij, ne sont plus en développement actif et ne sont donc plus recommandés. Vous trouverez plus d'informations sur cet ensemble de plugins dans la version précédente de cette page :\n\n- <https://osdoc.cogsci.nl/3.2/manual/response/soundrecording/>"
  },
  "SR Box": {
    "fr": "Boîte SR"
  },
  "<notranslate>[TOC]</notranslate>\n\n## About the srbox plugin\n\nThe serial response (SR) box is a button box, specifically designed for response collection in psychological experiments. The original version, developed by Psychology Software Tools, has 5 buttons, 5 lights, and is connected to the PC trough the serial port. There are also SR Box compatible devices by other manufacturers, which may differ in the number of buttons and lights and often use a USB connection, which emulates a serial port.\n\nThe SRBOX plugin for OpenSesame allows you to use the SR Box or compatible device in your OpenSesame experiments.\n\n## Screenshot\n\n<notranslate>\nfigure:\n  source: srbox.png\n  id: FigSrbox\n  caption: The srbox plugin in OpenSesame.\n</notranslate>\n\n## Setting the device name\n\nBy default, the plugin tries to autodetect your SR Box. If this works, you don't have to change it. If your experiment freezes, OpenSesame has chosen the wrong serial port and you must enter the device name manually. Under Windows, the device is probably called something like\n\n```text\nCOM4\n```\n\nUnder Linux the device is probably called something like\n\n```text\n/dev/tty0\n```\n\n## Requirements\n\nAn SR Box or compatible button box. Not all button boxes are compatible, see:\n\n- %link:buttonbox%\n\n## Using the SR Box from Python inline code\n\nThe `srbox` object does *not* exist when the plug-in is in dummy mode.\n\n<notranslate> include: include/api/srbox.md --%\n": {
    "fr": "<notranslate>[TOC]</notranslate>\n\n## À propos du plugin srbox\n\nLa boîte de réponse série (SR) est une boîte à boutons, spécifiquement conçue pour la collecte de réponses dans les expériences psychologiques. La version originale, développée par Psychology Software Tools, dispose de 5 boutons, 5 lumières et est connectée au PC via le port série. Il existe également des dispositifs compatibles avec la boîte SR Box fabriqués par d'autres fabricants, qui peuvent différer par le nombre de boutons et de lumières et utilisent souvent une connexion USB qui émule un port série.\n\nLe plugin SRBOX pour OpenSesame vous permet d'utiliser la boîte SR Box ou un dispositif compatible dans vos expériences OpenSesame.\n\n## Capture d'écran\n\n<notranslate>\nfigure:\n  source: srbox.png\n  id: FigSrbox\n  caption: Le plugin srbox dans OpenSesame.\n</notranslate>\n\n## Définition du nom du périphérique\n\nPar défaut, le plugin essaie de détecter automatiquement votre SR Box. Si cela fonctionne, vous n'avez pas besoin de le changer. Si votre expérience se bloque, OpenSesame a choisi le mauvais port série et vous devez entrer manuellement le nom du périphérique. Sous Windows, le périphérique est probablement appelé quelque chose comme\n\n```text\nCOM4\n```\n\nSous Linux, le périphérique est probablement appelé quelque chose comme\n\n```text\n/dev/tty0\n```\n\n## Exigences\n\nUne boîte de boutons SR Box ou compatible. Toutes les boîtes de boutons ne sont pas compatibles, voir :\n\n- %link:buttonbox%\n\n## Utiliser la SR Box depuis du code Python en ligne\n\nL'objet `srbox` n'existe *pas* lorsque le plug-in est en mode factice.\n\n<notranslate> include: include/api/srbox.md --%"
  },
  "Button box": {
    "fr": "Boîte de boutons"
  },
  "There are many different types of button boxes, and they all work in different ways. Therefore, there is no single OpenSesame item that works with all button boxes. (This is different from keyboards, which are standard devices that all work with the KEYBOARD_RESPONSE item.)\n\nCommon types of button boxes:\n\n- Some button boxes *emulate keypresses*. This is easy, because you can use the normal KEYBOARD_RESPONSE item.\n\t- %link:manual/response/keyboard%\n- Some button boxes *emulate a joystick*. This is also easy, because you can use the JOYSTICK plugin.\n\t- %link:joystick%\n- Some button boxes are compatible with the *Serial Response Box* that is developed by Psychology Software Tools. These button boxes are supported by the SRBOX plugin.\n\t- %link:srbox%\n- Some button boxes have their own Python libaries. In this case, you should be able to find example scripts of how to use the button box in Python, that is, in an OpenSesame INLINE_SCRIPT item.\n": {
    "fr": "Il existe de nombreux types de boîtes à boutons différents, et ils fonctionnent tous de différentes manières. Par conséquent, il n'y a pas de seul élément OpenSesame qui fonctionne avec toutes les boîtes à boutons. (Ceci est différent des claviers, qui sont des dispositifs standard qui fonctionnent tous avec l'élément KEYBOARD_RESPONSE.)\n\nTypes de boîtes à boutons courants :\n\n- Certaines boîtes à boutons *émulent des frappes*. C'est facile, car vous pouvez utiliser l'élément KEYBOARD_RESPONSE normal.\n\t- %link:manual/response/keyboard%\n- Certaines boîtes à boutons *émulent un joystick*. C'est également facile, car vous pouvez utiliser le plugin JOYSTICK.\n\t- %link:joystick%\n- Certaines boîtes à boutons sont compatibles avec le *Serial Response Box* développé par Psychology Software Tools. Ces boîtes à boutons sont prises en charge par le plugin SRBOX.\n\t- %link:srbox%\n- Certaines boîtes à boutons ont leurs propres bibliothèques Python. Dans ce cas, vous devriez être en mesure de trouver des exemples de scripts sur la façon d'utiliser la boîte à boutons en Python, c'est-à-dire dans un élément INLINE_SCRIPT OpenSesame."
  },
  "Keyboard responses": {
    "fr": "Réponses au clavier"
  },
  "Keyboard responses are collected with the KEYBOARD_RESPONSE item.\n\n<notranslate>[TOC]</notranslate>\n\n\n## Response variables\n\nThe KEYBOARD_RESPONSE sets the standard response variables as described here:\n\n- %link:manual/variables%\n\n## Key names\n\nKeys are generally identified by their character and/ or their description (depending on which is applicable). For example:\n\n- The `/` key is named 'slash' and '/'. You can use either of the two names.\n- The `a` is named 'a'.\n- The left-arrow key is named 'left'.\n\nIf you don't know what a particular key is named, you can:\n\n- Click on the 'List available keys' button; or\n- Create a simple experiment in which a KEYBOARD_RESPONSE is immediately followed by a FEEDBACK item with the text '{response}' on it. This will show the name of the previously collected response.\n\n\n## Correct response\n\nThe *Correct response* field indicates which response is considered correct. After a correct response, the `correct` variable is automatically set to 1; after an incorrect response (i.e. everything else), `correct` is set to 0; if no correct response is specified, `correct` is set to 'undefined'.\n\nYou can indicate the correct response in three main ways:\n\n- *Leave the field empty.* If you leave the *Correct response* field empty, OpenSesame will automatically check if a variable called `correct_response` has been defined, and, if so, use this variable for the correct response.\n- *Enter a literal value.* You can explicitly enter a response, such as 'left' in the case of a KEYBOARD_RESPONSE item. This is only useful if the correct response is fixed.\n- *Enter a variable name.* You can enter a variable, such as '{cr}'. In this case, this variable will be used for the correct response.\n\n\n## Allowed responses\n\nThe *Allowed responses* field indicates a list of allowed responses. All other responses will be ignored, except for 'Escape', which will pause the experiment. The allowed responses should be a semicolon-separated list of responses, such as 'a;left;/' for a KEYBOARD_RESPONSE. To accept all responses, leave the *Allowed responses* field empty.\n\n\n<notranslate>include: include/timeout.md--%\n\n## Collecting keyboard responses in Python\n\nYou can use the `keyboard` object to collect keyboard responses in Python:\n\n- %link:manual/python/keyboard%\n": {
    "fr": "Les réponses au clavier sont collectées avec l'élément KEYBOARD_RESPONSE.\n\n<notranslate>[TOC]</notranslate>\n\n\n## Variables de réponse\n\nLe KEYBOARD_RESPONSE définit les variables de réponse standard comme décrit ici :\n\n- %link:manual/variables%\n\n## Noms de touches\n\nLes touches sont généralement identifiées par leur caractère et/ou leur description (selon le cas). Par exemple :\n\n- La touche `/` est nommée 'slash' et '/'. Vous pouvez utiliser l'un ou l'autre des deux noms.\n- La touche `a` est nommée 'a'.\n- La touche flèche gauche est nommée 'left'.\n\nSi vous ne savez pas comment s'appelle une touche particulière, vous pouvez :\n\n- Cliquer sur le bouton 'Liste des touches disponibles' ; ou\n- Créer une expérience simple dans laquelle un KEYBOARD_RESPONSE est immédiatement suivi d'un élément FEEDBACK avec le texte '{response}' dessus. Cela montrera le nom de la réponse précédemment collectée.\n\n\n## Réponse correcte\n\nLe champ *Réponse correcte* indique quelle réponse est considérée comme correcte. Après une réponse correcte, la variable `correct` est automatiquement définie sur 1 ; après une réponse incorrecte (c'est-à-dire autre chose), `correct` est défini sur 0 ; si aucune réponse correcte n'est spécifiée, `correct` est défini sur 'undefined'.\n\nVous pouvez indiquer la réponse correcte de trois manières principales :\n\n- *Laissez le champ vide.* Si vous laissez le champ *Réponse correcte* vide, OpenSesame vérifiera automatiquement si une variable appelée `correct_response` a été définie et, le cas échéant, utilisera cette variable pour la réponse correcte.\n- *Entrez une valeur littérale.* Vous pouvez entrer explicitement une réponse, comme 'left' dans le cas d'un élément KEYBOARD_RESPONSE. Cela n'est utile que si la réponse correcte est fixe.\n- *Entrez un nom de variable.* Vous pouvez entrer une variable, comme '{cr}'. Dans ce cas, cette variable sera utilisée pour la réponse correcte.\n\n\n## Réponses autorisées\n\nLe champ *Réponses autorisées* indique une liste de réponses autorisées. Toutes les autres réponses seront ignorées, sauf 'Échap', qui mettra en pause l'expérience. Les réponses autorisées doivent être une liste de réponses séparées par des points-virgules, comme 'a;left;/' pour un KEYBOARD_RESPONSE. Pour accepter toutes les réponses, laissez le champ *Réponses autorisées* vide.\n\n<notranslate>include: include/timeout.md--%\n\n## Collecter des réponses au clavier en Python\n\nVous pouvez utiliser l'objet `keyboard` pour collecter des réponses au clavier en Python :\n\n- %link:manual/python/keyboard%"
  },
  "About JavaScript": {
    "fr": "À propos de JavaScript"
  },
  "In OpenSesame you can create complex experiments using only the graphical user interface (GUI). But you will sometimes encounter situations in which the functionality provided by the GUI is insufficient. In these cases you can add JavaScript code to your experiment.\n\nJavaScript is for experiments that run in a browser with OSWeb. If you need to run your experiment on the desktop, you need to use [Python](%url:manual/python/about%) instead of JavaScript.\n\n__Version note:__ Desktop support for JavaScript was removed in OpeSesame 4.0. This is because JavaScript support on the desktop was incomplete and was perceived by users as confusing without adding much benefit.\n{: .page-notification}\n\n<notranslate>[TOC]</notranslate>\n\n\n## Learning JavaScript\n\nThere are many JavaScript tutorials available online. One good resource is Code Academy:\n\n- <https://www.codecademy.com/learn/introduction-to-javascript>\n\n\n## JavaScript in the OpenSesame GUI\n\n\n### Inline_javascript items\n\nIn order to use JavaScript code you need to add an INLINE_JAVASCRIPT item to your experiment. After you have done this you will see something like %FigInlineJavaScript.\n\n<notranslate>\nfigure:\n id: FigInlineJavaScript\n source: inline-javascript.png\n caption: The INLINE_JAVASCRIPT item.\n</notranslate>\n\nAs you can see, the INLINE_JAVASCRIPT item consists of two tabs: one for the Prepare phase and one for the Run phase. The Prepare phase is executed first, to allow items to prepare for the time-critical run phase. It is good practice to construct `Canvas` objects during the Prepare phase, so that they can be presented without delay during the Run phase. But this is only convention; you can execute arbitrary JavaScript code during both phases.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Printing output to the console\n\nYou can print to the console with the `console.log()` command:\n\n```js\nconsole.log('This will appear in the console!')\n```\n\nWhen running on the desktop, the output will appear in the OpenSesame console (or: debug window). When running in a browser, the output will appear in the browser console.\n\n\n## Things to know\n\n### Common functions\n\nMany common functions are directly available in an INLINE_JAVASCRIPT item. For example:\n\n```js\n// `Canvas()` is a factory function that returns a `Canvas` object\nlet fixdotCanvas = Canvas()\nif (sometimes()) {  // Sometimes the fixdot is green\n    fixdotCanvas.fixdot({color: 'green'})\n} else {  // Sometimes it is red\n    fixdotCanvas.fixdot({color: 'red'})\n}\nfixdotCanvas.show()\n```\n\nFor a list of common functions, see:\n\n- %link:manual/javascript/common%\n\n\n### The `persistent` object: preserving objects across scripts\n\n__Version note__ As of OSWeb 2.0, all JavaScript code is executed in the same workspace and objects are therefore preserved across scripts. This means that you no longer need the `persistent` object.\n{:.page-notification}\n\nEach INLINE_JAVASCRIPT item is executed in its own workspace. This means—and this is different from Python INLINE_SCRIPT items!—that you cannot use variables or functions that you've declared in one script in another script. As a workaround, you can attach variables or functions as properties to the `persistent` object, which serves as a container of things that you want to preserve across scripts.\n\nThis way you can construct a `Canvas` in one INLINE_JAVASCRIPT ...\n\n```js\npersistent.myCanvas = Canvas()\npersistent.myCanvas.fixdot()\n```\n\n.. and show it in another INLINE_JAVASCRIPT:\n\n```js\npersistent.myCanvas.show()\n```\n\n\n### The `vars` object: Access to experimental variables\n\n__Version note__ As of OSWeb 2.0, all experimental variables are available as globals. This means that you no longer need the `vars` object.\n{:.page-notification}\n\nYou can access experimental variables through the `vars` object:\n\n```js\n// Get an experimental variable\nconsole.log('my_variable is: ' + vars.my_variable)\n// Set an experimental variable\nvars.my_variable = 'my_value'\n```": {
    "fr": "Dans OpenSesame, vous pouvez créer des expériences complexes en utilisant uniquement l'interface graphique (GUI). Mais il vous arrivera parfois de rencontrer des situations où les fonctionnalités offertes par le GUI sont insuffisantes. Dans ces cas, vous pouvez ajouter du code JavaScript à votre expérience.\n\nJavaScript est pour les expériences qui s'exécutent dans un navigateur avec OSWeb. Si vous avez besoin d'exécuter votre expérience sur le bureau, vous devez utiliser [Python](%url:manual/python/about%) au lieu de JavaScript.\n\n__Note de version :__ Le support du bureau pour JavaScript a été supprimé dans OpeSesame 4.0. Cela est dû au fait que la prise en charge de JavaScript sur le bureau était incomplète et perçue par les utilisateurs comme source de confusion sans apporter beaucoup d'avantages.\n{: .page-notification}\n\n<notranslate>[TOC]</notranslate>\n\n\n## Apprendre JavaScript\n\nIl existe de nombreux tutoriels JavaScript disponibles en ligne. Une bonne ressource est Code Academy :\n\n- <https://www.codecademy.com/learn/introduction-to-javascript>\n\n\n## JavaScript dans l'interface graphique OpenSesame\n\n\n### Éléments Inline_javascript\n\nPour utiliser du code JavaScript, vous devez ajouter un élément INLINE_JAVASCRIPT à votre expérience. Une fois cela fait, vous verrez quelque chose comme %FigInlineJavaScript.\n\n<notranslate>\nfigure:\n id: FigInlineJavaScript\n source: inline-javascript.png\n caption: L'élément INLINE_JAVASCRIPT.\n</notranslate>\n\nComme vous pouvez le voir, l'élément INLINE_JAVASCRIPT se compose de deux onglets : un pour la phase de préparation et un pour la phase d'exécution. La phase de préparation est exécutée en premier, pour permettre aux éléments de se préparer pour la phase d'exécution sensible au temps. Il est recommandé de construire les objets `Canvas` pendant la phase de préparation, afin qu'ils puissent être présentés sans délai pendant la phase d'exécution. Mais cela n'est qu'une convention ; vous pouvez exécuter du code JavaScript arbitraire pendant les deux phases.\n\nPour plus d'informations sur la stratégie de préparation-exécution, voir :\n\n- %link:prepare-run%\n\n\n### Afficher des informations sur la console\n\nVous pouvez imprimer sur la console avec la commande `console.log()` :\n\n```js\nconsole.log('Ceci apparaîtra dans la console !')\n```\n\nLors de l'exécution sur le bureau, la sortie apparaîtra dans la console OpenSesame (ou : fenêtre de débogage). Lors de l'exécution dans un navigateur, la sortie apparaîtra dans la console du navigateur.\n\n\n## Choses à savoir\n\n### Fonctions courantes\n\nDe nombreuses fonctions courantes sont directement disponibles dans un élément INLINE_JAVASCRIPT. Par exemple :\n\n```js\n// `Canvas()` est une fonction d'usine qui renvoie un objet `Canvas`\nlet fixdotCanvas = Canvas()\nif (sometimes()) {  // Parfois, le fixdot est vert\n    fixdotCanvas.fixdot({color: 'green'})\n} else {  // Parfois, il est rouge\n    fixdotCanvas.fixdot({color: 'red'})\n}\nfixdotCanvas.show()\n```\n\nPour une liste de fonctions courantes, voir :\n\n- %link:manual/javascript/common%\n\n\n### L'objet `persistent` : conserver des objets entre les scripts\n\n__Note de version__ À partir d'OSWeb 2.0, tous les codes JavaScript sont exécutés dans le même espace de travail et les objets sont donc conservés entre les scripts. Cela signifie que vous n'avez plus besoin de l'objet `persistent`.\n{:.page-notification}\n\nChaque élément INLINE_JAVASCRIPT est exécuté dans son propre espace de travail. Cela signifie — et cela diffère des éléments Python INLINE_SCRIPT ! — que vous ne pouvez pas utiliser de variables ou de fonctions que vous avez déclarées dans un script dans un autre script. Pour contourner cela, vous pouvez attacher des variables ou des fonctions en tant que propriétés à l'objet `persistent`, qui sert de conteneur pour les choses que vous voulez conserver entre les scripts.\n\nDe cette manière, vous pouvez construire un `Canvas` dans un INLINE_JAVASCRIPT ...\n\n```js\npersistent.myCanvas = Canvas()\npersistent.myCanvas.fixdot()\n```\n\n... et l'afficher dans un autre INLINE_JAVASCRIPT :\n\n```js\npersistent.myCanvas.show()\n```\n\n\n### L'objet `vars` : Accès aux variables expérimentales\n\n__Note de version__ À partir d'OSWeb 2.0, toutes les variables expérimentales sont disponibles en tant que globales. Cela signifie que vous n'avez plus besoin de l'objet `vars`.\n{:.page-notification}\n\nVous pouvez accéder aux variables expérimentales via l'objet `vars` :\n\n```js\n// Obtenir une variable expérimentale\nconsole.log('my_variable est : ' + vars.my_variable)\n// Définir une variable expérimentale\nvars.my_variable = 'my_value'\n```"
  },
  "\n### The `pool` object: Access to the file pool\n\nYou access 'files' from the file pool through the `pool` object. The most obvious use of this is to parse CSV files, for example with experimental conditions, from the file pool using the `csv-parse` library (described in more detail below).\n\n```js\nconst conditions = csvParse(\n    pool['attentional-capture-jobs.csv'].data,\n    {columns: true}\n)\nfor (const trial of conditions) {\n    console.log(trial.distractor)\n}\n```\n\nYou can also play sound files from the file pool directly. Assuming that there is a file called `bark.ogg` in the file pool, you can play it like so:\n\n```js\npool['bark.ogg'].data.play()\n```\n\n\n### The `Canvas` class: Presenting visual stimuli\n\nThe `Canvas` class is used to present visual stimuli. For example, you can show a fixation dot as follows:\n\n```js\nlet myCanvas = Canvas()\nmyCanvas.fixdot()\nmyCanvas.show()\n```\n\nA full overview of the `Canvas` class can be found here:\n\n- %link:manual/javascript/canvas%\n\n\n## Available JavaScript libraries\n\nSeveral convenient JavaScript libraries are bundled with OSWeb.\n\n\n### random-ext: advanced randomization\n\n\nThe `random-ext` library is available as `random`. This library provides many convenient, higher-level functions for randomization.\n\n__Example:__\n\nDraw eight circle with a random color and a location that is randomly sampled from a five by five grid:\n\n```js\nlet positions = xy_grid(5, 50)\npositions = random.subArray(positions, 8)\nconst cnv = Canvas()\ncnv.fixdot()\nfor (const [x, y] of positions) {\n    cnv.circle({x: x, y: y, r: 20, fill: true, color: random.color()})\n}\ncnv.show()\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/random-ext>\n\n\n### pythonic: Python-like functions for iterating over arrays\n\nThe `pythonic` library provides Python-like functions for iterating over arrays. Available functions are: `range()`, `enumerate()`, `items()`, `zip()`, and `zipLongest()`.\n\n__Example:__\n\nDraw a five by five grid of incrementing numbers:\n\n```js\nlet positions = xy_grid(5, 50)\nconst cnv = Canvas()\nfor (const [i, [x, y]] of enumerate(positions)) {\n    cnv.text({text: i, x: x, y: y})\n}\ncnv.show()\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/pythonic>\n\n\n### color-convert: color conversion utilities\n\nThe `color-convert` library is available as `convert`. It provides convenient high level functions for converting from one color specification to another.\n\n__Example:__\n\n```js\nconsole.log('The RGB values for blue are ' + convert.keyword.rgb('blue'))\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/color-convert>\n\n\n### csv-parse: parse CSV-formatted text into an Object\n\nThe synchronous `parse()` function from the `csv-parse` library is available. This allows you to parse CSV-formatted text, for example from a CSV file in the file pool, into an Object.\n\n__Example:__\n\n```js\nconst conditions = csvParse(\n    pool['attentional-capture-jobs.csv'].data,\n    {columns: true}\n)\nfor (const trial of conditions) {\n    console.log(trial.distractor)\n}\n```\n\nFor an overview, see:\n\n- <https://csv.js.org/parse/api/sync/#sync-api>\n\n\n## Debugging\n\nMost modern browsers, especially Chrome and Firefox, have a powerful built-in debugger. You can activate the debugger by adding a line that simply states `debugger` to your script (%FigDebuggerInlineJavaScript).\n\n<notranslate>\nfigure:\n id: FigDebuggerInlineJavaScript\n source: debugger-inline-javascript.png\n caption: Activating the debugger from an INLINE_JAVASCRIPT item.\n</notranslate>\n\n\nThen start the experiment and show the debugger (or: Dev tools in Chrome, or: Web Developer Tools in Firefox) as soon as the OSWeb welcome screen appears. The debugger will then pause the experiment when it encounters the `debugger` statement. At this point, you can use the Console to interact with the JavaScript workspace, or you can inspect variables using the Scope tool (%FigDebuggerChrome).": {
    "fr": "### L'objet `pool` : Accès au pool de fichiers\n\nVous accédez aux 'fichiers' du pool de fichiers via l'objet `pool`. L'utilisation la plus évidente de cela est de parser les fichiers CSV, par exemple avec les conditions expérimentales, à partir du pool de fichiers en utilisant la bibliothèque `csv-parse` (décrite plus en détail ci-dessous).\n\n```js\nconst conditions = csvParse(\n    pool['attentional-capture-jobs.csv'].data,\n    {columns: true}\n)\nfor (const trial of conditions) {\n    console.log(trial.distractor)\n}\n```\n\nVous pouvez également jouer des fichiers sonores directement à partir du pool de fichiers. En supposant qu'il y ait un fichier appelé `bark.ogg` dans le pool de fichiers, vous pouvez le jouer comme suit :\n\n```js\npool['bark.ogg'].data.play()\n```\n\n\n### La classe `Canvas` : Présentation de stimuli visuels\n\nLa classe `Canvas` est utilisée pour présenter des stimuli visuels. Par exemple, vous pouvez montrer un point de fixation comme suit:\n\n```js\nlet myCanvas = Canvas()\nmyCanvas.fixdot()\nmyCanvas.show()\n```\n\nUn aperçu complet de la classe `Canvas` peut être trouvé ici:\n\n- %link:manuel/javascript/canvas%\n\n\n## Bibliothèques JavaScript disponibles\n\nPlusieurs bibliothèques JavaScript pratiques sont intégrées dans OSWeb.\n\n\n### random-ext: randomisation avancée\n\nLa bibliothèque `random-ext` est disponible sous le nom de `random`. Cette bibliothèque fournit de nombreuses fonctions pratiques et de haut niveau pour la randomisation.\n\n__Exemple :__\n\nDessinez huit cercles avec une couleur aléatoire et une position qui est échantillonnée aléatoirement dans une grille de cinq sur cinq :\n\n```js\nlet positions = xy_grid(5, 50)\npositions = random.subArray(positions, 8)\nconst cnv = Canvas()\ncnv.fixdot()\nfor (const [x, y] of positions) {\n    cnv.circle({x: x, y: y, r: 20, fill: true, color: random.color()})\n}\ncnv.show()\n```\n\nPour un aperçu, voir :\n\n- <https://www.npmjs.com/package/random-ext>\n\n\n### pythonic: Fonctions similaires à Python pour itérer sur des tableaux\n\nLa bibliothèque `pythonic` fournit des fonctions similaires à Python pour itérer sur des tableaux. Les fonctions disponibles sont : `range()`, `enumerate()`, `items()`, `zip()`, et `zipLongest()`.\n\n__Exemple :__\n\nDessinez une grille de cinq sur cinq de chiffres croissants :\n\n```js\nlet positions = xy_grid(5, 50)\nconst cnv = Canvas()\nfor (const [i, [x, y]] of enumerate(positions)) {\n    cnv.text({text: i, x: x, y: y})\n}\ncnv.show()\n```\n\nPour un aperçu, voir :\n\n- <https://www.npmjs.com/package/pythonic>\n\n\n### color-convert: utilitaires de conversion de couleurs\n\nLa bibliothèque `color-convert` est disponible sous le nom de `convert`. Elle fournit des fonctions de haut niveau pratiques pour convertir une spécification de couleur en une autre.\n\n__Exemple :__\n\n```js\nconsole.log('Les valeurs RGB pour le bleu sont ' + convert.keyword.rgb('blue'))\n```\n\nPour un aperçu, voir :\n\n- <https://www.npmjs.com/package/color-convert>\n\n\n### csv-parse: conversion de texte au format CSV en un objet\n\nLa fonction synchronisée `parse()` de la bibliothèque `csv-parse` est disponible. Cela vous permet de parser un texte au format CSV, par exemple à partir d'un fichier CSV dans le pool de fichiers, en un objet.\n\n__Exemple :__\n\n```js\nconst conditions = csvParse(\n    pool['attentional-capture-jobs.csv'].data,\n    {columns: true}\n)\nfor (const trial of conditions) {\n    console.log(trial.distractor)\n}\n```\n\nPour un aperçu, voir :\n\n- <https://csv.js.org/parse/api/sync/#sync-api>\n\n\n## Débogage\n\nLa plupart des navigateurs modernes, en particulier Chrome et Firefox, disposent d'un débogueur intégré puissant. Vous pouvez activer le débogueur en ajoutant une ligne qui indique simplement `debugger` à votre script (%FigDebuggerInlineJavaScript).\n\n<notranslate>\nfigure:\n id: FigDebuggerInlineJavaScript\n source: debugger-inline-javascript.png\n caption: Activation du débogueur à partir d'un élément INLINE_JAVASCRIPT.\n</notranslate>\n\n\nEnsuite, démarrez l'expérience et affichez le débogueur (ou : Outils de développement dans Chrome, ou : Outils de développement Web dans Firefox) dès que l'écran d'accueil OSWeb apparaît. Le débogueur mettra alors l'expérience en pause lorsqu'il rencontrera l'instruction `debugger`. À ce stade, vous pouvez utiliser la console pour interagir avec l'espace de travail JavaScript, ou vous pouvez inspecter les variables à l'aide de l'outil Scope (%FigDebuggerChrome)."
  },
  "<notranslate>\nfigure:\n id: FigDebuggerChrome\n source: debugger-chrome.png\n caption: Inspecting the variable scope in Chrome.\n</notranslate>\n\nSee also:\n\n- %link:manual/osweb/osweb%\n": {
    "fr": "<notranslate>\nfigure:\n id: FigDebuggerChrome\n source: debugger-chrome.png\n caption: Inspecter la portée des variables dans Chrome.\n</notranslate>\n\nVoir aussi :\n\n- %link:manuel/osweb/osweb%"
  },
  "<notranslate>[TOC]</notranslate>\n\n\nThe following functions are available in INLINE_JAVASCRIPT items:\n\n<div class=\"cogsci-jsdoc\" markdown=\"1\">\n\n<notranslate> include: include/javascript-api/javascript_workspace_api.md --%\n\n</div>\n": {
    "fr": "<notranslate>[TOC]</notranslate>\n\nLes fonctions suivantes sont disponibles dans les éléments INLINE_JAVASCRIPT :\n\n<div class=\"cogsci-jsdoc\" markdown=\"1\">\n\n<notranslate> include: include/javascript-api/javascript_workspace_api.md --%\n\n</div>"
  },
  "Advanced_delay": {
    "fr": "Advanced_delay"
  },
  "The `advanced_delay` plug-in delays the experiment for a pre-specified average duration plus a random margin.\n\n- *Duration* is the average duration of the delay in milliseconds.\n- *Jitter* is the size of the variation in the delay in milliseconds.\n- *Jitter mode* is the how the jitter is calculated:\n\t- *Standard deviation* will draw the variation from a Gaussian distribution with Jitter as the standard deviation.\n\t- *Uniform* will draw the variation in duration from a uniform distribution.\n": {
    "fr": "Le plug-in `advanced_delay` retarde l'expérience pendant une durée moyenne pré-spécifiée plus une marge aléatoire.\n\n- *Durée* est la durée moyenne du retard en millisecondes.\n- *Jitter* est la taille de la variation du retard en millisecondes.\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n- *Mode Jitter* est la façon dont le jitter est calculé :\n\t- *Écart type* prélèvera la variation à partir d'une distribution gaussienne avec Jitter comme écart type.\n\t- *Uniforme* prélèvera la variation de durée à partir d'une distribution uniforme."
  },
  "Reset_feedback": {
    "fr": "Réinitialiser_retour"
  },
  "This plug-in has the same effect as presenting a FEEDBACK item with a duration of 0 ms\n{: .page-notification}\n\nIf you do not reset feedback variables, you may confound your feedback with responses that are not relevant to the task. For example, the key presses made during the instruction phase may affect the feedback during the first block of the experiment. Therefore, you will need to reset the feedback variables at appropriate moments.\n\nThis plug-in will reset the following variables to 0:\n\n- `total_response_time`\n- `total_response`\n- `acc`\n- `accuracy`\n- `avg_rt`\n- `average_response_time`\n": {
    "fr": "Ce plug-in a le même effet que de présenter un élément FEEDBACK avec une durée de 0 ms\n{: .page-notification}\n\nSi vous ne réinitialisez pas les variables de feedback, vous pouvez mélanger votre feedback avec des réponses qui ne sont pas pertinentes pour la tâche. Par exemple, les pressions de touches effectuées pendant la phase d'instruction peuvent affecter le feedback pendant le premier bloc de l'expérience. Par conséquent, vous devrez réinitialiser les variables de feedback aux moments appropriés.\n\nCe plug-in réinitialisera les variables suivantes à 0 :\n\n- `total_response_time`\n- `total_response`\n- `acc`\n- `accuracy`\n- `avg_rt`\n- `average_response_time`"
  },
  "Video tutorials": {
    "fr": "Tutoriels vidéo"
  },
  "<notranslate>[TOC]</notranslate>\n\n## OpenSesame 3.2: creating a visual-search experiment\n\n<notranslate>\nvideo:\n source: youtube\n id: VisualSearch32\n videoid: K2dcG_7Hs3Y\n width: 640\n height: 360\n caption: |\n  An intermediate-level tutorial for OpenSesame 3.2.\n</notranslate>\n\n\n## OpenSesame 3.1 step-by-step tutorial\n\nThe video below walks through the [step-by-step tutorial](/tutorials/step-by-step-tutorial/).\n\n<notranslate>\nvideo:\n source: youtube\n id: BeginnerTutorial31\n videoid: FCXcnAv9aMA\n width: 640\n height: 360\n caption: |\n  The step-by-step tutorial in video form.\n</notranslate>\n\n\n## OpenSesame 3.1 tutorial: Creating a visual-search experiment\n\n<notranslate>\nvideo:\n source: youtube\n id: VidTutorial31\n videoid: zXStoHomIJE\n width: 640\n height: 360\n caption: |\n  A shorter, slightly more advanced tutorial showing how to implement a visual-search experiment.\n</notranslate>\n\n\n## Tutorials for older versions of OpenSesame\n\n### OpenSesame 3.0 step-by-step tutorial\n\nThe video below walks through the [step-by-step tutorial](/tutorials/step-by-step-tutorial/).\n\n<notranslate>\nvideo:\n source: youtube\n id: VidTutorial30\n videoid: eiGXe-t-C28\n width: 640\n height: 360\n caption: |\n  The step-by-step tutorial in video form.\n</notranslate>\n\n### Creating a cat-faces experiment\n\nThe video below introduces the basic functionality of OpenSesame by providing a step-by-step walk-through for creating a 'cat-faces' experiment. In this experiment, the participant's task is to judge whether a (picture of a) cat is male or female. Quite tricky (the task, that is, creating the experiment is easy), but apparently people can do it after some training.\n\n- Duration: 43 minutes\n- OpenSesame version: 0.27.2\n\n<notranslate>\nvideo:\n source: youtube\n id: VidScreencast\n videoid: -zMH65re1m0\n width: 640\n height: 360\n caption: |\n  Video tutorial by <a href=\"http://chrislongmore.co.uk/\">Chris Longmore</a>.\n</notranslate>\n\n### Implementing counterbalancing\n\nThe video below shows how you can implement counterbalancing in OpenSesame.\n\n- Duration: 26 minutes\n- OpenSesame version: 0.27.2\n\n<notranslate>\nvideo:\n source: youtube\n id: VidCounterbalancing\n videoid: zP8ucRtWU5g\n width: 640\n height: 360\n caption: |\n  Video tutorial by <a href=\"http://chrislongmore.co.uk/\">Chris Longmore</a>.\n</notranslate>\n\n### Creating an affordances/ orientation experiment\n\nThe video below shows how to create a typical 'affordances/ orientation effect;-type experiment in OpenSesame in slightly over 5 minutes.\n\n- Duration: 8 minutes\n- OpenSesame version: 0.23\n\n<notranslate>\nvideo:\n source: youtube\n id: VidScreencastOld\n videoid: Liq9WCtN0Zk\n width: 640\n height: 360\n caption: |\n  Creating an affordances/ orientation experiment.\n</notranslate>\n\n\n## Python tutorials\n\n### Using Python inline script in OpenSesame 3.0\n\n<notranslate>\nvideo:\n source: youtube\n id: VidTutorial30\n videoid: sEjQlYCmY_w\n width: 640\n height: 360\n caption: |\n  A screencast that the demonstrates the basics of using Python inline script in OpenSesame.\n</notranslate>\n\n### 7 simple tricks to write better Python\n\n<notranslate>\nvideo:\n source: youtube\n id: Vid7Tricks\n videoid: VBokjWj_cEA\n width: 640\n height: 360\n caption: |\n  7 simple tricks to write better Python.\n</notranslate>\n\n### 7 more tricks to write better Python\n\n<notranslate>\nvideo:\n source: youtube\n id: Vid7MoreTricks\n videoid: SNTZpy0oDB8\n width: 640\n height: 360\n caption: |\n  7 more tricks to write better Python.\n</notranslate>\n\n### A simple explanation of function arguments and keywords\n\n<notranslate>\nvideo:\n source: youtube\n id: VidArguments\n videoid: CfI4cR66jQY\n width: 640\n height: 360\n caption: |\n  A simple explanation of function arguments and keywords.\n</notranslate>\n\n### List slicing and list comprehensions\n\n<notranslate>\nvideo:\n source: youtube\n id: VidListSlicing\n videoid: HobjHIpLhZk\n width: 640\n height: 360\n caption: |\n  Using lists effectively in Python.\n</notranslate>\n\n### Using lists effectively": {
    "fr": "[TOC]\n\n## OpenSesame 3.2 : créer une expérience de recherche visuelle\n\n## Tutoriel pas-à-pas OpenSesame 3.1\n\nLa vidéo ci-dessous présente le [tutoriel pas-à-pas](/tutorials/step-by-step-tutorial/).\n\n## OpenSesame 3.1 tutoriel : Création d'une expérience de recherche visuelle\n\n## Tutoriels pour les versions antérieures d'OpenSesame\n\n### Tutoriel pas-à-pas OpenSesame 3.0\n\nLa vidéo ci-dessous présente le [tutoriel pas-à-pas](/tutorials/step-by-step-tutorial/).\n\n### Créer une expérience de visages de chats\n\nLa vidéo ci-dessous présente l'utilisation des fonctions de base d'OpenSesame en montrant comment créer une expérience de \"visages de chats\". Dans cette expérience, la tâche du participant est de juger si un (photo de) chat est mâle ou femelle. C'est assez complexe (la tâche, je veux dire, créer l'expérience est facile), mais apparemment les gens y arrivent après un certain entraînement.\n\n- Durée : 43 minutes\n- Version OpenSesame : 0.27.2\n\n### Mise en œuvre de la contrebalancement\n\nLa vidéo ci-dessous montre comment mettre en œuvre le contrebalancement dans OpenSesame.\n\n- Durée : 26 minutes\n- Version OpenSesame : 0.27.2\n\n### Création d'une expérience sur les affordances / l'orientation\n\nLa vidéo ci-dessous montre comment créer une expérience typique de \"affordances / orientation effect\" dans OpenSesame en un peu plus de 5 minutes.\n\n- Durée : 8 minutes\n- Version OpenSesame : 0.23\n\n## Tutoriels Python\n\n### Utiliser le script Python en ligne dans OpenSesame 3.0\n\n### 7 astuces simples pour écrire un meilleur Python\n\n### 7 astuces supplémentaires pour écrire un meilleur Python\n\n### Une explication simple des arguments et des mots-clés de fonction\n\n### Tranchage de liste et compréhensions de liste\n\n### Utilisation efficace des listes"
  },
  "<notranslate>\nvideo:\n source: youtube\n id: VidUsingLists\n videoid: S55yOHvUyGk\n width: 640\n height: 360\n caption: |\n  Using lists effectively in Python.\n</notranslate>\n\n### Different ways to use objects and attributes\n\n<notranslate>\nvideo:\n source: youtube\n id: VidObjectsAttributes\n videoid: EBlOpvOAbxc\n width: 640\n height: 360\n caption: |\n  Different ways to use objects and attributes.\n</notranslate>\n\n[chris-longmore]: http://www.chrislongmore.co.uk/\n[tutorial]: /tutorials/step-by-step-tutorial\n[cat-faces-photos]: http://www.chrislongmore.co.uk/screencasts/supporting_material/catfacephotos.zip\n[cat-faces-experiment]: http://www.chrislongmore.co.uk/screencasts/supporting_material/cats.opensesame.tar.gz\n": {
    "fr": "<notranslate>\nvideo:\n source: youtube\n id: VidUsingLists\n videoid: S55yOHvUyGk\n width: 640\n height: 360\n caption: |\n  Utiliser efficacement les listes en Python.\n</notranslate>\n\n### Différentes façons d'utiliser les objets et les attributs\n\n<notranslate>\nvideo:\n source: youtube\n id: VidObjectsAttributes\n videoid: EBlOpvOAbxc\n width: 640\n height: 360\n caption: |\n  Différentes façons d'utiliser les objets et les attributs.\n</notranslate>\n\n[chris-longmore]: http://www.chrislongmore.co.uk/\n[tutorial]: /tutorials/step-by-step-tutorial\n[cat-faces-photos]: http://www.chrislongmore.co.uk/screencasts/supporting_material/catfacephotos.zip\n[cat-faces-experiment]: http://www.chrislongmore.co.uk/screencasts/supporting_material/cats.opensesame.tar.gz"
  }
}